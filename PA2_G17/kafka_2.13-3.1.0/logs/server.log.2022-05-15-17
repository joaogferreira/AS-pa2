[2022-05-15 17:09:50,712] INFO [GroupMetadataManager brokerId=3] Group consumer-group transitioned to Dead in generation 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:09:50,719] INFO [GroupCoordinator 3]: Removed 6 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:09:50,741] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:09:50,742] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:09:50,750] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:09:50,752] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:09:50,756] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1940 due to node 1 being disconnected (elapsed time since creation: 280ms, elapsed time since send: 280ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:09:50,757] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=1515852142, epoch=1940) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:09:50,762] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:09:50,764] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:09:50,770] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:09:50,770] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:09:50,771] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1829 due to node 4 being disconnected (elapsed time since creation: 371ms, elapsed time since send: 371ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:09:50,771] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=659819897, epoch=1829) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:09:50,772] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:09:50,772] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:09:50,775] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:09:50,776] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:09:50,801] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-3/Sensor-5.d4181b42a7ae481fbd36fea36b45a07c-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:09:50,806] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-3/Sensor-2.d929bc0fe4ab4a328710d32d1183d319-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:09:50,811] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-3/Sensor-0.880b984f7916428b9a6ecd12864a57ef-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:09:54,083] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:09:54,087] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:09:54,090] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:09:54,118] INFO [KafkaServer id=3] Controlled shutdown request returned successfully after 21ms (kafka.server.KafkaServer)
[2022-05-15 17:09:54,123] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:09:54,123] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:09:54,124] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:09:54,127] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:09:54,152] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:09:54,154] INFO [data-plane Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:09:54,161] INFO [data-plane Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:09:54,166] INFO [ExpirationReaper-3-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:54,343] INFO [ExpirationReaper-3-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:54,343] INFO [ExpirationReaper-3-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:54,345] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:09:54,347] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:54,449] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:54,449] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:54,452] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:09:54,454] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:09:54,454] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:09:54,455] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:09:54,455] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:09:54,457] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:09:54,458] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:09:54,459] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:54,649] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:54,649] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:54,650] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:54,841] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:54,841] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:54,843] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:09:54,845] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:09:54,846] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:09:54,846] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:09:54,846] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:09:54,848] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:09:54,851] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:09:54,851] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:09:54,852] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:09:54,852] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:55,047] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:55,047] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:55,048] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:55,070] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:55,070] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:55,071] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:55,261] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:55,261] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:55,262] INFO [ExpirationReaper-3-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:55,282] INFO [ExpirationReaper-3-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:55,282] INFO [ExpirationReaper-3-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:09:55,287] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:09:55,287] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:09:55,287] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:09:55,287] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:09:55,290] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:09:55,291] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:09:55,291] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:09:55,291] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:09:55,292] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:09:55,294] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:09:55,320] INFO [ProducerStateManager partition=__consumer_offsets-38] Wrote producer snapshot at offset 28503 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-05-15 17:09:55,336] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:09:55,347] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:09:55,347] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:09:55,347] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:09:55,348] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:09:55,455] INFO Session: 0x100000b00ad001b closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:09:55,455] INFO EventThread shut down for session: 0x100000b00ad001b (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:09:55,457] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:09:55,458] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:09:55,667] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:09:55,667] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:09:55,668] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:09:56,668] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:09:56,668] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:09:56,668] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:09:56,675] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:09:56,675] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:09:56,675] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:09:57,675] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:09:57,675] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:09:57,678] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:09:57,709] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:09:57,710] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:09:57,710] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:09:57,710] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:09:57,712] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:09:57,713] INFO App info kafka.server for 3 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:09:57,713] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:17:02,491] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:17:02,497] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:17:02,497] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:17:02,497] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:17:02,498] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:17:02,499] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 17:17:02,500] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 17:17:02,500] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 17:17:02,500] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-15 17:17:02,503] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-15 17:17:02,517] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:17:02,517] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:17:02,517] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:17:02,517] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:17:02,517] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:17:02,518] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-15 17:17:02,530] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@6156496 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-15 17:17:02,533] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 17:17:02,544] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,544] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,544] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,544] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,544] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,544] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,545] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,545] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,545] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,545] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,546] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,546] INFO Server environment:host.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,546] INFO Server environment:java.version=11.0.15 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,546] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,546] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,546] INFO Server environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,547] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,547] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,547] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,547] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,547] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,547] INFO Server environment:os.version=5.13.0-40-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,547] INFO Server environment:user.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,547] INFO Server environment:user.home=/home/joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,547] INFO Server environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,547] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,547] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,547] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,547] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,547] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,548] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,548] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,548] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,548] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,548] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,549] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-15 17:17:02,550] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,550] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,551] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 17:17:02,551] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 17:17:02,552] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:17:02,552] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:17:02,553] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:17:02,553] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:17:02,553] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:17:02,553] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:17:02,555] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,556] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,556] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:17:02,563] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 17:17:02,564] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 17:17:02,566] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 17:17:02,570] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 17:17:02,571] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:459)
	at java.base/sun.nio.ch.Net.bind(Net.java:448)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:676)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:158)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:112)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:67)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:140)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:90)
[2022-05-15 17:17:02,573] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-15 17:17:02,575] ERROR Exiting JVM with code 1 (org.apache.zookeeper.util.ServiceUtils)
[2022-05-15 17:17:07,948] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:17:08,254] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:17:08,345] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:17:08,348] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:17:08,349] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:17:08,365] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:17:08,371] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:08,371] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:08,371] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:08,371] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:08,372] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:08,372] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:08,372] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:08,372] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:08,372] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:08,372] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:08,372] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:08,372] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:08,372] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:08,372] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:08,372] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:08,372] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:08,372] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:08,372] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:08,374] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:08,381] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:17:08,386] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:08,400] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:17:08,404] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:08,405] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:08,408] INFO Socket connection established, initiating session, client: /127.0.0.1:57872, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:08,415] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad001e, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:08,419] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:17:08,493] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:17:08,639] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:17:08,646] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:17:08,696] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:17:08,705] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:17:08,759] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:08,761] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:08,763] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:08,765] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:08,806] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:17:08,812] INFO Skipping recovery for all logs in /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:17:08,895] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:08,922] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-21, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 97ms (1/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:17:08,929] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:08,934] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-3.3ab055093b354b5688c4a458d7e9b677-delete, topicId=8AGAy096RhSQp7wLDCWkxA, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (2/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:17:08,940] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:08,947] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-0.52243c3da86c49f5aab7c6fddbb81423-delete, topicId=8AGAy096RhSQp7wLDCWkxA, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (3/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:17:08,965] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 17940 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:08,966] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 17940 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:08,967] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs/__consumer_offsets-39/00000000000000017940.snapshot,17940)' (kafka.log.ProducerStateManager)
[2022-05-15 17:17:08,974] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Producer state recovery took 8ms for snapshot load and 0ms for segment recovery from offset 17940 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:08,980] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-39, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=17940) with 1 segments in 33ms (4/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:17:08,985] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:08,988] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-15, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:17:08,994] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:08,997] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-45, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (6/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:17:09,002] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:09,006] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-33, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:17:09,012] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:09,016] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-27, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (8/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:17:09,022] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:09,026] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-3, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (9/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:17:09,031] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:09,034] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-9, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (10/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:17:09,038] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:09,040] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-1.2176f61856d24a8eb313d870e0edbfb6-delete, topicId=8AGAy096RhSQp7wLDCWkxA, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (11/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:17:09,043] INFO Loaded 11 logs in 237ms. (kafka.log.LogManager)
[2022-05-15 17:17:09,044] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:17:09,046] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:17:09,313] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:09,446] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:17:09,449] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-15 17:17:09,480] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:17:09,486] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:09,502] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:09,503] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:09,505] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:09,507] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:09,521] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:17:09,580] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:17:09,599] INFO Stat of the created znode at /brokers/ids/0 is: 1421,1421,1652631429592,1652631429592,1,0,0,72057641293905950,192,0,1421
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:17:09,601] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://joao:9092, czxid (broker epoch): 1421 (kafka.zk.KafkaZkClient)
[2022-05-15 17:17:09,664] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:09,671] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:09,672] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:09,690] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:09,710] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:09,743] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:17:09,749] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:17:09,749] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:17:09,782] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:09,806] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:17:09,829] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:17:09,835] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:17:09,836] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:17:09,841] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:17:09,841] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:17:09,841] INFO Kafka startTimeMs: 1652631429836 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:17:09,844] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-15 17:17:09,925] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:09,955] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-3, __consumer_offsets-15, __consumer_offsets-39, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:09,969] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:09,980] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:09,983] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 17940 (kafka.cluster.Partition)
[2022-05-15 17:17:09,986] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:09,989] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:09,990] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:09,992] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:09,995] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:10,000] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:10,015] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:10,017] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:10,021] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:10,021] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:10,021] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:10,021] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:10,021] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:10,021] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:10,021] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:10,022] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:10,022] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:10,022] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:10,022] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:10,022] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:10,022] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:10,022] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:10,030] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 11 milliseconds for epoch 6, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:10,030] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 9 milliseconds for epoch 6, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:10,112] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 91 milliseconds for epoch 6, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:10,113] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 92 milliseconds for epoch 6, of which 92 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:10,113] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 91 milliseconds for epoch 6, of which 91 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:10,114] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 92 milliseconds for epoch 6, of which 91 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:10,114] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 92 milliseconds for epoch 6, of which 92 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:10,114] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 92 milliseconds for epoch 6, of which 92 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:12,404] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:17:12,700] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:17:12,782] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:17:12,785] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:17:12,785] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:17:12,798] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:17:12,802] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:12,802] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:12,802] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:12,802] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:12,802] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:12,802] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:12,803] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:12,803] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:12,803] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:12,803] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:12,803] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:12,803] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:12,804] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:12,804] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:12,804] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:12,804] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:12,804] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:12,804] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:12,806] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:12,812] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:17:12,816] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:12,828] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:17:12,832] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:12,833] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:12,837] INFO Socket connection established, initiating session, client: /127.0.0.1:57874, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:12,845] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad001f, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:12,850] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:17:12,922] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:17:13,054] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:17:13,059] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:17:13,112] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:17:13,120] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:17:13,170] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:13,171] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:13,173] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:13,176] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:13,216] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:17:13,220] INFO Skipping recovery for all logs in /tmp/kafka-logs-1 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:17:13,297] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:13,321] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-17, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 86ms (1/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:17:13,326] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:13,330] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-35, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (2/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:17:13,334] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:13,338] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-3.16b1051125964e3596d4857b45f4136a-delete, topicId=8AGAy096RhSQp7wLDCWkxA, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (3/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:17:13,344] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:13,347] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-4.67c08d6d894547509c49a4878e414511-delete, topicId=8AGAy096RhSQp7wLDCWkxA, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (4/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:17:13,352] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:13,356] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-41, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:17:13,360] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:13,364] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-0.af9dd6cd561645dea756319225e63f54-delete, topicId=8AGAy096RhSQp7wLDCWkxA, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (6/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:17:13,372] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:13,376] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-29, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (7/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:17:13,381] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:13,383] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-11, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:17:13,389] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:13,391] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-23, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:17:13,395] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:13,398] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-47, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:17:13,402] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:13,406] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-5, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:17:13,410] INFO Loaded 11 logs in 194ms. (kafka.log.LogManager)
[2022-05-15 17:17:13,411] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:17:13,412] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:17:13,665] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:13,809] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:17:13,812] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-15 17:17:13,842] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:17:13,849] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:13,866] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:13,868] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:13,870] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:13,871] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:13,885] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:17:13,945] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:17:13,962] INFO Stat of the created znode at /brokers/ids/1 is: 1481,1481,1652631433955,1652631433955,1,0,0,72057641293905951,192,0,1481
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:17:13,963] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://joao:9093, czxid (broker epoch): 1481 (kafka.zk.KafkaZkClient)
[2022-05-15 17:17:14,037] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:14,046] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:14,047] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:14,063] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:14,076] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:14,101] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:17:14,106] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:17:14,106] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:17:14,129] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:14,147] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:17:14,165] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:17:14,170] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:17:14,171] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:17:14,177] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:17:14,178] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:17:14,178] INFO Kafka startTimeMs: 1652631434171 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:17:14,180] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-15 17:17:14,253] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:14,278] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:14,283] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:14,283] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:14,284] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:14,285] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:14,285] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:14,286] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:14,287] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:14,287] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:14,314] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-5, __consumer_offsets-29, __consumer_offsets-41, __consumer_offsets-23) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:14,343] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:14,345] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:14,346] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:14,346] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:14,346] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:14,347] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:14,347] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:14,347] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:14,347] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:14,347] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:14,347] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:14,347] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:14,347] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:14,347] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:14,347] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:14,347] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:14,354] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 8 milliseconds for epoch 13, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:14,355] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 9 milliseconds for epoch 13, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:14,356] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 9 milliseconds for epoch 13, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:14,356] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 9 milliseconds for epoch 13, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:14,357] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 10 milliseconds for epoch 13, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:14,357] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 10 milliseconds for epoch 13, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:14,357] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 10 milliseconds for epoch 13, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:14,358] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 11 milliseconds for epoch 13, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:17,532] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:17:17,794] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:17:17,880] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:17:17,883] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:17:17,883] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:17:17,897] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:17:17,901] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:17,902] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:17,902] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:17,902] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:17,902] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:17,902] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:17,902] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:17,903] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:17,903] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:17,903] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:17,903] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:17,903] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:17,903] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:17,903] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:17,903] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:17,903] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:17,903] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:17,903] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:17,907] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:17,920] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:17:17,924] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:17,929] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:17:17,933] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:17,934] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:17,941] INFO Socket connection established, initiating session, client: /127.0.0.1:57876, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:17,948] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0020, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:17,951] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:17:18,023] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:17:18,159] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:17:18,164] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:17:18,215] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:17:18,223] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:17:18,270] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:18,271] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:18,273] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:18,274] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:18,310] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:17:18,314] INFO Skipping recovery for all logs in /tmp/kafka-logs-2 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:17:18,376] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:18,396] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-1.ce03e343d40f4ece8979d0e5b06abf87-delete, topicId=8AGAy096RhSQp7wLDCWkxA, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 66ms (1/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:17:18,412] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:18,415] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-49, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 18ms (2/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:17:18,422] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:18,426] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-19, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (3/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:17:18,430] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:18,433] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-7, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (4/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:17:18,438] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:18,441] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-13, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:17:18,445] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:18,448] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-37, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (6/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:17:18,451] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:18,455] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-43, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:17:18,459] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:18,462] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-1, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:17:18,468] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:18,473] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-5.64a60e0928544ea4b168effb37a60e37-delete, topicId=8AGAy096RhSQp7wLDCWkxA, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (9/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:17:18,478] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:18,481] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-4.a720b63a2e78468faf66cbc42c28f60f-delete, topicId=8AGAy096RhSQp7wLDCWkxA, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (10/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:17:18,486] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:18,489] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-31, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (11/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:17:18,494] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:18,496] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-25, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (12/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:17:18,499] INFO Loaded 12 logs in 189ms. (kafka.log.LogManager)
[2022-05-15 17:17:18,500] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:17:18,501] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:17:18,754] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:18,884] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:17:18,889] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-15 17:17:18,915] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:17:18,922] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:18,941] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:18,942] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:18,943] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:18,945] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:18,957] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:17:19,017] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:17:19,037] INFO Stat of the created znode at /brokers/ids/2 is: 1505,1505,1652631439030,1652631439030,1,0,0,72057641293905952,192,0,1505
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:17:19,039] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://joao:9094, czxid (broker epoch): 1505 (kafka.zk.KafkaZkClient)
[2022-05-15 17:17:19,109] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:19,115] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:19,116] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:19,132] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:19,144] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:19,170] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:17:19,174] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:17:19,174] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:17:19,198] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:19,221] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:17:19,240] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:17:19,245] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:17:19,245] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:17:19,249] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:17:19,249] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:17:19,249] INFO Kafka startTimeMs: 1652631439245 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:17:19,251] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-15 17:17:19,327] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:19,349] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:19,349] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:19,350] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:19,350] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:19,350] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:19,351] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:19,351] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:19,352] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:19,353] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:19,365] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:19,379] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-7, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:19,420] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:19,422] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:19,424] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:19,424] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:19,424] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:19,424] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:19,424] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:19,424] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:19,425] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:19,425] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:19,425] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:19,425] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:19,425] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:19,425] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:19,426] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:19,426] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:19,426] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 14 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:19,426] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 14 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:19,432] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 8 milliseconds for epoch 14, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:19,432] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 8 milliseconds for epoch 14, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:19,433] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 9 milliseconds for epoch 14, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:19,433] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 8 milliseconds for epoch 14, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:19,434] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 9 milliseconds for epoch 14, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:19,434] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 9 milliseconds for epoch 14, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:19,434] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 9 milliseconds for epoch 14, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:19,435] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 9 milliseconds for epoch 14, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:19,435] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 9 milliseconds for epoch 14, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:22,613] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:17:22,865] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:17:22,943] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:17:22,947] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:17:22,948] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:17:22,962] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:17:22,967] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:22,967] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:22,967] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:22,967] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:22,967] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:22,967] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:22,967] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:22,967] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:22,967] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:22,967] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:22,967] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:22,967] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:22,967] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:22,968] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:22,968] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:22,968] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:22,968] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:22,968] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:22,969] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:22,974] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:17:22,978] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:22,990] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:17:22,995] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:22,996] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:23,000] INFO Socket connection established, initiating session, client: /127.0.0.1:57880, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:23,007] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0021, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:23,011] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:17:23,081] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:17:23,204] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:17:23,210] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:17:23,264] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:17:23,273] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:17:23,322] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:23,323] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:23,325] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:23,326] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:23,368] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:17:23,373] INFO Skipping recovery for all logs in /tmp/kafka-logs-3 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:17:23,445] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:23,469] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-14, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 80ms (1/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:17:23,483] INFO Deleted producer state snapshot /tmp/kafka-logs-3/__consumer_offsets-38/00000000000000021911.snapshot (kafka.log.SnapshotFile)
[2022-05-15 17:17:23,486] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Loading producer state till offset 28503 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:23,487] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Reloading from producer snapshot and rebuilding producer state from offset 28503 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:23,488] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-3/__consumer_offsets-38/00000000000000028503.snapshot,28503)' (kafka.log.ProducerStateManager)
[2022-05-15 17:17:23,494] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 28503 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:23,498] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-38, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=28503) with 1 segments in 29ms (2/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:17:23,503] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:23,507] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-8, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (3/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:17:23,512] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:23,515] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-2, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:17:23,521] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:23,524] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-0.880b984f7916428b9a6ecd12864a57ef-delete, topicId=8AGAy096RhSQp7wLDCWkxA, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (5/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:17:23,529] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:23,531] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-26, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (6/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:17:23,536] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:23,541] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-20, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (7/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:17:23,546] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:23,551] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-32, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (8/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:17:23,557] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:23,560] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-2.d929bc0fe4ab4a328710d32d1183d319-delete, topicId=8AGAy096RhSQp7wLDCWkxA, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:17:23,566] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:23,570] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-5.d4181b42a7ae481fbd36fea36b45a07c-delete, topicId=8AGAy096RhSQp7wLDCWkxA, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (10/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:17:23,575] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:23,579] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-44, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (11/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:17:23,582] INFO Loaded 11 logs in 213ms. (kafka.log.LogManager)
[2022-05-15 17:17:23,582] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:17:23,584] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:17:23,815] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:23,940] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:17:23,944] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-05-15 17:17:23,969] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:17:23,974] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:23,990] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:23,992] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:23,994] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:23,996] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:24,007] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:17:24,071] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:17:24,089] INFO Stat of the created znode at /brokers/ids/3 is: 1530,1530,1652631444079,1652631444079,1,0,0,72057641293905953,192,0,1530
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:17:24,089] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://joao:9095, czxid (broker epoch): 1530 (kafka.zk.KafkaZkClient)
[2022-05-15 17:17:24,154] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:24,159] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:24,161] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:24,174] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:24,197] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:24,212] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:17:24,217] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:17:24,217] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:17:24,242] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:24,260] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:17:24,279] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:17:24,284] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:17:24,285] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:17:24,291] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:17:24,292] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:17:24,292] INFO Kafka startTimeMs: 1652631444286 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:17:24,293] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-05-15 17:17:24,379] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:24,396] INFO [Partition __consumer_offsets-2 broker=3] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:24,396] INFO [Partition __consumer_offsets-20 broker=3] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:24,397] INFO [Partition __consumer_offsets-38 broker=3] Log loaded for partition __consumer_offsets-38 with initial high watermark 28503 (kafka.cluster.Partition)
[2022-05-15 17:17:24,397] INFO [Partition __consumer_offsets-8 broker=3] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:24,397] INFO [Partition __consumer_offsets-26 broker=3] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:24,398] INFO [Partition __consumer_offsets-44 broker=3] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:24,398] INFO [Partition __consumer_offsets-14 broker=3] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:24,398] INFO [Partition __consumer_offsets-32 broker=3] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:24,425] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-26, __consumer_offsets-32, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:24,427] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:24,456] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 2 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:24,458] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:24,459] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 20 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:24,459] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:24,460] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 38 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:24,460] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:24,460] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 8 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:24,460] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:24,460] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 26 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:24,460] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:24,460] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 44 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:24,460] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:24,460] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 14 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:24,460] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:24,460] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 32 in epoch 15 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:24,460] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 15 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:24,467] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-2 in 8 milliseconds for epoch 15, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:24,467] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-20 in 8 milliseconds for epoch 15, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:24,557] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-38 in 97 milliseconds for epoch 15, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:24,558] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-8 in 98 milliseconds for epoch 15, of which 98 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:24,558] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-26 in 98 milliseconds for epoch 15, of which 98 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:24,559] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-44 in 99 milliseconds for epoch 15, of which 98 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:24,559] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-14 in 99 milliseconds for epoch 15, of which 99 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:24,559] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-32 in 99 milliseconds for epoch 15, of which 99 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:27,513] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:17:27,777] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:17:27,861] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:17:27,866] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:17:27,867] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:17:27,883] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:17:27,887] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:27,887] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:27,887] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:27,887] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:27,887] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:27,887] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:27,888] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:27,888] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:27,888] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:27,888] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:27,888] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:27,888] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:27,888] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:27,888] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:27,888] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:27,888] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:27,888] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:27,888] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:27,891] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:27,895] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:17:27,900] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:27,912] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:17:27,920] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:27,921] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:27,924] INFO Socket connection established, initiating session, client: /127.0.0.1:57882, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:27,932] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0022, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:27,936] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:17:28,010] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:17:28,147] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:17:28,154] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:17:28,200] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:17:28,209] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:17:28,255] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:28,257] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:28,258] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:28,260] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:28,299] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:17:28,303] INFO Skipping recovery for all logs in /tmp/kafka-logs-4 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:17:28,380] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:28,405] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-24, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 83ms (1/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:17:28,411] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:28,416] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-5.3bd3cfee391a4e569b87d45ab8d3e20f-delete, topicId=8AGAy096RhSQp7wLDCWkxA, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (2/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:17:28,421] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:28,425] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-3.5fc74ce81c4f41b2b0fb99903dd12cf2-delete, topicId=8AGAy096RhSQp7wLDCWkxA, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (3/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:17:28,430] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:28,435] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-12, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (4/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:17:28,440] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:28,443] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-30, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:17:28,449] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:28,453] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-36, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (6/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:17:28,456] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:28,459] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-42, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (7/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:17:28,463] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:28,466] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-0, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:17:28,472] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:28,475] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-18, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (9/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:17:28,479] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:28,483] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-2.382e4fb330d248bf8af1de0ff9acd30e-delete, topicId=8AGAy096RhSQp7wLDCWkxA, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (10/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:17:28,487] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:28,490] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-6, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:17:28,497] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:28,500] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-48, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (12/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:17:28,502] INFO Loaded 12 logs in 203ms. (kafka.log.LogManager)
[2022-05-15 17:17:28,503] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:17:28,505] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:17:28,744] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:28,876] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:17:28,879] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.Acceptor)
[2022-05-15 17:17:28,908] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:17:28,914] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:28,931] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:28,932] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:28,934] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:28,935] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:28,947] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:17:29,007] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:17:29,027] INFO Stat of the created znode at /brokers/ids/4 is: 1554,1554,1652631449019,1652631449019,1,0,0,72057641293905954,192,0,1554
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:17:29,029] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://joao:9096, czxid (broker epoch): 1554 (kafka.zk.KafkaZkClient)
[2022-05-15 17:17:29,099] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:29,104] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:29,105] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:29,122] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:29,134] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:29,153] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:17:29,157] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:17:29,157] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:17:29,191] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:29,207] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:17:29,227] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:17:29,233] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:17:29,233] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:17:29,239] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:17:29,239] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:17:29,239] INFO Kafka startTimeMs: 1652631449234 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:17:29,241] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2022-05-15 17:17:29,319] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:29,344] INFO [Partition __consumer_offsets-18 broker=4] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:29,344] INFO [Partition __consumer_offsets-36 broker=4] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:29,345] INFO [Partition __consumer_offsets-6 broker=4] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:29,345] INFO [Partition __consumer_offsets-24 broker=4] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:29,346] INFO [Partition __consumer_offsets-42 broker=4] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:29,346] INFO [Partition __consumer_offsets-12 broker=4] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:29,347] INFO [Partition __consumer_offsets-30 broker=4] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:29,347] INFO [Partition __consumer_offsets-0 broker=4] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:29,347] INFO [Partition __consumer_offsets-48 broker=4] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:29,357] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:29,375] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-12, __consumer_offsets-42, __consumer_offsets-18) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:29,409] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 18 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:29,411] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:29,412] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 36 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:29,413] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:29,413] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 6 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:29,413] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:29,413] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 24 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:29,413] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:29,413] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 42 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:29,413] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:29,413] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 12 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:29,413] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:29,413] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 30 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:29,413] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:29,413] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 0 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:29,413] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:29,413] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 48 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:29,413] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:29,420] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-18 in 8 milliseconds for epoch 13, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:29,421] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-36 in 8 milliseconds for epoch 13, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:29,421] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-6 in 8 milliseconds for epoch 13, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:29,421] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-24 in 8 milliseconds for epoch 13, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:29,421] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-42 in 8 milliseconds for epoch 13, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:29,421] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-12 in 8 milliseconds for epoch 13, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:29,422] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-30 in 9 milliseconds for epoch 13, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:29,422] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-0 in 9 milliseconds for epoch 13, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:29,422] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-48 in 9 milliseconds for epoch 13, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:32,505] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:17:32,776] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:17:32,860] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:17:32,864] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:17:32,865] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:17:32,879] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:17:32,885] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:32,885] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:32,885] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:32,885] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:32,885] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:32,885] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:32,886] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:32,886] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:32,886] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:32,886] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:32,886] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:32,886] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:32,886] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:32,886] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:32,886] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:32,886] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:32,886] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:32,886] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:32,888] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:17:32,892] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:17:32,897] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:32,908] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:17:32,913] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:32,914] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:32,917] INFO Socket connection established, initiating session, client: /127.0.0.1:57884, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:32,925] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0023, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:17:32,930] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:17:33,000] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:17:33,133] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:17:33,138] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:17:33,186] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:17:33,194] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:17:33,243] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:33,245] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:33,247] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:33,249] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:17:33,286] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:17:33,289] INFO Skipping recovery for all logs in /tmp/kafka-logs-5 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:17:33,368] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:33,396] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-46, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 92ms (1/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:17:33,402] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:33,408] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-10, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (2/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:17:33,414] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:33,420] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-28, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (3/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:17:33,426] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:33,431] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-4.9157d6de0f0045e2b693d079dfdfeb4f-delete, topicId=8AGAy096RhSQp7wLDCWkxA, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (4/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:17:33,450] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Loading producer state till offset 58 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:33,450] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 58 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:33,452] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-22/00000000000000000058.snapshot,58)' (kafka.log.ProducerStateManager)
[2022-05-15 17:17:33,458] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 58 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:33,464] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-22, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=58) with 1 segments in 31ms (5/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:17:33,468] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:33,473] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-16, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:17:33,477] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:33,483] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-1.810a4ab6abb045628a7235f4d4156743-delete, topicId=8AGAy096RhSQp7wLDCWkxA, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (7/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:17:33,488] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:33,491] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-2.8fdc15ede52d4fa3b557ceb6accfda2f-delete, topicId=8AGAy096RhSQp7wLDCWkxA, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:17:33,500] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Loading producer state till offset 18252 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:33,501] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 18252 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:33,501] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-40/00000000000000018252.snapshot,18252)' (kafka.log.ProducerStateManager)
[2022-05-15 17:17:33,501] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 18252 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:33,505] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-40, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=18252) with 1 segments in 14ms (9/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:17:33,511] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:33,516] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-34, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (10/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:17:33,521] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:33,525] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-4, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (11/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:17:33,528] INFO Loaded 11 logs in 242ms. (kafka.log.LogManager)
[2022-05-15 17:17:33,529] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:17:33,531] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:17:33,808] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:33,955] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:17:33,959] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.Acceptor)
[2022-05-15 17:17:33,988] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:17:33,996] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:34,013] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:34,014] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:34,016] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:34,017] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:34,031] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:17:34,101] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:17:34,122] INFO Stat of the created znode at /brokers/ids/5 is: 1579,1579,1652631454114,1652631454114,1,0,0,72057641293905955,192,0,1579
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:17:34,124] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://joao:9097, czxid (broker epoch): 1579 (kafka.zk.KafkaZkClient)
[2022-05-15 17:17:34,198] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:34,205] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:34,207] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:34,223] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:34,237] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:34,264] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:17:34,268] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:17:34,268] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:17:34,294] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:17:34,319] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:17:34,339] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:17:34,343] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:17:34,344] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:17:34,349] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:17:34,349] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:17:34,349] INFO Kafka startTimeMs: 1652631454344 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:17:34,352] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2022-05-15 17:17:34,422] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:34,455] INFO [Partition __consumer_offsets-34 broker=5] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:34,456] INFO [Partition __consumer_offsets-4 broker=5] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:34,456] INFO [Partition __consumer_offsets-22 broker=5] Log loaded for partition __consumer_offsets-22 with initial high watermark 58 (kafka.cluster.Partition)
[2022-05-15 17:17:34,456] INFO [Partition __consumer_offsets-40 broker=5] Log loaded for partition __consumer_offsets-40 with initial high watermark 18252 (kafka.cluster.Partition)
[2022-05-15 17:17:34,456] INFO [Partition __consumer_offsets-10 broker=5] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:34,457] INFO [Partition __consumer_offsets-28 broker=5] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:34,457] INFO [Partition __consumer_offsets-46 broker=5] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:34,458] INFO [Partition __consumer_offsets-16 broker=5] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:34,491] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:34,500] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:17:34,529] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 34 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:34,530] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:34,533] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 4 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:34,533] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:34,533] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 22 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:34,533] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:34,533] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 40 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:34,533] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:34,533] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 10 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:34,533] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:34,533] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 28 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:34,533] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:34,533] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 46 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:34,533] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:34,533] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 16 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:17:34,533] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:34,542] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-34 in 9 milliseconds for epoch 16, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:34,543] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-4 in 10 milliseconds for epoch 16, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:34,570] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-9fa5abef-fdc9-4c05-8f09-7f9780632837, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:17:34,584] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-ed3a6d0d-54c4-4b54-b4a4-a5d0ecba6f8e, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:17:34,584] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-1038faf2-d998-4707-9799-897de83d6136, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:17:34,584] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-b283a5ee-70be-4bf9-b41c-74e089f12e34, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:17:34,584] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-360d1581-f79b-41e6-82d3-fe3577615014, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:17:34,584] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-9e173d1e-b47a-4b16-9874-bf5d2688c730, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:17:34,584] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-81fafa38-80dc-43ea-ac6c-e398b06565dc, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:17:34,586] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-22 in 52 milliseconds for epoch 16, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:34,634] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-40 in 101 milliseconds for epoch 16, of which 53 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:34,635] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-10 in 102 milliseconds for epoch 16, of which 102 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:34,636] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-28 in 103 milliseconds for epoch 16, of which 103 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:34,637] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-46 in 104 milliseconds for epoch 16, of which 103 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:34,637] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-16 in 104 milliseconds for epoch 16, of which 104 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:17:38,217] INFO Creating topic Sensor with configuration {min.insync.replicas=2} and initial partition assignment HashMap(0 -> ArrayBuffer(5, 2, 3), 1 -> ArrayBuffer(4, 3, 0), 2 -> ArrayBuffer(1, 0, 5), 3 -> ArrayBuffer(2, 5, 4), 4 -> ArrayBuffer(3, 4, 1), 5 -> ArrayBuffer(0, 1, 2)) (kafka.zk.AdminZkClient)
[2022-05-15 17:17:38,267] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,267] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,269] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,270] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,273] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-4) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,273] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,281] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:38,282] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:38,287] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:38,288] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:38,288] INFO Created log for partition Sensor-5 in /tmp/kafka-logs/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:17:38,289] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:38,289] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-1/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:17:38,289] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:38,290] INFO [Partition Sensor-5 broker=0] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 17:17:38,291] INFO [Partition Sensor-5 broker=0] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:38,291] INFO [Partition Sensor-2 broker=1] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 17:17:38,291] INFO [Partition Sensor-2 broker=1] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:38,294] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-5/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:17:38,295] INFO [Partition Sensor-0 broker=5] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 17:17:38,296] INFO [Partition Sensor-0 broker=5] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:38,296] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-3/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:17:38,296] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-2/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:17:38,297] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-4/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:17:38,298] INFO [Partition Sensor-3 broker=2] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 17:17:38,298] INFO [Partition Sensor-4 broker=3] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 17:17:38,299] INFO [Partition Sensor-3 broker=2] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:38,299] INFO [Partition Sensor-4 broker=3] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:38,299] INFO [Partition Sensor-1 broker=4] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 17:17:38,300] INFO [Partition Sensor-1 broker=4] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:38,307] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:38,309] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-1/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:17:38,310] INFO [Partition Sensor-4 broker=1] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 17:17:38,310] INFO [Partition Sensor-4 broker=1] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:38,310] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:38,312] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:38,312] INFO Created log for partition Sensor-2 in /tmp/kafka-logs/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:17:38,313] INFO [Partition Sensor-2 broker=0] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 17:17:38,313] INFO [Partition Sensor-2 broker=0] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:38,314] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-5/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:17:38,315] INFO [Partition Sensor-3 broker=5] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 17:17:38,315] INFO [Partition Sensor-3 broker=5] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:38,316] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:38,319] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:38,319] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-4/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:17:38,318] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:38,319] INFO [Partition Sensor-4 broker=4] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 17:17:38,319] INFO [Partition Sensor-4 broker=4] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:38,320] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:38,321] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-3/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:17:38,321] INFO [Partition Sensor-0 broker=3] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 17:17:38,321] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:38,321] INFO [Partition Sensor-0 broker=3] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:38,322] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-1/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:17:38,322] INFO Created log for partition Sensor-1 in /tmp/kafka-logs/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:17:38,322] INFO [Partition Sensor-5 broker=1] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 17:17:38,322] INFO [Partition Sensor-5 broker=1] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:38,322] INFO [Partition Sensor-1 broker=0] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 17:17:38,322] INFO [Partition Sensor-1 broker=0] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:38,322] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(Sensor-4, Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,323] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,324] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-2/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:17:38,324] INFO [Partition Sensor-5 broker=2] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 17:17:38,324] INFO [Partition Sensor-5 broker=2] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:38,331] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:38,332] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:38,332] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-4/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:17:38,333] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:38,333] INFO [Partition Sensor-3 broker=4] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 17:17:38,333] INFO [Partition Sensor-3 broker=4] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:38,333] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(Sensor-4, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,335] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-2/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:17:38,335] INFO [Partition Sensor-0 broker=2] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 17:17:38,336] INFO [Partition Sensor-0 broker=2] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:38,336] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(Sensor-5, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,338] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-5/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:17:38,338] INFO [Partition Sensor-2 broker=5] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 17:17:38,338] INFO [Partition Sensor-2 broker=5] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:38,337] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:17:38,338] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,340] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-3/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:17:38,341] INFO [Partition Sensor-1 broker=3] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 17:17:38,341] INFO [Partition Sensor-1 broker=3] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:17:38,342] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,354] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,357] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,359] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 4 for partitions Map(Sensor-1 -> InitialFetchState(Some(xTEC6a39TDqg-PYWlqZkOA),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,362] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,363] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 1 for partitions Map(Sensor-2 -> InitialFetchState(Some(xTEC6a39TDqg-PYWlqZkOA),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,363] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,364] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,365] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(Sensor-5 -> InitialFetchState(Some(xTEC6a39TDqg-PYWlqZkOA),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,366] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:17:38,366] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:17:38,367] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,367] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,369] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:17:38,372] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,372] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 3 for partitions Map(Sensor-4 -> InitialFetchState(Some(xTEC6a39TDqg-PYWlqZkOA),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,374] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,375] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions Map(Sensor-5 -> InitialFetchState(Some(xTEC6a39TDqg-PYWlqZkOA),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,373] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,376] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,377] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,377] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:17:38,380] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,381] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 2 for partitions Map(Sensor-3 -> InitialFetchState(Some(xTEC6a39TDqg-PYWlqZkOA),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,383] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 4 for partitions Map(Sensor-1 -> InitialFetchState(Some(xTEC6a39TDqg-PYWlqZkOA),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,384] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,384] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,386] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,384] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 5 for partitions Map(Sensor-0 -> InitialFetchState(Some(xTEC6a39TDqg-PYWlqZkOA),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,388] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 2 for partitions Map(Sensor-3 -> InitialFetchState(Some(xTEC6a39TDqg-PYWlqZkOA),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,387] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:17:38,388] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,384] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,389] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 5 for partitions Map(Sensor-0 -> InitialFetchState(Some(xTEC6a39TDqg-PYWlqZkOA),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,389] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,389] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,389] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:17:38,390] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:17:38,390] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,391] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 1 for partitions Map(Sensor-2 -> InitialFetchState(Some(xTEC6a39TDqg-PYWlqZkOA),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,391] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,391] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:17:38,390] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:17:38,396] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:17:38,391] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:17:38,397] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,401] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 3 for partitions Map(Sensor-4 -> InitialFetchState(Some(xTEC6a39TDqg-PYWlqZkOA),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:17:38,402] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,402] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:17:38,526] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-4. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,530] WARN [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:17:38,532] WARN [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:18:08,939] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=74310, lastModifiedTime=1652630955841, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:18:08,942] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=74310, lastModifiedTime=1652630955841, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:18:08,947] INFO Deleted log /tmp/kafka-logs/Sensor-3.3ab055093b354b5688c4a458d7e9b677-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:08,947] INFO Deleted offset index /tmp/kafka-logs/Sensor-3.3ab055093b354b5688c4a458d7e9b677-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:08,950] INFO Deleted time index /tmp/kafka-logs/Sensor-3.3ab055093b354b5688c4a458d7e9b677-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:08,955] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs/Sensor-3.3ab055093b354b5688c4a458d7e9b677-delete. (kafka.log.LogManager)
[2022-05-15 17:18:08,956] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=72406, lastModifiedTime=1652630955873, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:18:08,957] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=72406, lastModifiedTime=1652630955873, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:18:08,958] INFO Deleted log /tmp/kafka-logs/Sensor-0.52243c3da86c49f5aab7c6fddbb81423-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:08,958] INFO Deleted offset index /tmp/kafka-logs/Sensor-0.52243c3da86c49f5aab7c6fddbb81423-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:08,958] INFO Deleted time index /tmp/kafka-logs/Sensor-0.52243c3da86c49f5aab7c6fddbb81423-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:08,959] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs/Sensor-0.52243c3da86c49f5aab7c6fddbb81423-delete. (kafka.log.LogManager)
[2022-05-15 17:18:09,042] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=66832, lastModifiedTime=1652630949540, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:18:09,042] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=66832, lastModifiedTime=1652630949540, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:18:09,044] INFO Deleted log /tmp/kafka-logs/Sensor-1.2176f61856d24a8eb313d870e0edbfb6-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:09,044] INFO Deleted offset index /tmp/kafka-logs/Sensor-1.2176f61856d24a8eb313d870e0edbfb6-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:09,044] INFO Deleted time index /tmp/kafka-logs/Sensor-1.2176f61856d24a8eb313d870e0edbfb6-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:09,045] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs/Sensor-1.2176f61856d24a8eb313d870e0edbfb6-delete. (kafka.log.LogManager)
[2022-05-15 17:18:13,343] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=74310, lastModifiedTime=1652630955841, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:18:13,346] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=74310, lastModifiedTime=1652630955841, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:18:13,350] INFO Deleted log /tmp/kafka-logs-1/Sensor-3.16b1051125964e3596d4857b45f4136a-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:13,352] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-3.16b1051125964e3596d4857b45f4136a-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:13,358] INFO Deleted time index /tmp/kafka-logs-1/Sensor-3.16b1051125964e3596d4857b45f4136a-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:13,364] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-1/Sensor-3.16b1051125964e3596d4857b45f4136a-delete. (kafka.log.LogManager)
[2022-05-15 17:18:13,365] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=41147, lastModifiedTime=1652630944512, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:18:13,365] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=41147, lastModifiedTime=1652630944512, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:18:13,366] INFO Deleted log /tmp/kafka-logs-1/Sensor-4.67c08d6d894547509c49a4878e414511-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:13,366] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-4.67c08d6d894547509c49a4878e414511-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:13,367] INFO Deleted time index /tmp/kafka-logs-1/Sensor-4.67c08d6d894547509c49a4878e414511-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:13,367] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-1/Sensor-4.67c08d6d894547509c49a4878e414511-delete. (kafka.log.LogManager)
[2022-05-15 17:18:13,368] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=72406, lastModifiedTime=1652630955869, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:18:13,368] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=72406, lastModifiedTime=1652630955869, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:18:13,369] INFO Deleted log /tmp/kafka-logs-1/Sensor-0.af9dd6cd561645dea756319225e63f54-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:13,370] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-0.af9dd6cd561645dea756319225e63f54-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:13,370] INFO Deleted time index /tmp/kafka-logs-1/Sensor-0.af9dd6cd561645dea756319225e63f54-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:13,371] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-1/Sensor-0.af9dd6cd561645dea756319225e63f54-delete. (kafka.log.LogManager)
[2022-05-15 17:18:18,401] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=66832, lastModifiedTime=1652630949540, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:18:18,402] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=66832, lastModifiedTime=1652630949540, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:18:18,405] INFO Deleted log /tmp/kafka-logs-2/Sensor-1.ce03e343d40f4ece8979d0e5b06abf87-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:18,406] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-1.ce03e343d40f4ece8979d0e5b06abf87-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:18,409] INFO Deleted time index /tmp/kafka-logs-2/Sensor-1.ce03e343d40f4ece8979d0e5b06abf87-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:18,413] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-2/Sensor-1.ce03e343d40f4ece8979d0e5b06abf87-delete. (kafka.log.LogManager)
[2022-05-15 17:18:18,474] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=44696, lastModifiedTime=1652630944260, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:18:18,474] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=44696, lastModifiedTime=1652630944260, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:18:18,475] INFO Deleted log /tmp/kafka-logs-2/Sensor-5.64a60e0928544ea4b168effb37a60e37-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:18,476] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-5.64a60e0928544ea4b168effb37a60e37-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:18,476] INFO Deleted time index /tmp/kafka-logs-2/Sensor-5.64a60e0928544ea4b168effb37a60e37-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:18,476] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-2/Sensor-5.64a60e0928544ea4b168effb37a60e37-delete. (kafka.log.LogManager)
[2022-05-15 17:18:18,482] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=41147, lastModifiedTime=1652630944512, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:18:18,483] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=41147, lastModifiedTime=1652630944512, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:18:18,484] INFO Deleted log /tmp/kafka-logs-2/Sensor-4.a720b63a2e78468faf66cbc42c28f60f-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:18,484] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-4.a720b63a2e78468faf66cbc42c28f60f-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:18,484] INFO Deleted time index /tmp/kafka-logs-2/Sensor-4.a720b63a2e78468faf66cbc42c28f60f-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:18,485] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-2/Sensor-4.a720b63a2e78468faf66cbc42c28f60f-delete. (kafka.log.LogManager)
[2022-05-15 17:18:23,531] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=72406, lastModifiedTime=1652630955873, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:18:23,534] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=72406, lastModifiedTime=1652630955873, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:18:23,541] INFO Deleted log /tmp/kafka-logs-3/Sensor-0.880b984f7916428b9a6ecd12864a57ef-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:23,541] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-0.880b984f7916428b9a6ecd12864a57ef-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:23,546] INFO Deleted time index /tmp/kafka-logs-3/Sensor-0.880b984f7916428b9a6ecd12864a57ef-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:23,553] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-3/Sensor-0.880b984f7916428b9a6ecd12864a57ef-delete. (kafka.log.LogManager)
[2022-05-15 17:18:23,560] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=67058, lastModifiedTime=1652630947240, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:18:23,560] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=67058, lastModifiedTime=1652630947240, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:18:23,562] INFO Deleted log /tmp/kafka-logs-3/Sensor-2.d929bc0fe4ab4a328710d32d1183d319-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:23,562] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-2.d929bc0fe4ab4a328710d32d1183d319-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:23,563] INFO Deleted time index /tmp/kafka-logs-3/Sensor-2.d929bc0fe4ab4a328710d32d1183d319-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:23,564] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-3/Sensor-2.d929bc0fe4ab4a328710d32d1183d319-delete. (kafka.log.LogManager)
[2022-05-15 17:18:23,570] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=44696, lastModifiedTime=1652630944260, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:18:23,571] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=44696, lastModifiedTime=1652630944260, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:18:23,573] INFO Deleted log /tmp/kafka-logs-3/Sensor-5.d4181b42a7ae481fbd36fea36b45a07c-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:23,574] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-5.d4181b42a7ae481fbd36fea36b45a07c-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:23,574] INFO Deleted time index /tmp/kafka-logs-3/Sensor-5.d4181b42a7ae481fbd36fea36b45a07c-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:23,575] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-3/Sensor-5.d4181b42a7ae481fbd36fea36b45a07c-delete. (kafka.log.LogManager)
[2022-05-15 17:18:28,421] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=44696, lastModifiedTime=1652630944260, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:18:28,423] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=44696, lastModifiedTime=1652630944260, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:18:28,426] INFO Deleted log /tmp/kafka-logs-4/Sensor-5.3bd3cfee391a4e569b87d45ab8d3e20f-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:28,427] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-5.3bd3cfee391a4e569b87d45ab8d3e20f-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:28,430] INFO Deleted time index /tmp/kafka-logs-4/Sensor-5.3bd3cfee391a4e569b87d45ab8d3e20f-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:28,434] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-4/Sensor-5.3bd3cfee391a4e569b87d45ab8d3e20f-delete. (kafka.log.LogManager)
[2022-05-15 17:18:28,435] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=74310, lastModifiedTime=1652630955841, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:18:28,435] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=74310, lastModifiedTime=1652630955841, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:18:28,436] INFO Deleted log /tmp/kafka-logs-4/Sensor-3.5fc74ce81c4f41b2b0fb99903dd12cf2-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:28,436] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-3.5fc74ce81c4f41b2b0fb99903dd12cf2-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:28,437] INFO Deleted time index /tmp/kafka-logs-4/Sensor-3.5fc74ce81c4f41b2b0fb99903dd12cf2-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:28,437] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-4/Sensor-3.5fc74ce81c4f41b2b0fb99903dd12cf2-delete. (kafka.log.LogManager)
[2022-05-15 17:18:28,484] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=67058, lastModifiedTime=1652630947244, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:18:28,485] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=67058, lastModifiedTime=1652630947244, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:18:28,487] INFO Deleted log /tmp/kafka-logs-4/Sensor-2.382e4fb330d248bf8af1de0ff9acd30e-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:28,488] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-2.382e4fb330d248bf8af1de0ff9acd30e-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:28,489] INFO Deleted time index /tmp/kafka-logs-4/Sensor-2.382e4fb330d248bf8af1de0ff9acd30e-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:28,490] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-4/Sensor-2.382e4fb330d248bf8af1de0ff9acd30e-delete. (kafka.log.LogManager)
[2022-05-15 17:18:33,435] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=41147, lastModifiedTime=1652630944508, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:18:33,436] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=41147, lastModifiedTime=1652630944508, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:18:33,440] INFO Deleted log /tmp/kafka-logs-5/Sensor-4.9157d6de0f0045e2b693d079dfdfeb4f-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:33,441] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-4.9157d6de0f0045e2b693d079dfdfeb4f-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:33,444] INFO Deleted time index /tmp/kafka-logs-5/Sensor-4.9157d6de0f0045e2b693d079dfdfeb4f-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:33,450] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-5/Sensor-4.9157d6de0f0045e2b693d079dfdfeb4f-delete. (kafka.log.LogManager)
[2022-05-15 17:18:33,484] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=66832, lastModifiedTime=1652630949540, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:18:33,484] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=66832, lastModifiedTime=1652630949540, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:18:33,485] INFO Deleted log /tmp/kafka-logs-5/Sensor-1.810a4ab6abb045628a7235f4d4156743-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:33,485] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-1.810a4ab6abb045628a7235f4d4156743-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:33,485] INFO Deleted time index /tmp/kafka-logs-5/Sensor-1.810a4ab6abb045628a7235f4d4156743-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:33,486] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-5/Sensor-1.810a4ab6abb045628a7235f4d4156743-delete. (kafka.log.LogManager)
[2022-05-15 17:18:33,490] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=67058, lastModifiedTime=1652630947244, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:18:33,491] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=67058, lastModifiedTime=1652630947244, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:18:33,492] INFO Deleted log /tmp/kafka-logs-5/Sensor-2.8fdc15ede52d4fa3b557ceb6accfda2f-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:33,493] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-2.8fdc15ede52d4fa3b557ceb6accfda2f-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:33,493] INFO Deleted time index /tmp/kafka-logs-5/Sensor-2.8fdc15ede52d4fa3b557ceb6accfda2f-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:18:33,494] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-5/Sensor-2.8fdc15ede52d4fa3b557ceb6accfda2f-delete. (kafka.log.LogManager)
[2022-05-15 17:28:28,396] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,396] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,396] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,396] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,396] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,396] INFO [Controller id=0, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,409] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:28:28,411] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:28:28,411] INFO [GroupMetadataManager brokerId=5] Group consumer transitioned to Dead in generation 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:28:28,412] INFO [GroupCoordinator 4]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:28:28,412] INFO [GroupCoordinator 3]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:28:28,412] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:28:28,414] INFO [GroupCoordinator 5]: Removed 6 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:28:28,441] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:28,441] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:28,442] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:28,443] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-2) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:28,444] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:28,445] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:28,444] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:28,445] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:28,445] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:28,446] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:28,446] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:28,446] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:28,449] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,450] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,451] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 2610 due to node 1 being disconnected (elapsed time since creation: 303ms, elapsed time since send: 303ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,451] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,451] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=751202668, epoch=2610) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:28:28,452] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,452] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,452] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,455] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,455] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,456] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,456] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1859 due to node 3 being disconnected (elapsed time since creation: 285ms, elapsed time since send: 285ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,456] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,457] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,458] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,458] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,459] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 2608 due to node 4 being disconnected (elapsed time since creation: 284ms, elapsed time since send: 284ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,459] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 2680 due to node 2 being disconnected (elapsed time since creation: 88ms, elapsed time since send: 88ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,459] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,461] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 2676 due to node 2 being disconnected (elapsed time since creation: 87ms, elapsed time since send: 87ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,457] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=833391688, epoch=1857) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:28:28,463] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1933 due to node 0 being disconnected (elapsed time since creation: 281ms, elapsed time since send: 281ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,463] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,460] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=1057352869, epoch=2606) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:28:28,464] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,465] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,466] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,462] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1494590199, epoch=2676) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:28:28,460] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=387648923, epoch=2680) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:28:28,467] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,467] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,467] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,468] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,468] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,468] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 2604 due to node 4 being disconnected (elapsed time since creation: 321ms, elapsed time since send: 321ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,468] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,468] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=297948684, epoch=2602) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:28:28,468] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,468] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,464] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=347502100, epoch=1933) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:28:28,470] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,471] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,471] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:28,472] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:28,473] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,473] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,474] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,474] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,474] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1927 due to node 0 being disconnected (elapsed time since creation: 244ms, elapsed time since send: 244ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,474] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 2591 due to node 5 being disconnected (elapsed time since creation: 491ms, elapsed time since send: 491ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,475] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,475] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=552343066, epoch=2591) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:28:28,475] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,475] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,476] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,476] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 2618 due to node 1 being disconnected (elapsed time since creation: 325ms, elapsed time since send: 325ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,474] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=413406543, epoch=1927) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:28:28,476] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,476] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,476] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=492187654, epoch=2618) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:28:28,478] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,478] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,478] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,478] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,478] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,479] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1865 due to node 3 being disconnected (elapsed time since creation: 263ms, elapsed time since send: 263ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,479] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:28,479] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:28,480] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-2) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:28,479] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1820993584, epoch=1865) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:28:28,480] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,480] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:28,480] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,480] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:28,481] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:28,478] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,481] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 2591 due to node 5 being disconnected (elapsed time since creation: 441ms, elapsed time since send: 441ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:28,481] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=245424293, epoch=2591) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:28:28,483] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:28,484] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,484] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:28:28,485] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:28,488] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:28,489] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:28,494] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs/Sensor-5.f13da2e57509470984af3924ef0f4a15-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:28:28,499] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs/Sensor-2.7d0b160025f84ef5806466f0fea4543f-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:28:28,502] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs/Sensor-1.a6c0650b6e654f7092607cf0761da921-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:28:28,505] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-5/Sensor-2.286aace4d4c5418ab22fecd9b2088078-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:28:28,505] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-1/Sensor-4.83c89ac4dc374f3e9a429ac6e7b21d52-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:28:28,506] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-4/Sensor-4.93d9b79dde634583a9b12166fe46ac12-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:28:28,507] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-3/Sensor-4.c9027c94fec749cea2e9a44ae4d7b2b5-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:28:28,509] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-5/Sensor-3.b4eddb78e45f47e49b323699fc04fa72-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:28:28,510] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-1/Sensor-5.a185b53ae02649a19418146e158b88ca-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:28:28,510] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-4/Sensor-3.46cdd7e41b9a4345a8d782bed89e00c7-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:28:28,512] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-5/Sensor-0.8c52cdfd8f4f4575b395ac7abb9f8e56-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:28:28,512] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-3/Sensor-0.ee157d8decf944c48301ee28c5a8cafe-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:28:28,513] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-1/Sensor-2.7e4885ff8aa446aebe7c54199e95a4dd-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:28:28,514] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-4/Sensor-1.58d75da0aea84d2493dde5bb67a166dd-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:28:28,514] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-2/Sensor-5.be3052791bcd4039a7edf1eae9df8482-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:28:28,519] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-3/Sensor-1.242bc8959ac1446dbb0159c1038afec4-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:28:28,521] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-2/Sensor-3.390c3b5aff684938883eb02f72ba5bfa-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:28:28,524] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-2/Sensor-0.3eb39b1ee826495898bb80fc9915a4d7-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:28:31,775] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:28:31,775] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:28:31,775] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:28:31,775] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:28:31,775] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:28:31,775] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:28:31,777] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:28:31,777] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:28:31,777] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:28:31,778] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:28:31,778] INFO [KafkaServer id=4] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:28:31,779] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:28:31,779] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:28:31,781] INFO [KafkaServer id=5] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:28:31,781] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:28:31,781] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:28:31,782] INFO [KafkaServer id=5] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:28:31,783] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:28:31,797] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 8ms (kafka.server.KafkaServer)
[2022-05-15 17:28:31,799] INFO [KafkaServer id=3] Controlled shutdown request returned successfully after 13ms (kafka.server.KafkaServer)
[2022-05-15 17:28:31,800] INFO [KafkaServer id=5] Controlled shutdown request returned successfully after 9ms (kafka.server.KafkaServer)
[2022-05-15 17:28:31,801] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 13ms (kafka.server.KafkaServer)
[2022-05-15 17:28:31,801] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:28:31,802] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 15ms (kafka.server.KafkaServer)
[2022-05-15 17:28:31,802] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:28:31,803] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:28:31,804] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:28:31,802] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:28:31,804] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:28:31,804] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:28:31,805] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:28:31,805] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:28:31,806] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:28:31,806] INFO [KafkaServer id=4] Controlled shutdown request returned successfully after 19ms (kafka.server.KafkaServer)
[2022-05-15 17:28:31,806] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:28:31,805] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:28:31,806] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:28:31,806] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:28:31,805] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:28:31,805] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:28:31,806] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:28:31,808] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:28:31,809] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:28:31,809] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:28:31,814] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:28:31,815] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:28:31,815] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:28:31,817] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:28:31,823] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:28:31,823] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:28:31,824] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:28:31,825] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:28:31,825] INFO [data-plane Kafka Request Handler on Broker 5], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:28:31,828] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:28:31,828] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:28:31,830] INFO [data-plane Kafka Request Handler on Broker 5], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:28:31,830] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:28:31,830] INFO [data-plane Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:28:31,832] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:28:31,833] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:28:31,833] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:28:31,834] INFO [data-plane Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:28:31,834] INFO [ExpirationReaper-5-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,834] INFO [data-plane Kafka Request Handler on Broker 4], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:28:31,835] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:28:31,839] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:28:31,839] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,840] INFO [data-plane Kafka Request Handler on Broker 4], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:28:31,840] INFO [ExpirationReaper-3-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,841] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,843] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,844] INFO [ExpirationReaper-4-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,859] INFO [ExpirationReaper-5-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,859] INFO [ExpirationReaper-5-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,860] INFO [KafkaApi-5] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:28:31,860] INFO [ExpirationReaper-5-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,905] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,905] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,907] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:28:31,908] INFO [ExpirationReaper-4-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,908] INFO [ExpirationReaper-4-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,909] INFO [KafkaApi-4] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:28:31,910] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,910] INFO [ExpirationReaper-4-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,951] INFO [ExpirationReaper-5-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,951] INFO [ExpirationReaper-5-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,954] INFO [TransactionCoordinator id=5] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:28:31,956] INFO [Transaction State Manager 5]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:28:31,956] INFO [Transaction Marker Channel Manager 5]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:28:31,956] INFO [Transaction Marker Channel Manager 5]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:28:31,956] INFO [Transaction Marker Channel Manager 5]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:28:31,957] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,957] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,958] INFO [TransactionCoordinator id=5] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:28:31,958] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:28:31,959] INFO [GroupCoordinator 5]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:28:31,959] INFO [ExpirationReaper-5-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,960] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,980] INFO [ExpirationReaper-5-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,980] INFO [ExpirationReaper-5-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,980] INFO [ExpirationReaper-5-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,993] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,994] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,995] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:28:31,997] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:28:31,997] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:28:31,997] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,997] INFO [ExpirationReaper-5-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,997] INFO [ExpirationReaper-5-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,997] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,997] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:28:31,997] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:28:31,998] INFO [GroupCoordinator 5]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:28:31,998] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:28:31,998] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:28:31,998] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:28:31,999] INFO [ReplicaManager broker=5] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:28:31,999] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:28:31,999] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:31,999] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:28:31,999] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:28:31,999] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,000] INFO [ReplicaFetcherManager on broker 5] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:32,001] INFO [ReplicaFetcherManager on broker 5] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:32,001] INFO [ReplicaAlterLogDirsManager on broker 5] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:32,002] INFO [ReplicaAlterLogDirsManager on broker 5] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:32,002] INFO [ExpirationReaper-5-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,007] INFO [ExpirationReaper-3-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,007] INFO [ExpirationReaper-3-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,008] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:28:32,009] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,009] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,009] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,010] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:28:32,011] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:28:32,011] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:28:32,012] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:28:32,011] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:28:32,013] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:28:32,013] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:28:32,014] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,035] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,035] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,036] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,061] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,061] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,061] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,074] INFO [ExpirationReaper-4-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,074] INFO [ExpirationReaper-4-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,076] INFO [TransactionCoordinator id=4] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:28:32,077] INFO [Transaction State Manager 4]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:28:32,077] INFO [Transaction Marker Channel Manager 4]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:28:32,078] INFO [Transaction Marker Channel Manager 4]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:28:32,078] INFO [Transaction Marker Channel Manager 4]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:28:32,079] INFO [TransactionCoordinator id=4] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:28:32,079] INFO [GroupCoordinator 4]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:28:32,080] INFO [ExpirationReaper-4-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,095] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,095] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,098] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:28:32,099] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:28:32,099] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:28:32,100] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:28:32,100] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:28:32,101] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:28:32,102] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:28:32,102] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,104] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,104] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,106] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:28:32,107] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:28:32,107] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:28:32,108] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:28:32,107] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:28:32,109] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:28:32,109] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:28:32,110] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,117] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,117] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,117] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,127] INFO [ExpirationReaper-5-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,127] INFO [ExpirationReaper-5-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,127] INFO [ExpirationReaper-5-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,148] INFO [ExpirationReaper-5-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,148] INFO [ExpirationReaper-5-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,148] INFO [ExpirationReaper-5-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,181] INFO [ExpirationReaper-5-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,181] INFO [ExpirationReaper-5-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,181] INFO [ExpirationReaper-5-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,207] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,207] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,208] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:28:32,209] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:28:32,209] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:28:32,210] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:28:32,210] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:28:32,211] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:32,212] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:32,213] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:32,213] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:32,213] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,247] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,247] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,248] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,260] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,260] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,260] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,261] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,261] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,262] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:28:32,263] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:28:32,263] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:28:32,263] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:28:32,263] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:28:32,264] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:32,265] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:32,265] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:32,266] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:32,266] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,274] INFO [ExpirationReaper-4-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,274] INFO [ExpirationReaper-4-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,274] INFO [ExpirationReaper-4-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,289] INFO [ExpirationReaper-4-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,289] INFO [ExpirationReaper-4-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,290] INFO [GroupCoordinator 4]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:28:32,291] INFO [ReplicaManager broker=4] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:28:32,291] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:28:32,292] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:28:32,292] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:28:32,293] INFO [ReplicaFetcherManager on broker 4] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:32,293] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,293] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,294] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,295] INFO [ReplicaFetcherManager on broker 4] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:32,295] INFO [ReplicaAlterLogDirsManager on broker 4] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:32,296] INFO [ReplicaAlterLogDirsManager on broker 4] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:32,296] INFO [ExpirationReaper-4-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,297] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,297] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,298] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:28:32,298] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:28:32,299] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:28:32,299] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:28:32,299] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:28:32,299] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:32,300] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:32,300] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:32,301] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:32,301] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,304] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,304] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,305] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:28:32,306] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:28:32,306] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:28:32,306] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:28:32,306] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:28:32,307] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:32,307] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:28:32,308] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:32,308] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:28:32,308] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,327] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,327] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,327] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,359] INFO [ExpirationReaper-5-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,359] INFO [ExpirationReaper-5-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,368] INFO [ReplicaManager broker=5] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:28:32,368] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,369] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,369] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,371] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:28:32,372] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,372] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,372] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,373] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:28:32,374] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:28:32,388] INFO [ProducerStateManager partition=__consumer_offsets-22] Wrote producer snapshot at offset 6389 with 0 producer ids in 3 ms. (kafka.log.ProducerStateManager)
[2022-05-15 17:28:32,399] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:28:32,405] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:28:32,405] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:28:32,405] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:28:32,406] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:28:32,437] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,437] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,437] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,437] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,437] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,438] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,438] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,438] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,438] WARN [Controller id=0, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,438] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,438] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,439] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,438] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,439] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,439] WARN [Controller id=0, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,440] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,440] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,445] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,446] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,446] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,447] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,447] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,448] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,453] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,453] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,454] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,468] INFO [ExpirationReaper-4-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,468] INFO [ExpirationReaper-4-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,469] INFO [ExpirationReaper-4-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,472] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,472] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,472] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,485] INFO [ExpirationReaper-4-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,485] INFO [ExpirationReaper-4-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,486] INFO [ExpirationReaper-4-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,493] INFO [ExpirationReaper-4-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,493] INFO [ExpirationReaper-4-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,494] INFO [ExpirationReaper-4-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,505] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,505] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,505] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,507] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,507] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,507] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,510] INFO Session: 0x100000b00ad0023 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:28:32,510] INFO EventThread shut down for session: 0x100000b00ad0023 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:28:32,511] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:28:32,512] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:32,517] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,517] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,518] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,541] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,541] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,541] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,541] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,541] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,542] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,546] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,546] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,546] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,547] WARN [Controller id=0, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,547] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,547] WARN [Controller id=0, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,547] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,547] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,547] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,559] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,559] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,560] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,642] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,642] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,642] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,643] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,643] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,643] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,648] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,648] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,648] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,648] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,648] WARN [Controller id=0, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,648] WARN [Controller id=0, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,648] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,649] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,649] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,650] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,650] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,655] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:28:32,655] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,655] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,655] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,658] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:28:32,658] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,659] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,659] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,659] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:28:32,660] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:28:32,664] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,664] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,668] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:28:32,668] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,669] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,669] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,671] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:28:32,672] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,672] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,672] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,673] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:28:32,674] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:28:32,683] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:28:32,689] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:28:32,690] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:28:32,690] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:28:32,690] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:28:32,693] INFO [ExpirationReaper-4-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,693] INFO [ExpirationReaper-4-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,693] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:28:32,696] INFO [ReplicaManager broker=4] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:28:32,696] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,697] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,697] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,697] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,699] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:28:32,699] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,699] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,699] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,700] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:28:32,701] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:28:32,704] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,704] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,705] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,724] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,726] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,727] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,728] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,728] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:28:32,728] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,729] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,731] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:28:32,731] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:28:32,731] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:28:32,731] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:28:32,732] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,732] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,732] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,732] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:28:32,734] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:28:32,734] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,735] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,735] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,736] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:28:32,736] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:28:32,736] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:28:32,737] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:28:32,738] WARN An exception was thrown while closing send thread for session 0x100000b00ad001e. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x100000b00ad001e, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 17:28:32,739] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:28:32,741] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:28:32,747] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,747] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,747] INFO [ExpirationReaper-3-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,752] INFO [ExpirationReaper-3-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,752] INFO [ExpirationReaper-3-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:28:32,756] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:28:32,757] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,757] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,757] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,759] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:28:32,759] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,759] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,759] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:28:32,760] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:28:32,760] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:28:32,766] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:28:32,781] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:28:32,784] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:28:32,784] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:28:32,785] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:28:32,785] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:28:32,794] INFO Session: 0x100000b00ad001f closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:28:32,794] INFO EventThread shut down for session: 0x100000b00ad001f (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:28:32,795] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:28:32,796] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:32,830] INFO [Controller id=2, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,830] INFO [Controller id=2, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,832] WARN [Controller id=2, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,832] WARN [Controller id=2, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,833] INFO [Controller id=2, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,833] INFO [Controller id=2, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,840] INFO Session: 0x100000b00ad001e closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:28:32,840] INFO EventThread shut down for session: 0x100000b00ad001e (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:28:32,841] INFO EventThread shut down for session: 0x100000b00ad0022 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:28:32,841] INFO Session: 0x100000b00ad0022 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:28:32,842] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:28:32,843] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:32,843] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:28:32,844] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:32,866] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:32,866] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:32,867] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:32,878] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:32,878] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:32,878] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:32,879] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:32,879] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:32,880] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:32,889] INFO Session: 0x100000b00ad0021 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:28:32,889] INFO EventThread shut down for session: 0x100000b00ad0021 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:28:32,890] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:28:32,891] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:32,934] INFO [Controller id=2, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,934] INFO [Controller id=2, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,934] WARN [Controller id=2, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,934] WARN [Controller id=2, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,935] INFO [Controller id=2, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,935] INFO [Controller id=2, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,967] INFO [Controller id=2, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,968] INFO [Controller id=2, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:28:32,971] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:28:32,971] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:28:32,971] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:28:32,973] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:28:33,076] INFO Session: 0x100000b00ad0020 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:28:33,076] INFO EventThread shut down for session: 0x100000b00ad0020 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:28:33,078] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:28:33,079] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,281] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,281] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,281] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,283] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,283] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,283] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,358] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,358] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,359] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,363] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,363] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,363] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,371] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,371] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,372] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,374] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,374] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,375] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,387] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,387] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,388] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,443] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,443] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,443] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,879] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,879] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:33,881] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:28:33,898] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:28:33,899] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:28:33,899] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:28:33,899] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:28:33,901] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:28:33,902] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:28:33,903] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:28:34,280] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:34,281] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:34,281] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:34,299] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:34,299] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:34,301] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:28:34,323] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:28:34,324] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:28:34,324] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:28:34,324] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:28:34,325] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:28:34,326] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:28:34,327] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:28:34,362] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:34,362] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:34,362] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:34,367] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:34,367] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:34,368] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:34,377] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:34,377] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:34,378] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:28:34,387] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:34,387] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:34,387] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:34,394] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:28:34,394] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:28:34,394] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:28:34,395] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:28:34,396] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:28:34,396] INFO App info kafka.server for 4 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:28:34,397] INFO [KafkaServer id=4] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:28:34,438] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:34,438] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:34,438] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:34,452] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:34,452] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:34,452] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:35,359] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:35,359] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:35,361] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:28:35,383] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:28:35,384] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:28:35,384] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:28:35,384] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:28:35,386] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:28:35,387] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:35,387] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:35,387] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:35,387] INFO App info kafka.server for 5 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:28:35,388] INFO [KafkaServer id=5] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:28:35,390] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:35,390] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:35,391] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:28:35,408] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:28:35,409] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:28:35,409] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:28:35,409] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:28:35,410] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:28:35,411] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:28:35,411] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:28:35,438] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:35,438] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:28:35,439] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:28:35,459] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:28:35,460] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:28:35,460] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:28:35,460] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:28:35,461] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:28:35,462] INFO App info kafka.server for 3 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:28:35,462] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:29:25,229] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:29:25,244] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:29:25,244] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:29:25,244] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:29:25,244] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:29:25,246] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 17:29:25,247] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 17:29:25,247] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 17:29:25,247] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-15 17:29:25,251] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-15 17:29:25,278] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:29:25,279] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:29:25,280] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:29:25,280] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:29:25,280] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:29:25,281] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-15 17:29:25,301] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@6156496 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-15 17:29:25,308] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 17:29:25,326] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,326] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,326] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,326] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,327] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,327] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,327] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,327] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,327] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,327] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,329] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,329] INFO Server environment:host.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,329] INFO Server environment:java.version=11.0.15 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,329] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,329] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,330] INFO Server environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,330] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,331] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,331] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,331] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,331] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,331] INFO Server environment:os.version=5.13.0-40-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,331] INFO Server environment:user.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,331] INFO Server environment:user.home=/home/joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,331] INFO Server environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,331] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,331] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,331] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,331] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,332] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,332] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,332] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,332] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,332] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,333] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,334] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-15 17:29:25,337] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,338] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,341] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 17:29:25,341] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 17:29:25,343] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:29:25,343] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:29:25,343] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:29:25,343] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:29:25,343] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:29:25,343] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:29:25,347] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,347] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,347] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:29:25,356] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 17:29:25,358] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 17:29:25,360] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 17:29:25,366] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 17:29:25,369] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:459)
	at java.base/sun.nio.ch.Net.bind(Net.java:448)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:676)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:158)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:112)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:67)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:140)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:90)
[2022-05-15 17:29:25,375] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-15 17:29:25,378] ERROR Exiting JVM with code 1 (org.apache.zookeeper.util.ServiceUtils)
[2022-05-15 17:29:30,300] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:29:30,607] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:29:30,705] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:29:30,709] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:29:30,710] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:29:30,728] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:29:30,732] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:30,733] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:30,733] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:30,733] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:30,733] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:30,733] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:30,734] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:30,734] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:30,734] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:30,734] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:30,734] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:30,734] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:30,734] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:30,734] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:30,734] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:30,734] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:30,734] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:30,734] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:30,747] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:30,754] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:29:30,760] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:30,765] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:29:30,770] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:30,771] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:30,775] INFO Socket connection established, initiating session, client: /127.0.0.1:57886, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:30,781] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0024, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:30,785] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:29:30,859] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:29:31,003] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:29:31,009] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:29:31,063] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:29:31,074] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:29:31,130] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:31,131] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:31,133] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:31,136] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:31,184] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:29:31,189] INFO Skipping recovery for all logs in /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:29:31,274] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:31,298] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-21, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 94ms (1/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:29:31,321] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 17940 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:31,321] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 17940 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:31,323] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs/__consumer_offsets-39/00000000000000017940.snapshot,17940)' (kafka.log.ProducerStateManager)
[2022-05-15 17:29:31,328] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 17940 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:31,332] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-39, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=17940) with 1 segments in 32ms (2/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:29:31,338] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:31,341] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-15, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (3/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:29:31,345] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:31,350] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-1.a6c0650b6e654f7092607cf0761da921-delete, topicId=xTEC6a39TDqg-PYWlqZkOA, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (4/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:29:31,356] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:31,359] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-45, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (5/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:29:31,364] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:31,367] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-33, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:29:31,373] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:31,376] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-2.7d0b160025f84ef5806466f0fea4543f-delete, topicId=xTEC6a39TDqg-PYWlqZkOA, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (7/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:29:31,381] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:31,386] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-27, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (8/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:29:31,392] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:31,395] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-3, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (9/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:29:31,400] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:31,404] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-9, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:29:31,408] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:31,412] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-5.f13da2e57509470984af3924ef0f4a15-delete, topicId=xTEC6a39TDqg-PYWlqZkOA, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (11/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:29:31,416] INFO Loaded 11 logs in 232ms. (kafka.log.LogManager)
[2022-05-15 17:29:31,417] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:29:31,419] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:29:31,715] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:31,870] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:29:31,875] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-15 17:29:31,901] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:29:31,909] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:31,925] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:31,926] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:31,927] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:31,928] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:31,941] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:29:31,994] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:29:32,015] INFO Stat of the created znode at /brokers/ids/0 is: 1712,1712,1652632172007,1652632172007,1,0,0,72057641293905956,192,0,1712
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:29:32,016] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://joao:9092, czxid (broker epoch): 1712 (kafka.zk.KafkaZkClient)
[2022-05-15 17:29:32,083] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:32,089] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:32,090] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:32,107] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:32,139] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:32,158] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:29:32,163] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:29:32,163] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:29:32,195] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:32,219] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:29:32,243] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:29:32,250] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:29:32,251] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:29:32,258] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:29:32,258] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:29:32,258] INFO Kafka startTimeMs: 1652632172252 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:29:32,262] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-15 17:29:32,313] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:32,326] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:32,357] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:32,357] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:32,357] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 17940 (kafka.cluster.Partition)
[2022-05-15 17:29:32,357] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:32,357] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:32,357] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:32,357] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:32,357] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:32,441] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-3, __consumer_offsets-15, __consumer_offsets-39, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:29:32,478] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:32,480] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:32,481] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:32,482] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:32,482] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:32,482] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:32,482] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:32,482] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:32,482] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:32,482] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:32,482] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:32,482] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:32,482] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:32,482] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:32,482] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 8 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:32,482] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 8 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:32,494] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 13 milliseconds for epoch 8, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:32,495] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 13 milliseconds for epoch 8, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:32,592] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 110 milliseconds for epoch 8, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:32,593] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 111 milliseconds for epoch 8, of which 111 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:32,594] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 112 milliseconds for epoch 8, of which 112 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:32,594] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 112 milliseconds for epoch 8, of which 112 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:32,595] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 113 milliseconds for epoch 8, of which 113 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:32,595] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 113 milliseconds for epoch 8, of which 113 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:34,960] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:29:35,239] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:29:35,327] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:29:35,330] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:29:35,331] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:29:35,347] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:29:35,352] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:35,352] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:35,352] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:35,352] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:35,353] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:35,353] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:35,353] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:35,353] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:35,353] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:35,353] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:35,353] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:35,353] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:35,353] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:35,353] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:35,353] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:35,353] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:35,353] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:35,353] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:35,355] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:35,360] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:29:35,365] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:35,377] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:29:35,384] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:35,385] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:35,389] INFO Socket connection established, initiating session, client: /127.0.0.1:57888, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:35,396] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0025, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:35,400] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:29:35,476] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:29:35,612] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:29:35,617] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:29:35,663] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:29:35,672] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:29:35,721] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:35,722] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:35,723] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:35,725] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:35,765] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:29:35,770] INFO Skipping recovery for all logs in /tmp/kafka-logs-1 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:29:35,842] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:35,866] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-17, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 81ms (1/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:29:35,871] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:35,874] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-35, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (2/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:29:35,879] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:35,885] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-2.7e4885ff8aa446aebe7c54199e95a4dd-delete, topicId=xTEC6a39TDqg-PYWlqZkOA, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (3/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:29:35,890] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:35,893] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-41, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:29:35,898] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:35,901] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-29, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:29:35,906] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:35,909] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-11, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (6/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:29:35,913] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:35,918] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-23, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:29:35,922] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:35,924] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-5.a185b53ae02649a19418146e158b88ca-delete, topicId=xTEC6a39TDqg-PYWlqZkOA, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (8/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:29:35,928] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:35,931] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-47, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (9/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:29:35,935] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:35,938] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-4.83c89ac4dc374f3e9a429ac6e7b21d52-delete, topicId=xTEC6a39TDqg-PYWlqZkOA, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:29:35,943] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:35,947] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-5, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (11/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:29:35,951] INFO Loaded 11 logs in 186ms. (kafka.log.LogManager)
[2022-05-15 17:29:35,952] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:29:35,953] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:29:36,211] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:36,348] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:29:36,352] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-15 17:29:36,378] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:29:36,385] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:36,401] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:36,402] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:36,405] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:36,406] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:36,417] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:29:36,481] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:29:36,504] INFO Stat of the created znode at /brokers/ids/1 is: 1780,1780,1652632176496,1652632176496,1,0,0,72057641293905957,192,0,1780
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:29:36,506] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://joao:9093, czxid (broker epoch): 1780 (kafka.zk.KafkaZkClient)
[2022-05-15 17:29:36,596] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:36,600] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:36,602] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:36,619] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:36,631] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:36,657] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:29:36,662] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:29:36,662] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:29:36,688] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:36,706] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:29:36,729] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:29:36,735] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:29:36,735] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:29:36,740] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:29:36,740] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:29:36,740] INFO Kafka startTimeMs: 1652632176735 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:29:36,743] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-15 17:29:36,825] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:36,844] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:36,845] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:36,845] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:36,845] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:36,845] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:36,846] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:36,846] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:36,846] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:36,874] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-5, __consumer_offsets-29, __consumer_offsets-41, __consumer_offsets-23) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:29:36,889] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:36,908] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 17 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:36,909] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 17 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:36,911] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 17 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:36,911] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 17 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:36,911] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 17 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:36,911] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 17 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:36,911] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 17 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:36,911] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 17 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:36,912] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 17 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:36,912] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 17 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:36,912] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 17 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:36,912] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 17 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:36,912] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 17 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:36,912] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 17 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:36,912] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 17 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:36,912] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 17 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:36,920] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 11 milliseconds for epoch 17, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:36,921] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 10 milliseconds for epoch 17, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:36,922] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 11 milliseconds for epoch 17, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:36,922] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 11 milliseconds for epoch 17, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:36,922] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 10 milliseconds for epoch 17, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:36,923] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 11 milliseconds for epoch 17, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:36,923] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 11 milliseconds for epoch 17, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:36,923] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 11 milliseconds for epoch 17, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:40,196] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:29:40,457] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:29:40,536] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:29:40,540] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:29:40,540] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:29:40,556] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:29:40,562] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:40,562] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:40,562] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:40,562] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:40,562] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:40,562] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:40,562] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:40,563] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:40,563] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:40,563] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:40,563] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:40,563] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:40,563] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:40,563] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:40,563] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:40,563] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:40,563] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:40,563] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:40,573] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:40,579] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:29:40,584] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:40,587] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:29:40,592] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:40,593] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:40,598] INFO Socket connection established, initiating session, client: /127.0.0.1:57890, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:40,605] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0026, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:40,609] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:29:40,685] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:29:40,815] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:29:40,820] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:29:40,875] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:29:40,885] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:29:40,938] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:40,939] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:40,942] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:40,943] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:40,981] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:29:40,985] INFO Skipping recovery for all logs in /tmp/kafka-logs-2 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:29:41,055] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:41,081] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-49, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 81ms (1/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:29:41,087] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:41,092] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-19, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (2/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:29:41,097] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:41,101] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-7, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (3/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:29:41,105] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:41,109] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-3.390c3b5aff684938883eb02f72ba5bfa-delete, topicId=xTEC6a39TDqg-PYWlqZkOA, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:29:41,115] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:41,118] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-13, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (5/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:29:41,123] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:41,126] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-37, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:29:41,131] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:41,134] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-43, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:29:41,140] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:41,146] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-1, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (8/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:29:41,151] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:41,153] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-0.3eb39b1ee826495898bb80fc9915a4d7-delete, topicId=xTEC6a39TDqg-PYWlqZkOA, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (9/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:29:41,158] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:41,162] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-5.be3052791bcd4039a7edf1eae9df8482-delete, topicId=xTEC6a39TDqg-PYWlqZkOA, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (10/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:29:41,167] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:41,171] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-31, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (11/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:29:41,177] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:41,182] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-25, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (12/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:29:41,184] INFO Loaded 12 logs in 203ms. (kafka.log.LogManager)
[2022-05-15 17:29:41,185] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:29:41,186] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:29:41,442] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:41,571] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:29:41,574] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-15 17:29:41,606] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:29:41,616] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:41,632] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:41,634] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:41,635] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:41,637] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:41,650] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:29:41,719] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:29:41,736] INFO Stat of the created znode at /brokers/ids/2 is: 1804,1804,1652632181728,1652632181728,1,0,0,72057641293905958,192,0,1804
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:29:41,738] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://joao:9094, czxid (broker epoch): 1804 (kafka.zk.KafkaZkClient)
[2022-05-15 17:29:41,806] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:41,813] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:41,814] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:41,827] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:41,837] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:41,863] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:29:41,866] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:29:41,867] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:29:41,890] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:41,905] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:29:41,926] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:29:41,930] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:29:41,931] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:29:41,935] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:29:41,936] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:29:41,936] INFO Kafka startTimeMs: 1652632181931 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:29:41,938] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-15 17:29:42,021] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:42,029] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:42,030] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:42,030] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:42,030] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:42,030] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:42,031] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:42,031] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:42,031] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:42,031] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:42,056] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:42,060] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-7, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:29:42,097] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:42,099] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:42,100] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:42,101] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:42,101] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:42,101] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:42,101] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:42,101] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:42,101] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:42,101] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:42,101] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:42,101] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:42,101] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:42,101] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:42,101] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:42,101] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:42,101] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:42,101] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:42,108] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 7 milliseconds for epoch 16, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:42,109] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 8 milliseconds for epoch 16, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:42,109] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 8 milliseconds for epoch 16, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:42,110] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 9 milliseconds for epoch 16, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:42,110] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 9 milliseconds for epoch 16, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:42,111] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 10 milliseconds for epoch 16, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:42,111] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 10 milliseconds for epoch 16, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:42,111] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 10 milliseconds for epoch 16, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:42,112] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 11 milliseconds for epoch 16, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:45,154] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:29:45,412] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:29:45,491] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:29:45,493] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:29:45,494] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:29:45,508] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:29:45,513] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:45,513] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:45,513] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:45,513] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:45,513] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:45,513] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:45,514] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:45,514] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:45,514] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:45,514] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:45,514] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:45,514] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:45,514] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:45,514] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:45,514] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:45,514] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:45,514] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:45,514] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:45,516] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:45,519] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:29:45,525] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:45,537] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:29:45,543] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:45,544] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:45,547] INFO Socket connection established, initiating session, client: /127.0.0.1:57892, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:45,554] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0027, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:45,559] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:29:45,632] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:29:45,759] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:29:45,766] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:29:45,818] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:29:45,826] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:29:45,877] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:45,878] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:45,880] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:45,883] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:45,921] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:29:45,925] INFO Skipping recovery for all logs in /tmp/kafka-logs-3 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:29:45,999] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:46,024] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-14, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 86ms (1/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:29:46,045] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Loading producer state till offset 28503 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:46,045] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Reloading from producer snapshot and rebuilding producer state from offset 28503 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:46,047] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-3/__consumer_offsets-38/00000000000000028503.snapshot,28503)' (kafka.log.ProducerStateManager)
[2022-05-15 17:29:46,053] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Producer state recovery took 8ms for snapshot load and 0ms for segment recovery from offset 28503 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:46,057] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-38, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=28503) with 1 segments in 32ms (2/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:29:46,062] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:46,065] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-1.242bc8959ac1446dbb0159c1038afec4-delete, topicId=xTEC6a39TDqg-PYWlqZkOA, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (3/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:29:46,070] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:46,076] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-8, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (4/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:29:46,082] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:46,085] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-2, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (5/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:29:46,090] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:46,093] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-4.c9027c94fec749cea2e9a44ae4d7b2b5-delete, topicId=xTEC6a39TDqg-PYWlqZkOA, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:29:46,097] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:46,100] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-26, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:29:46,105] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:46,109] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-20, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (8/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:29:46,114] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:46,116] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-32, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (9/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:29:46,122] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:46,125] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-0.ee157d8decf944c48301ee28c5a8cafe-delete, topicId=xTEC6a39TDqg-PYWlqZkOA, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (10/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:29:46,129] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:46,132] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-44, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:29:46,136] INFO Loaded 11 logs in 214ms. (kafka.log.LogManager)
[2022-05-15 17:29:46,137] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:29:46,138] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:29:46,400] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:46,516] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:29:46,519] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-05-15 17:29:46,546] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:29:46,553] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:46,572] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:46,573] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:46,576] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:46,577] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:46,588] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:29:46,648] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:29:46,669] INFO Stat of the created znode at /brokers/ids/3 is: 1829,1829,1652632186661,1652632186661,1,0,0,72057641293905959,192,0,1829
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:29:46,670] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://joao:9095, czxid (broker epoch): 1829 (kafka.zk.KafkaZkClient)
[2022-05-15 17:29:46,735] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:46,740] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:46,742] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:46,757] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:46,768] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:46,796] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:29:46,800] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:29:46,800] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:29:46,824] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:46,843] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:29:46,863] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:29:46,871] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:29:46,871] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:29:46,877] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:29:46,878] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:29:46,878] INFO Kafka startTimeMs: 1652632186871 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:29:46,880] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-05-15 17:29:46,958] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:46,986] INFO [Partition __consumer_offsets-2 broker=3] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:46,986] INFO [Partition __consumer_offsets-20 broker=3] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:46,987] INFO [Partition __consumer_offsets-38 broker=3] Log loaded for partition __consumer_offsets-38 with initial high watermark 28503 (kafka.cluster.Partition)
[2022-05-15 17:29:46,987] INFO [Partition __consumer_offsets-8 broker=3] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:46,988] INFO [Partition __consumer_offsets-26 broker=3] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:46,988] INFO [Partition __consumer_offsets-44 broker=3] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:46,989] INFO [Partition __consumer_offsets-14 broker=3] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:46,989] INFO [Partition __consumer_offsets-32 broker=3] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:47,010] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:47,013] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-26, __consumer_offsets-32, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:29:47,046] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 2 in epoch 17 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:47,047] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 17 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:47,050] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 20 in epoch 17 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:47,050] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 17 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:47,050] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 38 in epoch 17 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:47,050] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 17 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:47,050] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 8 in epoch 17 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:47,050] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 17 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:47,050] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 26 in epoch 17 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:47,050] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 17 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:47,050] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 44 in epoch 17 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:47,050] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 17 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:47,051] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 14 in epoch 17 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:47,051] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 17 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:47,051] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 32 in epoch 17 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:47,051] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 17 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:47,058] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-2 in 9 milliseconds for epoch 17, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:47,059] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-20 in 9 milliseconds for epoch 17, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:47,154] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-38 in 104 milliseconds for epoch 17, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:47,154] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-8 in 104 milliseconds for epoch 17, of which 104 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:47,155] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-26 in 105 milliseconds for epoch 17, of which 105 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:47,155] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-44 in 104 milliseconds for epoch 17, of which 104 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:47,156] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-14 in 105 milliseconds for epoch 17, of which 104 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:47,156] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-32 in 105 milliseconds for epoch 17, of which 105 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:50,291] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:29:50,542] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:29:50,621] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:29:50,624] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:29:50,624] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:29:50,639] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:29:50,644] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:50,644] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:50,644] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:50,644] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:50,644] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:50,644] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:50,645] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:50,645] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:50,645] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:50,645] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:50,645] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:50,645] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:50,646] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:50,646] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:50,646] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:50,646] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:50,646] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:50,646] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:50,656] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:50,660] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:29:50,666] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:50,671] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:29:50,676] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:50,678] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:50,682] INFO Socket connection established, initiating session, client: /127.0.0.1:57894, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:50,690] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0028, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:50,694] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:29:50,764] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:29:50,890] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:29:50,895] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:29:50,943] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:29:50,951] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:29:50,998] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:50,999] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:51,001] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:51,003] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:51,043] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:29:51,047] INFO Skipping recovery for all logs in /tmp/kafka-logs-4 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:29:51,120] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:51,144] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-24, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 84ms (1/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:29:51,150] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:51,155] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-12, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (2/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:29:51,159] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:51,162] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-3.46cdd7e41b9a4345a8d782bed89e00c7-delete, topicId=xTEC6a39TDqg-PYWlqZkOA, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (3/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:29:51,166] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:51,171] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-30, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:29:51,176] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:51,178] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-4.93d9b79dde634583a9b12166fe46ac12-delete, topicId=xTEC6a39TDqg-PYWlqZkOA, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:29:51,183] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:51,187] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-36, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (6/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:29:51,191] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:51,195] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-42, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:29:51,199] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:51,204] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-0, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (8/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:29:51,210] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:51,212] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-18, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:29:51,216] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:51,219] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-6, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (10/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:29:51,223] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:51,226] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-48, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:29:51,232] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:51,235] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-1.58d75da0aea84d2493dde5bb67a166dd-delete, topicId=xTEC6a39TDqg-PYWlqZkOA, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (12/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:29:51,239] INFO Loaded 12 logs in 196ms. (kafka.log.LogManager)
[2022-05-15 17:29:51,240] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:29:51,241] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:29:51,486] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:51,606] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:29:51,610] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.Acceptor)
[2022-05-15 17:29:51,640] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:29:51,646] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:51,662] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:51,663] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:51,665] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:51,666] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:51,680] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:29:51,748] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:29:51,765] INFO Stat of the created znode at /brokers/ids/4 is: 1853,1853,1652632191758,1652632191758,1,0,0,72057641293905960,192,0,1853
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:29:51,767] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://joao:9096, czxid (broker epoch): 1853 (kafka.zk.KafkaZkClient)
[2022-05-15 17:29:51,836] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:51,841] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:51,842] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:51,856] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:51,869] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:51,895] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:29:51,899] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:29:51,899] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:29:51,923] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:51,941] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:29:51,959] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:29:51,964] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:29:51,964] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:29:51,970] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:29:51,970] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:29:51,970] INFO Kafka startTimeMs: 1652632191965 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:29:51,974] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2022-05-15 17:29:52,051] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:52,083] INFO [Partition __consumer_offsets-18 broker=4] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:52,083] INFO [Partition __consumer_offsets-36 broker=4] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:52,083] INFO [Partition __consumer_offsets-6 broker=4] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:52,083] INFO [Partition __consumer_offsets-24 broker=4] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:52,083] INFO [Partition __consumer_offsets-42 broker=4] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:52,084] INFO [Partition __consumer_offsets-12 broker=4] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:52,084] INFO [Partition __consumer_offsets-30 broker=4] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:52,084] INFO [Partition __consumer_offsets-0 broker=4] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:52,084] INFO [Partition __consumer_offsets-48 broker=4] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:52,095] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:52,110] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-12, __consumer_offsets-42, __consumer_offsets-18) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:29:52,148] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 18 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:52,150] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:52,152] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 36 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:52,153] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:52,153] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 6 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:52,153] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:52,153] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 24 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:52,153] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:52,153] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 42 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:52,153] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:52,153] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 12 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:52,153] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:52,153] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 30 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:52,154] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:52,154] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 0 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:52,154] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:52,154] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 48 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:52,154] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:52,159] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-18 in 8 milliseconds for epoch 16, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:52,160] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-36 in 7 milliseconds for epoch 16, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:52,160] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-6 in 7 milliseconds for epoch 16, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:52,160] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-24 in 7 milliseconds for epoch 16, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:52,161] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-42 in 8 milliseconds for epoch 16, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:52,161] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-12 in 8 milliseconds for epoch 16, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:52,162] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-30 in 8 milliseconds for epoch 16, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:52,162] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-0 in 8 milliseconds for epoch 16, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:52,162] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-48 in 8 milliseconds for epoch 16, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:55,134] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:29:55,389] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:29:55,463] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:29:55,466] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:29:55,467] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:29:55,480] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:29:55,488] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:55,488] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:55,488] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:55,488] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:55,488] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:55,488] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:55,489] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:55,489] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:55,489] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:55,489] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:55,489] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:55,489] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:55,489] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:55,489] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:55,489] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:55,489] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:55,489] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:55,489] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:55,491] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:29:55,495] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:29:55,507] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:55,510] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:29:55,516] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:55,518] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:55,525] INFO Socket connection established, initiating session, client: /127.0.0.1:57896, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:55,531] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0029, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:29:55,535] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:29:55,613] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:29:55,743] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:29:55,750] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:29:55,797] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:29:55,808] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:29:55,856] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:55,858] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:55,859] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:55,861] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:29:55,895] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:29:55,898] INFO Skipping recovery for all logs in /tmp/kafka-logs-5 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:29:55,962] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:55,987] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-3.b4eddb78e45f47e49b323699fc04fa72-delete, topicId=xTEC6a39TDqg-PYWlqZkOA, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 73ms (1/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:29:55,999] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:56,003] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-46, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (2/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:29:56,007] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:56,011] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-10, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (3/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:29:56,014] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:56,019] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-28, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:29:56,023] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:56,026] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-0.8c52cdfd8f4f4575b395ac7abb9f8e56-delete, topicId=xTEC6a39TDqg-PYWlqZkOA, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (5/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:29:56,038] INFO Deleted producer state snapshot /tmp/kafka-logs-5/__consumer_offsets-22/00000000000000000058.snapshot (kafka.log.SnapshotFile)
[2022-05-15 17:29:56,040] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Loading producer state till offset 6389 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:56,040] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 6389 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:56,041] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-22/00000000000000006389.snapshot,6389)' (kafka.log.ProducerStateManager)
[2022-05-15 17:29:56,046] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 6389 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:56,049] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-22, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=6389) with 1 segments in 22ms (6/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:29:56,055] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:56,059] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-16, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (7/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:29:56,063] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:56,065] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-2.286aace4d4c5418ab22fecd9b2088078-delete, topicId=xTEC6a39TDqg-PYWlqZkOA, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (8/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:29:56,073] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Loading producer state till offset 18252 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:56,074] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 18252 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:56,074] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-40/00000000000000018252.snapshot,18252)' (kafka.log.ProducerStateManager)
[2022-05-15 17:29:56,074] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 18252 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:56,076] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-40, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=18252) with 1 segments in 11ms (9/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:29:56,081] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:56,084] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-34, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (10/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:29:56,089] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:29:56,091] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-4, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:29:56,094] INFO Loaded 11 logs in 199ms. (kafka.log.LogManager)
[2022-05-15 17:29:56,095] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:29:56,096] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:29:56,331] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:56,457] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:29:56,461] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.Acceptor)
[2022-05-15 17:29:56,493] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:29:56,499] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:56,518] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:56,519] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:56,521] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:56,522] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:56,536] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:29:56,600] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:29:56,619] INFO Stat of the created znode at /brokers/ids/5 is: 1878,1878,1652632196610,1652632196610,1,0,0,72057641293905961,192,0,1878
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:29:56,620] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://joao:9097, czxid (broker epoch): 1878 (kafka.zk.KafkaZkClient)
[2022-05-15 17:29:56,691] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:56,697] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:56,699] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:56,715] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:56,729] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:56,756] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:29:56,759] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:29:56,759] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:29:56,782] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:29:56,801] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:29:56,820] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:29:56,825] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:29:56,826] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:29:56,831] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:29:56,832] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:29:56,832] INFO Kafka startTimeMs: 1652632196826 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:29:56,833] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2022-05-15 17:29:56,904] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:56,942] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:29:56,946] INFO [Partition __consumer_offsets-34 broker=5] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:56,947] INFO [Partition __consumer_offsets-4 broker=5] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:56,947] INFO [Partition __consumer_offsets-22 broker=5] Log loaded for partition __consumer_offsets-22 with initial high watermark 6389 (kafka.cluster.Partition)
[2022-05-15 17:29:56,947] INFO [Partition __consumer_offsets-40 broker=5] Log loaded for partition __consumer_offsets-40 with initial high watermark 18252 (kafka.cluster.Partition)
[2022-05-15 17:29:56,947] INFO [Partition __consumer_offsets-10 broker=5] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:56,948] INFO [Partition __consumer_offsets-28 broker=5] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:56,948] INFO [Partition __consumer_offsets-46 broker=5] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:56,949] INFO [Partition __consumer_offsets-16 broker=5] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:29:56,975] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:29:57,010] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 34 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:57,011] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:57,013] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 4 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:57,013] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:57,013] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 22 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:57,013] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:57,013] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 40 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:57,013] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:57,014] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 10 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:57,014] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:57,014] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 28 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:57,014] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:57,014] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 46 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:57,014] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:57,014] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 16 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:29:57,014] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:57,022] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-34 in 10 milliseconds for epoch 20, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:57,023] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-4 in 10 milliseconds for epoch 20, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:57,044] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-9fa5abef-fdc9-4c05-8f09-7f9780632837, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:29:57,056] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-ed3a6d0d-54c4-4b54-b4a4-a5d0ecba6f8e, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:29:57,057] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-1038faf2-d998-4707-9799-897de83d6136, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:29:57,057] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-b283a5ee-70be-4bf9-b41c-74e089f12e34, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:29:57,057] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-360d1581-f79b-41e6-82d3-fe3577615014, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:29:57,057] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-9e173d1e-b47a-4b16-9874-bf5d2688c730, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:29:57,057] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-81fafa38-80dc-43ea-ac6c-e398b06565dc, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:29:57,086] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-22 in 73 milliseconds for epoch 20, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:57,114] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-40 in 100 milliseconds for epoch 20, of which 73 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:57,114] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-10 in 100 milliseconds for epoch 20, of which 100 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:57,115] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-28 in 101 milliseconds for epoch 20, of which 100 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:57,116] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-46 in 102 milliseconds for epoch 20, of which 101 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:29:57,116] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-16 in 101 milliseconds for epoch 20, of which 101 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:30:00,587] INFO Creating topic Sensor with configuration {min.insync.replicas=2} and initial partition assignment HashMap(0 -> ArrayBuffer(5, 4, 1), 1 -> ArrayBuffer(4, 1, 2), 2 -> ArrayBuffer(1, 2, 3), 3 -> ArrayBuffer(2, 3, 0), 4 -> ArrayBuffer(3, 0, 5), 5 -> ArrayBuffer(0, 5, 4)) (kafka.zk.AdminZkClient)
[2022-05-15 17:30:00,637] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,638] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,639] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,641] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,641] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,642] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-4) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,654] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:30:00,654] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:30:00,654] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:30:00,655] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:30:00,659] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:30:00,658] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:30:00,661] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-4/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:30:00,661] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-1/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:30:00,663] INFO [Partition Sensor-1 broker=4] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 17:30:00,664] INFO [Partition Sensor-1 broker=4] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:30:00,663] INFO [Partition Sensor-2 broker=1] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 17:30:00,664] INFO [Partition Sensor-2 broker=1] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:30:00,664] INFO Created log for partition Sensor-5 in /tmp/kafka-logs/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:30:00,666] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-5/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:30:00,665] INFO [Partition Sensor-5 broker=0] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 17:30:00,666] INFO [Partition Sensor-5 broker=0] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:30:00,666] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-3/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:30:00,667] INFO [Partition Sensor-0 broker=5] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 17:30:00,669] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-2/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:30:00,669] INFO [Partition Sensor-0 broker=5] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:30:00,671] INFO [Partition Sensor-3 broker=2] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 17:30:00,671] INFO [Partition Sensor-3 broker=2] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:30:00,667] INFO [Partition Sensor-4 broker=3] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 17:30:00,672] INFO [Partition Sensor-4 broker=3] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:30:00,679] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:30:00,679] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:30:00,679] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:30:00,683] INFO Created log for partition Sensor-4 in /tmp/kafka-logs/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:30:00,683] INFO [Partition Sensor-4 broker=0] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 17:30:00,683] INFO [Partition Sensor-4 broker=0] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:30:00,683] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-4/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:30:00,684] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:30:00,684] INFO [Partition Sensor-5 broker=4] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 17:30:00,684] INFO [Partition Sensor-5 broker=4] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:30:00,686] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-5/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:30:00,686] INFO [Partition Sensor-4 broker=5] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 17:30:00,686] INFO [Partition Sensor-4 broker=5] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:30:00,687] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-1/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:30:00,688] INFO [Partition Sensor-0 broker=1] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 17:30:00,688] INFO [Partition Sensor-0 broker=1] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:30:00,690] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:30:00,690] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:30:00,692] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-3/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:30:00,692] INFO [Partition Sensor-3 broker=3] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 17:30:00,692] INFO [Partition Sensor-3 broker=3] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:30:00,692] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:30:00,692] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:30:00,693] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-2/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:30:00,694] INFO [Partition Sensor-2 broker=2] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 17:30:00,694] INFO [Partition Sensor-2 broker=2] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:30:00,695] INFO Created log for partition Sensor-3 in /tmp/kafka-logs/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:30:00,695] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-4/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:30:00,695] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:30:00,695] INFO [Partition Sensor-3 broker=0] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 17:30:00,695] INFO [Partition Sensor-0 broker=4] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 17:30:00,695] INFO [Partition Sensor-3 broker=0] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:30:00,695] INFO [Partition Sensor-0 broker=4] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:30:00,696] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(Sensor-4, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,696] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(Sensor-5, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,697] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:30:00,698] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-5/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:30:00,698] INFO [Partition Sensor-5 broker=5] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 17:30:00,698] INFO [Partition Sensor-5 broker=5] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:30:00,699] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(Sensor-4, Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,701] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-1/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:30:00,701] INFO [Partition Sensor-1 broker=1] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 17:30:00,701] INFO [Partition Sensor-1 broker=1] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:30:00,701] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,701] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:30:00,704] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-3/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:30:00,704] INFO [Partition Sensor-2 broker=3] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 17:30:00,705] INFO [Partition Sensor-2 broker=3] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:30:00,705] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,705] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:30:00,706] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-2/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:30:00,707] INFO [Partition Sensor-1 broker=2] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 17:30:00,707] INFO [Partition Sensor-1 broker=2] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:30:00,707] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,728] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,732] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,734] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions Map(Sensor-3 -> InitialFetchState(Some(lqj_eVvnQ1yZBBD5Vi-oZQ),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,741] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,742] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 4 for partitions Map(Sensor-1 -> InitialFetchState(Some(lqj_eVvnQ1yZBBD5Vi-oZQ),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,742] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 3 for partitions Map(Sensor-4 -> InitialFetchState(Some(lqj_eVvnQ1yZBBD5Vi-oZQ),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,742] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,743] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,742] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,745] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,746] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:30:00,746] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:30:00,747] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,748] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 5 for partitions Map(Sensor-0 -> InitialFetchState(Some(lqj_eVvnQ1yZBBD5Vi-oZQ),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,748] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 0 for partitions Map(Sensor-5 -> InitialFetchState(Some(lqj_eVvnQ1yZBBD5Vi-oZQ),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,748] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,749] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,750] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:30:00,750] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:30:00,751] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 4 for partitions Map(Sensor-1 -> InitialFetchState(Some(lqj_eVvnQ1yZBBD5Vi-oZQ),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,754] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,754] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 0 for partitions Map(Sensor-5 -> InitialFetchState(Some(lqj_eVvnQ1yZBBD5Vi-oZQ),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,754] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,757] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,757] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 5 for partitions Map(Sensor-0 -> InitialFetchState(Some(lqj_eVvnQ1yZBBD5Vi-oZQ),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,759] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:30:00,759] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,760] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,760] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,762] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,764] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:30:00,764] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:30:00,765] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 2 for partitions Map(Sensor-3 -> InitialFetchState(Some(lqj_eVvnQ1yZBBD5Vi-oZQ),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,759] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,766] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(Sensor-2 -> InitialFetchState(Some(lqj_eVvnQ1yZBBD5Vi-oZQ),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,767] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,767] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:30:00,767] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:30:00,770] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,770] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 1 for partitions Map(Sensor-2 -> InitialFetchState(Some(lqj_eVvnQ1yZBBD5Vi-oZQ),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,770] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,770] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,770] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 3 for partitions Map(Sensor-4 -> InitialFetchState(Some(lqj_eVvnQ1yZBBD5Vi-oZQ),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:30:00,770] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,770] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:30:00,772] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,777] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:30:00,777] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:30:00,868] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-3. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,869] WARN [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-4. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,888] WARN [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:00,909] WARN [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-0. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:30:31,352] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=157134, lastModifiedTime=1652631620696, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:30:31,353] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=157134, lastModifiedTime=1652631620696, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:30:31,356] INFO Deleted log /tmp/kafka-logs/Sensor-1.a6c0650b6e654f7092607cf0761da921-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:31,356] INFO Deleted offset index /tmp/kafka-logs/Sensor-1.a6c0650b6e654f7092607cf0761da921-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:31,359] INFO Deleted time index /tmp/kafka-logs/Sensor-1.a6c0650b6e654f7092607cf0761da921-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:31,364] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs/Sensor-1.a6c0650b6e654f7092607cf0761da921-delete. (kafka.log.LogManager)
[2022-05-15 17:30:31,376] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=157834, lastModifiedTime=1652631620672, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:30:31,377] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=157834, lastModifiedTime=1652631620672, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:30:31,379] INFO Deleted log /tmp/kafka-logs/Sensor-2.7d0b160025f84ef5806466f0fea4543f-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:31,379] INFO Deleted offset index /tmp/kafka-logs/Sensor-2.7d0b160025f84ef5806466f0fea4543f-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:31,380] INFO Deleted time index /tmp/kafka-logs/Sensor-2.7d0b160025f84ef5806466f0fea4543f-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:31,380] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs/Sensor-2.7d0b160025f84ef5806466f0fea4543f-delete. (kafka.log.LogManager)
[2022-05-15 17:30:31,413] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=78565, lastModifiedTime=1652631602627, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:30:31,414] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=78565, lastModifiedTime=1652631602627, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:30:31,414] INFO Deleted log /tmp/kafka-logs/Sensor-5.f13da2e57509470984af3924ef0f4a15-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:31,414] INFO Deleted offset index /tmp/kafka-logs/Sensor-5.f13da2e57509470984af3924ef0f4a15-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:31,414] INFO Deleted time index /tmp/kafka-logs/Sensor-5.f13da2e57509470984af3924ef0f4a15-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:31,415] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs/Sensor-5.f13da2e57509470984af3924ef0f4a15-delete. (kafka.log.LogManager)
[2022-05-15 17:30:35,890] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=157834, lastModifiedTime=1652631620668, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:30:35,892] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=157834, lastModifiedTime=1652631620668, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:30:35,896] INFO Deleted log /tmp/kafka-logs-1/Sensor-2.7e4885ff8aa446aebe7c54199e95a4dd-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:35,896] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-2.7e4885ff8aa446aebe7c54199e95a4dd-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:35,898] INFO Deleted time index /tmp/kafka-logs-1/Sensor-2.7e4885ff8aa446aebe7c54199e95a4dd-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:35,902] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-1/Sensor-2.7e4885ff8aa446aebe7c54199e95a4dd-delete. (kafka.log.LogManager)
[2022-05-15 17:30:35,925] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=78565, lastModifiedTime=1652631602627, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:30:35,926] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=78565, lastModifiedTime=1652631602627, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:30:35,927] INFO Deleted log /tmp/kafka-logs-1/Sensor-5.a185b53ae02649a19418146e158b88ca-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:35,929] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-5.a185b53ae02649a19418146e158b88ca-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:35,930] INFO Deleted time index /tmp/kafka-logs-1/Sensor-5.a185b53ae02649a19418146e158b88ca-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:35,930] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-1/Sensor-5.a185b53ae02649a19418146e158b88ca-delete. (kafka.log.LogManager)
[2022-05-15 17:30:35,938] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=71168, lastModifiedTime=1652631601135, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:30:35,938] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=71168, lastModifiedTime=1652631601135, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:30:35,939] INFO Deleted log /tmp/kafka-logs-1/Sensor-4.83c89ac4dc374f3e9a429ac6e7b21d52-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:35,939] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-4.83c89ac4dc374f3e9a429ac6e7b21d52-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:35,939] INFO Deleted time index /tmp/kafka-logs-1/Sensor-4.83c89ac4dc374f3e9a429ac6e7b21d52-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:35,940] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-1/Sensor-4.83c89ac4dc374f3e9a429ac6e7b21d52-delete. (kafka.log.LogManager)
[2022-05-15 17:30:41,113] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=164333, lastModifiedTime=1652631621360, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:30:41,114] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=164333, lastModifiedTime=1652631621360, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:30:41,118] INFO Deleted log /tmp/kafka-logs-2/Sensor-3.390c3b5aff684938883eb02f72ba5bfa-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:41,118] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-3.390c3b5aff684938883eb02f72ba5bfa-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:41,122] INFO Deleted time index /tmp/kafka-logs-2/Sensor-3.390c3b5aff684938883eb02f72ba5bfa-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:41,126] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-2/Sensor-3.390c3b5aff684938883eb02f72ba5bfa-delete. (kafka.log.LogManager)
[2022-05-15 17:30:41,154] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=155487, lastModifiedTime=1652631620052, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:30:41,155] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=155487, lastModifiedTime=1652631620052, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:30:41,156] INFO Deleted log /tmp/kafka-logs-2/Sensor-0.3eb39b1ee826495898bb80fc9915a4d7-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:41,157] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-0.3eb39b1ee826495898bb80fc9915a4d7-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:41,157] INFO Deleted time index /tmp/kafka-logs-2/Sensor-0.3eb39b1ee826495898bb80fc9915a4d7-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:41,158] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-2/Sensor-0.3eb39b1ee826495898bb80fc9915a4d7-delete. (kafka.log.LogManager)
[2022-05-15 17:30:41,163] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=78565, lastModifiedTime=1652631602627, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:30:41,163] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=78565, lastModifiedTime=1652631602627, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:30:41,164] INFO Deleted log /tmp/kafka-logs-2/Sensor-5.be3052791bcd4039a7edf1eae9df8482-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:41,165] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-5.be3052791bcd4039a7edf1eae9df8482-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:41,165] INFO Deleted time index /tmp/kafka-logs-2/Sensor-5.be3052791bcd4039a7edf1eae9df8482-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:41,166] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-2/Sensor-5.be3052791bcd4039a7edf1eae9df8482-delete. (kafka.log.LogManager)
[2022-05-15 17:30:46,075] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=157134, lastModifiedTime=1652631620696, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:30:46,077] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=157134, lastModifiedTime=1652631620696, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:30:46,082] INFO Deleted log /tmp/kafka-logs-3/Sensor-1.242bc8959ac1446dbb0159c1038afec4-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:46,082] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-1.242bc8959ac1446dbb0159c1038afec4-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:46,086] INFO Deleted time index /tmp/kafka-logs-3/Sensor-1.242bc8959ac1446dbb0159c1038afec4-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:46,091] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-3/Sensor-1.242bc8959ac1446dbb0159c1038afec4-delete. (kafka.log.LogManager)
[2022-05-15 17:30:46,094] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=71168, lastModifiedTime=1652631601131, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:30:46,095] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=71168, lastModifiedTime=1652631601131, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:30:46,096] INFO Deleted log /tmp/kafka-logs-3/Sensor-4.c9027c94fec749cea2e9a44ae4d7b2b5-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:46,096] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-4.c9027c94fec749cea2e9a44ae4d7b2b5-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:46,097] INFO Deleted time index /tmp/kafka-logs-3/Sensor-4.c9027c94fec749cea2e9a44ae4d7b2b5-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:46,097] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-3/Sensor-4.c9027c94fec749cea2e9a44ae4d7b2b5-delete. (kafka.log.LogManager)
[2022-05-15 17:30:46,126] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=155487, lastModifiedTime=1652631620052, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:30:46,126] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=155487, lastModifiedTime=1652631620052, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:30:46,128] INFO Deleted log /tmp/kafka-logs-3/Sensor-0.ee157d8decf944c48301ee28c5a8cafe-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:46,128] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-0.ee157d8decf944c48301ee28c5a8cafe-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:46,129] INFO Deleted time index /tmp/kafka-logs-3/Sensor-0.ee157d8decf944c48301ee28c5a8cafe-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:46,129] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-3/Sensor-0.ee157d8decf944c48301ee28c5a8cafe-delete. (kafka.log.LogManager)
[2022-05-15 17:30:51,166] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=164333, lastModifiedTime=1652631621364, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:30:51,167] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=164333, lastModifiedTime=1652631621364, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:30:51,170] INFO Deleted log /tmp/kafka-logs-4/Sensor-3.46cdd7e41b9a4345a8d782bed89e00c7-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:51,170] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-3.46cdd7e41b9a4345a8d782bed89e00c7-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:51,173] INFO Deleted time index /tmp/kafka-logs-4/Sensor-3.46cdd7e41b9a4345a8d782bed89e00c7-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:51,178] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-4/Sensor-3.46cdd7e41b9a4345a8d782bed89e00c7-delete. (kafka.log.LogManager)
[2022-05-15 17:30:51,179] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=71168, lastModifiedTime=1652631601135, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:30:51,179] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=71168, lastModifiedTime=1652631601135, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:30:51,180] INFO Deleted log /tmp/kafka-logs-4/Sensor-4.93d9b79dde634583a9b12166fe46ac12-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:51,180] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-4.93d9b79dde634583a9b12166fe46ac12-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:51,180] INFO Deleted time index /tmp/kafka-logs-4/Sensor-4.93d9b79dde634583a9b12166fe46ac12-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:51,181] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-4/Sensor-4.93d9b79dde634583a9b12166fe46ac12-delete. (kafka.log.LogManager)
[2022-05-15 17:30:51,236] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=157134, lastModifiedTime=1652631620692, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:30:51,236] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=157134, lastModifiedTime=1652631620692, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:30:51,237] INFO Deleted log /tmp/kafka-logs-4/Sensor-1.58d75da0aea84d2493dde5bb67a166dd-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:51,237] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-1.58d75da0aea84d2493dde5bb67a166dd-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:51,238] INFO Deleted time index /tmp/kafka-logs-4/Sensor-1.58d75da0aea84d2493dde5bb67a166dd-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:51,238] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-4/Sensor-1.58d75da0aea84d2493dde5bb67a166dd-delete. (kafka.log.LogManager)
[2022-05-15 17:30:55,986] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=164333, lastModifiedTime=1652631621364, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:30:55,988] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=164333, lastModifiedTime=1652631621364, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:30:55,991] INFO Deleted log /tmp/kafka-logs-5/Sensor-3.b4eddb78e45f47e49b323699fc04fa72-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:55,992] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-3.b4eddb78e45f47e49b323699fc04fa72-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:55,994] INFO Deleted time index /tmp/kafka-logs-5/Sensor-3.b4eddb78e45f47e49b323699fc04fa72-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:55,998] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-5/Sensor-3.b4eddb78e45f47e49b323699fc04fa72-delete. (kafka.log.LogManager)
[2022-05-15 17:30:56,027] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=155487, lastModifiedTime=1652631620048, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:30:56,027] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=155487, lastModifiedTime=1652631620048, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:30:56,028] INFO Deleted log /tmp/kafka-logs-5/Sensor-0.8c52cdfd8f4f4575b395ac7abb9f8e56-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:56,029] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-0.8c52cdfd8f4f4575b395ac7abb9f8e56-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:56,029] INFO Deleted time index /tmp/kafka-logs-5/Sensor-0.8c52cdfd8f4f4575b395ac7abb9f8e56-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:56,029] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-5/Sensor-0.8c52cdfd8f4f4575b395ac7abb9f8e56-delete. (kafka.log.LogManager)
[2022-05-15 17:30:56,066] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=157834, lastModifiedTime=1652631620672, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:30:56,066] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=157834, lastModifiedTime=1652631620672, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:30:56,067] INFO Deleted log /tmp/kafka-logs-5/Sensor-2.286aace4d4c5418ab22fecd9b2088078-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:56,067] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-2.286aace4d4c5418ab22fecd9b2088078-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:56,067] INFO Deleted time index /tmp/kafka-logs-5/Sensor-2.286aace4d4c5418ab22fecd9b2088078-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:30:56,068] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-5/Sensor-2.286aace4d4c5418ab22fecd9b2088078-delete. (kafka.log.LogManager)
[2022-05-15 17:31:42,414] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group consumer in Empty state. Created a new member id consumer-consumer-6-45d54f6e-f1d8-43f7-8ace-1db96ac0cfac and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:31:42,423] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group consumer in Empty state. Created a new member id consumer-consumer-3-a0d7c5c7-e384-4339-b0be-414878362e3e and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:31:42,429] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group consumer in Empty state. Created a new member id consumer-consumer-2-ee781f71-f1c3-46d7-bd93-d90a4fe359ff and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:31:42,430] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group consumer in Empty state. Created a new member id consumer-consumer-4-d15976bc-df63-4682-8583-fd67cbb1d9df and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:31:42,432] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group consumer in Empty state. Created a new member id consumer-consumer-1-0287b15c-1acd-4475-b9ce-b994aebeeff2 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:31:42,433] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group consumer in Empty state. Created a new member id consumer-consumer-5-78575c72-7be8-4563-b114-53b271a8ef70 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:31:42,472] INFO [GroupCoordinator 5]: Preparing to rebalance group consumer in state PreparingRebalance with old generation 0 (__consumer_offsets-22) (reason: Adding new member consumer-consumer-6-45d54f6e-f1d8-43f7-8ace-1db96ac0cfac with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:31:42,521] INFO [GroupCoordinator 5]: Stabilized group consumer generation 1 (__consumer_offsets-22) with 6 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:31:42,609] INFO [GroupCoordinator 5]: Assignment received from leader consumer-consumer-6-45d54f6e-f1d8-43f7-8ace-1db96ac0cfac for group consumer for generation 1. The group has 6 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:34:42,903] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:34:42,905] INFO [GroupCoordinator 4]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:34:42,905] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:34:42,905] INFO [GroupCoordinator 3]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:34:42,906] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:34:42,910] INFO [GroupCoordinator 5]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:34:42,937] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:42,937] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:42,937] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:42,937] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:42,937] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:42,937] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:42,937] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:42,937] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:42,940] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,941] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:42,943] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:42,944] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:42,944] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1199 due to node 0 being disconnected (elapsed time since creation: 181ms, elapsed time since send: 181ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:42,945] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,946] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,946] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,947] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,948] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:42,948] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,948] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:42,949] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:42,949] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:42,945] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=1846583890, epoch=1199) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:34:42,951] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,951] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,951] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1145 due to node 3 being disconnected (elapsed time since creation: 152ms, elapsed time since send: 152ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:42,952] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1888 due to node 1 being disconnected (elapsed time since creation: 314ms, elapsed time since send: 314ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:42,955] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,956] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:42,956] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:42,957] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,953] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=31140562, epoch=1888) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:34:42,957] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,953] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=260982605, epoch=1145) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:34:42,958] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,958] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,958] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,958] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,958] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,956] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:42,958] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:42,958] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:42,959] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1863 due to node 5 being disconnected (elapsed time since creation: 257ms, elapsed time since send: 257ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:42,958] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:42,960] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1863 due to node 5 being disconnected (elapsed time since creation: 258ms, elapsed time since send: 258ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:42,961] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1965 due to node 2 being disconnected (elapsed time since creation: 442ms, elapsed time since send: 442ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:42,960] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=1283389663, epoch=1863) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:34:42,961] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,962] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,962] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1965 due to node 2 being disconnected (elapsed time since creation: 427ms, elapsed time since send: 427ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:42,962] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=651846088, epoch=1963) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:34:42,963] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,963] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,964] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,960] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=1990868385, epoch=1861) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:34:42,964] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,964] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,965] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:42,965] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:42,965] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,965] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,965] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,964] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:42,962] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=519811719, epoch=1965) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:34:42,968] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:42,968] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1199 due to node 0 being disconnected (elapsed time since creation: 186ms, elapsed time since send: 186ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:42,968] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:42,968] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,968] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,969] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,968] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=1673143143, epoch=1199) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:34:42,970] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:42,970] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,971] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1145 due to node 3 being disconnected (elapsed time since creation: 171ms, elapsed time since send: 171ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:42,970] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,971] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1469185290, epoch=1143) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:34:42,971] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:42,972] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,972] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,972] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:42,974] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:42,975] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:42,981] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:42,982] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:42,985] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,986] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-4/Sensor-5.8dd36f04d1e74508ac2bc3547b94d36d-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:34:42,991] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-4/Sensor-0.7dd0040726864ca0b6fd4801081a2780-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:34:42,985] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:42,991] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1889 due to node 1 being disconnected (elapsed time since creation: 9ms, elapsed time since send: 9ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:42,991] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=1933762653, epoch=1889) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:34:42,992] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,992] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-2/Sensor-2.996712becfe04eb69e576ce2db27a1f1-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:34:42,992] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:34:42,993] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-1/Sensor-2.4a9de3d773964141a37cea605a0eb99b-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:34:42,994] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs/Sensor-4.c4d1c072989f4a46b97aff67ad218f7e-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:34:42,995] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-4/Sensor-1.bd59ec9c1b194ed79567b1c2faeef008-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:34:42,998] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-3/Sensor-4.0d580935c85546e28032d871d801960a-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:34:42,997] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-1/Sensor-0.39a7be63d9c7491eb2ded56aa41a9d35-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:34:42,998] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs/Sensor-5.61eae1a81f2546b4bd8024433c7730de-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:34:42,998] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-2/Sensor-3.6d337915b4fd455492d8a37c0c784468-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:34:43,001] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs/Sensor-3.6debb531955d4834aab4e2f5a82aef5f-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:34:43,001] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-1/Sensor-1.b26b3a06934e4e25831a69664d5640f2-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:34:43,002] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-2/Sensor-1.17a93e63d1af4c21b455a5ebfe075d05-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:34:43,002] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-3/Sensor-2.4e0c3f82a0a54d208c5f37bd5a59ae6f-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:34:43,004] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-5/Sensor-4.2dec1beb72394f4c978d3c4e146c5dac-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:34:43,005] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-3/Sensor-3.0ae2acd5da8645579e45a3fd6c1ec921-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:34:43,008] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-5/Sensor-5.f67a50a0eeba4eab8e8e15d2970eabca-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:34:43,011] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-5/Sensor-0.7f1445b26df5473ea45a53b0bfe0d848-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:34:46,281] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:34:46,281] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:34:46,281] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:34:46,282] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:34:46,281] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:34:46,285] INFO [KafkaServer id=5] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:34:46,287] INFO [KafkaServer id=5] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:34:46,289] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:34:46,290] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:34:46,290] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:34:46,291] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:34:46,292] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:34:46,292] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:34:46,292] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:34:46,292] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:34:46,295] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:34:46,295] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:34:46,298] INFO [KafkaServer id=4] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:34:46,317] INFO [KafkaServer id=5] Controlled shutdown request returned successfully after 21ms (kafka.server.KafkaServer)
[2022-05-15 17:34:46,319] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 20ms (kafka.server.KafkaServer)
[2022-05-15 17:34:46,321] INFO [KafkaServer id=3] Controlled shutdown request returned successfully after 20ms (kafka.server.KafkaServer)
[2022-05-15 17:34:46,322] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:34:46,323] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:34:46,323] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:34:46,323] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:34:46,324] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:34:46,324] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:34:46,324] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 19ms (kafka.server.KafkaServer)
[2022-05-15 17:34:46,325] INFO [KafkaServer id=4] Controlled shutdown request returned successfully after 16ms (kafka.server.KafkaServer)
[2022-05-15 17:34:46,325] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:34:46,326] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 18ms (kafka.server.KafkaServer)
[2022-05-15 17:34:46,326] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:34:46,326] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:34:46,326] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:34:46,326] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:34:46,328] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:34:46,328] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:34:46,329] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:34:46,330] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:34:46,330] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:34:46,332] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:34:46,332] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:34:46,333] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:34:46,332] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:34:46,333] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:34:46,333] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:34:46,335] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:34:46,336] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:34:46,348] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:34:46,351] INFO [data-plane Kafka Request Handler on Broker 5], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:34:46,351] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:34:46,354] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:34:46,354] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:34:46,357] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:34:46,358] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:34:46,358] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:34:46,360] INFO [data-plane Kafka Request Handler on Broker 5], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:34:46,360] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:34:46,360] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:34:46,360] INFO [data-plane Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:34:46,364] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:34:46,365] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,367] INFO [ExpirationReaper-5-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,367] INFO [data-plane Kafka Request Handler on Broker 4], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:34:46,367] INFO [data-plane Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:34:46,368] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:34:46,367] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:34:46,372] INFO [ExpirationReaper-3-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,374] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,374] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,375] INFO [data-plane Kafka Request Handler on Broker 4], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:34:46,378] INFO [ExpirationReaper-4-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,382] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,382] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,383] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:34:46,384] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,441] INFO [ExpirationReaper-4-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,441] INFO [ExpirationReaper-4-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,443] INFO [KafkaApi-4] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:34:46,444] INFO [ExpirationReaper-4-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,489] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,489] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,490] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,490] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,491] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:34:46,493] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,493] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:34:46,493] INFO [ExpirationReaper-4-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,493] INFO [ExpirationReaper-4-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,495] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:34:46,495] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:34:46,495] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:34:46,495] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:34:46,497] INFO [ExpirationReaper-5-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,497] INFO [ExpirationReaper-5-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,498] INFO [TransactionCoordinator id=4] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:34:46,498] INFO [KafkaApi-5] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:34:46,499] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:34:46,499] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,499] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,500] INFO [Transaction State Manager 4]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:34:46,500] INFO [Transaction Marker Channel Manager 4]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:34:46,500] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:34:46,500] INFO [Transaction Marker Channel Manager 4]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:34:46,500] INFO [Transaction Marker Channel Manager 4]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:34:46,501] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,501] INFO [ExpirationReaper-5-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,503] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:34:46,503] INFO [TransactionCoordinator id=4] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:34:46,504] INFO [GroupCoordinator 4]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:34:46,504] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:34:46,504] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:34:46,504] INFO [ExpirationReaper-4-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,504] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:34:46,504] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:34:46,506] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:34:46,507] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:34:46,508] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,537] INFO [ExpirationReaper-3-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,537] INFO [ExpirationReaper-3-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,538] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:34:46,540] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,549] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,550] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,550] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,564] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,564] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,566] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:34:46,568] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,575] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,575] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,576] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:34:46,578] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:34:46,579] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:34:46,579] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:34:46,579] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:34:46,580] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:46,581] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:46,582] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:46,583] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:46,583] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,597] INFO [ExpirationReaper-5-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,597] INFO [ExpirationReaper-5-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,600] INFO [TransactionCoordinator id=5] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:34:46,602] INFO [Transaction State Manager 5]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:34:46,602] INFO [Transaction Marker Channel Manager 5]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:34:46,603] INFO [Transaction Marker Channel Manager 5]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:34:46,602] INFO [Transaction Marker Channel Manager 5]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:34:46,605] INFO [TransactionCoordinator id=5] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:34:46,606] INFO [GroupCoordinator 5]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:34:46,607] INFO [ExpirationReaper-5-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,628] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,628] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,633] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:34:46,635] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:34:46,635] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:34:46,635] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:34:46,635] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:34:46,637] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:34:46,638] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:34:46,639] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,648] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,649] INFO [ExpirationReaper-5-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,648] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,649] INFO [ExpirationReaper-5-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,649] INFO [ExpirationReaper-5-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,649] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,670] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,670] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,675] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:34:46,676] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:34:46,676] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:34:46,678] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:34:46,678] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:34:46,680] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:34:46,682] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:34:46,683] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,692] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,692] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,693] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,696] INFO [ExpirationReaper-5-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,696] INFO [ExpirationReaper-5-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,697] INFO [GroupCoordinator 5]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:34:46,699] INFO [ReplicaManager broker=5] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:34:46,699] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:34:46,700] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:34:46,700] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:34:46,701] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,701] INFO [ReplicaFetcherManager on broker 5] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:46,701] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,702] INFO [ExpirationReaper-4-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,702] INFO [ExpirationReaper-4-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,702] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,703] INFO [ExpirationReaper-4-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,705] INFO [ReplicaFetcherManager on broker 5] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:46,705] INFO [ReplicaAlterLogDirsManager on broker 5] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:46,705] INFO [ReplicaAlterLogDirsManager on broker 5] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:46,706] INFO [ExpirationReaper-5-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,725] INFO [ExpirationReaper-4-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,725] INFO [ExpirationReaper-4-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,726] INFO [GroupCoordinator 4]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:34:46,727] INFO [ReplicaManager broker=4] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:34:46,727] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:34:46,727] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:34:46,728] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:34:46,728] INFO [ReplicaFetcherManager on broker 4] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:46,730] INFO [ReplicaFetcherManager on broker 4] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:46,730] INFO [ReplicaAlterLogDirsManager on broker 4] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:46,731] INFO [ReplicaAlterLogDirsManager on broker 4] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:46,731] INFO [ExpirationReaper-4-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,742] INFO [ExpirationReaper-4-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,742] INFO [ExpirationReaper-4-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,743] INFO [ExpirationReaper-4-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,752] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,752] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,753] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,788] INFO [ExpirationReaper-5-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,788] INFO [ExpirationReaper-5-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,789] INFO [ExpirationReaper-5-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,815] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,815] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,815] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,833] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,833] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,834] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,842] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,842] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,843] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:34:46,845] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:34:46,845] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:34:46,846] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:34:46,846] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:34:46,847] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:46,849] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:46,849] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:46,850] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:46,850] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,870] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,870] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,872] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:34:46,873] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:34:46,873] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:34:46,874] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:34:46,874] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:34:46,875] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:46,877] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:46,878] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:46,878] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:46,878] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,897] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,897] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,899] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:34:46,901] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:34:46,902] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:34:46,902] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:34:46,902] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:34:46,904] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:46,906] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:34:46,907] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:46,908] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:34:46,908] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,929] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,929] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,929] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,941] INFO [ExpirationReaper-4-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,941] INFO [ExpirationReaper-4-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,942] INFO [ExpirationReaper-4-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,944] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,944] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,945] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,947] INFO [ExpirationReaper-5-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,947] INFO [ExpirationReaper-5-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,949] INFO [ExpirationReaper-5-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,975] INFO [ExpirationReaper-4-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,976] INFO [ExpirationReaper-4-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,976] INFO [ExpirationReaper-4-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,996] INFO [ExpirationReaper-5-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,996] INFO [ExpirationReaper-5-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,997] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,997] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:46,997] INFO [ExpirationReaper-5-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,004] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:34:47,005] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,006] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,006] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,009] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:34:47,009] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,010] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,010] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,011] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:34:47,013] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:34:47,029] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,029] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,030] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,040] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:34:47,049] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,049] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,050] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,061] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:34:47,062] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:34:47,061] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:34:47,063] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:34:47,070] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,070] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,072] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,097] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,098] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,102] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:34:47,103] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,104] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,104] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,106] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:34:47,106] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,107] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,107] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,108] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:34:47,109] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:34:47,134] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:34:47,141] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,141] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,142] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,143] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:34:47,143] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:34:47,143] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:34:47,145] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:34:47,150] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,150] INFO [ExpirationReaper-4-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,150] INFO [ExpirationReaper-4-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,150] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,151] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,155] INFO [ReplicaManager broker=4] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:34:47,156] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,156] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,156] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,158] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:34:47,159] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,159] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,159] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,160] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:34:47,161] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:34:47,169] INFO EventThread shut down for session: 0x100000b00ad0024 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:34:47,169] INFO Session: 0x100000b00ad0024 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:47,172] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:34:47,172] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,183] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,183] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,183] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,191] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:34:47,197] INFO [ExpirationReaper-5-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,197] INFO [ExpirationReaper-5-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,202] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:34:47,203] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:34:47,203] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:34:47,204] INFO [ReplicaManager broker=5] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:34:47,205] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:34:47,205] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,206] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,206] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,209] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:34:47,211] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,211] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,211] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,212] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:34:47,213] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:34:47,217] INFO [Controller id=3, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,217] INFO [Controller id=3, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,217] INFO [Controller id=3, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,217] INFO [Controller id=3, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,217] INFO [Controller id=3, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,221] WARN [Controller id=3, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,221] WARN [Controller id=3, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,221] WARN [Controller id=3, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,221] WARN [Controller id=3, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,221] WARN [Controller id=3, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,223] INFO [Controller id=3, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,223] INFO [Controller id=3, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,223] INFO [Controller id=3, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,224] INFO [Controller id=3, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,224] INFO [Controller id=3, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,240] INFO [ProducerStateManager partition=__consumer_offsets-22] Wrote producer snapshot at offset 6390 with 0 producer ids in 4 ms. (kafka.log.ProducerStateManager)
[2022-05-15 17:34:47,242] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,242] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,243] INFO [ExpirationReaper-3-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,250] INFO Session: 0x100000b00ad0025 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:47,250] INFO EventThread shut down for session: 0x100000b00ad0025 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:34:47,253] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:34:47,253] INFO [ExpirationReaper-3-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,253] INFO [ExpirationReaper-3-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,254] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,258] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:34:47,258] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:34:47,260] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,260] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,260] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,264] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:34:47,265] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,265] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,266] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,267] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:34:47,269] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:34:47,271] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:34:47,272] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:34:47,272] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:34:47,273] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:34:47,307] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:34:47,307] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,307] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,308] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,311] INFO EventThread shut down for session: 0x100000b00ad0028 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:34:47,311] INFO Session: 0x100000b00ad0028 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:47,313] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:34:47,315] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,325] INFO [Controller id=3, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,325] INFO [Controller id=3, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,325] WARN [Controller id=3, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,325] INFO [Controller id=3, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,325] INFO [Controller id=3, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,325] INFO [Controller id=3, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,326] WARN [Controller id=3, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,326] WARN [Controller id=3, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,326] WARN [Controller id=3, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,325] WARN [Controller id=3, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,326] INFO [Controller id=3, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,327] INFO [Controller id=3, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,327] INFO [Controller id=3, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,327] INFO [Controller id=3, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,328] INFO [Controller id=3, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,341] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,341] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:34:47,346] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:34:47,346] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,347] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,348] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,350] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:34:47,351] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,352] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,352] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:34:47,353] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:34:47,354] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:34:47,379] INFO EventThread shut down for session: 0x100000b00ad0029 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:34:47,379] INFO Session: 0x100000b00ad0029 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:47,382] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:34:47,383] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,396] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:34:47,402] INFO [Controller id=3, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,407] INFO [Controller id=3, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,408] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:34:47,409] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:34:47,409] INFO [Controller id=3, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,409] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:34:47,412] INFO [Controller id=3, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:34:47,412] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:34:47,415] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:34:47,415] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:34:47,415] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:34:47,423] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:34:47,518] INFO Session: 0x100000b00ad0026 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:47,518] INFO EventThread shut down for session: 0x100000b00ad0026 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:34:47,521] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:34:47,523] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,528] INFO Session: 0x100000b00ad0027 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:47,528] INFO EventThread shut down for session: 0x100000b00ad0027 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:34:47,530] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:34:47,531] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,775] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,776] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,776] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,780] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,780] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,781] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,939] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,939] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,939] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,944] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,944] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,944] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,946] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,946] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,946] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,950] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,950] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:47,950] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,006] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,006] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,006] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,056] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,056] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,056] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,183] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,183] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,183] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,780] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,780] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,780] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,785] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,785] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,786] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:34:48,816] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:34:48,817] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:34:48,817] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:34:48,817] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:34:48,819] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:34:48,820] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:34:48,821] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:34:48,939] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,940] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,940] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,940] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,940] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,940] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,945] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,945] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,947] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:34:48,948] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,949] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:48,951] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:34:48,973] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:34:48,974] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:34:48,974] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:34:48,974] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:34:48,976] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:34:48,977] INFO App info kafka.server for 3 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:34:48,978] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:34:48,981] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:34:48,982] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:34:48,982] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:34:48,982] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:34:48,984] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:34:48,986] INFO App info kafka.server for 5 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:34:48,986] INFO [KafkaServer id=5] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:34:49,006] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:49,006] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:49,006] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:49,050] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:49,050] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:49,050] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:49,183] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:49,183] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:49,184] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:49,201] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:49,201] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:49,203] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:34:49,233] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:34:49,235] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:34:49,235] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:34:49,235] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:34:49,238] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:34:49,239] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:34:49,240] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:34:50,002] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:50,003] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:50,003] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:50,006] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:50,006] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:50,008] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:34:50,033] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:34:50,033] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:34:50,033] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:34:50,034] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:34:50,036] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:34:50,036] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:34:50,037] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:34:50,050] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:50,050] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:50,051] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:50,051] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:50,051] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:34:50,053] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:34:50,081] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:34:50,082] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:34:50,082] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:34:50,082] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:34:50,084] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:34:50,085] INFO App info kafka.server for 4 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:34:50,086] INFO [KafkaServer id=4] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:34:54,370] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:34:54,387] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:34:54,387] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:34:54,388] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:34:54,388] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:34:54,390] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 17:34:54,390] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 17:34:54,390] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 17:34:54,390] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-15 17:34:54,396] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-15 17:34:54,415] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:34:54,417] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:34:54,417] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:34:54,417] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:34:54,418] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:34:54,418] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-15 17:34:54,444] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@6156496 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-15 17:34:54,451] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 17:34:54,467] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,467] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,467] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,467] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,467] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,467] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,467] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,467] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,468] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,468] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,471] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,471] INFO Server environment:host.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,471] INFO Server environment:java.version=11.0.15 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,471] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,471] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,471] INFO Server environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,472] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,472] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,472] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,472] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,472] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,472] INFO Server environment:os.version=5.13.0-40-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,472] INFO Server environment:user.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,472] INFO Server environment:user.home=/home/joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,472] INFO Server environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,472] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,472] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,472] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,473] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,473] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,473] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,473] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,473] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,473] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,473] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,474] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-15 17:34:54,476] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,477] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,478] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 17:34:54,478] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 17:34:54,479] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:34:54,479] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:34:54,480] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:34:54,480] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:34:54,480] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:34:54,480] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:34:54,485] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,486] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,486] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:34:54,500] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 17:34:54,502] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 17:34:54,505] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 17:34:54,512] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 17:34:54,513] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:459)
	at java.base/sun.nio.ch.Net.bind(Net.java:448)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:676)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:158)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:112)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:67)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:140)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:90)
[2022-05-15 17:34:54,517] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-15 17:34:54,522] ERROR Exiting JVM with code 1 (org.apache.zookeeper.util.ServiceUtils)
[2022-05-15 17:34:59,278] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:34:59,549] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:34:59,640] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:34:59,644] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:34:59,645] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:34:59,659] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:34:59,663] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:59,664] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:59,664] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:59,664] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:59,664] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:59,664] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:59,664] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:59,665] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:59,665] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:59,665] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:59,665] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:59,665] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:59,665] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:59,665] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:59,665] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:59,665] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:59,665] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:59,665] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:59,668] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:34:59,673] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:34:59,679] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:34:59,690] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:34:59,695] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:34:59,696] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:34:59,700] INFO Socket connection established, initiating session, client: /127.0.0.1:57898, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:34:59,710] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad002a, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:34:59,714] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:34:59,783] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:34:59,931] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:34:59,936] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:34:59,981] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:34:59,989] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:35:00,037] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:00,039] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:00,041] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:00,044] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:00,083] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:35:00,087] INFO Skipping recovery for all logs in /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:35:00,160] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:00,182] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-21, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 82ms (1/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:35:00,187] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:00,191] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-5.61eae1a81f2546b4bd8024433c7730de-delete, topicId=lqj_eVvnQ1yZBBD5Vi-oZQ, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (2/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:35:00,196] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:00,200] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-3.6debb531955d4834aab4e2f5a82aef5f-delete, topicId=lqj_eVvnQ1yZBBD5Vi-oZQ, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (3/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:35:00,217] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 17940 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:00,217] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 17940 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:00,218] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs/__consumer_offsets-39/00000000000000017940.snapshot,17940)' (kafka.log.ProducerStateManager)
[2022-05-15 17:35:00,224] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 17940 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:00,227] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-39, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=17940) with 1 segments in 26ms (4/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:35:00,231] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:00,235] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-15, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:35:00,240] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:00,245] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-4.c4d1c072989f4a46b97aff67ad218f7e-delete, topicId=lqj_eVvnQ1yZBBD5Vi-oZQ, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (6/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:35:00,250] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:00,254] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-45, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:35:00,259] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:00,263] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-33, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (8/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:35:00,269] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:00,272] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-27, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (9/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:35:00,277] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:00,281] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-3, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (10/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:35:00,285] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:00,289] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-9, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (11/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:35:00,292] INFO Loaded 11 logs in 209ms. (kafka.log.LogManager)
[2022-05-15 17:35:00,293] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:35:00,295] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:35:00,565] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:00,722] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:35:00,726] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-15 17:35:00,750] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:35:00,758] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:00,779] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:00,781] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:00,782] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:00,783] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:00,797] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:35:00,854] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:35:00,876] INFO Stat of the created znode at /brokers/ids/0 is: 1973,1973,1652632500869,1652632500869,1,0,0,72057641293905962,192,0,1973
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:35:00,878] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://joao:9092, czxid (broker epoch): 1973 (kafka.zk.KafkaZkClient)
[2022-05-15 17:35:00,950] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:00,960] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:00,962] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:00,985] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:00,998] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:01,027] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:35:01,031] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:35:01,031] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:35:01,066] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:01,090] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:35:01,117] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:35:01,125] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:35:01,126] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:35:01,132] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:35:01,133] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:35:01,133] INFO Kafka startTimeMs: 1652632501126 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:35:01,137] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-15 17:35:01,163] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:01,176] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:01,231] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:01,231] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:01,232] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 17940 (kafka.cluster.Partition)
[2022-05-15 17:35:01,232] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:01,232] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:01,232] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:01,232] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:01,232] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:01,306] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-3, __consumer_offsets-15, __consumer_offsets-39, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:01,346] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 10 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:01,348] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 10 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:01,350] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 10 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:01,350] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 10 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:01,350] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 10 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:01,350] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 10 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:01,350] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 10 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:01,350] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 10 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:01,350] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 10 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:01,350] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 10 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:01,350] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 10 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:01,350] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 10 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:01,351] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 10 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:01,351] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 10 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:01,351] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 10 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:01,351] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 10 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:01,359] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 9 milliseconds for epoch 10, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:01,360] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 10 milliseconds for epoch 10, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:01,450] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 100 milliseconds for epoch 10, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:01,451] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 101 milliseconds for epoch 10, of which 100 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:01,452] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 102 milliseconds for epoch 10, of which 101 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:01,452] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 102 milliseconds for epoch 10, of which 102 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:01,453] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 102 milliseconds for epoch 10, of which 102 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:01,454] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 103 milliseconds for epoch 10, of which 103 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:04,102] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:35:04,378] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:35:04,464] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:35:04,467] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:35:04,467] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:35:04,487] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:35:04,492] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:04,492] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:04,492] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:04,492] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:04,492] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:04,492] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:04,493] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:04,493] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:04,493] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:04,493] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:04,493] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:04,493] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:04,493] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:04,493] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:04,493] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:04,493] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:04,493] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:04,493] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:04,496] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:04,499] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:35:04,505] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:04,518] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:35:04,523] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:04,523] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:04,528] INFO Socket connection established, initiating session, client: /127.0.0.1:57900, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:04,534] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad002b, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:04,540] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:35:04,617] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:35:04,753] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:35:04,758] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:35:04,807] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:35:04,815] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:35:04,866] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:04,867] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:04,869] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:04,870] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:04,905] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:35:04,911] INFO Skipping recovery for all logs in /tmp/kafka-logs-1 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:35:04,991] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:05,019] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-17, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 92ms (1/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:35:05,025] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:05,031] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-35, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (2/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:35:05,036] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:05,040] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-0.39a7be63d9c7491eb2ded56aa41a9d35-delete, topicId=lqj_eVvnQ1yZBBD5Vi-oZQ, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (3/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:35:05,045] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:05,050] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-2.4a9de3d773964141a37cea605a0eb99b-delete, topicId=lqj_eVvnQ1yZBBD5Vi-oZQ, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (4/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:35:05,054] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:05,058] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-41, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:35:05,064] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:05,067] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-29, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (6/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:35:05,074] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:05,079] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-11, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (7/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:35:05,084] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:05,088] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-23, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (8/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:35:05,093] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:05,096] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-47, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:35:05,101] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:05,105] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-5, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (10/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:35:05,110] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:05,112] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-1.b26b3a06934e4e25831a69664d5640f2-delete, topicId=lqj_eVvnQ1yZBBD5Vi-oZQ, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:35:05,116] INFO Loaded 11 logs in 210ms. (kafka.log.LogManager)
[2022-05-15 17:35:05,116] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:35:05,117] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:35:05,382] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:05,524] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:35:05,528] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-15 17:35:05,558] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:35:05,564] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:05,581] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:05,582] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:05,584] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:05,585] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:05,600] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:35:05,657] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:35:05,676] INFO Stat of the created znode at /brokers/ids/1 is: 2041,2041,1652632505667,1652632505667,1,0,0,72057641293905963,192,0,2041
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:35:05,678] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://joao:9093, czxid (broker epoch): 2041 (kafka.zk.KafkaZkClient)
[2022-05-15 17:35:05,749] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:05,755] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:05,756] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:05,771] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:05,785] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:05,812] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:35:05,816] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:35:05,816] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:35:05,843] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:05,858] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:35:05,882] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:35:05,887] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:35:05,887] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:35:05,892] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:35:05,892] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:35:05,892] INFO Kafka startTimeMs: 1652632505887 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:35:05,893] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-15 17:35:05,971] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:05,995] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:06,002] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:06,003] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:06,003] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:06,003] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:06,004] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:06,005] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:06,005] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:06,006] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:06,032] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-5, __consumer_offsets-29, __consumer_offsets-41, __consumer_offsets-23) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:06,069] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 19 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:06,070] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 19 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:06,072] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 19 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:06,072] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 19 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:06,073] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 19 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:06,073] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 19 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:06,073] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 19 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:06,073] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 19 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:06,073] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 19 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:06,073] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 19 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:06,073] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 19 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:06,074] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 19 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:06,074] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 19 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:06,074] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 19 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:06,074] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 19 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:06,074] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 19 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:06,081] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 10 milliseconds for epoch 19, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:06,082] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 9 milliseconds for epoch 19, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:06,083] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 9 milliseconds for epoch 19, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:06,083] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 10 milliseconds for epoch 19, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:06,083] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 10 milliseconds for epoch 19, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:06,083] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 9 milliseconds for epoch 19, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:06,083] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 9 milliseconds for epoch 19, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:06,083] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 9 milliseconds for epoch 19, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:09,375] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:35:09,657] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:35:09,742] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:35:09,745] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:35:09,745] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:35:09,760] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:35:09,765] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:09,765] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:09,765] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:09,765] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:09,765] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:09,766] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:09,766] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:09,766] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:09,766] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:09,766] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:09,766] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:09,766] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:09,766] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:09,766] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:09,766] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:09,766] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:09,767] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:09,767] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:09,771] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:09,776] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:35:09,782] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:09,794] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:35:09,799] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:09,799] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:09,806] INFO Socket connection established, initiating session, client: /127.0.0.1:57902, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:09,813] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad002c, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:09,818] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:35:09,891] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:35:10,022] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:35:10,028] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:35:10,074] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:35:10,082] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:35:10,129] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:10,130] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:10,132] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:10,134] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:10,174] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:35:10,178] INFO Skipping recovery for all logs in /tmp/kafka-logs-2 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:35:10,249] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:10,271] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-49, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 78ms (1/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:35:10,279] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:10,282] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-19, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (2/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:35:10,288] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:10,294] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-7, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (3/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:35:10,300] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:10,305] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-13, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (4/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:35:10,309] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:10,312] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-37, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (5/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:35:10,316] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:10,319] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-43, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (6/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:35:10,325] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:10,328] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-1, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:35:10,332] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:10,337] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-3.6d337915b4fd455492d8a37c0c784468-delete, topicId=lqj_eVvnQ1yZBBD5Vi-oZQ, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (8/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:35:10,343] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:10,345] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-31, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:35:10,349] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:10,353] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-1.17a93e63d1af4c21b455a5ebfe075d05-delete, topicId=lqj_eVvnQ1yZBBD5Vi-oZQ, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (10/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:35:10,357] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:10,359] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-25, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (11/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:35:10,365] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:10,370] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-2.996712becfe04eb69e576ce2db27a1f1-delete, topicId=lqj_eVvnQ1yZBBD5Vi-oZQ, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (12/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:35:10,373] INFO Loaded 12 logs in 199ms. (kafka.log.LogManager)
[2022-05-15 17:35:10,374] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:35:10,375] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:35:10,615] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:10,739] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:35:10,742] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-15 17:35:10,772] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:35:10,777] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:10,794] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:10,796] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:10,797] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:10,798] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:10,812] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:35:10,874] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:35:10,892] INFO Stat of the created znode at /brokers/ids/2 is: 2065,2065,1652632510885,1652632510885,1,0,0,72057641293905964,192,0,2065
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:35:10,893] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://joao:9094, czxid (broker epoch): 2065 (kafka.zk.KafkaZkClient)
[2022-05-15 17:35:10,956] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:10,961] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:10,962] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:10,978] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:10,991] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:11,011] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:35:11,021] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:35:11,021] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:35:11,047] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:11,065] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:35:11,086] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:35:11,091] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:35:11,092] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:35:11,097] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:35:11,097] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:35:11,097] INFO Kafka startTimeMs: 1652632511092 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:35:11,100] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-15 17:35:11,181] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:11,197] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:11,198] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:11,198] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:11,199] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:11,199] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:11,199] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:11,200] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:11,200] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:11,201] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:11,229] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:11,229] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-7, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:11,271] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:11,273] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:11,275] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:11,275] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:11,275] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:11,275] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:11,275] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:11,275] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:11,275] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:11,275] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:11,275] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:11,275] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:11,275] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:11,276] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:11,276] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:11,276] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:11,276] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:11,276] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:11,283] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 9 milliseconds for epoch 18, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:11,284] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 9 milliseconds for epoch 18, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:11,285] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 9 milliseconds for epoch 18, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:11,285] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 10 milliseconds for epoch 18, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:11,286] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 11 milliseconds for epoch 18, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:11,286] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 11 milliseconds for epoch 18, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:11,287] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 11 milliseconds for epoch 18, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:11,287] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 11 milliseconds for epoch 18, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:11,287] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 11 milliseconds for epoch 18, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:14,248] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:35:14,510] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:35:14,593] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:35:14,596] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:35:14,597] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:35:14,611] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:35:14,616] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:14,617] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:14,617] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:14,617] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:14,617] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:14,617] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:14,617] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:14,617] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:14,617] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:14,617] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:14,617] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:14,618] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:14,618] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:14,618] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:14,618] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:14,618] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:14,618] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:14,618] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:14,620] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:14,623] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:35:14,628] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:14,640] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:35:14,645] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:14,645] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:14,650] INFO Socket connection established, initiating session, client: /127.0.0.1:57904, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:14,658] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad002d, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:14,662] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:35:14,730] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:35:14,868] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:35:14,873] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:35:14,919] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:35:14,927] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:35:14,975] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:14,975] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:14,977] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:14,979] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:15,017] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:35:15,021] INFO Skipping recovery for all logs in /tmp/kafka-logs-3 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:35:15,098] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:15,122] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-14, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 88ms (1/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:35:15,127] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:15,131] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-4.0d580935c85546e28032d871d801960a-delete, topicId=lqj_eVvnQ1yZBBD5Vi-oZQ, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (2/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:35:15,146] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Loading producer state till offset 28503 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:15,146] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Reloading from producer snapshot and rebuilding producer state from offset 28503 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:15,149] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-3/__consumer_offsets-38/00000000000000028503.snapshot,28503)' (kafka.log.ProducerStateManager)
[2022-05-15 17:35:15,155] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Producer state recovery took 9ms for snapshot load and 0ms for segment recovery from offset 28503 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:15,160] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-38, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=28503) with 1 segments in 29ms (3/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:35:15,165] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:15,169] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-8, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (4/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:35:15,174] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:15,177] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-3.0ae2acd5da8645579e45a3fd6c1ec921-delete, topicId=lqj_eVvnQ1yZBBD5Vi-oZQ, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:35:15,183] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:15,186] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-2, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (6/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:35:15,191] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:15,194] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-26, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:35:15,198] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:15,200] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-20, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (8/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:35:15,207] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:15,210] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-32, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (9/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:35:15,215] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:15,219] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-2.4e0c3f82a0a54d208c5f37bd5a59ae6f-delete, topicId=lqj_eVvnQ1yZBBD5Vi-oZQ, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (10/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:35:15,223] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:15,226] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-44, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:35:15,230] INFO Loaded 11 logs in 212ms. (kafka.log.LogManager)
[2022-05-15 17:35:15,231] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:35:15,233] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:35:15,486] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:15,613] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:35:15,617] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-05-15 17:35:15,647] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:35:15,654] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:15,669] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:15,670] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:15,671] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:15,673] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:15,686] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:35:15,747] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:35:15,766] INFO Stat of the created znode at /brokers/ids/3 is: 2090,2090,1652632515758,1652632515758,1,0,0,72057641293905965,192,0,2090
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:35:15,767] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://joao:9095, czxid (broker epoch): 2090 (kafka.zk.KafkaZkClient)
[2022-05-15 17:35:15,843] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:15,850] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:15,851] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:15,865] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:15,889] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:15,906] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:35:15,911] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:35:15,911] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:35:15,941] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:15,963] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:35:15,981] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:35:15,987] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:35:15,987] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:35:15,991] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:35:15,991] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:35:15,992] INFO Kafka startTimeMs: 1652632515987 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:35:15,994] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-05-15 17:35:16,058] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:16,092] INFO [Partition __consumer_offsets-2 broker=3] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:16,093] INFO [Partition __consumer_offsets-20 broker=3] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:16,093] INFO [Partition __consumer_offsets-38 broker=3] Log loaded for partition __consumer_offsets-38 with initial high watermark 28503 (kafka.cluster.Partition)
[2022-05-15 17:35:16,094] INFO [Partition __consumer_offsets-8 broker=3] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:16,094] INFO [Partition __consumer_offsets-26 broker=3] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:16,095] INFO [Partition __consumer_offsets-44 broker=3] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:16,095] INFO [Partition __consumer_offsets-14 broker=3] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:16,095] INFO [Partition __consumer_offsets-32 broker=3] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:16,097] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:16,124] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-26, __consumer_offsets-32, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:16,155] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 2 in epoch 19 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:16,157] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 19 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:16,159] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 20 in epoch 19 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:16,159] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 19 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:16,159] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 38 in epoch 19 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:16,159] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 19 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:16,159] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 8 in epoch 19 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:16,159] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 19 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:16,159] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 26 in epoch 19 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:16,159] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 19 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:16,159] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 44 in epoch 19 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:16,159] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 19 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:16,159] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 14 in epoch 19 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:16,159] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 19 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:16,159] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 32 in epoch 19 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:16,159] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 19 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:16,169] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-2 in 10 milliseconds for epoch 19, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:16,170] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-20 in 11 milliseconds for epoch 19, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:16,257] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-38 in 98 milliseconds for epoch 19, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:16,258] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-8 in 99 milliseconds for epoch 19, of which 99 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:16,258] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-26 in 99 milliseconds for epoch 19, of which 99 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:16,258] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-44 in 99 milliseconds for epoch 19, of which 99 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:16,258] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-14 in 99 milliseconds for epoch 19, of which 99 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:16,259] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-32 in 100 milliseconds for epoch 19, of which 99 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:19,237] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:35:19,485] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:35:19,563] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:35:19,566] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:35:19,567] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:35:19,582] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:35:19,587] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:19,587] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:19,587] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:19,587] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:19,587] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:19,587] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:19,587] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:19,587] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:19,587] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:19,587] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:19,587] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:19,587] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:19,587] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:19,587] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:19,588] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:19,588] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:19,588] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:19,588] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:19,598] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:19,603] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:35:19,607] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:19,612] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:35:19,618] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:19,619] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:19,623] INFO Socket connection established, initiating session, client: /127.0.0.1:57906, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:19,632] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad002e, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:19,637] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:35:19,706] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:35:19,841] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:35:19,846] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:35:19,895] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:35:19,903] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:35:19,947] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:19,949] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:19,950] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:19,951] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:19,987] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:35:19,991] INFO Skipping recovery for all logs in /tmp/kafka-logs-4 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:35:20,062] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:20,090] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-24, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 85ms (1/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:35:20,096] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:20,100] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-12, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (2/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:35:20,106] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:20,109] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-5.8dd36f04d1e74508ac2bc3547b94d36d-delete, topicId=lqj_eVvnQ1yZBBD5Vi-oZQ, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (3/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:35:20,114] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:20,117] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-30, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:35:20,122] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:20,124] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-36, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:35:20,129] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:20,131] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-42, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (6/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:35:20,136] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:20,140] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-0, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (7/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:35:20,145] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:20,149] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-18, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (8/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:35:20,154] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:20,156] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-6, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (9/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:35:20,160] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:20,163] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-0.7dd0040726864ca0b6fd4801081a2780-delete, topicId=lqj_eVvnQ1yZBBD5Vi-oZQ, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:35:20,167] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:20,170] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-48, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:35:20,176] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:20,180] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-1.bd59ec9c1b194ed79567b1c2faeef008-delete, topicId=lqj_eVvnQ1yZBBD5Vi-oZQ, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (12/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:35:20,183] INFO Loaded 12 logs in 195ms. (kafka.log.LogManager)
[2022-05-15 17:35:20,183] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:35:20,184] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:35:20,425] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:20,537] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:35:20,541] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.Acceptor)
[2022-05-15 17:35:20,565] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:35:20,573] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:20,589] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:20,591] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:20,592] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:20,594] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:20,606] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:35:20,665] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:35:20,686] INFO Stat of the created znode at /brokers/ids/4 is: 2114,2114,1652632520676,1652632520676,1,0,0,72057641293905966,192,0,2114
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:35:20,687] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://joao:9096, czxid (broker epoch): 2114 (kafka.zk.KafkaZkClient)
[2022-05-15 17:35:20,749] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:20,754] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:20,755] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:20,771] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:20,785] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:20,810] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:35:20,815] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:35:20,815] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:35:20,840] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:20,858] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:35:20,875] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:35:20,882] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:35:20,883] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:35:20,887] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:35:20,888] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:35:20,889] INFO Kafka startTimeMs: 1652632520883 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:35:20,891] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2022-05-15 17:35:20,978] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:21,005] INFO [Partition __consumer_offsets-18 broker=4] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:21,005] INFO [Partition __consumer_offsets-36 broker=4] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:21,005] INFO [Partition __consumer_offsets-6 broker=4] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:21,005] INFO [Partition __consumer_offsets-24 broker=4] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:21,006] INFO [Partition __consumer_offsets-42 broker=4] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:21,006] INFO [Partition __consumer_offsets-12 broker=4] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:21,006] INFO [Partition __consumer_offsets-30 broker=4] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:21,006] INFO [Partition __consumer_offsets-0 broker=4] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:21,006] INFO [Partition __consumer_offsets-48 broker=4] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:21,031] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-12, __consumer_offsets-42, __consumer_offsets-18) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:21,036] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:21,068] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 18 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:21,070] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:21,072] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 36 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:21,072] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:21,072] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 6 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:21,072] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:21,072] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 24 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:21,072] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:21,072] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 42 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:21,072] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:21,072] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 12 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:21,072] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:21,072] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 30 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:21,073] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:21,073] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 0 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:21,073] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:21,073] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 48 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:21,073] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:21,080] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-18 in 7 milliseconds for epoch 18, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:21,080] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-36 in 8 milliseconds for epoch 18, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:21,080] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-6 in 8 milliseconds for epoch 18, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:21,081] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-24 in 9 milliseconds for epoch 18, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:21,081] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-42 in 9 milliseconds for epoch 18, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:21,081] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-12 in 9 milliseconds for epoch 18, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:21,081] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-30 in 8 milliseconds for epoch 18, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:21,081] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-0 in 8 milliseconds for epoch 18, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:21,081] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-48 in 8 milliseconds for epoch 18, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:24,212] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:35:24,488] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:35:24,572] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:35:24,575] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:35:24,576] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:35:24,591] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:35:24,595] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:24,595] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:24,595] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:24,595] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:24,596] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:24,596] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:24,596] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:24,596] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:24,596] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:24,596] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:24,596] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:24,596] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:24,596] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:24,596] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:24,596] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:24,596] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:24,597] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:24,597] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:24,599] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:35:24,605] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:35:24,611] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:24,623] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:35:24,628] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:24,630] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:24,633] INFO Socket connection established, initiating session, client: /127.0.0.1:57908, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:24,643] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad002f, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:35:24,649] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:35:24,726] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:35:24,867] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:35:24,871] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:35:24,921] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:35:24,930] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:35:24,980] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:24,982] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:24,984] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:24,985] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:35:25,020] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:35:25,023] INFO Skipping recovery for all logs in /tmp/kafka-logs-5 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:35:25,097] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:25,120] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-46, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 80ms (1/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:35:25,126] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:25,130] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-10, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (2/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:35:25,134] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:25,139] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-0.7f1445b26df5473ea45a53b0bfe0d848-delete, topicId=lqj_eVvnQ1yZBBD5Vi-oZQ, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (3/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:35:25,144] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:25,147] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-5.f67a50a0eeba4eab8e8e15d2970eabca-delete, topicId=lqj_eVvnQ1yZBBD5Vi-oZQ, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:35:25,152] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:25,157] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-28, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (5/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:35:25,162] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:25,165] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-4.2dec1beb72394f4c978d3c4e146c5dac-delete, topicId=lqj_eVvnQ1yZBBD5Vi-oZQ, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:35:25,180] INFO Deleted producer state snapshot /tmp/kafka-logs-5/__consumer_offsets-22/00000000000000006389.snapshot (kafka.log.SnapshotFile)
[2022-05-15 17:35:25,183] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Loading producer state till offset 6390 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:25,183] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 6390 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:25,184] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-22/00000000000000006390.snapshot,6390)' (kafka.log.ProducerStateManager)
[2022-05-15 17:35:25,189] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 6390 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:25,192] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-22, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=6390) with 1 segments in 27ms (7/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:35:25,197] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:25,199] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-16, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:35:25,211] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Loading producer state till offset 18252 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:25,211] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 18252 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:25,211] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-40/00000000000000018252.snapshot,18252)' (kafka.log.ProducerStateManager)
[2022-05-15 17:35:25,211] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 18252 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:25,214] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-40, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=18252) with 1 segments in 13ms (9/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:35:25,218] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:25,220] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-34, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (10/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:35:25,225] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:25,227] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-4, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:35:25,231] INFO Loaded 11 logs in 211ms. (kafka.log.LogManager)
[2022-05-15 17:35:25,232] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:35:25,233] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:35:25,472] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:25,609] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:35:25,614] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.Acceptor)
[2022-05-15 17:35:25,644] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:35:25,650] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:25,665] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:25,667] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:25,669] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:25,670] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:25,683] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:35:25,749] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:35:25,768] INFO Stat of the created znode at /brokers/ids/5 is: 2139,2139,1652632525760,1652632525760,1,0,0,72057641293905967,192,0,2139
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:35:25,770] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://joao:9097, czxid (broker epoch): 2139 (kafka.zk.KafkaZkClient)
[2022-05-15 17:35:25,849] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:25,855] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:25,856] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:25,874] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:25,895] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:25,911] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:35:25,916] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:35:25,916] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:35:25,940] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:35:25,957] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:35:25,979] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:35:25,984] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:35:25,985] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:35:25,989] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:35:25,989] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:35:25,989] INFO Kafka startTimeMs: 1652632525985 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:35:25,992] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2022-05-15 17:35:26,054] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:26,083] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:35:26,096] INFO [Partition __consumer_offsets-34 broker=5] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:26,096] INFO [Partition __consumer_offsets-4 broker=5] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:26,097] INFO [Partition __consumer_offsets-22 broker=5] Log loaded for partition __consumer_offsets-22 with initial high watermark 6390 (kafka.cluster.Partition)
[2022-05-15 17:35:26,097] INFO [Partition __consumer_offsets-40 broker=5] Log loaded for partition __consumer_offsets-40 with initial high watermark 18252 (kafka.cluster.Partition)
[2022-05-15 17:35:26,097] INFO [Partition __consumer_offsets-10 broker=5] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:26,098] INFO [Partition __consumer_offsets-28 broker=5] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:26,098] INFO [Partition __consumer_offsets-46 broker=5] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:26,099] INFO [Partition __consumer_offsets-16 broker=5] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:26,126] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:26,160] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 34 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:26,161] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:26,163] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 4 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:26,163] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:26,163] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 22 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:26,163] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:26,164] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 40 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:26,164] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:26,164] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 10 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:26,164] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:26,164] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 28 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:26,164] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:26,164] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 46 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:26,164] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:26,164] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 16 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:26,164] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:26,172] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-34 in 10 milliseconds for epoch 22, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:26,173] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-4 in 10 milliseconds for epoch 22, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:26,194] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-9fa5abef-fdc9-4c05-8f09-7f9780632837, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:35:26,206] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-ed3a6d0d-54c4-4b54-b4a4-a5d0ecba6f8e, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:35:26,206] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-1038faf2-d998-4707-9799-897de83d6136, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:35:26,206] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-b283a5ee-70be-4bf9-b41c-74e089f12e34, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:35:26,206] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-360d1581-f79b-41e6-82d3-fe3577615014, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:35:26,206] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-9e173d1e-b47a-4b16-9874-bf5d2688c730, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:35:26,206] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-81fafa38-80dc-43ea-ac6c-e398b06565dc, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:35:26,234] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-d15976bc-df63-4682-8583-fd67cbb1d9df, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:35:26,235] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-a0d7c5c7-e384-4339-b0be-414878362e3e, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:35:26,235] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-ee781f71-f1c3-46d7-bd93-d90a4fe359ff, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:35:26,235] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-78575c72-7be8-4563-b114-53b271a8ef70, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:35:26,235] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-0287b15c-1acd-4475-b9ce-b994aebeeff2, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:35:26,235] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-45d54f6e-f1d8-43f7-8ace-1db96ac0cfac, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:35:26,238] INFO [GroupCoordinator 5]: Loading group metadata for consumer with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:35:26,244] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-22 in 81 milliseconds for epoch 22, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:26,272] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-40 in 108 milliseconds for epoch 22, of which 81 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:26,273] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-10 in 109 milliseconds for epoch 22, of which 109 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:26,274] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-28 in 110 milliseconds for epoch 22, of which 109 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:26,274] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-46 in 110 milliseconds for epoch 22, of which 110 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:26,275] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-16 in 111 milliseconds for epoch 22, of which 111 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:35:29,939] INFO Creating topic Sensor with configuration {min.insync.replicas=2} and initial partition assignment HashMap(0 -> ArrayBuffer(4, 2, 3), 1 -> ArrayBuffer(1, 3, 0), 2 -> ArrayBuffer(2, 0, 5), 3 -> ArrayBuffer(3, 5, 4), 4 -> ArrayBuffer(0, 4, 1), 5 -> ArrayBuffer(5, 1, 2)) (kafka.zk.AdminZkClient)
[2022-05-15 17:35:29,988] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-4) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:29,989] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:29,991] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:29,992] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:29,993] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:29,994] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:30,000] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:30,002] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:30,004] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:30,006] INFO Created log for partition Sensor-4 in /tmp/kafka-logs/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:35:30,007] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:30,007] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:30,007] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:30,008] INFO [Partition Sensor-4 broker=0] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 17:35:30,008] INFO [Partition Sensor-4 broker=0] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:30,009] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-1/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:35:30,010] INFO [Partition Sensor-1 broker=1] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 17:35:30,011] INFO [Partition Sensor-1 broker=1] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:30,011] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-5/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:35:30,012] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-2/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:35:30,013] INFO [Partition Sensor-5 broker=5] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 17:35:30,013] INFO [Partition Sensor-5 broker=5] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:30,013] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-3/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:35:30,013] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-4/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:35:30,014] INFO [Partition Sensor-2 broker=2] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 17:35:30,015] INFO [Partition Sensor-3 broker=3] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 17:35:30,015] INFO [Partition Sensor-2 broker=2] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:30,015] INFO [Partition Sensor-3 broker=3] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:30,015] INFO [Partition Sensor-0 broker=4] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 17:35:30,016] INFO [Partition Sensor-0 broker=4] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:30,020] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:30,022] INFO Created log for partition Sensor-2 in /tmp/kafka-logs/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:35:30,022] INFO [Partition Sensor-2 broker=0] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 17:35:30,023] INFO [Partition Sensor-2 broker=0] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:30,025] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:30,028] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-1/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:35:30,028] INFO [Partition Sensor-4 broker=1] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 17:35:30,028] INFO [Partition Sensor-4 broker=1] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:30,033] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:30,034] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:30,036] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-5/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:35:30,036] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:30,036] INFO [Partition Sensor-3 broker=5] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 17:35:30,036] INFO [Partition Sensor-3 broker=5] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:30,036] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-4/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:35:30,037] INFO [Partition Sensor-4 broker=4] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 17:35:30,037] INFO [Partition Sensor-4 broker=4] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:30,037] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:30,039] INFO Created log for partition Sensor-1 in /tmp/kafka-logs/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:35:30,038] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:30,040] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-3/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:35:30,040] INFO [Partition Sensor-1 broker=0] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 17:35:30,041] INFO [Partition Sensor-1 broker=0] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:30,041] INFO [Partition Sensor-0 broker=3] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 17:35:30,041] INFO [Partition Sensor-0 broker=3] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:30,041] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:30,042] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-1/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:35:30,043] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:30,043] INFO [Partition Sensor-5 broker=1] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 17:35:30,044] INFO [Partition Sensor-5 broker=1] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:30,044] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(Sensor-4, Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:30,046] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:30,046] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-2/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:35:30,046] INFO [Partition Sensor-5 broker=2] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 17:35:30,046] INFO [Partition Sensor-5 broker=2] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:30,047] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:30,047] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-5/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:35:30,047] INFO [Partition Sensor-2 broker=5] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 17:35:30,047] INFO [Partition Sensor-2 broker=5] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:30,047] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:30,048] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-4/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:35:30,048] INFO [Partition Sensor-3 broker=4] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 17:35:30,049] INFO [Partition Sensor-3 broker=4] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:30,049] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(Sensor-4, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:30,050] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:30,052] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-3/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:35:30,053] INFO [Partition Sensor-1 broker=3] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 17:35:30,053] INFO [Partition Sensor-1 broker=3] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:30,053] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:30,054] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:35:30,055] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-2/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:35:30,055] INFO [Partition Sensor-0 broker=2] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 17:35:30,055] INFO [Partition Sensor-0 broker=2] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:35:30,056] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(Sensor-5, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:30,069] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,071] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,071] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,074] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions Map(Sensor-2 -> InitialFetchState(Some(1BNya-rrTie1owmr9eGHaA),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:30,076] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 2 for partitions Map(Sensor-2 -> InitialFetchState(Some(1BNya-rrTie1owmr9eGHaA),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:30,077] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(Sensor-4 -> InitialFetchState(Some(1BNya-rrTie1owmr9eGHaA),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:30,079] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,080] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,082] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,082] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 3 for partitions Map(Sensor-3 -> InitialFetchState(Some(1BNya-rrTie1owmr9eGHaA),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:30,083] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:35:30,082] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,083] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,083] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,084] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,084] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 5 for partitions Map(Sensor-5 -> InitialFetchState(Some(1BNya-rrTie1owmr9eGHaA),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:30,083] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,085] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,086] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:35:30,084] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:35:30,086] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:35:30,089] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 0 for partitions Map(Sensor-4 -> InitialFetchState(Some(1BNya-rrTie1owmr9eGHaA),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:30,085] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:35:30,091] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 4 for partitions Map(Sensor-0 -> InitialFetchState(Some(1BNya-rrTie1owmr9eGHaA),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:30,094] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,094] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 1 for partitions Map(Sensor-1 -> InitialFetchState(Some(1BNya-rrTie1owmr9eGHaA),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:30,096] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,097] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,097] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,098] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:35:30,095] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,100] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,100] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 3 for partitions Map(Sensor-3 -> InitialFetchState(Some(1BNya-rrTie1owmr9eGHaA),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:30,100] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:35:30,102] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:35:30,102] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:35:30,105] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,105] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 1 for partitions Map(Sensor-1 -> InitialFetchState(Some(1BNya-rrTie1owmr9eGHaA),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:30,105] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,105] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,106] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:35:30,116] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 4 for partitions Map(Sensor-0 -> InitialFetchState(Some(1BNya-rrTie1owmr9eGHaA),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:30,120] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,125] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:35:30,139] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 5 for partitions Map(Sensor-5 -> InitialFetchState(Some(1BNya-rrTie1owmr9eGHaA),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:35:30,139] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,142] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,142] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:35:30,219] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-2. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,219] WARN [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,221] WARN [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-3. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:35:30,223] WARN [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-2. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:36:00,196] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=66241, lastModifiedTime=1652632318733, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:36:00,198] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=66241, lastModifiedTime=1652632318733, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:36:00,202] INFO Deleted log /tmp/kafka-logs/Sensor-5.61eae1a81f2546b4bd8024433c7730de-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:00,202] INFO Deleted offset index /tmp/kafka-logs/Sensor-5.61eae1a81f2546b4bd8024433c7730de-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:00,204] INFO Deleted time index /tmp/kafka-logs/Sensor-5.61eae1a81f2546b4bd8024433c7730de-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:00,208] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs/Sensor-5.61eae1a81f2546b4bd8024433c7730de-delete. (kafka.log.LogManager)
[2022-05-15 17:36:00,209] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=142586, lastModifiedTime=1652632338582, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:36:00,209] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=142586, lastModifiedTime=1652632338582, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:36:00,210] INFO Deleted log /tmp/kafka-logs/Sensor-3.6debb531955d4834aab4e2f5a82aef5f-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:00,210] INFO Deleted offset index /tmp/kafka-logs/Sensor-3.6debb531955d4834aab4e2f5a82aef5f-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:00,210] INFO Deleted time index /tmp/kafka-logs/Sensor-3.6debb531955d4834aab4e2f5a82aef5f-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:00,211] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs/Sensor-3.6debb531955d4834aab4e2f5a82aef5f-delete. (kafka.log.LogManager)
[2022-05-15 17:36:00,246] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=60805, lastModifiedTime=1652632317257, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:36:00,246] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=60805, lastModifiedTime=1652632317257, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:36:00,247] INFO Deleted log /tmp/kafka-logs/Sensor-4.c4d1c072989f4a46b97aff67ad218f7e-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:00,247] INFO Deleted offset index /tmp/kafka-logs/Sensor-4.c4d1c072989f4a46b97aff67ad218f7e-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:00,248] INFO Deleted time index /tmp/kafka-logs/Sensor-4.c4d1c072989f4a46b97aff67ad218f7e-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:00,248] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs/Sensor-4.c4d1c072989f4a46b97aff67ad218f7e-delete. (kafka.log.LogManager)
[2022-05-15 17:36:05,044] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=133130, lastModifiedTime=1652632337254, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:36:05,045] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=133130, lastModifiedTime=1652632337254, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:36:05,048] INFO Deleted log /tmp/kafka-logs-1/Sensor-0.39a7be63d9c7491eb2ded56aa41a9d35-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:05,048] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-0.39a7be63d9c7491eb2ded56aa41a9d35-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:05,052] INFO Deleted time index /tmp/kafka-logs-1/Sensor-0.39a7be63d9c7491eb2ded56aa41a9d35-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:05,056] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-1/Sensor-0.39a7be63d9c7491eb2ded56aa41a9d35-delete. (kafka.log.LogManager)
[2022-05-15 17:36:05,057] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=135230, lastModifiedTime=1652632337694, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:36:05,058] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=135230, lastModifiedTime=1652632337694, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:36:05,058] INFO Deleted log /tmp/kafka-logs-1/Sensor-2.4a9de3d773964141a37cea605a0eb99b-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:05,059] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-2.4a9de3d773964141a37cea605a0eb99b-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:05,059] INFO Deleted time index /tmp/kafka-logs-1/Sensor-2.4a9de3d773964141a37cea605a0eb99b-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:05,059] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-1/Sensor-2.4a9de3d773964141a37cea605a0eb99b-delete. (kafka.log.LogManager)
[2022-05-15 17:36:05,113] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=136844, lastModifiedTime=1652632337994, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:36:05,114] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=136844, lastModifiedTime=1652632337994, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:36:05,115] INFO Deleted log /tmp/kafka-logs-1/Sensor-1.b26b3a06934e4e25831a69664d5640f2-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:05,116] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-1.b26b3a06934e4e25831a69664d5640f2-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:05,117] INFO Deleted time index /tmp/kafka-logs-1/Sensor-1.b26b3a06934e4e25831a69664d5640f2-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:05,118] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-1/Sensor-1.b26b3a06934e4e25831a69664d5640f2-delete. (kafka.log.LogManager)
[2022-05-15 17:36:10,341] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=142586, lastModifiedTime=1652632338582, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:36:10,342] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=142586, lastModifiedTime=1652632338582, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:36:10,345] INFO Deleted log /tmp/kafka-logs-2/Sensor-3.6d337915b4fd455492d8a37c0c784468-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:10,345] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-3.6d337915b4fd455492d8a37c0c784468-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:10,348] INFO Deleted time index /tmp/kafka-logs-2/Sensor-3.6d337915b4fd455492d8a37c0c784468-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:10,351] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-2/Sensor-3.6d337915b4fd455492d8a37c0c784468-delete. (kafka.log.LogManager)
[2022-05-15 17:36:10,354] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=136844, lastModifiedTime=1652632337994, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:36:10,354] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=136844, lastModifiedTime=1652632337994, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:36:10,355] INFO Deleted log /tmp/kafka-logs-2/Sensor-1.17a93e63d1af4c21b455a5ebfe075d05-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:10,355] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-1.17a93e63d1af4c21b455a5ebfe075d05-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:10,355] INFO Deleted time index /tmp/kafka-logs-2/Sensor-1.17a93e63d1af4c21b455a5ebfe075d05-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:10,356] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-2/Sensor-1.17a93e63d1af4c21b455a5ebfe075d05-delete. (kafka.log.LogManager)
[2022-05-15 17:36:10,370] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=135230, lastModifiedTime=1652632337698, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:36:10,370] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=135230, lastModifiedTime=1652632337698, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:36:10,371] INFO Deleted log /tmp/kafka-logs-2/Sensor-2.996712becfe04eb69e576ce2db27a1f1-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:10,371] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-2.996712becfe04eb69e576ce2db27a1f1-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:10,371] INFO Deleted time index /tmp/kafka-logs-2/Sensor-2.996712becfe04eb69e576ce2db27a1f1-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:10,372] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-2/Sensor-2.996712becfe04eb69e576ce2db27a1f1-delete. (kafka.log.LogManager)
[2022-05-15 17:36:11,246] INFO [GroupCoordinator 5]: Member consumer-consumer-4-d15976bc-df63-4682-8583-fd67cbb1d9df in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:36:11,252] INFO [GroupCoordinator 5]: Preparing to rebalance group consumer in state PreparingRebalance with old generation 1 (__consumer_offsets-22) (reason: removing member consumer-consumer-4-d15976bc-df63-4682-8583-fd67cbb1d9df on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:36:11,253] INFO [GroupCoordinator 5]: Member consumer-consumer-3-a0d7c5c7-e384-4339-b0be-414878362e3e in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:36:11,254] INFO [GroupCoordinator 5]: Member consumer-consumer-2-ee781f71-f1c3-46d7-bd93-d90a4fe359ff in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:36:11,255] INFO [GroupCoordinator 5]: Member consumer-consumer-5-78575c72-7be8-4563-b114-53b271a8ef70 in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:36:11,255] INFO [GroupCoordinator 5]: Member consumer-consumer-1-0287b15c-1acd-4475-b9ce-b994aebeeff2 in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:36:11,255] INFO [GroupCoordinator 5]: Member consumer-consumer-6-45d54f6e-f1d8-43f7-8ace-1db96ac0cfac in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:36:11,257] INFO [GroupCoordinator 5]: Group consumer with generation 2 is now empty (__consumer_offsets-22) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:36:15,133] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=60805, lastModifiedTime=1652632317253, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:36:15,135] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=60805, lastModifiedTime=1652632317253, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:36:15,137] INFO Deleted log /tmp/kafka-logs-3/Sensor-4.0d580935c85546e28032d871d801960a-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:15,138] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-4.0d580935c85546e28032d871d801960a-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:15,140] INFO Deleted time index /tmp/kafka-logs-3/Sensor-4.0d580935c85546e28032d871d801960a-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:15,147] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-3/Sensor-4.0d580935c85546e28032d871d801960a-delete. (kafka.log.LogManager)
[2022-05-15 17:36:15,178] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=142586, lastModifiedTime=1652632338582, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:36:15,178] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=142586, lastModifiedTime=1652632338582, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:36:15,180] INFO Deleted log /tmp/kafka-logs-3/Sensor-3.0ae2acd5da8645579e45a3fd6c1ec921-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:15,181] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-3.0ae2acd5da8645579e45a3fd6c1ec921-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:15,181] INFO Deleted time index /tmp/kafka-logs-3/Sensor-3.0ae2acd5da8645579e45a3fd6c1ec921-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:15,182] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-3/Sensor-3.0ae2acd5da8645579e45a3fd6c1ec921-delete. (kafka.log.LogManager)
[2022-05-15 17:36:15,219] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=135230, lastModifiedTime=1652632337698, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:36:15,220] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=135230, lastModifiedTime=1652632337698, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:36:15,221] INFO Deleted log /tmp/kafka-logs-3/Sensor-2.4e0c3f82a0a54d208c5f37bd5a59ae6f-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:15,221] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-2.4e0c3f82a0a54d208c5f37bd5a59ae6f-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:15,221] INFO Deleted time index /tmp/kafka-logs-3/Sensor-2.4e0c3f82a0a54d208c5f37bd5a59ae6f-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:15,222] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-3/Sensor-2.4e0c3f82a0a54d208c5f37bd5a59ae6f-delete. (kafka.log.LogManager)
[2022-05-15 17:36:20,114] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=66241, lastModifiedTime=1652632318737, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:36:20,115] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=66241, lastModifiedTime=1652632318737, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:36:20,117] INFO Deleted log /tmp/kafka-logs-4/Sensor-5.8dd36f04d1e74508ac2bc3547b94d36d-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:20,118] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-5.8dd36f04d1e74508ac2bc3547b94d36d-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:20,121] INFO Deleted time index /tmp/kafka-logs-4/Sensor-5.8dd36f04d1e74508ac2bc3547b94d36d-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:20,125] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-4/Sensor-5.8dd36f04d1e74508ac2bc3547b94d36d-delete. (kafka.log.LogManager)
[2022-05-15 17:36:20,164] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=133130, lastModifiedTime=1652632337254, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:36:20,165] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=133130, lastModifiedTime=1652632337254, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:36:20,166] INFO Deleted log /tmp/kafka-logs-4/Sensor-0.7dd0040726864ca0b6fd4801081a2780-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:20,167] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-0.7dd0040726864ca0b6fd4801081a2780-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:20,168] INFO Deleted time index /tmp/kafka-logs-4/Sensor-0.7dd0040726864ca0b6fd4801081a2780-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:20,168] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-4/Sensor-0.7dd0040726864ca0b6fd4801081a2780-delete. (kafka.log.LogManager)
[2022-05-15 17:36:20,181] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=136844, lastModifiedTime=1652632337994, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:36:20,182] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=136844, lastModifiedTime=1652632337994, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:36:20,183] INFO Deleted log /tmp/kafka-logs-4/Sensor-1.bd59ec9c1b194ed79567b1c2faeef008-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:20,183] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-1.bd59ec9c1b194ed79567b1c2faeef008-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:20,183] INFO Deleted time index /tmp/kafka-logs-4/Sensor-1.bd59ec9c1b194ed79567b1c2faeef008-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:20,183] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-4/Sensor-1.bd59ec9c1b194ed79567b1c2faeef008-delete. (kafka.log.LogManager)
[2022-05-15 17:36:25,141] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=133130, lastModifiedTime=1652632337254, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:36:25,142] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=133130, lastModifiedTime=1652632337254, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:36:25,144] INFO Deleted log /tmp/kafka-logs-5/Sensor-0.7f1445b26df5473ea45a53b0bfe0d848-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:25,145] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-0.7f1445b26df5473ea45a53b0bfe0d848-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:25,148] INFO Deleted time index /tmp/kafka-logs-5/Sensor-0.7f1445b26df5473ea45a53b0bfe0d848-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:25,152] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-5/Sensor-0.7f1445b26df5473ea45a53b0bfe0d848-delete. (kafka.log.LogManager)
[2022-05-15 17:36:25,152] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=66241, lastModifiedTime=1652632318737, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:36:25,152] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=66241, lastModifiedTime=1652632318737, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:36:25,153] INFO Deleted log /tmp/kafka-logs-5/Sensor-5.f67a50a0eeba4eab8e8e15d2970eabca-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:25,153] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-5.f67a50a0eeba4eab8e8e15d2970eabca-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:25,153] INFO Deleted time index /tmp/kafka-logs-5/Sensor-5.f67a50a0eeba4eab8e8e15d2970eabca-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:25,154] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-5/Sensor-5.f67a50a0eeba4eab8e8e15d2970eabca-delete. (kafka.log.LogManager)
[2022-05-15 17:36:25,165] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=60805, lastModifiedTime=1652632317257, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:36:25,166] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=60805, lastModifiedTime=1652632317257, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:36:25,167] INFO Deleted log /tmp/kafka-logs-5/Sensor-4.2dec1beb72394f4c978d3c4e146c5dac-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:25,167] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-4.2dec1beb72394f4c978d3c4e146c5dac-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:25,168] INFO Deleted time index /tmp/kafka-logs-5/Sensor-4.2dec1beb72394f4c978d3c4e146c5dac-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:36:25,169] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-5/Sensor-4.2dec1beb72394f4c978d3c4e146c5dac-delete. (kafka.log.LogManager)
[2022-05-15 17:47:02,775] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,775] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,775] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,775] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,775] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,775] INFO [Controller id=0, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,786] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:02,787] INFO [GroupCoordinator 3]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:02,787] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:02,789] INFO [GroupMetadataManager brokerId=5] Group consumer transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:02,789] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:02,790] INFO [GroupCoordinator 4]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:02,791] INFO [GroupCoordinator 5]: Removed 6 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:02,812] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:02,812] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:02,813] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:02,813] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:02,813] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-3, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:02,813] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-3, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:02,813] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:02,813] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:02,814] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:02,814] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:02,814] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:02,815] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:02,817] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,819] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,819] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 5429 due to node 2 being disconnected (elapsed time since creation: 428ms, elapsed time since send: 428ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,820] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,820] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=265656827, epoch=5427) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:47:02,820] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,820] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,821] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,821] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,821] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,822] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,822] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,822] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,824] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,825] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 5480 due to node 1 being disconnected (elapsed time since creation: 404ms, elapsed time since send: 404ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,826] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 5440 due to node 2 being disconnected (elapsed time since creation: 423ms, elapsed time since send: 423ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,828] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 5407 due to node 4 being disconnected (elapsed time since creation: 183ms, elapsed time since send: 183ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,826] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=459445120, epoch=5480) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:47:02,830] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,830] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 3219 due to node 0 being disconnected (elapsed time since creation: 340ms, elapsed time since send: 340ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,830] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,827] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=2141647059, epoch=5438) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:47:02,831] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,831] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,832] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,828] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=1871618471, epoch=5407) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:47:02,833] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,833] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 5476 due to node 1 being disconnected (elapsed time since creation: 411ms, elapsed time since send: 411ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,833] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,833] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,834] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,833] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=564536220, epoch=5474) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:47:02,834] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,834] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,831] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=10740970, epoch=3219) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:47:02,835] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,836] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,836] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,836] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:02,837] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,837] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,837] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:02,837] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,837] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,838] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 5677 due to node 3 being disconnected (elapsed time since creation: 92ms, elapsed time since send: 92ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,838] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 5407 due to node 4 being disconnected (elapsed time since creation: 196ms, elapsed time since send: 196ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,839] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 5650 due to node 3 being disconnected (elapsed time since creation: 121ms, elapsed time since send: 121ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,838] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1496776079, epoch=5675) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:47:02,839] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,838] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=1988794451, epoch=5407) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:47:02,839] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,839] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,840] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,840] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,841] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,841] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 3389 due to node 5 being disconnected (elapsed time since creation: 384ms, elapsed time since send: 384ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,841] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:02,841] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=1062987754, epoch=3389) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:47:02,842] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:02,843] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,843] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,843] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,843] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-3, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:02,844] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,844] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 3399 due to node 5 being disconnected (elapsed time since creation: 361ms, elapsed time since send: 361ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:02,844] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-3, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:02,840] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=658437335, epoch=5650) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:47:02,844] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=728061864, epoch=3399) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:47:02,844] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,844] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,845] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,846] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,846] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:02,846] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:02,847] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:02,848] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:02,852] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,853] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,854] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:02,857] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:02,858] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:02,859] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs/Sensor-4.7b0d8777c2df462bbd39de74adbcc140-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:47:02,862] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs/Sensor-2.f5a8ca650b41499aae1ff0d48732aa51-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:47:02,865] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs/Sensor-1.61582f8bbbfd479eb5715deb729cc913-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:47:02,866] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-2/Sensor-5.5fd87f3e82a64c229bb7f91a529e0507-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:47:02,867] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-5/Sensor-5.2ce10580bc584aef8b9c43892fede293-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:47:02,869] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-2/Sensor-2.0be41a42297747d6a31707dca89205fe-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:47:02,871] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-1/Sensor-4.cd4f9e0ddeb940dc94f56c37e2041909-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:47:02,873] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-5/Sensor-2.f6c5a78bcc8a4554b065c6dcb704d279-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:47:02,873] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-2/Sensor-0.4385c1edc6e041d7af7adbacb257590b-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:47:02,875] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-1/Sensor-5.c3da4785f9f441baa070a445dd9b92ca-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:47:02,875] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-3/Sensor-3.f59ca30a8e6f4224a829161d5051150a-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:47:02,878] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-4/Sensor-4.7819c0f2a7664c379edb5dd95c887c6e-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:47:02,879] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-5/Sensor-3.ce4bfbe8a60b45b3af779002b654716d-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:47:02,879] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-3/Sensor-0.b869786bb9f74ab8a3ccdf050bbc5b24-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:47:02,877] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-1/Sensor-1.e97ebd018a984284ae286c2972f730ea-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:47:02,882] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-4/Sensor-3.0c52ff8367ea47e2a8a7143985606cda-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:47:02,882] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-3/Sensor-1.298886379efc4bf3a462ae86138e6e55-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:47:02,888] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-4/Sensor-0.008ea0b37279468281d7237db5c9c9d5-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:47:06,155] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:47:06,155] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:47:06,155] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:47:06,155] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:47:06,155] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:47:06,155] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:47:06,157] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:47:06,158] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:47:06,157] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:47:06,158] INFO [KafkaServer id=5] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:47:06,158] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:47:06,158] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:47:06,159] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:47:06,159] INFO [KafkaServer id=4] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:47:06,159] INFO [KafkaServer id=5] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:47:06,160] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:47:06,160] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:47:06,162] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:47:06,174] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 8ms (kafka.server.KafkaServer)
[2022-05-15 17:47:06,175] INFO [KafkaServer id=4] Controlled shutdown request returned successfully after 10ms (kafka.server.KafkaServer)
[2022-05-15 17:47:06,176] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:06,176] INFO [KafkaServer id=3] Controlled shutdown request returned successfully after 11ms (kafka.server.KafkaServer)
[2022-05-15 17:47:06,177] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:06,177] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:06,177] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 9ms (kafka.server.KafkaServer)
[2022-05-15 17:47:06,178] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:06,178] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:06,178] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:47:06,179] INFO [KafkaServer id=5] Controlled shutdown request returned successfully after 11ms (kafka.server.KafkaServer)
[2022-05-15 17:47:06,179] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:06,178] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:06,180] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:06,180] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:06,180] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 12ms (kafka.server.KafkaServer)
[2022-05-15 17:47:06,180] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:06,180] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:47:06,180] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:06,180] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:06,181] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:47:06,182] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:06,182] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:47:06,182] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:06,182] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:06,184] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:47:06,188] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:06,189] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:06,189] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:06,193] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:47:06,194] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:47:06,194] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:47:06,195] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:47:06,195] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:47:06,195] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:47:06,196] INFO [data-plane Kafka Request Handler on Broker 4], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:47:06,198] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:47:06,198] INFO [data-plane Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:47:06,199] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:47:06,199] INFO [data-plane Kafka Request Handler on Broker 4], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:47:06,201] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:47:06,202] INFO [data-plane Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:47:06,203] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:47:06,204] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,204] INFO [ExpirationReaper-4-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,206] INFO [ExpirationReaper-3-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,207] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:47:06,207] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,208] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:47:06,208] INFO [data-plane Kafka Request Handler on Broker 5], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:47:06,210] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:47:06,211] INFO [data-plane Kafka Request Handler on Broker 5], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:47:06,212] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,214] INFO [ExpirationReaper-5-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,240] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,241] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,242] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:47:06,243] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,253] INFO [ExpirationReaper-4-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,253] INFO [ExpirationReaper-4-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,254] INFO [KafkaApi-4] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:47:06,255] INFO [ExpirationReaper-4-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,284] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,284] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,285] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:47:06,287] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,328] INFO [ExpirationReaper-5-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,328] INFO [ExpirationReaper-5-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,328] INFO [ExpirationReaper-3-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,328] INFO [ExpirationReaper-3-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,328] INFO [ExpirationReaper-4-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,328] INFO [ExpirationReaper-4-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,329] INFO [KafkaApi-5] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:47:06,330] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:47:06,330] INFO [ExpirationReaper-5-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,331] INFO [TransactionCoordinator id=4] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:06,331] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,332] INFO [Transaction State Manager 4]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:47:06,332] INFO [Transaction Marker Channel Manager 4]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:06,332] INFO [Transaction Marker Channel Manager 4]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:06,332] INFO [Transaction Marker Channel Manager 4]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:06,333] INFO [TransactionCoordinator id=4] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:06,334] INFO [GroupCoordinator 4]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:06,335] INFO [ExpirationReaper-4-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,349] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,349] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,351] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:06,352] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,352] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,352] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,352] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,353] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:47:06,353] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:06,354] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:47:06,353] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:06,354] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:06,355] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:06,355] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,356] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:06,356] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:06,357] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,358] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:47:06,358] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:06,358] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,358] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,358] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:06,358] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,358] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:06,359] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:06,360] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:06,361] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,371] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,371] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,373] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:06,374] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:47:06,374] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:06,375] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:06,375] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:06,376] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:06,377] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:06,378] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,434] INFO [ExpirationReaper-5-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,434] INFO [ExpirationReaper-5-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,436] INFO [TransactionCoordinator id=5] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:06,437] INFO [Transaction State Manager 5]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:47:06,437] INFO [Transaction Marker Channel Manager 5]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:06,437] INFO [Transaction Marker Channel Manager 5]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:06,437] INFO [Transaction Marker Channel Manager 5]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:06,439] INFO [TransactionCoordinator id=5] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:06,440] INFO [GroupCoordinator 5]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:06,440] INFO [ExpirationReaper-5-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,452] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,452] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,454] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:06,455] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:47:06,455] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:06,456] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:06,456] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:06,457] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:06,458] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:06,459] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,528] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,528] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,530] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:06,530] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:47:06,530] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:06,531] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:06,531] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:06,532] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:06,533] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:06,533] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:06,534] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:06,534] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,534] INFO [ExpirationReaper-4-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,534] INFO [ExpirationReaper-4-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,535] INFO [ExpirationReaper-4-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,552] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,552] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,553] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,553] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,553] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,553] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,572] INFO [ExpirationReaper-4-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,572] INFO [ExpirationReaper-4-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,573] INFO [GroupCoordinator 4]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:06,574] INFO [ReplicaManager broker=4] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:47:06,574] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:06,574] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:06,574] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:06,575] INFO [ReplicaFetcherManager on broker 4] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:06,577] INFO [ReplicaFetcherManager on broker 4] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:06,577] INFO [ReplicaAlterLogDirsManager on broker 4] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:06,578] INFO [ReplicaAlterLogDirsManager on broker 4] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:06,578] INFO [ExpirationReaper-4-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,585] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,585] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,586] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:06,587] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:47:06,587] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:06,587] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:06,587] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:06,588] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:06,590] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:06,590] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:06,590] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:06,590] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,628] INFO [ExpirationReaper-5-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,628] INFO [ExpirationReaper-5-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,629] INFO [ExpirationReaper-5-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,634] INFO [ExpirationReaper-5-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,634] INFO [ExpirationReaper-5-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,635] INFO [GroupCoordinator 5]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:06,636] INFO [ReplicaManager broker=5] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:47:06,636] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:06,637] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,636] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:06,637] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,636] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:06,637] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,637] INFO [ReplicaFetcherManager on broker 5] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:06,639] INFO [ReplicaFetcherManager on broker 5] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:06,639] INFO [ReplicaAlterLogDirsManager on broker 5] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:06,640] INFO [ReplicaAlterLogDirsManager on broker 5] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:06,640] INFO [ExpirationReaper-5-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,684] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,684] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,685] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:06,686] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:47:06,687] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:06,687] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:06,687] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:06,688] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:06,689] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,689] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,689] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,690] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:06,691] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:06,691] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:06,691] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,727] INFO [ExpirationReaper-4-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,727] INFO [ExpirationReaper-4-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,727] INFO [ExpirationReaper-4-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,753] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,753] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,754] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:06,755] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:47:06,755] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:06,755] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:06,755] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:06,756] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:06,758] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:06,759] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:06,759] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:47:06,759] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,766] INFO [ExpirationReaper-4-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,766] INFO [ExpirationReaper-4-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,767] INFO [ExpirationReaper-4-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,767] INFO [ExpirationReaper-5-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,767] INFO [ExpirationReaper-5-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,767] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,767] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,768] INFO [ExpirationReaper-5-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,768] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,783] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,783] INFO [ExpirationReaper-4-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,783] INFO [ExpirationReaper-4-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,783] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,784] INFO [ExpirationReaper-4-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,784] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,800] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,800] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,801] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,848] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,848] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,848] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,908] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,909] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,909] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,920] INFO [ExpirationReaper-5-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,920] INFO [ExpirationReaper-5-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,921] INFO [ExpirationReaper-5-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,953] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,953] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,953] INFO [ExpirationReaper-4-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,953] INFO [ExpirationReaper-4-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,954] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,959] INFO [ReplicaManager broker=4] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:47:06,960] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:06,961] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:06,961] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:06,963] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:47:06,963] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:06,963] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:06,963] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:06,964] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:47:06,965] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:47:06,982] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:47:06,984] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,984] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,987] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:06,987] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:47:06,988] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:06,988] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:06,988] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:06,989] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:06,989] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:06,989] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:06,990] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:47:06,990] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:06,991] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:06,991] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:06,991] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:47:06,992] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:47:06,993] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,993] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:06,993] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,000] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,000] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,001] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,011] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:47:07,016] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,016] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,016] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,016] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,016] INFO [Controller id=0, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,017] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,017] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,017] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,017] INFO [Controller id=0, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,017] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,017] WARN [Controller id=0, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,017] WARN [Controller id=0, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,017] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,017] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,018] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,018] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,018] INFO [Controller id=0, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,018] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,018] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,019] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,020] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,022] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,022] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,023] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,024] INFO [Controller id=0, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,026] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:07,026] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:07,026] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:07,027] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:07,045] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,045] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,045] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,060] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,060] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,061] INFO [ExpirationReaper-3-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,068] INFO [ExpirationReaper-5-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,068] INFO [ExpirationReaper-5-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,068] INFO [ExpirationReaper-5-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,087] INFO [ExpirationReaper-3-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,087] INFO [ExpirationReaper-3-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,090] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:47:07,091] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,091] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,091] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,093] INFO Session: 0x100000b00ad002e closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:07,093] INFO EventThread shut down for session: 0x100000b00ad002e (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:07,093] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:47:07,093] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,094] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,094] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,094] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:07,094] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:47:07,095] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:07,095] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:47:07,100] INFO [Controller id=3, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,100] INFO [Controller id=3, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,100] INFO [Controller id=3, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,100] INFO [Controller id=3, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,102] WARN [Controller id=3, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,102] WARN [Controller id=3, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,102] WARN [Controller id=3, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,102] WARN [Controller id=3, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,104] INFO [Controller id=3, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,104] INFO [Controller id=3, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,104] INFO [Controller id=3, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,105] INFO [Controller id=3, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,115] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:47:07,129] INFO Session: 0x100000b00ad002a closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:07,129] INFO EventThread shut down for session: 0x100000b00ad002a (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:07,131] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:07,132] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:07,153] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,153] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,153] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,158] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:07,158] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:07,158] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:07,183] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,183] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,188] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:47:07,189] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,189] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,189] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,192] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:47:07,192] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,192] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,193] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,193] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:47:07,193] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,193] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,194] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:47:07,204] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:47:07,205] INFO [Controller id=3, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,205] INFO [Controller id=3, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,205] WARN [Controller id=3, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,205] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,205] WARN [Controller id=3, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,205] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,205] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,206] INFO [Controller id=3, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,206] INFO [Controller id=3, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,206] WARN [Controller id=3, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,206] INFO [Controller id=3, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,206] INFO [Controller id=3, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,206] INFO [Controller id=3, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,206] WARN [Controller id=3, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,207] INFO [Controller id=3, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,208] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:47:07,208] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,208] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,208] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,209] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:47:07,210] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:47:07,216] INFO [Controller id=3, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,219] INFO [Controller id=3, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,224] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:47:07,227] INFO [Controller id=3, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,228] INFO [Controller id=3, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,232] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:07,232] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:07,232] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:07,232] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:47:07,233] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:07,233] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:07,233] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:07,233] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:07,234] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:07,239] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:07,239] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:07,239] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:07,240] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:07,268] INFO [ExpirationReaper-5-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,268] INFO [ExpirationReaper-5-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:07,271] INFO [ReplicaManager broker=5] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:47:07,271] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,271] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,271] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,273] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:47:07,274] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,274] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,274] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:07,275] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:47:07,275] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:47:07,289] INFO [ProducerStateManager partition=__consumer_offsets-22] Wrote producer snapshot at offset 41030 with 0 producer ids in 3 ms. (kafka.log.ProducerStateManager)
[2022-05-15 17:47:07,300] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:47:07,309] INFO [Controller id=5, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,310] WARN [Controller id=5, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,311] INFO [Controller id=5, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,336] INFO Session: 0x100000b00ad002d closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:07,336] INFO EventThread shut down for session: 0x100000b00ad002d (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:07,338] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:07,338] INFO Session: 0x100000b00ad002c closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:07,338] INFO EventThread shut down for session: 0x100000b00ad002c (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:07,338] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:07,340] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:07,340] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:07,343] INFO Session: 0x100000b00ad002b closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:07,343] INFO EventThread shut down for session: 0x100000b00ad002b (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:07,344] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:07,344] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:07,412] INFO [Controller id=5, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,412] WARN [Controller id=5, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,413] INFO [Controller id=5, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,436] INFO [Controller id=5, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:47:07,439] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:07,439] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:07,439] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:07,440] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:07,443] WARN An exception was thrown while closing send thread for session 0x100000b00ad002f. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x100000b00ad002f, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 17:47:07,545] INFO Session: 0x100000b00ad002f closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:07,545] INFO EventThread shut down for session: 0x100000b00ad002f (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:07,547] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:07,547] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:07,991] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:07,991] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:07,991] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,012] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,012] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,012] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,092] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,092] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,092] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,092] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,093] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,093] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,104] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,104] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,104] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,117] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,117] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,117] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,119] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,119] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,119] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,158] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,158] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,158] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,247] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,247] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,248] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,254] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,254] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:08,254] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:09,002] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:09,002] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:09,003] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:09,068] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:09,068] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:09,068] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:09,099] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:09,099] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:09,099] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:09,112] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:09,112] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:09,113] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:09,158] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:09,158] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:09,159] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:09,253] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:09,253] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:09,253] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:09,991] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:09,991] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:09,993] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:47:10,013] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:47:10,014] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:47:10,014] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:47:10,014] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:47:10,016] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:47:10,017] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:10,017] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:47:10,063] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:10,063] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:10,064] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:10,075] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:10,075] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:10,077] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:47:10,093] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:10,093] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:10,094] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:47:10,098] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:47:10,099] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:47:10,099] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:47:10,100] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:47:10,101] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:47:10,102] INFO App info kafka.server for 4 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:10,103] INFO [KafkaServer id=4] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:47:10,106] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:10,106] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:10,108] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:47:10,115] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:47:10,115] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:47:10,116] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:47:10,116] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:47:10,118] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:47:10,119] INFO App info kafka.server for 3 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:10,119] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:47:10,125] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:47:10,126] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:47:10,126] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:47:10,126] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:47:10,126] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:47:10,127] INFO App info kafka.server for 5 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:10,127] INFO [KafkaServer id=5] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:47:10,157] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:10,157] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:10,159] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:47:10,183] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:47:10,184] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:47:10,184] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:47:10,184] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:47:10,186] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:47:10,187] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:10,187] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:47:10,248] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:10,248] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:10,249] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:47:10,268] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:47:10,268] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:47:10,268] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:47:10,268] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:47:10,269] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:47:10,269] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:10,270] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:47:12,214] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:47:12,220] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:47:12,221] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:47:12,221] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:47:12,221] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:47:12,222] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 17:47:12,223] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 17:47:12,223] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 17:47:12,223] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-15 17:47:12,226] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-15 17:47:12,239] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:47:12,240] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:47:12,240] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:47:12,240] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:47:12,240] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 17:47:12,240] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-15 17:47:12,251] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@6156496 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-15 17:47:12,255] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 17:47:12,265] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,265] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,265] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,265] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,265] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,265] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,265] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,265] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,265] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,265] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,266] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,267] INFO Server environment:host.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,267] INFO Server environment:java.version=11.0.15 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,267] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,267] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,267] INFO Server environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,267] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,267] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,267] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,267] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,267] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,267] INFO Server environment:os.version=5.13.0-40-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,268] INFO Server environment:user.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,268] INFO Server environment:user.home=/home/joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,268] INFO Server environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,268] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,268] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,268] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,268] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,268] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,268] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,268] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,268] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,268] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,268] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,269] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-15 17:47:12,270] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,270] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,271] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 17:47:12,271] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 17:47:12,273] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:47:12,273] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:47:12,273] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:47:12,273] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:47:12,273] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:47:12,273] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 17:47:12,275] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,275] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,275] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 17:47:12,282] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 17:47:12,284] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 17:47:12,286] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 17:47:12,293] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 17:47:12,293] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:459)
	at java.base/sun.nio.ch.Net.bind(Net.java:448)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:676)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:158)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:112)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:67)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:140)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:90)
[2022-05-15 17:47:12,296] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-15 17:47:12,298] ERROR Exiting JVM with code 1 (org.apache.zookeeper.util.ServiceUtils)
[2022-05-15 17:47:17,289] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:47:17,556] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:47:17,646] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:47:17,649] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:47:17,650] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:47:17,667] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:17,673] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:17,673] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:17,673] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:17,673] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:17,673] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:17,674] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:17,674] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:17,674] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:17,674] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:17,674] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:17,674] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:17,674] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:17,674] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:17,674] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:17,674] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:17,674] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:17,675] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:17,675] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:17,677] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:17,682] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:47:17,687] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:17,703] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:17,709] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:17,710] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:17,713] INFO Socket connection established, initiating session, client: /127.0.0.1:57912, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:17,721] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0030, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:17,726] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:17,793] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:17,924] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:47:17,929] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:47:17,978] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:47:17,988] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:47:18,035] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:18,037] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:18,040] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:18,041] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:18,079] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:47:18,083] INFO Skipping recovery for all logs in /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:47:18,154] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:18,177] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-21, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 80ms (1/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:47:18,182] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:18,186] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-1.61582f8bbbfd479eb5715deb729cc913-delete, topicId=1BNya-rrTie1owmr9eGHaA, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (2/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:47:18,191] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:18,193] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-2.f5a8ca650b41499aae1ff0d48732aa51-delete, topicId=1BNya-rrTie1owmr9eGHaA, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (3/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:47:18,209] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 17940 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:18,210] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 17940 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:18,211] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs/__consumer_offsets-39/00000000000000017940.snapshot,17940)' (kafka.log.ProducerStateManager)
[2022-05-15 17:47:18,216] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 17940 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:18,219] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-39, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=17940) with 1 segments in 25ms (4/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:47:18,223] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:18,226] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-15, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:47:18,231] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:18,234] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-45, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:47:18,240] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:18,243] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-33, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:47:18,246] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:18,249] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-4.7b0d8777c2df462bbd39de74adbcc140-delete, topicId=1BNya-rrTie1owmr9eGHaA, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (8/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:47:18,253] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:18,255] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-27, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (9/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:47:18,259] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:18,262] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-3, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:47:18,267] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:18,270] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-9, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (11/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 17:47:18,275] INFO Loaded 11 logs in 196ms. (kafka.log.LogManager)
[2022-05-15 17:47:18,276] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:47:18,278] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:47:18,543] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:18,668] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:47:18,674] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-15 17:47:18,703] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:47:18,711] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:18,728] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:18,730] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:18,731] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:18,732] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:18,745] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:18,790] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:47:18,811] INFO Stat of the created znode at /brokers/ids/0 is: 2295,2295,1652633238802,1652633238802,1,0,0,72057641293905968,192,0,2295
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:47:18,811] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://joao:9092, czxid (broker epoch): 2295 (kafka.zk.KafkaZkClient)
[2022-05-15 17:47:18,866] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:18,875] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:18,876] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:18,893] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:18,920] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:18,941] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:18,947] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:18,948] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:18,980] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:19,004] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:19,025] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:47:19,030] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:47:19,031] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:47:19,037] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:19,038] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:19,038] INFO Kafka startTimeMs: 1652633239031 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:19,041] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-15 17:47:19,115] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:19,125] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:19,126] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:19,126] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 17940 (kafka.cluster.Partition)
[2022-05-15 17:47:19,126] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:19,127] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:19,127] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:19,127] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:19,127] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:19,153] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:19,191] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-3, __consumer_offsets-15, __consumer_offsets-39, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:19,226] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:19,227] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:19,229] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:19,229] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:19,229] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:19,229] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:19,229] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:19,229] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:19,229] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:19,229] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:19,229] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:19,229] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:19,230] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:19,230] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:19,230] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 13 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:19,230] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 13 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:19,236] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 7 milliseconds for epoch 13, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:19,237] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 8 milliseconds for epoch 13, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:19,312] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 83 milliseconds for epoch 13, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:19,313] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 84 milliseconds for epoch 13, of which 84 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:19,313] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 84 milliseconds for epoch 13, of which 84 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:19,314] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 85 milliseconds for epoch 13, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:19,314] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 84 milliseconds for epoch 13, of which 84 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:19,315] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 84 milliseconds for epoch 13, of which 84 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:22,215] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:47:22,483] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:47:22,562] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:47:22,565] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:47:22,566] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:47:22,583] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:22,590] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:22,591] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:22,591] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:22,591] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:22,591] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:22,591] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:22,591] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:22,591] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:22,592] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:22,592] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:22,592] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:22,592] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:22,592] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:22,592] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:22,592] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:22,592] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:22,592] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:22,592] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:22,594] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:22,606] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:47:22,611] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:22,614] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:22,618] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:22,619] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:22,622] INFO Socket connection established, initiating session, client: /127.0.0.1:57914, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:22,629] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0031, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:22,633] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:22,695] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:22,828] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:47:22,834] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:47:22,881] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:47:22,889] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:47:22,940] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:22,941] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:22,943] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:22,945] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:22,981] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:47:22,985] INFO Skipping recovery for all logs in /tmp/kafka-logs-1 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:47:23,061] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:23,087] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-17, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 88ms (1/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:47:23,093] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:23,096] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-35, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (2/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:47:23,103] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:23,106] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-41, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (3/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:47:23,110] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:23,113] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-4.cd4f9e0ddeb940dc94f56c37e2041909-delete, topicId=1BNya-rrTie1owmr9eGHaA, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (4/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:47:23,117] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:23,120] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-5.c3da4785f9f441baa070a445dd9b92ca-delete, topicId=1BNya-rrTie1owmr9eGHaA, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:47:23,126] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:23,129] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-29, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:47:23,133] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:23,138] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-11, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:47:23,142] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:23,146] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-23, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (8/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:47:23,152] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:23,154] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-47, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:47:23,159] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:23,163] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-1.e97ebd018a984284ae286c2972f730ea-delete, topicId=1BNya-rrTie1owmr9eGHaA, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (10/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:47:23,167] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:23,170] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-5, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (11/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 17:47:23,173] INFO Loaded 11 logs in 192ms. (kafka.log.LogManager)
[2022-05-15 17:47:23,173] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:47:23,174] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:47:23,439] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:23,570] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:47:23,574] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-15 17:47:23,605] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:47:23,612] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:23,629] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:23,630] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:23,631] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:23,633] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:23,645] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:23,710] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:47:23,728] INFO Stat of the created znode at /brokers/ids/1 is: 2363,2363,1652633243720,1652633243720,1,0,0,72057641293905969,192,0,2363
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:47:23,729] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://joao:9093, czxid (broker epoch): 2363 (kafka.zk.KafkaZkClient)
[2022-05-15 17:47:23,796] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:23,801] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:23,802] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:23,815] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:23,827] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:23,852] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:23,859] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:23,859] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:23,882] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:23,898] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:23,919] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:47:23,925] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:47:23,926] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:47:23,931] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:23,931] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:23,931] INFO Kafka startTimeMs: 1652633243926 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:23,934] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-15 17:47:24,016] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:24,031] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:24,032] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:24,032] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:24,033] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:24,033] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:24,033] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:24,034] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:24,034] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:24,049] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:24,058] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-5, __consumer_offsets-29, __consumer_offsets-41, __consumer_offsets-23) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:24,097] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:24,098] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:24,101] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:24,101] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:24,101] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:24,102] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:24,102] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:24,102] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:24,102] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:24,102] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:24,102] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:24,102] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:24,102] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:24,103] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:24,103] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:24,103] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:24,110] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 11 milliseconds for epoch 22, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:24,111] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 10 milliseconds for epoch 22, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:24,111] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 9 milliseconds for epoch 22, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:24,112] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 10 milliseconds for epoch 22, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:24,112] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 10 milliseconds for epoch 22, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:24,112] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 10 milliseconds for epoch 22, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:24,113] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 10 milliseconds for epoch 22, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:24,113] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 10 milliseconds for epoch 22, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:27,271] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:47:27,540] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:47:27,622] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:47:27,627] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:47:27,627] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:47:27,645] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:27,651] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:27,651] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:27,651] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:27,651] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:27,651] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:27,651] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:27,652] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:27,652] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:27,652] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:27,652] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:27,652] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:27,652] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:27,652] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:27,652] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:27,652] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:27,652] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:27,652] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:27,652] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:27,654] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:27,660] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:47:27,666] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:27,679] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:27,683] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:27,684] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:27,688] INFO Socket connection established, initiating session, client: /127.0.0.1:57916, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:27,693] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0032, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:27,698] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:27,770] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:27,896] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:47:27,902] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:47:27,949] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:47:27,956] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:47:28,005] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:28,006] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:28,007] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:28,009] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:28,047] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:47:28,051] INFO Skipping recovery for all logs in /tmp/kafka-logs-2 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:47:28,125] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:28,151] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-49, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 86ms (1/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:47:28,156] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:28,162] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-19, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (2/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:47:28,168] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:28,171] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-7, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (3/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:47:28,176] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:28,180] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-13, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:47:28,184] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:28,187] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-37, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:47:28,192] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:28,197] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-43, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (6/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:47:28,202] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:28,206] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-0.4385c1edc6e041d7af7adbacb257590b-delete, topicId=1BNya-rrTie1owmr9eGHaA, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (7/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:47:28,211] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:28,215] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-1, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (8/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:47:28,220] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:28,223] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-31, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (9/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:47:28,227] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:28,230] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-25, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:47:28,235] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:28,238] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-5.5fd87f3e82a64c229bb7f91a529e0507-delete, topicId=1BNya-rrTie1owmr9eGHaA, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (11/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:47:28,242] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:28,245] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-2.0be41a42297747d6a31707dca89205fe-delete, topicId=1BNya-rrTie1owmr9eGHaA, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (12/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 17:47:28,249] INFO Loaded 12 logs in 201ms. (kafka.log.LogManager)
[2022-05-15 17:47:28,250] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:47:28,252] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:47:28,498] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:28,619] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:47:28,622] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-15 17:47:28,647] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:47:28,654] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:28,670] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:28,671] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:28,673] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:28,674] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:28,685] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:28,748] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:47:28,768] INFO Stat of the created znode at /brokers/ids/2 is: 2387,2387,1652633248758,1652633248758,1,0,0,72057641293905970,192,0,2387
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:47:28,769] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://joao:9094, czxid (broker epoch): 2387 (kafka.zk.KafkaZkClient)
[2022-05-15 17:47:28,848] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:28,854] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:28,855] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:28,870] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:28,882] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:28,903] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:28,911] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:28,912] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:28,937] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:28,953] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:28,977] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:47:28,983] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:47:28,984] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:47:28,990] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:28,990] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:28,990] INFO Kafka startTimeMs: 1652633248984 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:28,993] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-15 17:47:29,059] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:29,090] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:29,091] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:29,091] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:29,092] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:29,092] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:29,093] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:29,093] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:29,094] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:29,094] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:29,110] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:29,122] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-7, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:29,155] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 21 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:29,157] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 21 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:29,159] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 21 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:29,160] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 21 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:29,160] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 21 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:29,160] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 21 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:29,160] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 21 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:29,160] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 21 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:29,160] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 21 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:29,160] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 21 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:29,160] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 21 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:29,160] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 21 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:29,160] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 21 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:29,160] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 21 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:29,160] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 21 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:29,161] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 21 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:29,161] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 21 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:29,161] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 21 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:29,168] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 10 milliseconds for epoch 21, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:29,169] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 9 milliseconds for epoch 21, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:29,169] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 9 milliseconds for epoch 21, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:29,170] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 9 milliseconds for epoch 21, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:29,170] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 10 milliseconds for epoch 21, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:29,170] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 10 milliseconds for epoch 21, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:29,170] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 10 milliseconds for epoch 21, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:29,170] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 9 milliseconds for epoch 21, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:29,170] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 9 milliseconds for epoch 21, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:32,290] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:47:32,574] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:47:32,668] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:47:32,672] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:47:32,672] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:47:32,689] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:32,695] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:32,695] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:32,695] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:32,695] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:32,695] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:32,695] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:32,696] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:32,696] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:32,697] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:32,697] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:32,697] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:32,697] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:32,697] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:32,697] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:32,697] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:32,697] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:32,697] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:32,697] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:32,699] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:32,704] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:47:32,709] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:32,721] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:32,726] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:32,728] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:32,733] INFO Socket connection established, initiating session, client: /127.0.0.1:57918, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:32,738] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0033, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:32,743] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:32,815] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:32,957] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:47:32,963] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:47:33,018] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:47:33,028] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:47:33,078] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:33,079] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:33,082] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:33,083] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:33,130] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:47:33,135] INFO Skipping recovery for all logs in /tmp/kafka-logs-3 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:47:33,215] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:33,245] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-14, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 97ms (1/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:47:33,267] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Loading producer state till offset 28503 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:33,267] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Reloading from producer snapshot and rebuilding producer state from offset 28503 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:33,269] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-3/__consumer_offsets-38/00000000000000028503.snapshot,28503)' (kafka.log.ProducerStateManager)
[2022-05-15 17:47:33,275] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Producer state recovery took 8ms for snapshot load and 0ms for segment recovery from offset 28503 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:33,281] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-38, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=28503) with 1 segments in 35ms (2/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:47:33,286] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:33,290] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-8, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (3/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:47:33,298] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:33,305] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-2, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (4/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:47:33,310] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:33,314] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-26, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (5/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:47:33,320] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:33,325] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-20, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (6/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:47:33,329] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:33,333] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-3.f59ca30a8e6f4224a829161d5051150a-delete, topicId=1BNya-rrTie1owmr9eGHaA, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:47:33,337] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:33,340] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-32, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:47:33,345] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:33,348] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-1.298886379efc4bf3a462ae86138e6e55-delete, topicId=1BNya-rrTie1owmr9eGHaA, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:47:33,353] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:33,356] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-0.b869786bb9f74ab8a3ccdf050bbc5b24-delete, topicId=1BNya-rrTie1owmr9eGHaA, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (10/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:47:33,361] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:33,365] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-44, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (11/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 17:47:33,368] INFO Loaded 11 logs in 238ms. (kafka.log.LogManager)
[2022-05-15 17:47:33,369] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:47:33,370] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:47:33,640] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:33,797] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:47:33,802] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-05-15 17:47:33,830] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:47:33,837] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:33,852] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:33,854] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:33,856] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:33,858] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:33,872] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:33,947] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:47:33,967] INFO Stat of the created znode at /brokers/ids/3 is: 2412,2412,1652633253958,1652633253958,1,0,0,72057641293905971,192,0,2412
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:47:33,969] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://joao:9095, czxid (broker epoch): 2412 (kafka.zk.KafkaZkClient)
[2022-05-15 17:47:34,044] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:34,050] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:34,052] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:34,069] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:34,082] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:34,114] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:34,119] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:34,119] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:34,146] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:34,167] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:34,188] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:47:34,194] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:47:34,194] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:47:34,200] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:34,200] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:34,201] INFO Kafka startTimeMs: 1652633254194 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:34,204] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-05-15 17:47:34,329] INFO [Partition __consumer_offsets-2 broker=3] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:34,330] INFO [Partition __consumer_offsets-20 broker=3] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:34,331] INFO [Partition __consumer_offsets-38 broker=3] Log loaded for partition __consumer_offsets-38 with initial high watermark 28503 (kafka.cluster.Partition)
[2022-05-15 17:47:34,331] INFO [Partition __consumer_offsets-8 broker=3] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:34,332] INFO [Partition __consumer_offsets-26 broker=3] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:34,332] INFO [Partition __consumer_offsets-44 broker=3] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:34,333] INFO [Partition __consumer_offsets-14 broker=3] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:34,334] INFO [Partition __consumer_offsets-32 broker=3] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:34,341] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:34,352] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:34,367] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-26, __consumer_offsets-32, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:34,405] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 2 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:34,407] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:34,409] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 20 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:34,410] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:34,410] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 38 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:34,410] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:34,410] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 8 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:34,410] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:34,410] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 26 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:34,411] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:34,411] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 44 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:34,411] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:34,411] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 14 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:34,411] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:34,411] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 32 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:34,411] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:34,420] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-2 in 12 milliseconds for epoch 22, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:34,421] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-20 in 11 milliseconds for epoch 22, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:34,506] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-38 in 96 milliseconds for epoch 22, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:34,507] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-8 in 97 milliseconds for epoch 22, of which 96 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:34,507] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-26 in 96 milliseconds for epoch 22, of which 96 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:34,508] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-44 in 97 milliseconds for epoch 22, of which 97 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:34,508] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-14 in 97 milliseconds for epoch 22, of which 97 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:34,509] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-32 in 98 milliseconds for epoch 22, of which 98 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:37,300] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:47:37,562] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:47:37,649] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:47:37,653] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:47:37,653] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:47:37,670] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:37,674] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:37,674] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:37,674] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:37,674] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:37,674] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:37,674] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:37,675] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:37,675] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:37,675] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:37,675] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:37,675] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:37,675] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:37,675] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:37,675] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:37,675] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:37,675] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:37,675] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:37,675] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:37,677] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:37,682] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:47:37,686] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:37,701] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:37,706] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:37,707] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:37,711] INFO Socket connection established, initiating session, client: /127.0.0.1:57920, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:37,719] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0034, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:37,725] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:37,796] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:37,927] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:47:37,932] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:47:37,981] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:47:37,990] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:47:38,039] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:38,040] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:38,042] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:38,043] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:38,082] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:47:38,086] INFO Skipping recovery for all logs in /tmp/kafka-logs-4 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:47:38,164] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:38,186] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-24, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 84ms (1/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:47:38,192] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:38,197] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-0.008ea0b37279468281d7237db5c9c9d5-delete, topicId=1BNya-rrTie1owmr9eGHaA, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (2/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:47:38,202] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:38,206] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-12, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (3/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:47:38,212] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:38,215] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-30, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (4/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:47:38,220] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:38,224] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-36, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (5/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:47:38,231] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:38,234] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-42, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (6/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:47:38,239] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:38,242] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-0, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:47:38,247] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:38,250] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-3.0c52ff8367ea47e2a8a7143985606cda-delete, topicId=1BNya-rrTie1owmr9eGHaA, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:47:38,254] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:38,258] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-18, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (9/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:47:38,265] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:38,267] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-6, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (10/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:47:38,271] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:38,274] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-48, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:47:38,279] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:38,281] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-4.7819c0f2a7664c379edb5dd95c887c6e-delete, topicId=1BNya-rrTie1owmr9eGHaA, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (12/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 17:47:38,284] INFO Loaded 12 logs in 202ms. (kafka.log.LogManager)
[2022-05-15 17:47:38,285] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:47:38,285] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:47:38,535] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:38,663] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:47:38,666] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.Acceptor)
[2022-05-15 17:47:38,693] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:47:38,700] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:38,716] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:38,717] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:38,719] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:38,720] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:38,734] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:38,799] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:47:38,819] INFO Stat of the created znode at /brokers/ids/4 is: 2436,2436,1652633258812,1652633258812,1,0,0,72057641293905972,192,0,2436
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:47:38,820] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://joao:9096, czxid (broker epoch): 2436 (kafka.zk.KafkaZkClient)
[2022-05-15 17:47:38,887] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:38,894] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:38,895] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:38,908] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:38,924] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:38,951] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:38,955] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:38,955] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:38,979] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:38,996] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:39,016] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:47:39,021] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:47:39,022] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:47:39,028] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:39,029] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:39,029] INFO Kafka startTimeMs: 1652633259022 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:39,031] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2022-05-15 17:47:39,106] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:39,132] INFO [Partition __consumer_offsets-18 broker=4] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:39,133] INFO [Partition __consumer_offsets-36 broker=4] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:39,133] INFO [Partition __consumer_offsets-6 broker=4] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:39,133] INFO [Partition __consumer_offsets-24 broker=4] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:39,134] INFO [Partition __consumer_offsets-42 broker=4] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:39,134] INFO [Partition __consumer_offsets-12 broker=4] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:39,135] INFO [Partition __consumer_offsets-30 broker=4] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:39,135] INFO [Partition __consumer_offsets-0 broker=4] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:39,135] INFO [Partition __consumer_offsets-48 broker=4] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:39,145] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:39,162] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-12, __consumer_offsets-42, __consumer_offsets-18) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:39,199] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 18 in epoch 23 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:39,201] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 23 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:39,203] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 36 in epoch 23 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:39,203] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 23 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:39,203] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 6 in epoch 23 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:39,203] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 23 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:39,203] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 24 in epoch 23 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:39,204] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 23 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:39,204] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 42 in epoch 23 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:39,204] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 23 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:39,204] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 12 in epoch 23 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:39,204] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 23 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:39,204] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 30 in epoch 23 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:39,204] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 23 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:39,204] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 0 in epoch 23 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:39,204] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 23 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:39,204] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 48 in epoch 23 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:39,204] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 23 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:39,211] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-18 in 8 milliseconds for epoch 23, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:39,212] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-36 in 9 milliseconds for epoch 23, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:39,212] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-6 in 9 milliseconds for epoch 23, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:39,213] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-24 in 9 milliseconds for epoch 23, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:39,213] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-42 in 9 milliseconds for epoch 23, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:39,213] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-12 in 9 milliseconds for epoch 23, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:39,214] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-30 in 10 milliseconds for epoch 23, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:39,214] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-0 in 10 milliseconds for epoch 23, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:39,214] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-48 in 10 milliseconds for epoch 23, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:42,261] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 17:47:42,530] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 17:47:42,614] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:47:42,617] INFO starting (kafka.server.KafkaServer)
[2022-05-15 17:47:42,617] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 17:47:42,631] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:42,634] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:42,634] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:42,634] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:42,634] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:42,634] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:42,634] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:42,634] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:42,634] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:42,634] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:42,635] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:42,635] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:42,635] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:42,635] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:42,635] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:42,635] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:42,635] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:42,635] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:42,635] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:42,638] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:47:42,644] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 17:47:42,649] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:42,660] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:42,664] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:42,665] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:42,668] INFO Socket connection established, initiating session, client: /127.0.0.1:57922, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:42,676] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0035, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:47:42,683] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:47:42,757] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:47:42,892] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 17:47:42,898] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 17:47:42,946] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:47:42,954] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 17:47:43,001] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:43,002] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:43,004] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:43,006] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:47:43,044] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:47:43,048] INFO Skipping recovery for all logs in /tmp/kafka-logs-5 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 17:47:43,127] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:43,155] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-46, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 93ms (1/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:47:43,161] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:43,165] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-10, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (2/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:47:43,169] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:43,175] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-28, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (3/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:47:43,179] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:43,183] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-5.2ce10580bc584aef8b9c43892fede293-delete, topicId=1BNya-rrTie1owmr9eGHaA, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:47:43,197] INFO Deleted producer state snapshot /tmp/kafka-logs-5/__consumer_offsets-22/00000000000000006390.snapshot (kafka.log.SnapshotFile)
[2022-05-15 17:47:43,199] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Loading producer state till offset 41030 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:43,199] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 41030 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:43,201] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-22/00000000000000041030.snapshot,41030)' (kafka.log.ProducerStateManager)
[2022-05-15 17:47:43,209] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Producer state recovery took 10ms for snapshot load and 0ms for segment recovery from offset 41030 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:43,213] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-22, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=41030) with 1 segments in 30ms (5/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:47:43,218] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:43,221] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-16, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:47:43,225] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:43,228] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-3.ce4bfbe8a60b45b3af779002b654716d-delete, topicId=1BNya-rrTie1owmr9eGHaA, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (7/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:47:43,232] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:43,234] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-2.f6c5a78bcc8a4554b065c6dcb704d279-delete, topicId=1BNya-rrTie1owmr9eGHaA, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (8/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:47:43,243] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Loading producer state till offset 18252 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:43,243] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 18252 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:43,243] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-40/00000000000000018252.snapshot,18252)' (kafka.log.ProducerStateManager)
[2022-05-15 17:47:43,244] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 18252 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:43,246] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-40, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=18252) with 1 segments in 12ms (9/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:47:43,252] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:43,255] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-34, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (10/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:47:43,260] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:43,263] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-4, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (11/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 17:47:43,265] INFO Loaded 11 logs in 221ms. (kafka.log.LogManager)
[2022-05-15 17:47:43,266] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 17:47:43,268] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 17:47:43,527] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:43,669] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 17:47:43,675] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.Acceptor)
[2022-05-15 17:47:43,703] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:47:43,710] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:43,729] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:43,731] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:43,732] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:43,734] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:43,746] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:47:43,808] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 17:47:43,825] INFO Stat of the created znode at /brokers/ids/5 is: 2461,2461,1652633263817,1652633263817,1,0,0,72057641293905973,192,0,2461
 (kafka.zk.KafkaZkClient)
[2022-05-15 17:47:43,827] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://joao:9097, czxid (broker epoch): 2461 (kafka.zk.KafkaZkClient)
[2022-05-15 17:47:43,895] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:43,901] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:43,903] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:43,918] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:43,930] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:43,959] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:43,964] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:47:43,964] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:47:43,996] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:47:44,020] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:47:44,040] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:47:44,045] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 17:47:44,046] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 17:47:44,050] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:44,051] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:44,051] INFO Kafka startTimeMs: 1652633264046 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:47:44,053] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2022-05-15 17:47:44,116] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:44,138] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:47:44,155] INFO [Partition __consumer_offsets-34 broker=5] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:44,155] INFO [Partition __consumer_offsets-4 broker=5] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:44,155] INFO [Partition __consumer_offsets-22 broker=5] Log loaded for partition __consumer_offsets-22 with initial high watermark 41030 (kafka.cluster.Partition)
[2022-05-15 17:47:44,155] INFO [Partition __consumer_offsets-40 broker=5] Log loaded for partition __consumer_offsets-40 with initial high watermark 18252 (kafka.cluster.Partition)
[2022-05-15 17:47:44,155] INFO [Partition __consumer_offsets-10 broker=5] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:44,156] INFO [Partition __consumer_offsets-28 broker=5] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:44,156] INFO [Partition __consumer_offsets-46 broker=5] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:44,157] INFO [Partition __consumer_offsets-16 broker=5] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:44,185] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:44,215] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 34 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:44,217] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:44,218] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 4 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:44,218] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:44,219] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 22 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:44,219] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:44,219] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 40 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:44,219] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:44,219] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 10 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:44,219] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:44,219] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 28 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:44,219] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:44,219] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 46 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:44,219] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:44,219] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 16 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:47:44,219] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:44,230] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-34 in 12 milliseconds for epoch 24, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:44,231] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-4 in 12 milliseconds for epoch 24, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:44,252] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-9fa5abef-fdc9-4c05-8f09-7f9780632837, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:47:44,263] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-ed3a6d0d-54c4-4b54-b4a4-a5d0ecba6f8e, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:47:44,263] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-1038faf2-d998-4707-9799-897de83d6136, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:47:44,263] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-b283a5ee-70be-4bf9-b41c-74e089f12e34, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:47:44,263] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-360d1581-f79b-41e6-82d3-fe3577615014, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:47:44,263] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-9e173d1e-b47a-4b16-9874-bf5d2688c730, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:47:44,264] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-81fafa38-80dc-43ea-ac6c-e398b06565dc, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:47:44,288] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-d15976bc-df63-4682-8583-fd67cbb1d9df, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:47:44,288] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-a0d7c5c7-e384-4339-b0be-414878362e3e, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:47:44,288] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-ee781f71-f1c3-46d7-bd93-d90a4fe359ff, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:47:44,288] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-78575c72-7be8-4563-b114-53b271a8ef70, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:47:44,288] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-0287b15c-1acd-4475-b9ce-b994aebeeff2, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:47:44,289] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-45d54f6e-f1d8-43f7-8ace-1db96ac0cfac, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 17:47:44,344] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-22 in 125 milliseconds for epoch 24, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:44,364] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-40 in 145 milliseconds for epoch 24, of which 126 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:44,365] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-10 in 146 milliseconds for epoch 24, of which 145 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:44,365] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-28 in 146 milliseconds for epoch 24, of which 146 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:44,366] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-46 in 147 milliseconds for epoch 24, of which 147 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:44,367] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-16 in 148 milliseconds for epoch 24, of which 148 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 17:47:47,910] INFO Creating topic Sensor with configuration {min.insync.replicas=2} and initial partition assignment HashMap(0 -> ArrayBuffer(5, 0, 4)) (kafka.zk.AdminZkClient)
[2022-05-15 17:47:47,952] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:47,963] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:47,964] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:47,965] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 17:47:47,967] INFO Created log for partition Sensor-0 in /tmp/kafka-logs/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:47:47,968] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-4/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:47:47,968] INFO [Partition Sensor-0 broker=0] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 17:47:47,969] INFO [Partition Sensor-0 broker=0] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:47,969] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-5/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 17:47:47,969] INFO [Partition Sensor-0 broker=4] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 17:47:47,970] INFO [Partition Sensor-0 broker=4] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:47,970] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:47,970] INFO [Partition Sensor-0 broker=5] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 17:47:47,971] INFO [Partition Sensor-0 broker=5] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 17:47:47,971] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:47,987] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:47,990] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 5 for partitions Map(Sensor-0 -> InitialFetchState(Some(p9wUrT5ySYuWIhJ6i536_w),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:47,993] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:47,994] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:47,996] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:47:47,997] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 5 for partitions Map(Sensor-0 -> InitialFetchState(Some(p9wUrT5ySYuWIhJ6i536_w),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:47:47,998] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:47:48,000] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 17:48:18,190] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=474016, lastModifiedTime=1652632861087, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:48:18,192] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=474016, lastModifiedTime=1652632861087, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:48:18,195] INFO Deleted log /tmp/kafka-logs/Sensor-1.61582f8bbbfd479eb5715deb729cc913-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:18,195] INFO Deleted offset index /tmp/kafka-logs/Sensor-1.61582f8bbbfd479eb5715deb729cc913-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:18,198] INFO Deleted time index /tmp/kafka-logs/Sensor-1.61582f8bbbfd479eb5715deb729cc913-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:18,204] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs/Sensor-1.61582f8bbbfd479eb5715deb729cc913-delete. (kafka.log.LogManager)
[2022-05-15 17:48:18,205] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=470269, lastModifiedTime=1652632861039, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:48:18,205] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=470269, lastModifiedTime=1652632861039, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:48:18,206] INFO Deleted log /tmp/kafka-logs/Sensor-2.f5a8ca650b41499aae1ff0d48732aa51-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:18,206] INFO Deleted offset index /tmp/kafka-logs/Sensor-2.f5a8ca650b41499aae1ff0d48732aa51-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:18,206] INFO Deleted time index /tmp/kafka-logs/Sensor-2.f5a8ca650b41499aae1ff0d48732aa51-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:18,207] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs/Sensor-2.f5a8ca650b41499aae1ff0d48732aa51-delete. (kafka.log.LogManager)
[2022-05-15 17:48:18,249] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=216697, lastModifiedTime=1652632843091, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:48:18,250] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=216697, lastModifiedTime=1652632843091, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:48:18,252] INFO Deleted log /tmp/kafka-logs/Sensor-4.7b0d8777c2df462bbd39de74adbcc140-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:18,252] INFO Deleted offset index /tmp/kafka-logs/Sensor-4.7b0d8777c2df462bbd39de74adbcc140-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:18,253] INFO Deleted time index /tmp/kafka-logs/Sensor-4.7b0d8777c2df462bbd39de74adbcc140-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:18,253] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs/Sensor-4.7b0d8777c2df462bbd39de74adbcc140-delete. (kafka.log.LogManager)
[2022-05-15 17:48:23,117] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=216697, lastModifiedTime=1652632843095, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:48:23,118] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=216697, lastModifiedTime=1652632843095, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:48:23,121] INFO Deleted log /tmp/kafka-logs-1/Sensor-4.cd4f9e0ddeb940dc94f56c37e2041909-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:23,122] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-4.cd4f9e0ddeb940dc94f56c37e2041909-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:23,126] INFO Deleted time index /tmp/kafka-logs-1/Sensor-4.cd4f9e0ddeb940dc94f56c37e2041909-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:23,133] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-1/Sensor-4.cd4f9e0ddeb940dc94f56c37e2041909-delete. (kafka.log.LogManager)
[2022-05-15 17:48:23,134] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=236118, lastModifiedTime=1652632844087, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:48:23,134] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=236118, lastModifiedTime=1652632844087, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:48:23,135] INFO Deleted log /tmp/kafka-logs-1/Sensor-5.c3da4785f9f441baa070a445dd9b92ca-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:23,135] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-5.c3da4785f9f441baa070a445dd9b92ca-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:23,136] INFO Deleted time index /tmp/kafka-logs-1/Sensor-5.c3da4785f9f441baa070a445dd9b92ca-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:23,136] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-1/Sensor-5.c3da4785f9f441baa070a445dd9b92ca-delete. (kafka.log.LogManager)
[2022-05-15 17:48:23,163] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=474016, lastModifiedTime=1652632861087, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:48:23,163] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=474016, lastModifiedTime=1652632861087, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:48:23,165] INFO Deleted log /tmp/kafka-logs-1/Sensor-1.e97ebd018a984284ae286c2972f730ea-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:23,165] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-1.e97ebd018a984284ae286c2972f730ea-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:23,165] INFO Deleted time index /tmp/kafka-logs-1/Sensor-1.e97ebd018a984284ae286c2972f730ea-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:23,166] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-1/Sensor-1.e97ebd018a984284ae286c2972f730ea-delete. (kafka.log.LogManager)
[2022-05-15 17:48:28,211] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=466623, lastModifiedTime=1652632860807, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:48:28,213] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=466623, lastModifiedTime=1652632860807, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:48:28,216] INFO Deleted log /tmp/kafka-logs-2/Sensor-0.4385c1edc6e041d7af7adbacb257590b-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:28,217] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-0.4385c1edc6e041d7af7adbacb257590b-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:28,219] INFO Deleted time index /tmp/kafka-logs-2/Sensor-0.4385c1edc6e041d7af7adbacb257590b-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:28,222] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-2/Sensor-0.4385c1edc6e041d7af7adbacb257590b-delete. (kafka.log.LogManager)
[2022-05-15 17:48:28,238] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=236118, lastModifiedTime=1652632844083, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:48:28,238] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=236118, lastModifiedTime=1652632844083, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:48:28,239] INFO Deleted log /tmp/kafka-logs-2/Sensor-5.5fd87f3e82a64c229bb7f91a529e0507-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:28,239] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-5.5fd87f3e82a64c229bb7f91a529e0507-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:28,240] INFO Deleted time index /tmp/kafka-logs-2/Sensor-5.5fd87f3e82a64c229bb7f91a529e0507-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:28,241] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-2/Sensor-5.5fd87f3e82a64c229bb7f91a529e0507-delete. (kafka.log.LogManager)
[2022-05-15 17:48:28,246] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=470269, lastModifiedTime=1652632861039, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:48:28,246] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=470269, lastModifiedTime=1652632861039, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:48:28,247] INFO Deleted log /tmp/kafka-logs-2/Sensor-2.0be41a42297747d6a31707dca89205fe-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:28,247] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-2.0be41a42297747d6a31707dca89205fe-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:28,247] INFO Deleted time index /tmp/kafka-logs-2/Sensor-2.0be41a42297747d6a31707dca89205fe-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:28,248] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-2/Sensor-2.0be41a42297747d6a31707dca89205fe-delete. (kafka.log.LogManager)
[2022-05-15 17:48:33,336] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=495067, lastModifiedTime=1652632861895, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:48:33,339] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=495067, lastModifiedTime=1652632861895, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:48:33,344] INFO Deleted log /tmp/kafka-logs-3/Sensor-3.f59ca30a8e6f4224a829161d5051150a-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:33,344] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-3.f59ca30a8e6f4224a829161d5051150a-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:33,346] INFO Deleted time index /tmp/kafka-logs-3/Sensor-3.f59ca30a8e6f4224a829161d5051150a-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:33,349] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-3/Sensor-3.f59ca30a8e6f4224a829161d5051150a-delete. (kafka.log.LogManager)
[2022-05-15 17:48:33,350] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=474016, lastModifiedTime=1652632861087, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:48:33,350] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=474016, lastModifiedTime=1652632861087, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:48:33,351] INFO Deleted log /tmp/kafka-logs-3/Sensor-1.298886379efc4bf3a462ae86138e6e55-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:33,351] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-1.298886379efc4bf3a462ae86138e6e55-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:33,351] INFO Deleted time index /tmp/kafka-logs-3/Sensor-1.298886379efc4bf3a462ae86138e6e55-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:33,352] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-3/Sensor-1.298886379efc4bf3a462ae86138e6e55-delete. (kafka.log.LogManager)
[2022-05-15 17:48:33,357] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=466623, lastModifiedTime=1652632860807, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:48:33,358] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=466623, lastModifiedTime=1652632860807, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:48:33,360] INFO Deleted log /tmp/kafka-logs-3/Sensor-0.b869786bb9f74ab8a3ccdf050bbc5b24-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:33,360] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-0.b869786bb9f74ab8a3ccdf050bbc5b24-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:33,361] INFO Deleted time index /tmp/kafka-logs-3/Sensor-0.b869786bb9f74ab8a3ccdf050bbc5b24-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:33,361] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-3/Sensor-0.b869786bb9f74ab8a3ccdf050bbc5b24-delete. (kafka.log.LogManager)
[2022-05-15 17:48:38,200] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=466623, lastModifiedTime=1652632860807, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:48:38,202] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=466623, lastModifiedTime=1652632860807, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:48:38,207] INFO Deleted log /tmp/kafka-logs-4/Sensor-0.008ea0b37279468281d7237db5c9c9d5-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:38,207] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-0.008ea0b37279468281d7237db5c9c9d5-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:38,210] INFO Deleted time index /tmp/kafka-logs-4/Sensor-0.008ea0b37279468281d7237db5c9c9d5-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:38,213] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-4/Sensor-0.008ea0b37279468281d7237db5c9c9d5-delete. (kafka.log.LogManager)
[2022-05-15 17:48:38,250] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=495067, lastModifiedTime=1652632861895, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:48:38,251] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=495067, lastModifiedTime=1652632861895, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:48:38,252] INFO Deleted log /tmp/kafka-logs-4/Sensor-3.0c52ff8367ea47e2a8a7143985606cda-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:38,252] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-3.0c52ff8367ea47e2a8a7143985606cda-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:38,252] INFO Deleted time index /tmp/kafka-logs-4/Sensor-3.0c52ff8367ea47e2a8a7143985606cda-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:38,253] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-4/Sensor-3.0c52ff8367ea47e2a8a7143985606cda-delete. (kafka.log.LogManager)
[2022-05-15 17:48:38,282] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=216697, lastModifiedTime=1652632843091, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:48:38,283] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=216697, lastModifiedTime=1652632843091, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:48:38,283] INFO Deleted log /tmp/kafka-logs-4/Sensor-4.7819c0f2a7664c379edb5dd95c887c6e-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:38,284] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-4.7819c0f2a7664c379edb5dd95c887c6e-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:38,284] INFO Deleted time index /tmp/kafka-logs-4/Sensor-4.7819c0f2a7664c379edb5dd95c887c6e-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:38,285] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-4/Sensor-4.7819c0f2a7664c379edb5dd95c887c6e-delete. (kafka.log.LogManager)
[2022-05-15 17:48:43,186] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=236118, lastModifiedTime=1652632844083, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:48:43,188] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=236118, lastModifiedTime=1652632844083, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:48:43,190] INFO Deleted log /tmp/kafka-logs-5/Sensor-5.2ce10580bc584aef8b9c43892fede293-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:43,191] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-5.2ce10580bc584aef8b9c43892fede293-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:43,195] INFO Deleted time index /tmp/kafka-logs-5/Sensor-5.2ce10580bc584aef8b9c43892fede293-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:43,200] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-5/Sensor-5.2ce10580bc584aef8b9c43892fede293-delete. (kafka.log.LogManager)
[2022-05-15 17:48:43,227] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=495067, lastModifiedTime=1652632861895, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:48:43,228] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=495067, lastModifiedTime=1652632861895, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:48:43,229] INFO Deleted log /tmp/kafka-logs-5/Sensor-3.ce4bfbe8a60b45b3af779002b654716d-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:43,230] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-3.ce4bfbe8a60b45b3af779002b654716d-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:43,230] INFO Deleted time index /tmp/kafka-logs-5/Sensor-3.ce4bfbe8a60b45b3af779002b654716d-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:43,231] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-5/Sensor-3.ce4bfbe8a60b45b3af779002b654716d-delete. (kafka.log.LogManager)
[2022-05-15 17:48:43,234] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=470269, lastModifiedTime=1652632861039, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 17:48:43,235] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=470269, lastModifiedTime=1652632861039, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 17:48:43,235] INFO Deleted log /tmp/kafka-logs-5/Sensor-2.f6c5a78bcc8a4554b065c6dcb704d279-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:43,236] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-2.f6c5a78bcc8a4554b065c6dcb704d279-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:43,236] INFO Deleted time index /tmp/kafka-logs-5/Sensor-2.f6c5a78bcc8a4554b065c6dcb704d279-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 17:48:43,236] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-5/Sensor-2.f6c5a78bcc8a4554b065c6dcb704d279-delete. (kafka.log.LogManager)
[2022-05-15 17:50:23,600] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group consumer in Empty state. Created a new member id consumer-consumer-1-954ef0dc-d124-405b-9bb6-119086dd08c0 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:50:23,619] INFO [GroupCoordinator 5]: Preparing to rebalance group consumer in state PreparingRebalance with old generation 0 (__consumer_offsets-22) (reason: Adding new member consumer-consumer-1-954ef0dc-d124-405b-9bb6-119086dd08c0 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:50:23,624] INFO [GroupCoordinator 5]: Stabilized group consumer generation 1 (__consumer_offsets-22) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:50:23,638] INFO [GroupCoordinator 5]: Assignment received from leader consumer-consumer-1-954ef0dc-d124-405b-9bb6-119086dd08c0 for group consumer for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:51:11,634] INFO [GroupCoordinator 5]: Member consumer-consumer-1-954ef0dc-d124-405b-9bb6-119086dd08c0 in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:51:11,635] INFO [GroupCoordinator 5]: Preparing to rebalance group consumer in state PreparingRebalance with old generation 1 (__consumer_offsets-22) (reason: removing member consumer-consumer-1-954ef0dc-d124-405b-9bb6-119086dd08c0 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:51:11,636] INFO [GroupCoordinator 5]: Group consumer with generation 2 is now empty (__consumer_offsets-22) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:51:29,346] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group consumer in Empty state. Created a new member id consumer-consumer-1-3f51cd43-28ab-4459-969e-211543e6cd72 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:51:29,355] INFO [GroupCoordinator 5]: Preparing to rebalance group consumer in state PreparingRebalance with old generation 2 (__consumer_offsets-22) (reason: Adding new member consumer-consumer-1-3f51cd43-28ab-4459-969e-211543e6cd72 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:51:29,359] INFO [GroupCoordinator 5]: Stabilized group consumer generation 3 (__consumer_offsets-22) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:51:29,399] INFO [GroupCoordinator 5]: Assignment received from leader consumer-consumer-1-3f51cd43-28ab-4459-969e-211543e6cd72 for group consumer for generation 3. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:53:07,768] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group consumer in Stable state. Created a new member id consumer-consumer-1-4b8634e2-92f3-4603-97c5-35df7219bd84 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:53:07,798] INFO [GroupCoordinator 5]: Preparing to rebalance group consumer in state PreparingRebalance with old generation 3 (__consumer_offsets-22) (reason: Adding new member consumer-consumer-1-4b8634e2-92f3-4603-97c5-35df7219bd84 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:53:39,307] INFO [GroupCoordinator 5]: Member consumer-consumer-1-3f51cd43-28ab-4459-969e-211543e6cd72 in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:53:39,309] INFO [GroupCoordinator 5]: Stabilized group consumer generation 4 (__consumer_offsets-22) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:53:39,320] INFO [GroupCoordinator 5]: Assignment received from leader consumer-consumer-1-4b8634e2-92f3-4603-97c5-35df7219bd84 for group consumer for generation 4. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:56:23,464] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:56:23,466] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:56:23,466] INFO [GroupCoordinator 4]: Removed 0 offsets associated with deleted partitions: Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:56:23,467] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:56:23,467] INFO [GroupCoordinator 3]: Removed 0 offsets associated with deleted partitions: Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:56:23,472] INFO [GroupCoordinator 5]: Removed 1 offsets associated with deleted partitions: Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:56:23,484] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:56:23,485] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:56:23,485] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:56:23,485] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:56:23,486] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:56:23,486] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:56:23,489] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:56:23,490] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:56:23,490] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:56:23,490] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:56:23,492] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:23,492] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:23,495] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 11567 due to node 5 being disconnected (elapsed time since creation: 387ms, elapsed time since send: 387ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:23,495] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 11567 due to node 5 being disconnected (elapsed time since creation: 387ms, elapsed time since send: 387ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:23,496] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=253338603, epoch=11567) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:56:23,496] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:56:23,496] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:56:23,495] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=910327841, epoch=11567) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 17:56:23,499] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:56:23,499] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 17:56:23,501] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:56:23,501] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:56:23,503] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-5/Sensor-0.d0038cb97f28474fa784aa562da7ae1b-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:56:23,504] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:56:23,504] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:56:23,509] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs/Sensor-0.f347012a743244e68bd164ee66f3de06-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:56:23,514] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-4/Sensor-0.783bcff9861845a599f7764eceb8c7d2-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 17:56:26,828] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:56:26,829] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:56:26,829] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:56:26,829] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:56:26,829] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:56:26,829] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 17:56:26,831] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:56:26,832] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:56:26,831] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:56:26,833] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:56:26,833] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:56:26,834] INFO [KafkaServer id=5] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:56:26,832] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:56:26,833] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-05-15 17:56:26,835] INFO [KafkaServer id=4] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:56:26,836] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:56:26,836] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:56:26,839] INFO [KafkaServer id=5] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 17:56:26,858] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 20ms (kafka.server.KafkaServer)
[2022-05-15 17:56:26,860] INFO [KafkaServer id=4] Controlled shutdown request returned successfully after 12ms (kafka.server.KafkaServer)
[2022-05-15 17:56:26,861] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:56:26,861] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:56:26,861] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:56:26,863] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:56:26,863] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:56:26,863] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:56:26,863] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:56:26,863] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 8ms (kafka.server.KafkaServer)
[2022-05-15 17:56:26,864] INFO [KafkaServer id=5] Controlled shutdown request returned successfully after 11ms (kafka.server.KafkaServer)
[2022-05-15 17:56:26,864] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:56:26,866] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 13ms (kafka.server.KafkaServer)
[2022-05-15 17:56:26,870] INFO [KafkaServer id=3] Controlled shutdown request returned successfully after 13ms (kafka.server.KafkaServer)
[2022-05-15 17:56:26,870] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:56:26,872] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:56:26,874] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:56:26,874] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:56:26,876] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:56:26,876] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:56:26,878] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:56:26,879] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:56:26,879] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:56:26,879] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:56:26,880] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:56:26,880] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:56:26,881] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:56:26,880] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:56:26,882] INFO [data-plane Kafka Request Handler on Broker 4], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:56:26,885] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:56:26,885] INFO [data-plane Kafka Request Handler on Broker 4], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:56:26,879] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:56:26,888] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:56:26,888] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:56:26,889] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:56:26,889] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 17:56:26,890] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:56:26,890] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:56:26,892] INFO [ExpirationReaper-4-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:26,892] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:26,894] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:56:26,895] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:56:26,897] INFO [data-plane Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:56:26,897] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:56:26,898] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:56:26,899] INFO [data-plane Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:56:26,900] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:26,901] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:56:26,902] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 17:56:26,903] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:26,904] INFO [data-plane Kafka Request Handler on Broker 5], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:56:26,906] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:26,907] INFO [ExpirationReaper-3-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:26,907] INFO [data-plane Kafka Request Handler on Broker 5], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 17:56:26,903] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:26,908] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:56:26,909] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:26,909] INFO [ExpirationReaper-5-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:26,935] INFO [ExpirationReaper-3-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:26,935] INFO [ExpirationReaper-3-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:26,936] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:56:26,939] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:26,963] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:26,963] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:26,964] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:56:26,964] INFO [ExpirationReaper-5-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:26,964] INFO [ExpirationReaper-5-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:26,965] INFO [ExpirationReaper-4-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:26,965] INFO [ExpirationReaper-4-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:26,966] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:26,966] INFO [KafkaApi-5] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:56:26,966] INFO [KafkaApi-4] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:56:26,967] INFO [ExpirationReaper-5-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:26,968] INFO [ExpirationReaper-4-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,005] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,005] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,008] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:56:27,010] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:56:27,010] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:56:27,011] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:56:27,011] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:56:27,012] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:56:27,013] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:56:27,013] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,019] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,019] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,022] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:56:27,024] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:56:27,024] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:56:27,025] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:56:27,025] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:56:27,026] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:56:27,027] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:56:27,027] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,059] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,059] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,061] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:56:27,063] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:56:27,063] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:56:27,064] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:56:27,064] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:56:27,066] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:56:27,066] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:56:27,066] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,072] INFO [ExpirationReaper-4-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,072] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,072] INFO [ExpirationReaper-4-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,072] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,074] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 17:56:27,074] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,076] INFO [TransactionCoordinator id=4] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:56:27,077] INFO [Transaction State Manager 4]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:56:27,077] INFO [Transaction Marker Channel Manager 4]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:56:27,078] INFO [Transaction Marker Channel Manager 4]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:56:27,078] INFO [Transaction Marker Channel Manager 4]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:56:27,079] INFO [TransactionCoordinator id=4] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:56:27,080] INFO [GroupCoordinator 4]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:56:27,080] INFO [ExpirationReaper-4-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,081] INFO [ExpirationReaper-4-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,081] INFO [ExpirationReaper-4-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,082] INFO [ExpirationReaper-4-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,086] INFO [ExpirationReaper-5-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,086] INFO [ExpirationReaper-5-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,089] INFO [TransactionCoordinator id=5] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:56:27,090] INFO [Transaction State Manager 5]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:56:27,090] INFO [Transaction Marker Channel Manager 5]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:56:27,090] INFO [Transaction Marker Channel Manager 5]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:56:27,090] INFO [Transaction Marker Channel Manager 5]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:56:27,091] INFO [TransactionCoordinator id=5] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:56:27,092] INFO [GroupCoordinator 5]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:56:27,092] INFO [ExpirationReaper-5-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,192] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,192] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,194] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:56:27,195] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 17:56:27,196] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:56:27,197] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:56:27,197] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 17:56:27,199] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 17:56:27,199] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:56:27,200] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,204] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,204] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,205] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,205] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,205] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,205] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:56:27,205] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,205] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,206] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,206] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:56:27,207] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:56:27,207] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:56:27,207] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:56:27,208] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:56:27,209] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:56:27,209] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:56:27,209] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:56:27,210] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,245] INFO [ExpirationReaper-5-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,245] INFO [ExpirationReaper-5-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,245] INFO [ExpirationReaper-5-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,255] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,255] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,256] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,260] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,260] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,260] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,272] INFO [ExpirationReaper-4-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,272] INFO [ExpirationReaper-4-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,273] INFO [GroupCoordinator 4]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:56:27,274] INFO [ReplicaManager broker=4] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:56:27,275] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:56:27,275] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:56:27,275] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:56:27,276] INFO [ReplicaFetcherManager on broker 4] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:56:27,278] INFO [ReplicaFetcherManager on broker 4] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:56:27,279] INFO [ReplicaAlterLogDirsManager on broker 4] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:56:27,279] INFO [ReplicaAlterLogDirsManager on broker 4] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:56:27,279] INFO [ExpirationReaper-4-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,292] INFO [ExpirationReaper-4-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,292] INFO [ExpirationReaper-4-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,292] INFO [ExpirationReaper-4-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,319] INFO [ExpirationReaper-5-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,319] INFO [ExpirationReaper-5-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,320] INFO [GroupCoordinator 5]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:56:27,321] INFO [ReplicaManager broker=5] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:56:27,321] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:56:27,321] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:56:27,321] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:56:27,322] INFO [ReplicaFetcherManager on broker 5] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:56:27,323] INFO [ReplicaFetcherManager on broker 5] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:56:27,323] INFO [ReplicaAlterLogDirsManager on broker 5] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:56:27,324] INFO [ReplicaAlterLogDirsManager on broker 5] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:56:27,324] INFO [ExpirationReaper-5-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,384] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,384] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,385] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,405] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,405] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,406] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:56:27,407] INFO [ExpirationReaper-5-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,407] INFO [ExpirationReaper-5-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,408] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:56:27,408] INFO [ExpirationReaper-5-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,408] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:56:27,408] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:56:27,408] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:56:27,410] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:56:27,412] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:56:27,413] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:56:27,413] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:56:27,413] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,445] INFO [ExpirationReaper-5-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,445] INFO [ExpirationReaper-5-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,446] INFO [ExpirationReaper-5-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,453] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,453] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,454] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,460] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,460] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,461] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:56:27,462] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:56:27,462] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:56:27,462] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:56:27,462] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:56:27,463] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:56:27,464] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:56:27,464] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:56:27,465] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:56:27,465] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,481] INFO [ExpirationReaper-4-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,481] INFO [ExpirationReaper-4-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,482] INFO [ExpirationReaper-4-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,493] INFO [ExpirationReaper-4-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,494] INFO [ExpirationReaper-4-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,494] INFO [ExpirationReaper-4-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,513] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,513] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,513] INFO [ExpirationReaper-5-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,513] INFO [ExpirationReaper-5-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,514] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,514] INFO [ExpirationReaper-5-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,517] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,517] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,518] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,519] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,519] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,520] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,574] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,574] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,575] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 17:56:27,576] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 17:56:27,577] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:56:27,577] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:56:27,578] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 17:56:27,578] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:56:27,579] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 17:56:27,579] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:56:27,580] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 17:56:27,580] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,599] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,599] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,600] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,610] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,610] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,611] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,650] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,650] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,650] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,692] INFO [ExpirationReaper-4-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,692] INFO [ExpirationReaper-4-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,701] INFO [ReplicaManager broker=4] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:56:27,701] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,702] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,702] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,706] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:56:27,706] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,707] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,707] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,707] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:56:27,708] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:56:27,708] INFO [ExpirationReaper-5-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,708] INFO [ExpirationReaper-5-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,712] INFO [ReplicaManager broker=5] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:56:27,712] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,713] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,713] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,713] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,713] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,715] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:56:27,715] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,715] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,715] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,716] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:56:27,717] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:56:27,717] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:56:27,718] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,718] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,718] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,720] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:56:27,720] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,721] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,721] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,721] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:56:27,722] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:56:27,728] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:56:27,732] INFO [ProducerStateManager partition=__consumer_offsets-22] Wrote producer snapshot at offset 41063 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-05-15 17:56:27,732] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:56:27,732] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:56:27,732] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:56:27,733] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:56:27,738] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:56:27,741] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:56:27,745] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:56:27,746] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:56:27,746] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:56:27,747] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:56:27,759] INFO [Controller id=0, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,759] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,759] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,759] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,759] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,764] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,764] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,764] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,764] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,764] INFO [Controller id=0, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,764] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,764] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,764] WARN [Controller id=0, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,764] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,764] WARN [Controller id=0, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,765] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,765] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,765] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,765] INFO [Controller id=0, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,765] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,766] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,768] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,769] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,771] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,772] INFO [Controller id=0, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,774] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:56:27,774] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:56:27,774] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:56:27,775] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:56:27,793] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,793] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,793] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,799] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,799] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,800] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,810] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,810] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,810] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,811] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,811] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,815] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:56:27,816] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,816] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,816] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,818] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:56:27,818] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,819] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,819] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,820] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:56:27,821] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:56:27,836] INFO Session: 0x100000b00ad0034 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:56:27,836] INFO EventThread shut down for session: 0x100000b00ad0034 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:56:27,838] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:56:27,839] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:27,840] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:56:27,840] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,840] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:27,843] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:56:27,844] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,845] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,845] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,846] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:56:27,847] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,847] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,847] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:27,848] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:56:27,848] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:56:27,850] INFO EventThread shut down for session: 0x100000b00ad0035 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:56:27,850] INFO Session: 0x100000b00ad0035 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:56:27,852] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:56:27,852] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:27,868] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:56:27,875] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:56:27,876] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:56:27,876] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:56:27,877] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:56:27,879] INFO Session: 0x100000b00ad0030 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:56:27,879] INFO EventThread shut down for session: 0x100000b00ad0030 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:56:27,879] INFO [Controller id=1, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,879] INFO [Controller id=1, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,879] INFO [Controller id=1, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,881] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:56:27,882] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:27,882] WARN [Controller id=1, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,882] WARN [Controller id=1, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,882] WARN [Controller id=1, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,886] INFO [Controller id=1, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,886] INFO [Controller id=1, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,886] INFO [Controller id=1, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,983] INFO EventThread shut down for session: 0x100000b00ad0032 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:56:27,983] INFO Session: 0x100000b00ad0032 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:56:27,985] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:56:27,986] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:27,987] INFO [Controller id=1, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,987] INFO [Controller id=1, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,987] WARN [Controller id=1, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,987] WARN [Controller id=1, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,988] INFO [Controller id=1, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,988] INFO [Controller id=1, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,989] INFO [Controller id=1, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,989] WARN [Controller id=1, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:27,989] INFO [Controller id=1, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:28,005] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:28,005] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:28,006] INFO [ExpirationReaper-3-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:28,036] INFO [Controller id=1, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:28,039] INFO [Controller id=1, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:28,040] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:56:28,041] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:56:28,041] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:56:28,041] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:56:28,075] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:28,075] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:28,075] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:28,082] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:28,082] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:28,082] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:28,112] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:28,112] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:28,112] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:28,113] INFO [Controller id=3, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:28,114] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:28,114] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:28,114] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:28,114] WARN [Controller id=3, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:28,115] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:28,115] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:28,115] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:28,116] INFO [Controller id=3, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:28,145] INFO Session: 0x100000b00ad0031 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:56:28,145] INFO EventThread shut down for session: 0x100000b00ad0031 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:56:28,148] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:56:28,148] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:28,205] INFO [ExpirationReaper-3-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:28,205] INFO [ExpirationReaper-3-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 17:56:28,208] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 17:56:28,209] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:28,209] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:28,209] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:28,211] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:56:28,212] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:28,212] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:28,212] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 17:56:28,213] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 17:56:28,213] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 17:56:28,217] INFO [Controller id=3, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:28,217] WARN [Controller id=3, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:28,218] INFO [Controller id=3, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:28,241] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 17:56:28,290] INFO [Controller id=3, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 17:56:28,293] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:56:28,293] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:56:28,293] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 17:56:28,295] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:56:28,400] INFO EventThread shut down for session: 0x100000b00ad0033 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 17:56:28,400] INFO Session: 0x100000b00ad0033 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 17:56:28,402] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 17:56:28,403] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,025] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,025] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,026] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,075] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,075] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,075] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,080] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,080] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,080] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,082] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,082] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,082] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,084] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,084] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,085] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,092] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,092] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,094] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:56:29,109] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:56:29,110] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:56:29,110] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:56:29,110] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:56:29,112] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:56:29,112] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,112] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,112] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,113] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,113] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:56:29,113] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,113] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,113] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:56:29,113] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,113] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,115] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:56:29,119] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,119] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,120] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,134] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:56:29,135] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:56:29,135] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:56:29,135] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:56:29,137] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:56:29,138] INFO App info kafka.server for 4 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:56:29,138] INFO [KafkaServer id=4] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:56:29,158] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,158] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:29,158] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:30,021] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:30,021] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:30,021] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:30,082] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:30,082] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:30,084] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:56:30,105] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:56:30,105] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:56:30,105] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:56:30,106] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:56:30,107] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:56:30,107] INFO App info kafka.server for 5 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:56:30,107] INFO [KafkaServer id=5] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:56:30,113] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:30,113] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:30,114] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:56:30,129] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:56:30,130] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:56:30,130] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:56:30,130] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:56:30,132] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:56:30,133] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:56:30,133] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:56:30,156] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:30,156] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:30,157] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:30,163] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:30,163] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:30,163] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:31,017] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:31,017] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:31,017] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:31,022] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:31,022] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:31,023] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:56:31,051] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:56:31,052] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:56:31,052] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:56:31,052] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:56:31,054] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:56:31,054] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:56:31,055] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-15 17:56:31,163] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:31,163] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 17:56:31,164] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 17:56:31,179] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 17:56:31,180] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:56:31,180] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:56:31,180] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 17:56:31,181] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 17:56:31,182] INFO App info kafka.server for 3 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 17:56:31,182] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
