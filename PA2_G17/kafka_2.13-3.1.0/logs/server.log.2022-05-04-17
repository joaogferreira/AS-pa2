[2022-05-04 17:09:56,732] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:09:56,765] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:09:56,766] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:09:56,775] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:09:56,776] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:09:56,779] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 3429 due to node 1 being disconnected (elapsed time since creation: 80ms, elapsed time since send: 80ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:09:56,779] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=89822184, epoch=3427) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-04 17:09:56,781] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:09:56,781] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:09:56,786] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:09:56,787] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:09:56,787] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 3429 due to node 4 being disconnected (elapsed time since creation: 131ms, elapsed time since send: 131ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:09:56,787] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=1276470756, epoch=3427) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-04 17:09:56,788] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:09:56,788] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:09:56,792] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:09:56,792] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:09:56,812] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-2/Sensor-5.7ff1c20f5a344792877a773a59b0bc84-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-04 17:09:56,815] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-2/Sensor-0.7184a6ce6e304c88baa67cc9463d7900-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-04 17:09:56,819] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-2/Sensor-1.0a56dc8cdabb4eaf9833b33974941e6d-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-04 17:09:57,099] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 17:09:57,101] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-04 17:09:57,103] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-04 17:09:57,128] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 11ms (kafka.server.KafkaServer)
[2022-05-04 17:09:57,131] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:09:57,132] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:09:57,132] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:09:57,134] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-04 17:09:57,149] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-04 17:09:57,151] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 17:09:57,157] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 17:09:57,161] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:57,195] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:57,195] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:57,196] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-04 17:09:57,198] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:57,332] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:57,332] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:57,334] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:09:57,336] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-04 17:09:57,336] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:09:57,336] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:09:57,336] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:09:57,338] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:09:57,338] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:09:57,339] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:57,454] WARN Session 0x1000116d1d90002 for sever localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x1000116d1d90002, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-04 17:09:57,499] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:57,499] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:57,500] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:57,695] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:57,695] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:57,697] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:09:57,697] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-04 17:09:57,698] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:09:57,698] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:09:57,698] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:09:57,699] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:09:57,700] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:09:57,700] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:09:57,701] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:09:57,701] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:57,754] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:57,754] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:57,754] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:57,881] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:57,881] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:57,881] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:57,897] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:57,897] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:57,897] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:58,082] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:58,082] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:09:58,088] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-04 17:09:58,088] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:09:58,088] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:09:58,088] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:09:58,091] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 17:09:58,092] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:09:58,092] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:09:58,092] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:09:58,093] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 17:09:58,094] INFO Shutting down. (kafka.log.LogManager)
[2022-05-04 17:09:58,113] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-04 17:09:58,119] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:09:58,119] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:09:58,119] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:09:58,120] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:09:59,449] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:09:59,449] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:09:59,450] WARN An exception was thrown while closing send thread for session 0x1000116d1d90002. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-04 17:09:59,553] INFO Session: 0x1000116d1d90002 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:09:59,553] INFO EventThread shut down for session: 0x1000116d1d90002 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:09:59,555] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:09:59,556] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:09:59,920] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:09:59,920] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:09:59,920] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:09:59,924] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:09:59,924] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:09:59,924] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:00,920] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:00,920] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:00,921] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:00,930] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:00,930] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:00,931] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-04 17:10:00,951] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-04 17:10:00,951] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:10:00,951] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:10:00,952] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:10:00,953] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 17:10:00,953] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:10:00,953] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-04 17:10:12,725] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 17:10:12,731] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 17:10:12,731] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 17:10:12,731] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 17:10:12,731] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 17:10:12,732] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 17:10:12,733] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 17:10:12,733] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 17:10:12,733] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-04 17:10:12,735] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-04 17:10:12,747] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 17:10:12,747] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 17:10:12,747] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 17:10:12,747] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 17:10:12,748] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 17:10:12,748] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-04 17:10:12,758] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@6156496 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-04 17:10:12,761] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 17:10:12,769] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,769] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,769] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,769] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,769] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,769] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,769] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,769] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,769] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,769] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,770] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,770] INFO Server environment:host.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,770] INFO Server environment:java.version=11.0.15 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,770] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,770] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,770] INFO Server environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,771] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,771] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,771] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,771] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,771] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,771] INFO Server environment:os.version=5.13.0-40-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,771] INFO Server environment:user.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,771] INFO Server environment:user.home=/home/joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,771] INFO Server environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,771] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,771] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,771] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,771] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,771] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,771] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,771] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,772] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,772] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,772] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,773] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-04 17:10:12,774] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,774] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,775] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-04 17:10:12,775] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-04 17:10:12,776] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 17:10:12,776] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 17:10:12,776] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 17:10:12,776] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 17:10:12,776] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 17:10:12,776] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 17:10:12,778] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,779] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,779] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,784] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-04 17:10:12,785] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-04 17:10:12,786] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-04 17:10:12,790] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-04 17:10:12,804] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-04 17:10:12,804] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-04 17:10:12,805] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 17:10:12,805] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 17:10:12,809] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-05-04 17:10:12,809] INFO Reading snapshot /tmp/zookeeper/version-2/snapshot.2b4 (org.apache.zookeeper.server.persistence.FileSnap)
[2022-05-04 17:10:12,823] INFO The digest in the snapshot has digest version of 2, , with zxid as 0x2b4, and digest value as 270992104626 (org.apache.zookeeper.server.DataTree)
[2022-05-04 17:10:12,839] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-04 17:10:12,855] INFO 230 txns loaded in 25 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 17:10:12,855] INFO Snapshot loaded in 50 ms, highest zxid is 0x39a, digest is 275774952313 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-04 17:10:12,855] INFO Snapshotting: 0x39a to /tmp/zookeeper/version-2/snapshot.39a (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 17:10:12,857] INFO Snapshot taken in 2 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:12,864] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-05-04 17:10:12,865] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-05-04 17:10:12,882] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-05-04 17:10:17,812] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 17:10:18,061] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 17:10:18,136] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 17:10:18,139] INFO starting (kafka.server.KafkaServer)
[2022-05-04 17:10:18,140] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 17:10:18,153] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:18,157] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:18,157] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:18,157] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:18,157] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:18,158] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:18,158] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:18,158] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:18,158] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:18,158] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:18,158] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:18,158] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:18,158] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:18,158] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:18,158] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:18,158] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:18,159] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:18,159] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:18,159] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:18,161] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:18,165] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 17:10:18,170] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:18,181] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:18,187] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:18,188] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:18,191] INFO Socket connection established, initiating session, client: /127.0.0.1:55008, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:18,205] INFO Creating new log file: log.39b (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-05-04 17:10:18,217] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000131dada0000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:18,220] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:18,328] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:10:18,454] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 17:10:18,460] INFO Cluster ID = lqKBofKATK6pu47xJ3IrsQ (kafka.server.KafkaServer)
[2022-05-04 17:10:18,506] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:10:18,516] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:10:18,562] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:18,563] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:18,565] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:18,567] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:18,604] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:10:18,607] INFO Skipping recovery for all logs in /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 17:10:18,671] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:18,691] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-17, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 72ms (1/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:10:18,693] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:18,696] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-2.d113d1f1731f49a1af6c81a055b79348-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (2/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:10:18,701] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:18,705] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-35, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (3/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:10:18,709] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:18,712] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-3.bf0079cbbc8c4b6b9ed6e7d5f8e0b44a-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (4/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:10:18,713] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:18,716] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-1.2060b907c2c049d486864117f5a5a528-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (5/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:10:18,721] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:18,723] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-41, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (6/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:10:18,728] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:18,730] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-29, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:10:18,735] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:18,738] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-11, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (8/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:10:18,743] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:18,746] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-23, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (9/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:10:18,750] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:18,753] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-47, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:10:18,757] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:18,760] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-5, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (11/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:10:18,763] INFO Loaded 11 logs in 159ms. (kafka.log.LogManager)
[2022-05-04 17:10:18,764] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 17:10:18,766] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 17:10:18,972] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:19,073] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 17:10:19,078] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-04 17:10:19,103] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 17:10:19,108] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:19,124] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:19,125] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:19,127] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:19,129] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:19,143] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:10:19,205] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 17:10:19,230] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72058791559495680' does not match current session '72058907674673152' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2022-05-04 17:10:19,238] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:324)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-05-04 17:10:19,240] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-05-04 17:10:19,241] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-04 17:10:19,244] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-04 17:10:19,250] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-05-04 17:10:19,250] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:10:19,251] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:10:19,251] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:10:19,251] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:10:19,252] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:10:19,253] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:10:19,253] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:10:19,253] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:19,326] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:19,326] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:19,327] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:19,525] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:19,525] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:19,526] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:19,528] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:19,528] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:19,529] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:19,529] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:19,529] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:19,538] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-05-04 17:10:19,538] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:19,539] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:19,539] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:19,545] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 17:10:19,546] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:19,547] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:19,547] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:19,548] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 17:10:19,549] INFO Shutting down. (kafka.log.LogManager)
[2022-05-04 17:10:19,582] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-04 17:10:19,583] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:10:19,583] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:10:19,583] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:10:19,584] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:19,690] INFO Session: 0x1000131dada0000 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:19,691] INFO EventThread shut down for session: 0x1000131dada0000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:19,693] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:19,693] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:20,563] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:20,564] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:20,564] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:20,565] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:20,565] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:20,565] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:20,566] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:20,566] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:20,567] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:20,567] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:20,567] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:20,570] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-05-04 17:10:20,597] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-05-04 17:10:20,598] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:10:20,598] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:10:20,599] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:10:20,600] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 17:10:20,605] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:10:20,605] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-05-04 17:10:20,605] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-05-04 17:10:20,606] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-05-04 17:10:22,811] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 17:10:23,042] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 17:10:23,114] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 17:10:23,117] INFO starting (kafka.server.KafkaServer)
[2022-05-04 17:10:23,118] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 17:10:23,130] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:23,134] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:23,134] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:23,135] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:23,135] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:23,135] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:23,135] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:23,135] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:23,135] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:23,135] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:23,135] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:23,135] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:23,135] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:23,135] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:23,135] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:23,135] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:23,135] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:23,135] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:23,135] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:23,137] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:23,141] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 17:10:23,146] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:23,158] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:23,164] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:23,164] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:23,168] INFO Socket connection established, initiating session, client: /127.0.0.1:55010, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:23,177] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000131dada0001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:23,182] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:23,261] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:10:23,372] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 17:10:23,378] INFO Cluster ID = lqKBofKATK6pu47xJ3IrsQ (kafka.server.KafkaServer)
[2022-05-04 17:10:23,421] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:10:23,431] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:10:23,475] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:23,476] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:23,478] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:23,479] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:23,514] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:10:23,517] INFO Skipping recovery for all logs in /tmp/kafka-logs-1 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 17:10:23,568] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:23,586] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-5.7c15d591853b4ab78e9048dc5609f77b-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 56ms (1/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:10:23,598] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:23,602] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-14, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (2/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:10:23,607] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:23,610] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-38, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (3/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:10:23,615] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:23,618] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-8, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (4/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:10:23,633] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:23,633] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-1] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:23,634] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-1/__consumer_offsets-2/00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
[2022-05-04 17:10:23,639] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-1] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:23,642] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-2, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 24ms (5/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:10:23,648] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:23,654] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-4.1cf6bd74ffd446e5ad244173a41a37b8-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (6/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:10:23,659] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:23,662] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-26, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:10:23,666] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:23,669] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-20, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:10:23,674] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:23,676] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-32, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (9/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:10:23,678] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:23,680] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-3.cffbb723a3bf4ad08e376f63513505b5-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (10/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:10:23,684] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:23,686] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-44, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (11/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:10:23,689] INFO Loaded 11 logs in 175ms. (kafka.log.LogManager)
[2022-05-04 17:10:23,691] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 17:10:23,692] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 17:10:23,920] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:24,030] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 17:10:24,034] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-04 17:10:24,058] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 17:10:24,065] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:24,080] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:24,081] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:24,083] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:24,084] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:24,096] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:10:24,155] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 17:10:24,172] ERROR Error while creating ephemeral at /brokers/ids/1, node already exists and owner '72058791559495681' does not match current session '72058907674673153' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2022-05-04 17:10:24,177] ERROR [KafkaServer id=1] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:324)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-05-04 17:10:24,179] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-04 17:10:24,180] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-04 17:10:24,182] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-04 17:10:24,189] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-04 17:10:24,190] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:10:24,191] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:10:24,191] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:10:24,191] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:10:24,193] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:10:24,194] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:10:24,194] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:10:24,194] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:24,282] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:24,282] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:24,283] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:24,480] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:24,480] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:24,481] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:24,484] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:24,484] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:24,485] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:24,685] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:24,685] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:24,696] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-04 17:10:24,697] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:24,698] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:24,698] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:24,705] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 17:10:24,706] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:24,706] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:24,706] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:24,707] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 17:10:24,708] INFO Shutting down. (kafka.log.LogManager)
[2022-05-04 17:10:24,738] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-04 17:10:24,738] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:10:24,739] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:10:24,739] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:10:24,741] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:24,846] INFO Session: 0x1000131dada0001 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:24,846] INFO EventThread shut down for session: 0x1000131dada0001 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:24,849] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:24,850] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:25,476] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:25,477] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:25,477] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:25,478] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:25,478] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:25,478] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:25,478] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:25,479] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:25,479] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:25,480] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:25,480] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:25,482] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-04 17:10:25,504] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-04 17:10:25,505] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:10:25,505] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:10:25,506] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:10:25,508] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 17:10:25,511] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:10:25,512] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-04 17:10:25,512] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-05-04 17:10:25,513] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-04 17:10:27,823] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 17:10:28,054] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 17:10:28,130] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 17:10:28,133] INFO starting (kafka.server.KafkaServer)
[2022-05-04 17:10:28,133] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 17:10:28,148] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:28,153] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:28,153] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:28,153] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:28,153] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:28,153] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:28,153] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:28,154] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:28,154] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:28,154] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:28,154] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:28,154] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:28,154] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:28,154] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:28,154] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:28,154] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:28,154] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:28,154] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:28,154] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:28,156] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:28,161] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 17:10:28,166] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:28,180] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:28,186] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:28,188] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:28,193] INFO Socket connection established, initiating session, client: /127.0.0.1:55012, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:28,201] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000131dada0002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:28,205] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:28,287] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:10:28,409] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 17:10:28,414] INFO Cluster ID = lqKBofKATK6pu47xJ3IrsQ (kafka.server.KafkaServer)
[2022-05-04 17:10:28,459] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:10:28,469] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:10:28,518] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:28,519] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:28,521] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:28,523] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:28,562] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:10:28,566] INFO Skipping recovery for all logs in /tmp/kafka-logs-2 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 17:10:28,633] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:28,654] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-21, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 74ms (1/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:10:28,656] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:28,659] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-0.7184a6ce6e304c88baa67cc9463d7900-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (2/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:10:28,664] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:28,667] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-1.0a56dc8cdabb4eaf9833b33974941e6d-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (3/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:10:28,672] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:28,675] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-39, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:10:28,680] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:28,683] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-15, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:10:28,689] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:28,692] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-45, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:10:28,697] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:28,700] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-33, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:10:28,704] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:28,707] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-27, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:10:28,724] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs-2] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:28,724] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs-2] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:28,726] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-2/__consumer_offsets-3/00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
[2022-05-04 17:10:28,731] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs-2] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:28,734] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-3, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 27ms (9/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:10:28,739] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:28,743] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-9, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (10/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:10:28,744] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:28,747] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-5.7ff1c20f5a344792877a773a59b0bc84-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (11/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:10:28,749] INFO Loaded 11 logs in 186ms. (kafka.log.LogManager)
[2022-05-04 17:10:28,750] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 17:10:28,751] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 17:10:28,990] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:29,099] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 17:10:29,102] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-04 17:10:29,126] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 17:10:29,133] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:29,151] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:29,152] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:29,153] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:29,155] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:29,166] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:10:29,223] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 17:10:29,241] ERROR Error while creating ephemeral at /brokers/ids/2, node already exists and owner '72058791559495682' does not match current session '72058907674673154' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2022-05-04 17:10:29,246] ERROR [KafkaServer id=2] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:324)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-05-04 17:10:29,249] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-04 17:10:29,250] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-04 17:10:29,253] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-04 17:10:29,259] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-04 17:10:29,260] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:10:29,261] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:10:29,261] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:10:29,261] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:10:29,261] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:10:29,262] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:10:29,262] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:10:29,262] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:29,353] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:29,353] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:29,353] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:29,551] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:29,551] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:29,552] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:29,554] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:29,554] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:29,555] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:29,556] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:29,556] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:29,563] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-04 17:10:29,563] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:29,564] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:29,564] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:29,569] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 17:10:29,570] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:29,571] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:29,571] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:29,572] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 17:10:29,573] INFO Shutting down. (kafka.log.LogManager)
[2022-05-04 17:10:29,605] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-04 17:10:29,606] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:10:29,606] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:10:29,606] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:10:29,607] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:29,711] INFO Session: 0x1000131dada0002 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:29,712] INFO EventThread shut down for session: 0x1000131dada0002 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:29,714] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:29,715] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:30,519] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:30,520] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:30,520] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:30,521] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:30,521] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:30,521] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:30,522] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:30,522] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:30,522] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:30,524] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:30,524] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:30,526] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-04 17:10:30,546] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-04 17:10:30,546] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:10:30,547] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:10:30,547] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:10:30,548] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 17:10:30,552] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:10:30,552] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-04 17:10:30,552] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-05-04 17:10:30,553] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-04 17:10:32,354] INFO Expiring session 0x1000116d1d90002, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:32,354] INFO Expiring session 0x1000116d1d90000, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:32,355] INFO Expiring session 0x1000116d1d90001, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:32,355] INFO Expiring session 0x1000116d1d90005, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:32,355] INFO Expiring session 0x1000116d1d90004, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:32,355] INFO Expiring session 0x1000116d1d90003, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:10:32,998] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 17:10:33,367] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 17:10:33,482] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 17:10:33,486] INFO starting (kafka.server.KafkaServer)
[2022-05-04 17:10:33,486] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 17:10:33,503] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:33,509] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:33,509] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:33,510] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:33,510] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:33,510] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:33,510] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:33,510] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:33,510] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:33,510] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:33,510] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:33,511] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:33,511] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:33,511] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:33,511] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:33,511] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:33,511] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:33,511] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:33,511] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:33,523] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:33,532] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 17:10:33,540] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:33,546] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:33,552] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:33,554] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:33,560] INFO Socket connection established, initiating session, client: /127.0.0.1:55014, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:33,568] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000131dada0003, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:33,574] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:33,670] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:10:33,816] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 17:10:33,821] INFO Cluster ID = lqKBofKATK6pu47xJ3IrsQ (kafka.server.KafkaServer)
[2022-05-04 17:10:33,873] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:10:33,884] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:10:33,929] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:33,930] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:33,932] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:33,934] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:33,977] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-04 17:10:33,981] INFO Skipping recovery for all logs in /tmp/kafka-logs-3 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 17:10:34,067] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:34,099] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-46, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 102ms (1/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-04 17:10:34,102] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:34,105] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-0.33f45d5544ee4abdb700b96aa3a4be37-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (2/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-04 17:10:34,111] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:34,114] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-10, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (3/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-04 17:10:34,128] INFO Deleted producer state snapshot /tmp/kafka-logs-3/__consumer_offsets-28/00000000000000000003.snapshot (kafka.log.SnapshotFile)
[2022-05-04 17:10:34,130] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-3] Loading producer state till offset 6 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:34,130] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-3] Reloading from producer snapshot and rebuilding producer state from offset 6 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:34,132] INFO [ProducerStateManager partition=__consumer_offsets-28] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-3/__consumer_offsets-28/00000000000000000006.snapshot,6)' (kafka.log.ProducerStateManager)
[2022-05-04 17:10:34,138] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-3] Producer state recovery took 8ms for snapshot load and 0ms for segment recovery from offset 6 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:34,143] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-28, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=6) with 1 segments in 29ms (4/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-04 17:10:34,150] INFO Deleted producer state snapshot /tmp/kafka-logs-3/__consumer_offsets-22/00000000000000000384.snapshot (kafka.log.SnapshotFile)
[2022-05-04 17:10:34,150] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-3] Loading producer state till offset 729 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:34,150] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-3] Reloading from producer snapshot and rebuilding producer state from offset 729 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:34,150] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-3/__consumer_offsets-22/00000000000000000729.snapshot,729)' (kafka.log.ProducerStateManager)
[2022-05-04 17:10:34,151] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-3] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 729 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:34,154] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-22, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=729) with 1 segments in 10ms (5/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-04 17:10:34,161] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:34,164] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-16, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (6/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-04 17:10:34,169] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:34,175] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-2.4e9f677037244910b3740ddb38748d57-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (7/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-04 17:10:34,178] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:34,182] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-1.afd000d4a355496486e8b12c870b5acd-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-04 17:10:34,187] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:34,190] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-40, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-04 17:10:34,195] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:34,199] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-34, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (10/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-04 17:10:34,203] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:34,206] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-4, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-04 17:10:34,210] INFO Loaded 11 logs in 232ms. (kafka.log.LogManager)
[2022-05-04 17:10:34,211] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 17:10:34,212] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 17:10:34,515] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:34,636] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 17:10:34,639] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-05-04 17:10:34,665] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 17:10:34,670] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:34,685] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:34,687] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:34,689] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:34,691] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:34,702] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:10:34,751] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 17:10:34,770] INFO Stat of the created znode at /brokers/ids/3 is: 995,995,1651680634761,1651680634761,1,0,0,72058907674673155,192,0,995
 (kafka.zk.KafkaZkClient)
[2022-05-04 17:10:34,772] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://joao:9095, czxid (broker epoch): 995 (kafka.zk.KafkaZkClient)
[2022-05-04 17:10:34,825] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:34,831] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:34,833] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:34,849] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:34,877] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:34,892] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:10:34,896] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:10:34,896] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:10:34,926] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:34,946] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:10:34,968] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 17:10:34,975] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 17:10:34,976] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 17:10:34,981] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:10:34,981] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:10:34,981] INFO Kafka startTimeMs: 1651680634976 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:10:34,984] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-05-04 17:10:35,075] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:10:35,076] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:35,091] INFO [Partition __consumer_offsets-34 broker=3] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:10:35,100] INFO [Partition __consumer_offsets-4 broker=3] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:10:35,103] INFO [Partition __consumer_offsets-22 broker=3] Log loaded for partition __consumer_offsets-22 with initial high watermark 729 (kafka.cluster.Partition)
[2022-05-04 17:10:35,104] INFO [Partition __consumer_offsets-40 broker=3] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:10:35,106] INFO [Partition __consumer_offsets-10 broker=3] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:10:35,109] INFO [Partition __consumer_offsets-28 broker=3] Log loaded for partition __consumer_offsets-28 with initial high watermark 6 (kafka.cluster.Partition)
[2022-05-04 17:10:35,110] INFO [Partition __consumer_offsets-46 broker=3] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:10:35,113] INFO [Partition __consumer_offsets-16 broker=3] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:10:35,125] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:35,127] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 34 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:35,129] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:35,130] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 4 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:35,131] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:35,131] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 22 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:35,131] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:35,131] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 40 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:35,131] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:35,131] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 10 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:35,131] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:35,131] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 28 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:35,131] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:35,131] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 46 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:35,131] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:35,131] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 16 in epoch 2 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:35,131] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:35,138] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-34 in 8 milliseconds for epoch 2, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:35,139] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-4 in 8 milliseconds for epoch 2, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:35,173] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-e1bd79a5-49b7-40ca-a25d-2df860ea4d09, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,178] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-dafdcaeb-6cd8-49b5-8a4b-96542ea3f41a, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 2. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,184] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-ece5d338-1c57-49d7-8574-556b6083b6ed, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 4. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,185] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-1b4c4ab8-60e5-4bdc-9b3d-a906785bc7c7, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 6. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,186] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-d05e2960-1f59-458f-9fcb-9f9fdc689305, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 8. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,187] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-91b0e340-451e-4ef2-a383-100cef13b35b, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 12. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,188] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-c18bc7c6-d018-4cab-bb9b-3c63ebdb2ff1, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 14. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,189] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-af6e308d-1bfb-47df-9fcb-83e7e4850599, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 16. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,189] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-a9640652-8b1e-417e-8f07-a1d7679f4c60, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 17. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,190] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-c65783f4-f5d2-4963-9498-e0d6e2256bc3, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 19. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,191] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-43482c8b-c7e1-4c94-91ab-87a4535334c8, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 21. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,192] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-ead728c2-f7af-4b2f-b636-9367390d9e42, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 23. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,193] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-367fadb9-afe7-4134-b942-45c320a301b2, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 25. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,193] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-30c7ccba-b7b9-4c45-80b3-17d5902dec6d, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 27. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,194] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-fb843fe5-5d24-43b3-a1f4-62bc71c590df, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 32. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,196] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-7c13b94f-9727-4a1d-aca7-8bbbd4499438, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 34. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,196] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-a5298284-8896-41c3-8f99-e775d86adb52, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 38. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,197] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-a9bd0a98-1e46-4f3e-869d-88dc77ba47d3, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 41. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,198] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-02b93f74-f42e-45ed-823e-e6c27f7693e6, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 44. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,199] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-cb39a956-fe2a-4268-873b-a2fa2cf77e32, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 46. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,199] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-45b04d2d-784a-42f0-9642-947bf339b1d1, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 49. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,199] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-093ad393-de32-440d-8811-f17a1cc6da23, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 49. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,200] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-f716d18a-18b7-45fc-a72f-14f9c0565d2c, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 49. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,200] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-8d02c3ba-7479-451b-8c69-f6a2f7e99b84, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 51. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,202] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-e52cc317-91f7-4d6b-898c-9b3965dd0080, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 53. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,202] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-1b6fdc66-8379-4d23-8578-e21cdf8b77b6, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 55. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,203] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-5fb65fff-c802-4839-b3cc-e3424e89c7d1, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 60. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,203] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-bf869c80-1ab9-488b-aee2-6ff76f17ade8, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 61. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,203] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-0b943a5d-7a57-4a87-8abf-d284c88820f7, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 61. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,205] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-bf869c80-1ab9-488b-aee2-6ff76f17ade8, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 62. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,205] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-041b68f0-6182-4a9b-971b-42e16d82410b, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 64. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,209] INFO [GroupCoordinator 3]: Loading group metadata for consumer with generation 64 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:35,213] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-22 in 82 milliseconds for epoch 2, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:35,214] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-40 in 83 milliseconds for epoch 2, of which 82 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:35,214] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-10 in 83 milliseconds for epoch 2, of which 83 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:35,217] INFO Loaded member MemberMetadata(memberId=console-consumer-c5c8220a-6359-4a07-9af0-ec66ef4eaa06, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-55331 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,217] INFO Loaded member MemberMetadata(memberId=console-consumer-838b9f99-6084-4494-8bbe-d273bd18f011, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-2935 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:35,218] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-28 in 87 milliseconds for epoch 2, of which 83 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:35,218] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-46 in 87 milliseconds for epoch 2, of which 87 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:35,218] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-16 in 87 milliseconds for epoch 2, of which 87 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:37,944] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 17:10:38,264] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 17:10:38,374] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 17:10:38,380] INFO starting (kafka.server.KafkaServer)
[2022-05-04 17:10:38,381] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 17:10:38,401] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:38,406] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:38,407] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:38,407] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:38,407] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:38,407] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:38,407] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:38,407] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:38,407] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:38,407] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:38,407] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:38,407] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:38,407] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:38,407] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:38,407] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:38,407] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:38,407] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:38,407] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:38,407] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:38,418] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:38,425] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 17:10:38,431] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:38,435] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:38,442] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:38,443] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:38,447] INFO Socket connection established, initiating session, client: /127.0.0.1:55016, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:38,454] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000131dada0004, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:38,457] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:38,528] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:10:38,672] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 17:10:38,679] INFO Cluster ID = lqKBofKATK6pu47xJ3IrsQ (kafka.server.KafkaServer)
[2022-05-04 17:10:38,729] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:10:38,739] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:10:38,796] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:38,797] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:38,799] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:38,801] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:38,841] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-04 17:10:38,846] INFO Skipping recovery for all logs in /tmp/kafka-logs-4 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 17:10:38,914] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:38,937] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-4.4c897c7331b14edfa6659bcc7ae6e4ae-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 76ms (1/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-04 17:10:38,943] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:38,946] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-0.3ee5f36017264aa589aa877eb1278dd6-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (2/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-04 17:10:38,958] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:38,963] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-49, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (3/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-04 17:10:38,968] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:38,971] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-19, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-04 17:10:38,976] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:38,979] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-7, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-04 17:10:38,985] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:38,987] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-13, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-04 17:10:38,990] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:38,993] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-5.4df168045b2b448a982bbc6c6eb4b798-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (7/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-04 17:10:39,011] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-4] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:39,011] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-4] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:39,013] INFO [ProducerStateManager partition=__consumer_offsets-37] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-4/__consumer_offsets-37/00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
[2022-05-04 17:10:39,018] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-4] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:39,021] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-37, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 27ms (8/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-04 17:10:39,027] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:39,031] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-43, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (9/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-04 17:10:39,035] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:39,038] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-1, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (10/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-04 17:10:39,042] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:39,045] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-31, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-04 17:10:39,050] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:39,054] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-25, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (12/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-04 17:10:39,057] INFO Loaded 12 logs in 216ms. (kafka.log.LogManager)
[2022-05-04 17:10:39,058] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 17:10:39,059] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 17:10:39,334] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:39,463] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 17:10:39,467] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.Acceptor)
[2022-05-04 17:10:39,492] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 17:10:39,498] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:39,516] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:39,518] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:39,519] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:39,521] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:39,533] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:10:39,596] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 17:10:39,615] INFO Stat of the created znode at /brokers/ids/4 is: 1055,1055,1651680639607,1651680639607,1,0,0,72058907674673156,192,0,1055
 (kafka.zk.KafkaZkClient)
[2022-05-04 17:10:39,616] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://joao:9096, czxid (broker epoch): 1055 (kafka.zk.KafkaZkClient)
[2022-05-04 17:10:39,692] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:39,699] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:39,700] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:39,712] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:39,734] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:39,748] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:10:39,752] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:10:39,752] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:10:39,774] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:39,790] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:10:39,809] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 17:10:39,814] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 17:10:39,815] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 17:10:39,819] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:10:39,820] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:10:39,820] INFO Kafka startTimeMs: 1651680639815 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:10:39,822] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2022-05-04 17:10:39,902] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:39,906] INFO [Partition __consumer_offsets-19 broker=4] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:10:39,906] INFO [Partition __consumer_offsets-37 broker=4] Log loaded for partition __consumer_offsets-37 with initial high watermark 3 (kafka.cluster.Partition)
[2022-05-04 17:10:39,907] INFO [Partition __consumer_offsets-7 broker=4] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:10:39,907] INFO [Partition __consumer_offsets-25 broker=4] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:10:39,907] INFO [Partition __consumer_offsets-43 broker=4] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:10:39,908] INFO [Partition __consumer_offsets-13 broker=4] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:10:39,908] INFO [Partition __consumer_offsets-31 broker=4] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:10:39,909] INFO [Partition __consumer_offsets-1 broker=4] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:10:39,909] INFO [Partition __consumer_offsets-49 broker=4] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:10:39,931] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(__consumer_offsets-7, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:10:39,944] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:39,963] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 19 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:39,965] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:39,966] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 37 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:39,966] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:39,967] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 7 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:39,967] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:39,967] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 25 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:39,967] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:39,967] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 43 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:39,967] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:39,967] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 13 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:39,967] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:39,967] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 31 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:39,967] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:39,967] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 1 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:39,967] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:39,967] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 49 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:39,968] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:39,974] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-19 in 9 milliseconds for epoch 6, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:39,994] INFO Loaded member MemberMetadata(memberId=console-consumer-50c7f563-9c1d-48b9-91bc-e4d5c8cc6558, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-98496 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:39,998] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-37 in 31 milliseconds for epoch 6, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:39,998] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-7 in 31 milliseconds for epoch 6, of which 31 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:39,998] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-25 in 31 milliseconds for epoch 6, of which 31 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:39,999] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-43 in 32 milliseconds for epoch 6, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:39,999] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-13 in 32 milliseconds for epoch 6, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:39,999] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-31 in 32 milliseconds for epoch 6, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:39,999] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-1 in 32 milliseconds for epoch 6, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:39,999] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-49 in 31 milliseconds for epoch 6, of which 31 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:42,905] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 17:10:43,139] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 17:10:43,205] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 17:10:43,208] INFO starting (kafka.server.KafkaServer)
[2022-05-04 17:10:43,209] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 17:10:43,221] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:43,225] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:43,225] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:43,225] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:43,225] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:43,225] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:43,225] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:43,225] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:43,226] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:43,226] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:43,226] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:43,226] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:43,226] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:43,226] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:43,226] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:43,226] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:43,226] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:43,226] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:43,226] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:43,228] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:10:43,233] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 17:10:43,237] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:43,249] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:43,254] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:43,255] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:43,258] INFO Socket connection established, initiating session, client: /127.0.0.1:55018, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:43,268] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000131dada0005, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:10:43,274] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:10:43,344] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:10:43,456] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 17:10:43,462] INFO Cluster ID = lqKBofKATK6pu47xJ3IrsQ (kafka.server.KafkaServer)
[2022-05-04 17:10:43,500] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:10:43,508] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:10:43,550] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:43,551] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:43,554] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:43,555] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:10:43,586] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-04 17:10:43,589] INFO Skipping recovery for all logs in /tmp/kafka-logs-5 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 17:10:43,651] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:43,668] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-24, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 69ms (1/12 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-04 17:10:43,683] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-5] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:43,683] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:43,684] INFO [ProducerStateManager partition=__consumer_offsets-12] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-12/00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
[2022-05-04 17:10:43,689] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-5] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:43,692] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-12, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 23ms (2/12 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-04 17:10:43,696] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:43,699] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-30, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (3/12 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-04 17:10:43,704] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:43,707] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-36, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/12 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-04 17:10:43,711] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:43,714] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-42, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/12 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-04 17:10:43,718] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:43,721] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-0, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (6/12 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-04 17:10:43,723] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:43,725] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-3.4d3566a97a1e4ca9afb880171a08fff5-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (7/12 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-04 17:10:43,727] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:43,729] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-2.42685ef9279a46a6bf65daaaebd2e911-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (8/12 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-04 17:10:43,733] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:43,736] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-4.91b40b950a294e63a635248cd804185d-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (9/12 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-04 17:10:43,740] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:43,742] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-18, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (10/12 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-04 17:10:43,747] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-5] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:43,747] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:43,747] INFO [ProducerStateManager partition=__consumer_offsets-6] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-6/00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
[2022-05-04 17:10:43,747] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-5] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:43,749] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-6, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 7ms (11/12 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-04 17:10:43,754] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:10:43,755] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-48, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (12/12 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-04 17:10:43,759] INFO Loaded 12 logs in 173ms. (kafka.log.LogManager)
[2022-05-04 17:10:43,760] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 17:10:43,761] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 17:10:43,982] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:44,110] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 17:10:44,115] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.Acceptor)
[2022-05-04 17:10:44,150] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 17:10:44,158] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:44,175] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:44,177] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:44,179] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:44,180] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:44,197] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:10:44,269] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 17:10:44,288] INFO Stat of the created znode at /brokers/ids/5 is: 1080,1080,1651680644280,1651680644280,1,0,0,72058907674673157,192,0,1080
 (kafka.zk.KafkaZkClient)
[2022-05-04 17:10:44,290] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://joao:9097, czxid (broker epoch): 1080 (kafka.zk.KafkaZkClient)
[2022-05-04 17:10:44,361] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:44,367] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:44,369] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:44,382] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:44,409] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:44,422] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:10:44,427] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:10:44,427] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:10:44,455] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:10:44,472] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:10:44,494] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 17:10:44,499] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 17:10:44,500] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 17:10:44,505] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:10:44,505] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:10:44,505] INFO Kafka startTimeMs: 1651680644500 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:10:44,508] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2022-05-04 17:10:44,563] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:44,594] INFO [Partition __consumer_offsets-18 broker=5] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:10:44,595] INFO [Partition __consumer_offsets-36 broker=5] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:10:44,595] INFO [Partition __consumer_offsets-6 broker=5] Log loaded for partition __consumer_offsets-6 with initial high watermark 3 (kafka.cluster.Partition)
[2022-05-04 17:10:44,595] INFO [Partition __consumer_offsets-24 broker=5] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:10:44,595] INFO [Partition __consumer_offsets-42 broker=5] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:10:44,595] INFO [Partition __consumer_offsets-12 broker=5] Log loaded for partition __consumer_offsets-12 with initial high watermark 3 (kafka.cluster.Partition)
[2022-05-04 17:10:44,595] INFO [Partition __consumer_offsets-30 broker=5] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:10:44,595] INFO [Partition __consumer_offsets-0 broker=5] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:10:44,595] INFO [Partition __consumer_offsets-48 broker=5] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:10:44,596] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:10:44,618] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-12, __consumer_offsets-42, __consumer_offsets-18) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:10:44,652] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 18 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:44,653] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:44,655] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 36 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:44,655] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:44,655] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 6 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:44,655] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:44,655] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 24 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:44,655] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:44,655] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 42 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:44,655] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:44,655] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 12 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:44,655] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:44,655] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 30 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:44,655] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:44,655] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 0 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:44,655] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:44,656] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 48 in epoch 6 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:10:44,656] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 6 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:44,665] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-18 in 11 milliseconds for epoch 6, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:44,666] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-36 in 11 milliseconds for epoch 6, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:44,686] INFO Loaded member MemberMetadata(memberId=console-consumer-5fb61ebb-05fd-44e7-a816-7e2e88f8ef0e, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-60144 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:44,690] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-6 in 35 milliseconds for epoch 6, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:44,690] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-24 in 35 milliseconds for epoch 6, of which 35 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:44,690] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-42 in 35 milliseconds for epoch 6, of which 35 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:44,693] INFO Loaded member MemberMetadata(memberId=console-consumer-0d7094cd-fdbf-4ae0-b76d-c72d167367b1, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-95782 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:10:44,693] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-12 in 38 milliseconds for epoch 6, of which 35 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:44,694] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-30 in 39 milliseconds for epoch 6, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:44,694] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-0 in 38 milliseconds for epoch 6, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:10:44,694] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-48 in 38 milliseconds for epoch 6, of which 38 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:19,873] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 17:11:19,879] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 17:11:19,879] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 17:11:19,879] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 17:11:19,879] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 17:11:19,881] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 17:11:19,881] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 17:11:19,881] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-04 17:11:19,881] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-04 17:11:19,885] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-04 17:11:19,897] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 17:11:19,897] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 17:11:19,897] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 17:11:19,897] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 17:11:19,897] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-04 17:11:19,897] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-04 17:11:19,908] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@6156496 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-04 17:11:19,912] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-04 17:11:19,921] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,921] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,921] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,921] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,921] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,921] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,921] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,921] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,921] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,921] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,922] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,922] INFO Server environment:host.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,922] INFO Server environment:java.version=11.0.15 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,922] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,923] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,923] INFO Server environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,923] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,923] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,923] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,923] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,923] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,923] INFO Server environment:os.version=5.13.0-40-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,923] INFO Server environment:user.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,923] INFO Server environment:user.home=/home/joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,923] INFO Server environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,923] INFO Server environment:os.memory.free=489MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,923] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,923] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,923] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,924] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,924] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,924] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,924] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,924] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,924] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,925] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-04 17:11:19,926] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,927] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,927] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-04 17:11:19,928] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-04 17:11:19,928] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 17:11:19,929] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 17:11:19,929] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 17:11:19,929] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 17:11:19,929] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 17:11:19,929] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-04 17:11:19,931] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,931] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,931] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-04 17:11:19,937] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-04 17:11:19,938] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-04 17:11:19,941] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-04 17:11:19,945] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-04 17:11:19,946] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:459)
	at java.base/sun.nio.ch.Net.bind(Net.java:448)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:676)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:158)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:112)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:67)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:140)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:90)
[2022-05-04 17:11:19,948] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-04 17:11:19,950] ERROR Exiting JVM with code 1 (org.apache.zookeeper.util.ServiceUtils)
[2022-05-04 17:11:20,217] INFO [GroupCoordinator 3]: Member consumer-consumer-1-041b68f0-6182-4a9b-971b-42e16d82410b in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:20,221] INFO [GroupCoordinator 3]: Preparing to rebalance group consumer in state PreparingRebalance with old generation 64 (__consumer_offsets-22) (reason: removing member consumer-consumer-1-041b68f0-6182-4a9b-971b-42e16d82410b on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:20,223] INFO [GroupCoordinator 3]: Group consumer with generation 65 is now empty (__consumer_offsets-22) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:24,854] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 17:11:25,095] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 17:11:25,179] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 17:11:25,184] INFO starting (kafka.server.KafkaServer)
[2022-05-04 17:11:25,185] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 17:11:25,199] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:25,203] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:25,203] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:25,203] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:25,203] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:25,203] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:25,203] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:25,204] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:25,204] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:25,204] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:25,204] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:25,204] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:25,204] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:25,204] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:25,204] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:25,204] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:25,204] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:25,204] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:25,204] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:25,206] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:25,211] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 17:11:25,216] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:25,232] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:25,237] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:25,238] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:25,242] INFO Socket connection established, initiating session, client: /127.0.0.1:55020, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:25,249] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000131dada0006, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:25,253] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:25,322] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:11:25,439] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 17:11:25,445] INFO Cluster ID = lqKBofKATK6pu47xJ3IrsQ (kafka.server.KafkaServer)
[2022-05-04 17:11:25,494] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:11:25,502] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:11:25,553] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:25,554] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:25,556] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:25,558] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:25,595] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:11:25,599] INFO Skipping recovery for all logs in /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 17:11:25,656] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:25,677] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-17, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 65ms (1/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:11:25,680] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:25,684] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-2.d113d1f1731f49a1af6c81a055b79348-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (2/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:11:25,687] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:25,693] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-35, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (3/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:11:25,695] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:25,700] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-3.bf0079cbbc8c4b6b9ed6e7d5f8e0b44a-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (4/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:11:25,702] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:25,705] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-1.2060b907c2c049d486864117f5a5a528-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (5/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:11:25,707] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:25,711] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-41, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (6/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:11:25,714] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:25,717] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-29, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (7/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:11:25,719] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:25,722] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-11, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (8/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:11:25,725] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:25,727] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-23, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (9/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:11:25,729] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:25,732] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-47, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (10/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:11:25,734] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:25,736] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-5, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (11/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-04 17:11:25,740] INFO Loaded 11 logs in 144ms. (kafka.log.LogManager)
[2022-05-04 17:11:25,741] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 17:11:25,743] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 17:11:25,970] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:11:26,080] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 17:11:26,083] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-04 17:11:26,107] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 17:11:26,114] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:11:26,129] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:26,130] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:26,132] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:26,133] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:26,144] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:11:26,204] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 17:11:26,223] INFO Stat of the created znode at /brokers/ids/0 is: 1105,1105,1651680686215,1651680686215,1,0,0,72058907674673158,192,0,1105
 (kafka.zk.KafkaZkClient)
[2022-05-04 17:11:26,225] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://joao:9092, czxid (broker epoch): 1105 (kafka.zk.KafkaZkClient)
[2022-05-04 17:11:26,285] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:26,290] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:26,291] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:26,305] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:26,318] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:26,331] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:11:26,335] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:11:26,335] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:11:26,369] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:26,384] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:11:26,405] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 17:11:26,410] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 17:11:26,411] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 17:11:26,417] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:11:26,417] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:11:26,417] INFO Kafka startTimeMs: 1651680686411 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:11:26,419] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-04 17:11:26,483] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:11:26,511] INFO [Partition __consumer_offsets-35 broker=0] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:26,511] INFO [Partition __consumer_offsets-5 broker=0] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:26,511] INFO [Partition __consumer_offsets-23 broker=0] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:26,512] INFO [Partition __consumer_offsets-41 broker=0] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:26,512] INFO [Partition __consumer_offsets-11 broker=0] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:26,512] INFO [Partition __consumer_offsets-29 broker=0] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:26,512] INFO [Partition __consumer_offsets-47 broker=0] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:26,512] INFO [Partition __consumer_offsets-17 broker=0] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:26,517] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:11:26,535] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-5, __consumer_offsets-29, __consumer_offsets-41, __consumer_offsets-23) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:26,566] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 35 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:26,567] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:26,569] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 5 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:26,569] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:26,569] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 23 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:26,569] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:26,570] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 41 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:26,570] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:26,570] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 11 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:26,570] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:26,570] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 29 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:26,570] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:26,570] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 47 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:26,570] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:26,570] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 17 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:26,570] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:26,579] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-35 in 11 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:26,580] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-5 in 11 milliseconds for epoch 4, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:26,580] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-23 in 10 milliseconds for epoch 4, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:26,581] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-41 in 11 milliseconds for epoch 4, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:26,581] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-11 in 11 milliseconds for epoch 4, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:26,581] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-29 in 11 milliseconds for epoch 4, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:26,582] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-47 in 12 milliseconds for epoch 4, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:26,582] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-17 in 12 milliseconds for epoch 4, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:29,910] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 17:11:30,142] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 17:11:30,211] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 17:11:30,214] INFO starting (kafka.server.KafkaServer)
[2022-05-04 17:11:30,215] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 17:11:30,228] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:30,232] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:30,232] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:30,232] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:30,232] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:30,232] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:30,232] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:30,233] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:30,233] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:30,233] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:30,233] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:30,233] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:30,233] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:30,233] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:30,233] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:30,233] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:30,233] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:30,233] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:30,233] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:30,243] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:30,247] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 17:11:30,251] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:30,255] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:30,263] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:30,264] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:30,267] INFO Socket connection established, initiating session, client: /127.0.0.1:55022, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:30,274] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000131dada0007, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:30,278] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:30,359] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:11:30,478] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 17:11:30,485] INFO Cluster ID = lqKBofKATK6pu47xJ3IrsQ (kafka.server.KafkaServer)
[2022-05-04 17:11:30,523] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:11:30,531] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:11:30,576] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:30,577] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:30,579] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:30,581] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:30,614] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:11:30,619] INFO Skipping recovery for all logs in /tmp/kafka-logs-1 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 17:11:30,673] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:30,696] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-5.7c15d591853b4ab78e9048dc5609f77b-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 63ms (1/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:11:30,707] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:30,712] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-14, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (2/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:11:30,714] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:30,718] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-38, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (3/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:11:30,720] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:30,725] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-8, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (4/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:11:30,742] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:30,742] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-1] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:30,744] INFO [ProducerStateManager partition=__consumer_offsets-2] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-1/__consumer_offsets-2/00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
[2022-05-04 17:11:30,750] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-1] Producer state recovery took 7ms for snapshot load and 1ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:30,754] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-2, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 29ms (5/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:11:30,757] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:30,760] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-4.1cf6bd74ffd446e5ad244173a41a37b8-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (6/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:11:30,762] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:30,765] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-26, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (7/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:11:30,767] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:30,771] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-20, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (8/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:11:30,774] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:30,777] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-32, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (9/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:11:30,779] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:30,782] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-3.cffbb723a3bf4ad08e376f63513505b5-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (10/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:11:30,784] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:30,787] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-44, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (11/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-04 17:11:30,792] INFO Loaded 11 logs in 178ms. (kafka.log.LogManager)
[2022-05-04 17:11:30,793] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 17:11:30,794] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 17:11:30,995] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:11:31,089] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 17:11:31,092] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-04 17:11:31,114] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 17:11:31,120] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:11:31,136] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:31,137] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:31,139] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:31,140] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:31,151] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:11:31,201] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 17:11:31,217] INFO Stat of the created znode at /brokers/ids/1 is: 1129,1129,1651680691210,1651680691210,1,0,0,72058907674673159,192,0,1129
 (kafka.zk.KafkaZkClient)
[2022-05-04 17:11:31,218] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://joao:9093, czxid (broker epoch): 1129 (kafka.zk.KafkaZkClient)
[2022-05-04 17:11:31,281] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:31,286] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:31,288] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:31,301] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:31,323] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:31,336] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:11:31,342] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:11:31,342] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:11:31,364] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:31,382] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:11:31,400] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 17:11:31,405] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 17:11:31,405] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 17:11:31,410] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:11:31,411] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:11:31,411] INFO Kafka startTimeMs: 1651680691405 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:11:31,412] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-04 17:11:31,505] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:11:31,507] INFO [Partition __consumer_offsets-2 broker=1] Log loaded for partition __consumer_offsets-2 with initial high watermark 3 (kafka.cluster.Partition)
[2022-05-04 17:11:31,507] INFO [Partition __consumer_offsets-20 broker=1] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:31,508] INFO [Partition __consumer_offsets-38 broker=1] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:31,508] INFO [Partition __consumer_offsets-8 broker=1] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:31,509] INFO [Partition __consumer_offsets-26 broker=1] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:31,509] INFO [Partition __consumer_offsets-44 broker=1] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:31,510] INFO [Partition __consumer_offsets-14 broker=1] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:31,511] INFO [Partition __consumer_offsets-32 broker=1] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:31,523] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:11:31,537] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-26, __consumer_offsets-32, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:31,571] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 2 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:31,572] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:31,575] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 20 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:31,575] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:31,576] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 38 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:31,576] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:31,576] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 8 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:31,576] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:31,576] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 26 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:31,576] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:31,576] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 44 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:31,576] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:31,576] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 14 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:31,576] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:31,576] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 32 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:31,576] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:31,600] INFO Loaded member MemberMetadata(memberId=console-consumer-009336f0-6f4b-469d-b098-f83a10d17fd1, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-42320 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:11:31,607] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-2 in 34 milliseconds for epoch 4, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:31,608] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-20 in 33 milliseconds for epoch 4, of which 33 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:31,608] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-38 in 32 milliseconds for epoch 4, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:31,608] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-8 in 32 milliseconds for epoch 4, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:31,608] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-26 in 32 milliseconds for epoch 4, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:31,608] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-44 in 32 milliseconds for epoch 4, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:31,608] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-14 in 32 milliseconds for epoch 4, of which 32 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:31,609] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-32 in 33 milliseconds for epoch 4, of which 33 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:34,109] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876691, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-04 17:11:34,110] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876691, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-04 17:11:34,112] INFO Deleted log /tmp/kafka-logs-3/Sensor-0.33f45d5544ee4abdb700b96aa3a4be37-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:34,113] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-0.33f45d5544ee4abdb700b96aa3a4be37-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:34,115] INFO Deleted time index /tmp/kafka-logs-3/Sensor-0.33f45d5544ee4abdb700b96aa3a4be37-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:34,118] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-3/Sensor-0.33f45d5544ee4abdb700b96aa3a4be37-delete. (kafka.log.LogManager)
[2022-05-04 17:11:34,175] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876667, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-04 17:11:34,176] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876667, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-04 17:11:34,177] INFO Deleted log /tmp/kafka-logs-3/Sensor-2.4e9f677037244910b3740ddb38748d57-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:34,177] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-2.4e9f677037244910b3740ddb38748d57-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:34,177] INFO Deleted time index /tmp/kafka-logs-3/Sensor-2.4e9f677037244910b3740ddb38748d57-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:34,178] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-3/Sensor-2.4e9f677037244910b3740ddb38748d57-delete. (kafka.log.LogManager)
[2022-05-04 17:11:34,182] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876703, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-04 17:11:34,183] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876703, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-04 17:11:34,183] INFO Deleted log /tmp/kafka-logs-3/Sensor-1.afd000d4a355496486e8b12c870b5acd-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:34,183] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-1.afd000d4a355496486e8b12c870b5acd-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:34,183] INFO Deleted time index /tmp/kafka-logs-3/Sensor-1.afd000d4a355496486e8b12c870b5acd-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:34,184] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-3/Sensor-1.afd000d4a355496486e8b12c870b5acd-delete. (kafka.log.LogManager)
[2022-05-04 17:11:34,896] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 17:11:35,117] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 17:11:35,192] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 17:11:35,195] INFO starting (kafka.server.KafkaServer)
[2022-05-04 17:11:35,195] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 17:11:35,207] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:35,210] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:35,210] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:35,210] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:35,210] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:35,211] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:35,211] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:35,211] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:35,211] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:35,211] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:35,211] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:35,211] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:35,211] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:35,211] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:35,211] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:35,211] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:35,211] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:35,211] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:35,211] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:35,213] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:35,216] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 17:11:35,220] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:35,231] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:35,238] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:35,238] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:35,242] INFO Socket connection established, initiating session, client: /127.0.0.1:55024, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:35,248] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000131dada0008, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:35,252] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:35,318] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:11:35,440] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 17:11:35,445] INFO Cluster ID = lqKBofKATK6pu47xJ3IrsQ (kafka.server.KafkaServer)
[2022-05-04 17:11:35,483] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:11:35,490] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:11:35,536] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:35,537] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:35,539] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:35,541] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:35,577] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:11:35,580] INFO Skipping recovery for all logs in /tmp/kafka-logs-2 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-04 17:11:35,642] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:35,673] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-21, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 80ms (1/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:11:35,676] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:35,680] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-0.7184a6ce6e304c88baa67cc9463d7900-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (2/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:11:35,683] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:35,687] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-1.0a56dc8cdabb4eaf9833b33974941e6d-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (3/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:11:35,689] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:35,694] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-39, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (4/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:11:35,696] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:35,701] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-15, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:11:35,704] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:35,707] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-45, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (6/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:11:35,710] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:35,713] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-33, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (7/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:11:35,715] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:35,720] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-27, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:11:35,736] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs-2] Loading producer state till offset 3 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:35,736] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs-2] Reloading from producer snapshot and rebuilding producer state from offset 3 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:35,738] INFO [ProducerStateManager partition=__consumer_offsets-3] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-2/__consumer_offsets-3/00000000000000000003.snapshot,3)' (kafka.log.ProducerStateManager)
[2022-05-04 17:11:35,743] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs-2] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 3 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:35,746] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-3, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=3) with 1 segments in 26ms (9/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:11:35,749] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:35,751] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-9, topicId=ENccV6uaSyCgympibLOOaw, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (10/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:11:35,753] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:35,756] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-5.7ff1c20f5a344792877a773a59b0bc84-delete, topicId=5bkV77KkQxyDROeSBGPeHg, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (11/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-04 17:11:35,760] INFO Loaded 11 logs in 183ms. (kafka.log.LogManager)
[2022-05-04 17:11:35,761] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-04 17:11:35,762] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-04 17:11:35,986] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:11:36,114] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-04 17:11:36,118] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-04 17:11:36,146] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 17:11:36,153] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:11:36,170] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:36,171] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:36,173] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:36,174] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:36,187] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:11:36,259] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-04 17:11:36,282] INFO Stat of the created znode at /brokers/ids/2 is: 1153,1153,1651680696272,1651680696272,1,0,0,72058907674673160,192,0,1153
 (kafka.zk.KafkaZkClient)
[2022-05-04 17:11:36,283] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://joao:9094, czxid (broker epoch): 1153 (kafka.zk.KafkaZkClient)
[2022-05-04 17:11:36,341] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:36,346] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:36,347] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:36,361] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:36,381] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:36,396] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:11:36,400] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:11:36,401] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:11:36,422] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:11:36,437] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:11:36,457] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 17:11:36,462] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-04 17:11:36,462] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-04 17:11:36,467] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:11:36,467] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:11:36,467] INFO Kafka startTimeMs: 1651680696462 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:11:36,470] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-04 17:11:36,558] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:11:36,559] INFO [Partition __consumer_offsets-3 broker=2] Log loaded for partition __consumer_offsets-3 with initial high watermark 3 (kafka.cluster.Partition)
[2022-05-04 17:11:36,560] INFO [Partition __consumer_offsets-21 broker=2] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:36,560] INFO [Partition __consumer_offsets-39 broker=2] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:36,560] INFO [Partition __consumer_offsets-9 broker=2] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:36,560] INFO [Partition __consumer_offsets-27 broker=2] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:36,560] INFO [Partition __consumer_offsets-45 broker=2] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:36,561] INFO [Partition __consumer_offsets-15 broker=2] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:36,561] INFO [Partition __consumer_offsets-33 broker=2] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:36,586] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-3, __consumer_offsets-15, __consumer_offsets-39, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:36,597] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:11:36,617] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 3 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:36,618] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:36,620] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 21 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:36,621] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:36,621] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 39 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:36,621] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:36,621] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 9 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:36,621] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:36,621] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 27 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:36,622] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:36,622] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 45 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:36,622] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:36,622] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 15 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:36,622] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:36,622] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 33 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:11:36,622] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:36,645] INFO Loaded member MemberMetadata(memberId=console-consumer-8314cf05-d79e-4e31-b334-5ecd5230d6d8, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group console-consumer-63391 with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-04 17:11:36,651] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-3 in 31 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:36,652] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-21 in 31 milliseconds for epoch 4, of which 31 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:36,652] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-39 in 31 milliseconds for epoch 4, of which 31 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:36,652] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-9 in 31 milliseconds for epoch 4, of which 31 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:36,652] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-27 in 30 milliseconds for epoch 4, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:36,653] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-45 in 31 milliseconds for epoch 4, of which 30 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:36,653] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-15 in 31 milliseconds for epoch 4, of which 31 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:36,653] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-33 in 31 milliseconds for epoch 4, of which 31 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:11:38,938] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=1980918, lastModifiedTime=1651680577379, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-04 17:11:38,940] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=1980918, lastModifiedTime=1651680577379, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-04 17:11:38,945] INFO Deleted log /tmp/kafka-logs-4/Sensor-4.4c897c7331b14edfa6659bcc7ae6e4ae-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:38,945] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-4.4c897c7331b14edfa6659bcc7ae6e4ae-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:38,947] INFO Deleted time index /tmp/kafka-logs-4/Sensor-4.4c897c7331b14edfa6659bcc7ae6e4ae-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:38,951] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-4/Sensor-4.4c897c7331b14edfa6659bcc7ae6e4ae-delete. (kafka.log.LogManager)
[2022-05-04 17:11:38,951] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876671, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-04 17:11:38,951] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876671, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-04 17:11:38,952] INFO Deleted log /tmp/kafka-logs-4/Sensor-0.3ee5f36017264aa589aa877eb1278dd6-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:38,952] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-0.3ee5f36017264aa589aa877eb1278dd6-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:38,952] INFO Deleted time index /tmp/kafka-logs-4/Sensor-0.3ee5f36017264aa589aa877eb1278dd6-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:38,953] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-4/Sensor-0.3ee5f36017264aa589aa877eb1278dd6-delete. (kafka.log.LogManager)
[2022-05-04 17:11:38,994] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876707, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-04 17:11:38,994] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876707, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-04 17:11:38,995] INFO Deleted log /tmp/kafka-logs-4/Sensor-5.4df168045b2b448a982bbc6c6eb4b798-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:38,995] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-5.4df168045b2b448a982bbc6c6eb4b798-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:38,995] INFO Deleted time index /tmp/kafka-logs-4/Sensor-5.4df168045b2b448a982bbc6c6eb4b798-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:38,996] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-4/Sensor-5.4df168045b2b448a982bbc6c6eb4b798-delete. (kafka.log.LogManager)
[2022-05-04 17:11:39,878] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 17:11:40,111] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 17:11:40,190] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 17:11:40,193] INFO starting (kafka.server.KafkaServer)
[2022-05-04 17:11:40,194] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 17:11:40,210] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:40,218] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:40,218] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:40,218] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:40,218] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:40,218] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:40,218] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:40,218] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:40,218] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:40,218] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:40,218] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:40,218] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:40,218] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:40,219] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:40,219] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:40,219] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:40,219] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:40,219] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:40,219] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:40,221] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:40,225] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 17:11:40,230] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:40,242] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:40,246] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:40,247] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:40,251] INFO Socket connection established, initiating session, client: /127.0.0.1:55026, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:40,257] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000131dada0009, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:40,260] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:40,336] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:11:40,457] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 17:11:40,462] INFO Cluster ID = lqKBofKATK6pu47xJ3IrsQ (kafka.server.KafkaServer)
[2022-05-04 17:11:40,514] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:11:40,522] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:11:40,569] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:40,571] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:40,574] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:40,575] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:40,593] ERROR [KafkaServer id=3] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs-3. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:241)
	at scala.collection.StrictOptimizedIterableOps.flatMap(StrictOptimizedIterableOps.scala:117)
	at scala.collection.StrictOptimizedIterableOps.flatMap$(StrictOptimizedIterableOps.scala:104)
	at scala.collection.mutable.ArraySeq.flatMap(ArraySeq.scala:37)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:236)
	at kafka.log.LogManager.<init>(LogManager.scala:112)
	at kafka.log.LogManager$.apply(LogManager.scala:1315)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:259)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-05-04 17:11:40,596] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-05-04 17:11:40,598] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:11:40,599] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:11:40,600] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:11:40,601] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:40,707] INFO Session: 0x1000131dada0009 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:40,707] INFO EventThread shut down for session: 0x1000131dada0009 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:40,710] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:40,711] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:41,571] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:41,571] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:41,571] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:41,573] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:41,573] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:41,574] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:41,574] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:41,574] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:41,575] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:41,576] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:41,576] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:41,578] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:11:41,578] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:11:41,578] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:11:41,582] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 17:11:41,587] INFO App info kafka.server for 3 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:11:41,587] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2022-05-04 17:11:41,588] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-05-04 17:11:41,589] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-05-04 17:11:43,730] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876699, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-04 17:11:43,732] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876699, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-04 17:11:43,736] INFO Deleted log /tmp/kafka-logs-5/Sensor-3.4d3566a97a1e4ca9afb880171a08fff5-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:43,737] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-3.4d3566a97a1e4ca9afb880171a08fff5-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:43,738] INFO Deleted time index /tmp/kafka-logs-5/Sensor-3.4d3566a97a1e4ca9afb880171a08fff5-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:43,742] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-5/Sensor-3.4d3566a97a1e4ca9afb880171a08fff5-delete. (kafka.log.LogManager)
[2022-05-04 17:11:43,742] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876711, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-04 17:11:43,742] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876711, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-04 17:11:43,743] INFO Deleted log /tmp/kafka-logs-5/Sensor-2.42685ef9279a46a6bf65daaaebd2e911-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:43,743] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-2.42685ef9279a46a6bf65daaaebd2e911-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:43,743] INFO Deleted time index /tmp/kafka-logs-5/Sensor-2.42685ef9279a46a6bf65daaaebd2e911-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:43,744] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-5/Sensor-2.42685ef9279a46a6bf65daaaebd2e911-delete. (kafka.log.LogManager)
[2022-05-04 17:11:43,744] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=1980918, lastModifiedTime=1651680577379, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-04 17:11:43,744] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=1980918, lastModifiedTime=1651680577379, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-04 17:11:43,745] INFO Deleted log /tmp/kafka-logs-5/Sensor-4.91b40b950a294e63a635248cd804185d-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:43,746] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-4.91b40b950a294e63a635248cd804185d-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:43,746] INFO Deleted time index /tmp/kafka-logs-5/Sensor-4.91b40b950a294e63a635248cd804185d-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-04 17:11:43,746] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-5/Sensor-4.91b40b950a294e63a635248cd804185d-delete. (kafka.log.LogManager)
[2022-05-04 17:11:44,922] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 17:11:45,154] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 17:11:45,232] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 17:11:45,236] INFO starting (kafka.server.KafkaServer)
[2022-05-04 17:11:45,236] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 17:11:45,251] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:45,256] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:45,256] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:45,256] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:45,256] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:45,256] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:45,256] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:45,257] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:45,257] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:45,257] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:45,257] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:45,257] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:45,257] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:45,257] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:45,257] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:45,257] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:45,257] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:45,257] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:45,257] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:45,259] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:45,264] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 17:11:45,268] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:45,282] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:45,287] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:45,288] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:45,291] INFO Socket connection established, initiating session, client: /127.0.0.1:55028, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:45,298] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000131dada000a, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:45,302] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:45,377] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:11:45,503] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 17:11:45,509] INFO Cluster ID = lqKBofKATK6pu47xJ3IrsQ (kafka.server.KafkaServer)
[2022-05-04 17:11:45,556] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:11:45,565] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:11:45,610] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:45,612] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:45,613] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:45,615] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:45,632] ERROR [KafkaServer id=4] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs-4. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:241)
	at scala.collection.StrictOptimizedIterableOps.flatMap(StrictOptimizedIterableOps.scala:117)
	at scala.collection.StrictOptimizedIterableOps.flatMap$(StrictOptimizedIterableOps.scala:104)
	at scala.collection.mutable.ArraySeq.flatMap(ArraySeq.scala:37)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:236)
	at kafka.log.LogManager.<init>(LogManager.scala:112)
	at kafka.log.LogManager$.apply(LogManager.scala:1315)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:259)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-05-04 17:11:45,635] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2022-05-04 17:11:45,638] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:11:45,639] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:11:45,639] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:11:45,640] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:45,746] INFO Session: 0x1000131dada000a closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:45,746] INFO EventThread shut down for session: 0x1000131dada000a (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:45,750] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:45,750] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:46,612] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:46,612] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:46,613] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:46,613] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:46,613] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:46,613] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:46,614] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:46,614] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:46,615] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:46,615] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:46,615] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:46,618] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:11:46,618] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:11:46,618] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:11:46,623] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 17:11:46,627] INFO App info kafka.server for 4 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:11:46,627] INFO [KafkaServer id=4] shut down completed (kafka.server.KafkaServer)
[2022-05-04 17:11:46,627] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-05-04 17:11:46,628] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2022-05-04 17:11:49,944] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-04 17:11:50,171] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-04 17:11:50,243] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 17:11:50,246] INFO starting (kafka.server.KafkaServer)
[2022-05-04 17:11:50,247] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-04 17:11:50,259] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:50,263] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:50,264] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:50,264] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:50,264] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:50,264] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:50,264] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:50,264] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:50,264] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:50,264] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:50,264] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:50,264] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:50,264] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:50,264] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:50,264] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:50,264] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:50,265] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:50,265] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:50,265] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:50,266] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:50,270] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-04 17:11:50,275] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:50,288] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:50,294] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:50,295] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:50,299] INFO Socket connection established, initiating session, client: /127.0.0.1:55030, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:50,307] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000131dada000b, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:50,311] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:50,385] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:11:50,495] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-04 17:11:50,499] INFO Cluster ID = lqKBofKATK6pu47xJ3IrsQ (kafka.server.KafkaServer)
[2022-05-04 17:11:50,551] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:11:50,559] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-04 17:11:50,606] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:50,607] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:50,609] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:50,611] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:50,628] ERROR [KafkaServer id=5] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs-5. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:241)
	at scala.collection.StrictOptimizedIterableOps.flatMap(StrictOptimizedIterableOps.scala:117)
	at scala.collection.StrictOptimizedIterableOps.flatMap$(StrictOptimizedIterableOps.scala:104)
	at scala.collection.mutable.ArraySeq.flatMap(ArraySeq.scala:37)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:236)
	at kafka.log.LogManager.<init>(LogManager.scala:112)
	at kafka.log.LogManager$.apply(LogManager.scala:1315)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:259)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-05-04 17:11:50,631] INFO [KafkaServer id=5] shutting down (kafka.server.KafkaServer)
[2022-05-04 17:11:50,634] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:11:50,635] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:11:50,635] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:11:50,636] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:50,741] INFO Session: 0x1000131dada000b closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:11:50,741] INFO EventThread shut down for session: 0x1000131dada000b (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:11:50,745] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:11:50,746] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:51,608] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:51,608] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:51,609] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:52,609] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:52,609] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:52,610] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:52,610] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:52,610] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:52,610] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:52,612] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:52,612] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:11:52,614] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:11:52,614] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:11:52,615] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:11:52,621] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 17:11:52,626] INFO App info kafka.server for 5 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:11:52,626] INFO [KafkaServer id=5] shut down completed (kafka.server.KafkaServer)
[2022-05-04 17:11:52,627] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-05-04 17:11:52,628] INFO [KafkaServer id=5] shutting down (kafka.server.KafkaServer)
[2022-05-04 17:11:55,472] INFO Creating topic Sensor with configuration {min.insync.replicas=2} and initial partition assignment HashMap(0 -> ArrayBuffer(2, 4, 1), 1 -> ArrayBuffer(3, 1, 2), 2 -> ArrayBuffer(0, 2, 3), 3 -> ArrayBuffer(5, 3, 0), 4 -> ArrayBuffer(4, 0, 5), 5 -> ArrayBuffer(1, 5, 4)) (kafka.zk.AdminZkClient)
[2022-05-04 17:11:55,516] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-4) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,516] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,517] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,519] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,519] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,520] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,529] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:55,529] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:55,530] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:55,531] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:55,532] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:55,533] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:55,534] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-4/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-04 17:11:55,533] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-5/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-04 17:11:55,535] INFO [Partition Sensor-3 broker=5] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-04 17:11:55,535] INFO [Partition Sensor-3 broker=5] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:55,535] INFO [Partition Sensor-4 broker=4] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-04 17:11:55,535] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-3/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-04 17:11:55,536] INFO [Partition Sensor-4 broker=4] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:55,537] INFO [Partition Sensor-1 broker=3] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-04 17:11:55,538] INFO Created log for partition Sensor-2 in /tmp/kafka-logs/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-04 17:11:55,538] INFO [Partition Sensor-1 broker=3] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:55,539] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-2/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-04 17:11:55,539] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-1/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-04 17:11:55,539] INFO [Partition Sensor-2 broker=0] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-04 17:11:55,539] INFO [Partition Sensor-2 broker=0] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:55,540] INFO [Partition Sensor-0 broker=2] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-04 17:11:55,540] INFO [Partition Sensor-5 broker=1] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-04 17:11:55,541] INFO [Partition Sensor-0 broker=2] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:55,541] INFO [Partition Sensor-5 broker=1] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:55,548] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:55,548] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:55,550] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-5/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-04 17:11:55,550] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-4/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-04 17:11:55,550] INFO [Partition Sensor-4 broker=5] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-04 17:11:55,550] INFO [Partition Sensor-5 broker=4] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-04 17:11:55,550] INFO [Partition Sensor-4 broker=5] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:55,550] INFO [Partition Sensor-5 broker=4] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:55,552] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:55,553] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:55,554] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:55,554] INFO Created log for partition Sensor-4 in /tmp/kafka-logs/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-04 17:11:55,554] INFO [Partition Sensor-4 broker=0] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-04 17:11:55,555] INFO [Partition Sensor-4 broker=0] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:55,555] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-2/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-04 17:11:55,555] INFO [Partition Sensor-2 broker=2] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-04 17:11:55,555] INFO [Partition Sensor-2 broker=2] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:55,556] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-1/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-04 17:11:55,556] INFO [Partition Sensor-0 broker=1] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-04 17:11:55,556] INFO [Partition Sensor-0 broker=1] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:55,560] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:55,560] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:55,562] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-4/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-04 17:11:55,562] INFO [Partition Sensor-0 broker=4] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-04 17:11:55,562] INFO [Partition Sensor-0 broker=4] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:55,562] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:55,563] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(Sensor-5, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,563] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:55,563] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-5/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-04 17:11:55,563] INFO [Partition Sensor-5 broker=5] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-04 17:11:55,563] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:55,563] INFO [Partition Sensor-5 broker=5] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:55,564] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(Sensor-4, Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,564] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-2/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-04 17:11:55,564] INFO [Partition Sensor-1 broker=2] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-04 17:11:55,564] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:55,564] INFO [Partition Sensor-1 broker=2] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:55,564] INFO Created log for partition Sensor-3 in /tmp/kafka-logs/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-04 17:11:55,565] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,565] INFO [Partition Sensor-3 broker=0] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-04 17:11:55,565] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-3/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-04 17:11:55,565] INFO [Partition Sensor-3 broker=0] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:55,565] INFO [Partition Sensor-3 broker=3] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-04 17:11:55,565] INFO [Partition Sensor-3 broker=3] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:55,565] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(Sensor-4, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,566] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-1/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-04 17:11:55,566] INFO [Partition Sensor-1 broker=1] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-04 17:11:55,567] INFO [Partition Sensor-1 broker=1] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:55,567] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,570] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-04 17:11:55,571] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-3/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-04 17:11:55,571] INFO [Partition Sensor-2 broker=3] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-04 17:11:55,571] INFO [Partition Sensor-2 broker=3] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-04 17:11:55,572] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,586] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,588] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,589] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,590] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,593] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 4 for partitions Map(Sensor-4 -> InitialFetchState(Some(mMvqc1eyQnevZRZcJb4vNw),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,593] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 2 for partitions Map(Sensor-0 -> InitialFetchState(Some(mMvqc1eyQnevZRZcJb4vNw),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,595] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,595] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions Map(Sensor-2 -> InitialFetchState(Some(mMvqc1eyQnevZRZcJb4vNw),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,596] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,597] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 4 for partitions Map(Sensor-4 -> InitialFetchState(Some(mMvqc1eyQnevZRZcJb4vNw),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,597] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,598] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,599] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,600] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,601] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,601] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 3 for partitions Map(Sensor-1 -> InitialFetchState(Some(mMvqc1eyQnevZRZcJb4vNw),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,602] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,601] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,602] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions Map(Sensor-0 -> InitialFetchState(Some(mMvqc1eyQnevZRZcJb4vNw),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,602] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 1 for partitions Map(Sensor-5 -> InitialFetchState(Some(mMvqc1eyQnevZRZcJb4vNw),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,602] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,604] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 0 for partitions Map(Sensor-2 -> InitialFetchState(Some(mMvqc1eyQnevZRZcJb4vNw),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,603] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-04 17:11:55,603] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-04 17:11:55,604] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-04 17:11:55,604] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-04 17:11:55,601] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,602] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-04 17:11:55,605] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,607] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 5 for partitions Map(Sensor-3 -> InitialFetchState(Some(mMvqc1eyQnevZRZcJb4vNw),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,607] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,607] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,607] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,608] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-04 17:11:55,609] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,610] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 5 for partitions Map(Sensor-3 -> InitialFetchState(Some(mMvqc1eyQnevZRZcJb4vNw),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,610] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-04 17:11:55,610] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,611] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-04 17:11:55,611] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-04 17:11:55,601] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 1 for partitions Map(Sensor-5 -> InitialFetchState(Some(mMvqc1eyQnevZRZcJb4vNw),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,612] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,605] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-04 17:11:55,613] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-04 17:11:55,614] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,616] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 3 for partitions Map(Sensor-1 -> InitialFetchState(Some(mMvqc1eyQnevZRZcJb4vNw),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:11:55,617] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:11:55,617] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-04 17:11:55,717] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:12:07,129] INFO [GroupCoordinator 2]: Dynamic member with unknown member id joins group console-consumer-32708 in Empty state. Created a new member id console-consumer-5be86936-c124-4798-8ebe-30ebd30c8e3d and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:12:07,139] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-32708 in state PreparingRebalance with old generation 0 (__consumer_offsets-21) (reason: Adding new member console-consumer-5be86936-c124-4798-8ebe-30ebd30c8e3d with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:12:07,143] INFO [GroupCoordinator 2]: Stabilized group console-consumer-32708 generation 1 (__consumer_offsets-21) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:12:07,159] INFO [GroupCoordinator 2]: Assignment received from leader console-consumer-5be86936-c124-4798-8ebe-30ebd30c8e3d for group console-consumer-32708 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:12:13,912] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group consumer in Empty state. Created a new member id consumer-consumer-1-f0252873-e706-4b39-8a51-ca2b73900c50 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:12:13,918] INFO [GroupCoordinator 3]: Preparing to rebalance group consumer in state PreparingRebalance with old generation 65 (__consumer_offsets-22) (reason: Adding new member consumer-consumer-1-f0252873-e706-4b39-8a51-ca2b73900c50 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:12:13,922] INFO [GroupCoordinator 3]: Stabilized group consumer generation 66 (__consumer_offsets-22) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:12:13,940] INFO [GroupCoordinator 3]: Assignment received from leader consumer-consumer-1-f0252873-e706-4b39-8a51-ca2b73900c50 for group consumer for generation 66. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:12:25,689] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876691, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-04 17:12:25,691] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876691, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-04 17:12:25,694] INFO Deleted log /tmp/kafka-logs/Sensor-2.d113d1f1731f49a1af6c81a055b79348-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:25,695] INFO Deleted offset index /tmp/kafka-logs/Sensor-2.d113d1f1731f49a1af6c81a055b79348-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:25,697] INFO Deleted time index /tmp/kafka-logs/Sensor-2.d113d1f1731f49a1af6c81a055b79348-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:25,701] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs/Sensor-2.d113d1f1731f49a1af6c81a055b79348-delete. (kafka.log.LogManager)
[2022-05-04 17:12:25,701] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876667, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-04 17:12:25,701] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876667, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-04 17:12:25,702] INFO Deleted log /tmp/kafka-logs/Sensor-3.bf0079cbbc8c4b6b9ed6e7d5f8e0b44a-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:25,702] INFO Deleted offset index /tmp/kafka-logs/Sensor-3.bf0079cbbc8c4b6b9ed6e7d5f8e0b44a-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:25,702] INFO Deleted time index /tmp/kafka-logs/Sensor-3.bf0079cbbc8c4b6b9ed6e7d5f8e0b44a-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:25,703] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs/Sensor-3.bf0079cbbc8c4b6b9ed6e7d5f8e0b44a-delete. (kafka.log.LogManager)
[2022-05-04 17:12:25,706] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876699, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-04 17:12:25,706] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876699, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-04 17:12:25,707] INFO Deleted log /tmp/kafka-logs/Sensor-1.2060b907c2c049d486864117f5a5a528-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:25,707] INFO Deleted offset index /tmp/kafka-logs/Sensor-1.2060b907c2c049d486864117f5a5a528-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:25,707] INFO Deleted time index /tmp/kafka-logs/Sensor-1.2060b907c2c049d486864117f5a5a528-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:25,707] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs/Sensor-1.2060b907c2c049d486864117f5a5a528-delete. (kafka.log.LogManager)
[2022-05-04 17:12:27,406] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group consumer in Stable state. Created a new member id consumer-consumer-1-80e988a8-cd8d-4f1a-9df3-dde240b9b5cd and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:12:27,412] INFO [GroupCoordinator 3]: Preparing to rebalance group consumer in state PreparingRebalance with old generation 66 (__consumer_offsets-22) (reason: Adding new member consumer-consumer-1-80e988a8-cd8d-4f1a-9df3-dde240b9b5cd with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:12:30,700] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876667, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-04 17:12:30,705] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876667, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-04 17:12:30,711] INFO Deleted log /tmp/kafka-logs-1/Sensor-5.7c15d591853b4ab78e9048dc5609f77b-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:30,712] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-5.7c15d591853b4ab78e9048dc5609f77b-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:30,717] INFO Deleted time index /tmp/kafka-logs-1/Sensor-5.7c15d591853b4ab78e9048dc5609f77b-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:30,729] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-1/Sensor-5.7c15d591853b4ab78e9048dc5609f77b-delete. (kafka.log.LogManager)
[2022-05-04 17:12:30,762] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=1980918, lastModifiedTime=1651680577379, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-04 17:12:30,763] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=1980918, lastModifiedTime=1651680577379, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-04 17:12:30,766] INFO Deleted log /tmp/kafka-logs-1/Sensor-4.1cf6bd74ffd446e5ad244173a41a37b8-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:30,766] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-4.1cf6bd74ffd446e5ad244173a41a37b8-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:30,766] INFO Deleted time index /tmp/kafka-logs-1/Sensor-4.1cf6bd74ffd446e5ad244173a41a37b8-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:30,767] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-1/Sensor-4.1cf6bd74ffd446e5ad244173a41a37b8-delete. (kafka.log.LogManager)
[2022-05-04 17:12:30,783] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876703, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-04 17:12:30,784] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876703, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-04 17:12:30,785] INFO Deleted log /tmp/kafka-logs-1/Sensor-3.cffbb723a3bf4ad08e376f63513505b5-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:30,786] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-3.cffbb723a3bf4ad08e376f63513505b5-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:30,786] INFO Deleted time index /tmp/kafka-logs-1/Sensor-3.cffbb723a3bf4ad08e376f63513505b5-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:30,787] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-1/Sensor-3.cffbb723a3bf4ad08e376f63513505b5-delete. (kafka.log.LogManager)
[2022-05-04 17:12:35,684] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876703, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-04 17:12:35,686] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876703, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-04 17:12:35,691] INFO Deleted log /tmp/kafka-logs-2/Sensor-0.7184a6ce6e304c88baa67cc9463d7900-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:35,691] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-0.7184a6ce6e304c88baa67cc9463d7900-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:35,693] INFO Deleted time index /tmp/kafka-logs-2/Sensor-0.7184a6ce6e304c88baa67cc9463d7900-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:35,695] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-2/Sensor-0.7184a6ce6e304c88baa67cc9463d7900-delete. (kafka.log.LogManager)
[2022-05-04 17:12:35,696] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876667, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-04 17:12:35,696] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876667, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-04 17:12:35,697] INFO Deleted log /tmp/kafka-logs-2/Sensor-1.0a56dc8cdabb4eaf9833b33974941e6d-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:35,697] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-1.0a56dc8cdabb4eaf9833b33974941e6d-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:35,697] INFO Deleted time index /tmp/kafka-logs-2/Sensor-1.0a56dc8cdabb4eaf9833b33974941e6d-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:35,698] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-2/Sensor-1.0a56dc8cdabb4eaf9833b33974941e6d-delete. (kafka.log.LogManager)
[2022-05-04 17:12:35,757] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876691, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-04 17:12:35,757] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651678876691, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-04 17:12:35,758] INFO Deleted log /tmp/kafka-logs-2/Sensor-5.7ff1c20f5a344792877a773a59b0bc84-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:35,759] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-5.7ff1c20f5a344792877a773a59b0bc84-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:35,759] INFO Deleted time index /tmp/kafka-logs-2/Sensor-5.7ff1c20f5a344792877a773a59b0bc84-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-04 17:12:35,759] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-2/Sensor-5.7ff1c20f5a344792877a773a59b0bc84-delete. (kafka.log.LogManager)
[2022-05-04 17:12:52,128] INFO [GroupCoordinator 2]: Preparing to rebalance group console-consumer-32708 in state PreparingRebalance with old generation 1 (__consumer_offsets-21) (reason: Removing member console-consumer-5be86936-c124-4798-8ebe-30ebd30c8e3d on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:12:52,129] INFO [GroupCoordinator 2]: Group console-consumer-32708 with generation 2 is now empty (__consumer_offsets-21) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:12:52,132] INFO [GroupCoordinator 2]: Member MemberMetadata(memberId=console-consumer-5be86936-c124-4798-8ebe-30ebd30c8e3d, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group console-consumer-32708 through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:12:56,837] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group console-consumer-70880 in Empty state. Created a new member id console-consumer-bbc37822-0adc-4fb5-bfa7-667850fad76d and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:12:56,846] INFO [GroupCoordinator 5]: Preparing to rebalance group console-consumer-70880 in state PreparingRebalance with old generation 0 (__consumer_offsets-24) (reason: Adding new member console-consumer-bbc37822-0adc-4fb5-bfa7-667850fad76d with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:12:56,852] INFO [GroupCoordinator 5]: Stabilized group console-consumer-70880 generation 1 (__consumer_offsets-24) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:12:56,866] INFO [GroupCoordinator 5]: Assignment received from leader console-consumer-bbc37822-0adc-4fb5-bfa7-667850fad76d for group console-consumer-70880 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:13:01,930] INFO [GroupCoordinator 3]: Member consumer-consumer-1-f0252873-e706-4b39-8a51-ca2b73900c50 in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:13:01,931] INFO [GroupCoordinator 3]: Stabilized group consumer generation 67 (__consumer_offsets-22) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:13:46,932] INFO [GroupCoordinator 3]: Member consumer-consumer-1-80e988a8-cd8d-4f1a-9df3-dde240b9b5cd in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:13:46,933] INFO [GroupCoordinator 3]: Preparing to rebalance group consumer in state PreparingRebalance with old generation 67 (__consumer_offsets-22) (reason: removing member consumer-consumer-1-80e988a8-cd8d-4f1a-9df3-dde240b9b5cd on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:13:46,934] INFO [GroupCoordinator 3]: Group consumer with generation 68 is now empty (__consumer_offsets-22) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:15:17,697] INFO [GroupCoordinator 5]: Preparing to rebalance group console-consumer-70880 in state PreparingRebalance with old generation 1 (__consumer_offsets-24) (reason: Removing member console-consumer-bbc37822-0adc-4fb5-bfa7-667850fad76d on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:15:17,697] INFO [GroupCoordinator 5]: Group console-consumer-70880 with generation 2 is now empty (__consumer_offsets-24) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:15:17,700] INFO [GroupCoordinator 5]: Member MemberMetadata(memberId=console-consumer-bbc37822-0adc-4fb5-bfa7-667850fad76d, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group console-consumer-70880 through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:15:21,786] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group console-consumer-54653 in Empty state. Created a new member id console-consumer-629c8a22-553f-4fd6-b71f-7d36dfa9a2f2 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:15:21,789] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-54653 in state PreparingRebalance with old generation 0 (__consumer_offsets-34) (reason: Adding new member console-consumer-629c8a22-553f-4fd6-b71f-7d36dfa9a2f2 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:15:21,790] INFO [GroupCoordinator 3]: Stabilized group console-consumer-54653 generation 1 (__consumer_offsets-34) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:15:21,797] INFO [GroupCoordinator 3]: Assignment received from leader console-consumer-629c8a22-553f-4fd6-b71f-7d36dfa9a2f2 for group console-consumer-54653 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:15:26,548] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group consumer in Empty state. Created a new member id consumer-consumer-1-1414e2cb-a9f1-48e9-bdbb-70f769df55ff and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:15:26,551] INFO [GroupCoordinator 3]: Preparing to rebalance group consumer in state PreparingRebalance with old generation 68 (__consumer_offsets-22) (reason: Adding new member consumer-consumer-1-1414e2cb-a9f1-48e9-bdbb-70f769df55ff with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:15:26,552] INFO [GroupCoordinator 3]: Stabilized group consumer generation 69 (__consumer_offsets-22) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:15:26,558] INFO [GroupCoordinator 3]: Assignment received from leader consumer-consumer-1-1414e2cb-a9f1-48e9-bdbb-70f769df55ff for group consumer for generation 69. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:15:45,171] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group consumer in Stable state. Created a new member id consumer-consumer-1-79a7b090-7dea-4e20-84df-74570f2e2285 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:15:45,175] INFO [GroupCoordinator 3]: Preparing to rebalance group consumer in state PreparingRebalance with old generation 69 (__consumer_offsets-22) (reason: Adding new member consumer-consumer-1-79a7b090-7dea-4e20-84df-74570f2e2285 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:16:14,557] INFO [GroupCoordinator 3]: Member consumer-consumer-1-1414e2cb-a9f1-48e9-bdbb-70f769df55ff in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:16:14,558] INFO [GroupCoordinator 3]: Stabilized group consumer generation 70 (__consumer_offsets-22) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:16:14,572] INFO [GroupCoordinator 3]: Assignment received from leader consumer-consumer-1-79a7b090-7dea-4e20-84df-74570f2e2285 for group consumer for generation 70. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:20:44,411] INFO [GroupMetadataManager brokerId=5] Group console-consumer-70880 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:20:52,484] INFO [GroupCoordinator 3]: Member consumer-consumer-1-79a7b090-7dea-4e20-84df-74570f2e2285 in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:20:52,485] INFO [GroupCoordinator 3]: Preparing to rebalance group consumer in state PreparingRebalance with old generation 70 (__consumer_offsets-22) (reason: removing member consumer-consumer-1-79a7b090-7dea-4e20-84df-74570f2e2285 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:20:52,485] INFO [GroupCoordinator 3]: Group consumer with generation 71 is now empty (__consumer_offsets-22) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:20:52,654] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group consumer in Empty state. Created a new member id consumer-consumer-1-3ac00a46-1a77-4123-9573-29f8e0d29b27 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:20:52,659] INFO [GroupCoordinator 3]: Preparing to rebalance group consumer in state PreparingRebalance with old generation 71 (__consumer_offsets-22) (reason: Adding new member consumer-consumer-1-3ac00a46-1a77-4123-9573-29f8e0d29b27 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:20:52,659] INFO [GroupCoordinator 3]: Stabilized group consumer generation 72 (__consumer_offsets-22) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:20:52,670] INFO [GroupCoordinator 3]: Assignment received from leader consumer-consumer-1-3ac00a46-1a77-4123-9573-29f8e0d29b27 for group consumer for generation 72. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:21:36,384] INFO [GroupMetadataManager brokerId=2] Group console-consumer-32708 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:21:46,664] INFO [GroupCoordinator 3]: Member consumer-consumer-1-3ac00a46-1a77-4123-9573-29f8e0d29b27 in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:21:46,665] INFO [GroupCoordinator 3]: Preparing to rebalance group consumer in state PreparingRebalance with old generation 72 (__consumer_offsets-22) (reason: removing member consumer-consumer-1-3ac00a46-1a77-4123-9573-29f8e0d29b27 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:21:46,665] INFO [GroupCoordinator 3]: Group consumer with generation 73 is now empty (__consumer_offsets-22) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:21:51,181] INFO [GroupCoordinator 3]: Preparing to rebalance group console-consumer-54653 in state PreparingRebalance with old generation 1 (__consumer_offsets-34) (reason: Removing member console-consumer-629c8a22-553f-4fd6-b71f-7d36dfa9a2f2 on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:21:51,181] INFO [GroupCoordinator 3]: Group console-consumer-54653 with generation 2 is now empty (__consumer_offsets-34) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:21:51,182] INFO [GroupCoordinator 3]: Member MemberMetadata(memberId=console-consumer-629c8a22-553f-4fd6-b71f-7d36dfa9a2f2, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group console-consumer-54653 through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:22:51,166] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group consumer in Empty state. Created a new member id consumer-consumer-1-33c3ae56-6df2-4348-8261-b4dab0356823 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:22:51,173] INFO [GroupCoordinator 3]: Preparing to rebalance group consumer in state PreparingRebalance with old generation 73 (__consumer_offsets-22) (reason: Adding new member consumer-consumer-1-33c3ae56-6df2-4348-8261-b4dab0356823 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:22:51,174] INFO [GroupCoordinator 3]: Stabilized group consumer generation 74 (__consumer_offsets-22) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:22:51,183] INFO [GroupCoordinator 3]: Assignment received from leader consumer-consumer-1-33c3ae56-6df2-4348-8261-b4dab0356823 for group consumer for generation 74. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:23:19,107] INFO [GroupCoordinator 3]: Dynamic member with unknown member id joins group consumer in Stable state. Created a new member id consumer-consumer-1-56929ed8-375e-4291-83b5-ec5e38ca0921 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:23:19,111] INFO [GroupCoordinator 3]: Preparing to rebalance group consumer in state PreparingRebalance with old generation 74 (__consumer_offsets-22) (reason: Adding new member consumer-consumer-1-56929ed8-375e-4291-83b5-ec5e38ca0921 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:23:36,478] INFO [GroupCoordinator 4]: Dynamic member with unknown member id joins group console-consumer-21139 in Empty state. Created a new member id console-consumer-9ac52016-2fd7-4ef9-977e-b44e21456b9e and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:23:36,491] INFO [GroupCoordinator 4]: Preparing to rebalance group console-consumer-21139 in state PreparingRebalance with old generation 0 (__consumer_offsets-37) (reason: Adding new member console-consumer-9ac52016-2fd7-4ef9-977e-b44e21456b9e with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:23:36,498] INFO [GroupCoordinator 4]: Stabilized group console-consumer-21139 generation 1 (__consumer_offsets-37) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:23:36,519] INFO [GroupCoordinator 4]: Assignment received from leader console-consumer-9ac52016-2fd7-4ef9-977e-b44e21456b9e for group console-consumer-21139 for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:23:46,191] INFO [GroupCoordinator 3]: Member consumer-consumer-1-33c3ae56-6df2-4348-8261-b4dab0356823 in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:23:46,194] INFO [GroupCoordinator 3]: Stabilized group consumer generation 75 (__consumer_offsets-22) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:23:46,207] INFO [GroupCoordinator 3]: Assignment received from leader consumer-consumer-1-56929ed8-375e-4291-83b5-ec5e38ca0921 for group consumer for generation 75. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:28:14,522] INFO [GroupCoordinator 4]: Preparing to rebalance group console-consumer-21139 in state PreparingRebalance with old generation 1 (__consumer_offsets-37) (reason: Removing member console-consumer-9ac52016-2fd7-4ef9-977e-b44e21456b9e on LeaveGroup) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:28:14,523] INFO [GroupCoordinator 4]: Group console-consumer-21139 with generation 2 is now empty (__consumer_offsets-37) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:28:14,525] INFO [GroupCoordinator 4]: Member MemberMetadata(memberId=console-consumer-9ac52016-2fd7-4ef9-977e-b44e21456b9e, groupInstanceId=None, clientId=console-consumer, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range, cooperative-sticky)) has left group console-consumer-21139 through explicit `LeaveGroup` request (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:28:48,720] INFO [GroupCoordinator 3]: Member consumer-consumer-1-56929ed8-375e-4291-83b5-ec5e38ca0921 in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:28:48,720] INFO [GroupCoordinator 3]: Preparing to rebalance group consumer in state PreparingRebalance with old generation 75 (__consumer_offsets-22) (reason: removing member consumer-consumer-1-56929ed8-375e-4291-83b5-ec5e38ca0921 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:28:48,720] INFO [GroupCoordinator 3]: Group consumer with generation 76 is now empty (__consumer_offsets-22) (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:30:34,878] INFO [GroupMetadataManager brokerId=3] Group console-consumer-54653 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:30:39,737] INFO [GroupMetadataManager brokerId=4] Group console-consumer-21139 transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:42:31,128] INFO [Controller id=3, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,128] INFO [Controller id=3, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,128] INFO [Controller id=3, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,128] INFO [Controller id=3, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,128] INFO [Controller id=3, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,128] INFO [Controller id=3, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,140] INFO [GroupCoordinator 5]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:42:31,140] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:42:31,141] INFO [GroupCoordinator 4]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:42:31,142] INFO [GroupMetadataManager brokerId=3] Group consumer transitioned to Dead in generation 76 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-04 17:42:31,142] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:42:31,143] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:42:31,144] INFO [GroupCoordinator 3]: Removed 6 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:42:31,173] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:31,174] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:31,175] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:31,175] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:31,175] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:31,175] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:31,175] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:31,176] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:31,176] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:31,176] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:31,175] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:31,177] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:31,181] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,182] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,182] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 3660 due to node 0 being disconnected (elapsed time since creation: 59ms, elapsed time since send: 59ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,183] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=1651396531, epoch=3660) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-04 17:42:31,184] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,184] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,184] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,184] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,185] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,186] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,185] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,186] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:31,186] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,186] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,186] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:31,187] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,187] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,188] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,189] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 3660 due to node 1 being disconnected (elapsed time since creation: 338ms, elapsed time since send: 338ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,189] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 3660 due to node 3 being disconnected (elapsed time since creation: 106ms, elapsed time since send: 106ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,190] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 3660 due to node 2 being disconnected (elapsed time since creation: 117ms, elapsed time since send: 117ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,190] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 18662 due to node 4 being disconnected (elapsed time since creation: 138ms, elapsed time since send: 138ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,190] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,191] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 3659 due to node 2 being disconnected (elapsed time since creation: 499ms, elapsed time since send: 499ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,191] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,191] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 3660 due to node 5 being disconnected (elapsed time since creation: 64ms, elapsed time since send: 64ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,191] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=5918374, epoch=3660) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-04 17:42:31,193] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,190] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=377886627, epoch=3658) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-04 17:42:31,190] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=1398573651, epoch=3660) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-04 17:42:31,194] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,194] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,194] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,194] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,194] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,191] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=1566779131, epoch=18662) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-04 17:42:31,192] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=708908083, epoch=3659) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-04 17:42:31,196] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:31,196] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,196] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,190] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=13751937, epoch=3660) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-04 17:42:31,196] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:31,197] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,197] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,197] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,197] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,200] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,201] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,201] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,201] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 3660 due to node 0 being disconnected (elapsed time since creation: 103ms, elapsed time since send: 103ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,202] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,202] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 3661 due to node 5 being disconnected (elapsed time since creation: 104ms, elapsed time since send: 104ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,202] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,201] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=1481499369, epoch=3660) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-04 17:42:31,203] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,203] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,203] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,202] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=638565524, epoch=3661) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-04 17:42:31,204] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,204] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,204] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 18677 due to node 4 being disconnected (elapsed time since creation: 154ms, elapsed time since send: 154ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-04 17:42:31,204] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=597042629, epoch=18677) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-04 17:42:31,205] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,205] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,205] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:31,206] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:31,207] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,207] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,207] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,208] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,208] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:31,208] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,208] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-04 17:42:31,208] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:31,209] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:31,211] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:31,212] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:31,212] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:31,216] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-3/Sensor-2.21894601fbc8459c955cd4123615086e-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-04 17:42:31,219] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-3/Sensor-3.69146af0693d414cbe88d3375b79663f-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-04 17:42:31,219] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-1/Sensor-5.4319cf781b84411c8c02534188895518-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-04 17:42:31,222] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-3/Sensor-1.450bef0e6e6f43ac97e8bcec0223a649-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-04 17:42:31,225] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-1/Sensor-0.d9cfe693ad2044d382b0c02c164a03ee-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-04 17:42:31,227] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-2/Sensor-2.4ddc01f36cca46a692d4833c66189a33-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-04 17:42:31,228] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-1/Sensor-1.b8ef63b57ff74da1a7df61465a5bd952-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-04 17:42:31,231] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs/Sensor-4.a26c946be63145a096c9316a99cb7e45-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-04 17:42:31,231] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-2/Sensor-0.2b5955ec0d7448d38fbc8ee254569d21-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-04 17:42:31,232] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-5/Sensor-4.f6cacf82a35c452ea590420932af29c9-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-04 17:42:31,234] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-4/Sensor-4.99592b0da5e243e58802c111bf733f7a-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-04 17:42:31,235] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-2/Sensor-1.34ed9dcd622140b6ba989f74207b2eca-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-04 17:42:31,236] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs/Sensor-2.589cb33d8c684a1286e4c43b9f91bd2d-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-04 17:42:31,237] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-4/Sensor-5.6ab75d477399466d8bc59c09baac877b-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-04 17:42:31,237] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-5/Sensor-5.4e5976a4e36244eaaf44189ff5d9c717-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-04 17:42:31,239] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs/Sensor-3.3715523b2d0b4d77a073898eec6e3868-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-04 17:42:31,239] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-4/Sensor-0.1d6744b894f546aebec55f266ea330ca-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-04 17:42:31,240] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-5/Sensor-3.5ec4c33fdc2645289702e23046ccbc32-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-04 17:42:31,515] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 17:42:31,515] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 17:42:31,515] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 17:42:31,515] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 17:42:31,516] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 17:42:31,515] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-04 17:42:31,518] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-05-04 17:42:31,518] INFO [KafkaServer id=5] shutting down (kafka.server.KafkaServer)
[2022-05-04 17:42:31,518] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-04 17:42:31,519] INFO [KafkaServer id=5] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-04 17:42:31,519] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-04 17:42:31,519] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2022-05-04 17:42:31,521] INFO [KafkaServer id=4] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-04 17:42:31,522] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-05-04 17:42:31,522] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-04 17:42:31,522] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-04 17:42:31,523] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-04 17:42:31,523] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-04 17:42:31,540] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 8ms (kafka.server.KafkaServer)
[2022-05-04 17:42:31,542] INFO [KafkaServer id=4] Controlled shutdown request returned successfully after 9ms (kafka.server.KafkaServer)
[2022-05-04 17:42:31,542] INFO [KafkaServer id=3] Controlled shutdown request returned successfully after 10ms (kafka.server.KafkaServer)
[2022-05-04 17:42:31,543] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:42:31,543] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:42:31,543] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:42:31,543] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:42:31,544] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:42:31,544] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:42:31,544] INFO [KafkaServer id=5] Controlled shutdown request returned successfully after 13ms (kafka.server.KafkaServer)
[2022-05-04 17:42:31,544] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:42:31,544] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:42:31,544] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:42:31,545] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-04 17:42:31,545] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 14ms (kafka.server.KafkaServer)
[2022-05-04 17:42:31,545] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-04 17:42:31,546] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-04 17:42:31,546] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 13ms (kafka.server.KafkaServer)
[2022-05-04 17:42:31,547] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:42:31,547] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:42:31,548] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:42:31,548] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:42:31,549] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-04 17:42:31,550] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:42:31,547] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:42:31,547] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:42:31,550] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:42:31,551] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-04 17:42:31,551] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-04 17:42:31,553] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-04 17:42:31,555] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-04 17:42:31,557] INFO [data-plane Kafka Request Handler on Broker 4], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 17:42:31,557] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-04 17:42:31,559] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-04 17:42:31,560] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 17:42:31,561] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 17:42:31,562] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-04 17:42:31,564] INFO [data-plane Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 17:42:31,564] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 17:42:31,564] INFO [data-plane Kafka Request Handler on Broker 4], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 17:42:31,565] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 17:42:31,566] INFO [data-plane Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 17:42:31,569] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,569] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-04 17:42:31,570] INFO [ExpirationReaper-4-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,570] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,571] INFO [data-plane Kafka Request Handler on Broker 5], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 17:42:31,574] INFO [ExpirationReaper-3-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,574] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-04 17:42:31,574] INFO [data-plane Kafka Request Handler on Broker 5], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 17:42:31,575] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 17:42:31,578] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-04 17:42:31,579] INFO [ExpirationReaper-5-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,582] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,637] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,637] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,638] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-04 17:42:31,639] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,747] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,747] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,748] INFO [ExpirationReaper-3-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,748] INFO [ExpirationReaper-3-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,748] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,748] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,749] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-04 17:42:31,749] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-04 17:42:31,749] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,750] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:42:31,750] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,751] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-04 17:42:31,752] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:42:31,752] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:42:31,752] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:42:31,753] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:42:31,754] INFO [ExpirationReaper-5-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,754] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,754] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,754] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,754] INFO [ExpirationReaper-4-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,754] INFO [ExpirationReaper-5-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,754] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,754] INFO [ExpirationReaper-4-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,755] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:42:31,755] INFO [KafkaApi-4] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-04 17:42:31,755] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-04 17:42:31,756] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,757] INFO [ExpirationReaper-4-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,757] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,757] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:42:31,760] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-04 17:42:31,761] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:42:31,761] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:42:31,761] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:42:31,763] INFO [KafkaApi-5] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-04 17:42:31,763] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:42:31,763] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:42:31,763] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,763] INFO [ExpirationReaper-5-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,873] WARN Session 0x1000131dada0005 for sever localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x1000131dada0005, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-04 17:42:31,873] WARN Session 0x1000131dada0007 for sever localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x1000131dada0007, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-04 17:42:31,873] WARN Session 0x1000131dada0004 for sever localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x1000131dada0004, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-04 17:42:31,873] WARN Session 0x1000131dada0008 for sever localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x1000131dada0008, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-04 17:42:31,873] WARN Session 0x1000131dada0003 for sever localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x1000131dada0003, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-04 17:42:31,873] WARN Session 0x1000131dada0006 for sever localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x1000131dada0006, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-04 17:42:31,923] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,923] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,926] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:42:31,927] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-04 17:42:31,927] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:42:31,928] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:42:31,928] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:42:31,930] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:42:31,931] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,931] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,931] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:42:31,931] INFO [ExpirationReaper-4-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,931] INFO [ExpirationReaper-4-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,931] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,933] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:42:31,934] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-04 17:42:31,934] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:42:31,936] INFO [TransactionCoordinator id=4] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:42:31,936] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:42:31,936] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:42:31,937] INFO [Transaction State Manager 4]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-04 17:42:31,937] INFO [Transaction Marker Channel Manager 4]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:42:31,937] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:42:31,938] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:42:31,938] INFO [Transaction Marker Channel Manager 4]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:42:31,938] INFO [Transaction Marker Channel Manager 4]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:42:31,938] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,939] INFO [TransactionCoordinator id=4] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:42:31,939] INFO [GroupCoordinator 4]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:42:31,940] INFO [ExpirationReaper-4-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,948] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,948] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,948] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,954] INFO [ExpirationReaper-4-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,954] INFO [ExpirationReaper-5-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,954] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,954] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,954] INFO [ExpirationReaper-5-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,954] INFO [ExpirationReaper-4-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,954] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,954] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,954] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,954] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,955] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,955] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,955] INFO [ExpirationReaper-4-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,955] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,955] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,955] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,956] INFO [TransactionCoordinator id=5] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:42:31,957] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:42:31,958] INFO [Transaction State Manager 5]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-04 17:42:31,958] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-04 17:42:31,958] INFO [Transaction Marker Channel Manager 5]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:42:31,958] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:42:31,958] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:42:31,958] INFO [Transaction Marker Channel Manager 5]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:42:31,958] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:42:31,958] INFO [Transaction Marker Channel Manager 5]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-04 17:42:31,959] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:31,959] INFO [TransactionCoordinator id=5] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-04 17:42:31,960] INFO [GroupCoordinator 5]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:42:31,960] INFO [ExpirationReaper-5-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:31,961] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:31,961] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:31,962] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:31,962] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,154] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,154] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,154] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,154] INFO [ExpirationReaper-4-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,154] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,154] INFO [ExpirationReaper-5-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,154] INFO [ExpirationReaper-4-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,154] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,154] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,154] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,154] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,154] INFO [ExpirationReaper-5-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,155] INFO [ExpirationReaper-5-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,155] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,155] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:42:32,155] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:42:32,156] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:42:32,156] INFO [GroupCoordinator 4]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:42:32,157] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2022-05-04 17:42:32,157] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-04 17:42:32,157] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-05-04 17:42:32,157] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:42:32,157] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:42:32,157] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:42:32,158] INFO [ReplicaManager broker=4] Shutting down (kafka.server.ReplicaManager)
[2022-05-04 17:42:32,157] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:42:32,158] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:42:32,158] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:42:32,158] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:42:32,158] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:42:32,158] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:42:32,158] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:42:32,159] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:32,159] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:32,159] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:42:32,159] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:42:32,159] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:32,160] INFO [ReplicaFetcherManager on broker 4] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:32,160] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:32,161] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:32,161] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:32,161] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:32,162] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:32,162] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,162] INFO [ReplicaFetcherManager on broker 4] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:32,162] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:32,162] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:32,162] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:32,162] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,162] INFO [ReplicaAlterLogDirsManager on broker 4] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:32,162] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:32,162] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,163] INFO [ReplicaAlterLogDirsManager on broker 4] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:32,163] INFO [ExpirationReaper-4-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,335] INFO [ExpirationReaper-4-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,335] INFO [ExpirationReaper-4-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,336] INFO [ExpirationReaper-4-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,352] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,352] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,352] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,354] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,354] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,354] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,354] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,354] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,354] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,354] INFO [ExpirationReaper-5-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,354] INFO [ExpirationReaper-4-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,354] INFO [ExpirationReaper-5-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,354] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,354] INFO [ExpirationReaper-4-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,355] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,355] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,355] INFO [ExpirationReaper-4-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,355] INFO [GroupCoordinator 5]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-04 17:42:32,357] INFO [ReplicaManager broker=5] Shutting down (kafka.server.ReplicaManager)
[2022-05-04 17:42:32,357] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:42:32,357] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:42:32,357] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-04 17:42:32,358] INFO [ReplicaFetcherManager on broker 5] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:32,360] INFO [ReplicaFetcherManager on broker 5] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-04 17:42:32,361] INFO [ReplicaAlterLogDirsManager on broker 5] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:32,362] INFO [ReplicaAlterLogDirsManager on broker 5] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-04 17:42:32,362] INFO [ExpirationReaper-5-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,549] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,549] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,549] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,549] INFO [ExpirationReaper-4-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,550] INFO [ExpirationReaper-4-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,550] INFO [ExpirationReaper-4-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,554] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,554] INFO [ExpirationReaper-5-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,554] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,554] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,554] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,554] INFO [ExpirationReaper-5-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,554] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,554] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,555] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,555] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,555] INFO [ExpirationReaper-5-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,555] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,555] INFO [ExpirationReaper-4-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,555] INFO [ExpirationReaper-4-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,556] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,556] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,560] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-04 17:42:32,560] INFO [ReplicaManager broker=4] Shut down completely (kafka.server.ReplicaManager)
[2022-05-04 17:42:32,560] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,560] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,561] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,561] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,561] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,561] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,563] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 17:42:32,563] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 17:42:32,563] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,563] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,563] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,563] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,564] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,564] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,564] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 17:42:32,565] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 17:42:32,565] INFO Shutting down. (kafka.log.LogManager)
[2022-05-04 17:42:32,565] INFO Shutting down. (kafka.log.LogManager)
[2022-05-04 17:42:32,588] INFO [ProducerStateManager partition=__consumer_offsets-21] Wrote producer snapshot at offset 3 with 0 producer ids in 3 ms. (kafka.log.ProducerStateManager)
[2022-05-04 17:42:32,593] INFO [ProducerStateManager partition=__consumer_offsets-37] Wrote producer snapshot at offset 6 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-05-04 17:42:32,601] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-04 17:42:32,604] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-04 17:42:32,607] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:42:32,607] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:42:32,607] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:42:32,608] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:42:32,609] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:42:32,609] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:42:32,609] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:42:32,610] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:42:32,749] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,749] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,749] INFO [ExpirationReaper-3-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,755] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,755] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,755] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,755] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,755] INFO [ExpirationReaper-5-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,755] INFO [ExpirationReaper-5-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,755] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,755] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,755] INFO [ExpirationReaper-5-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,756] INFO [ExpirationReaper-3-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,756] INFO [ExpirationReaper-3-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,760] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2022-05-04 17:42:32,760] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,761] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,761] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,762] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 17:42:32,762] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,763] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,763] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,763] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 17:42:32,764] INFO Shutting down. (kafka.log.LogManager)
[2022-05-04 17:42:32,779] INFO [ProducerStateManager partition=__consumer_offsets-22] Wrote producer snapshot at offset 1149 with 0 producer ids in 3 ms. (kafka.log.ProducerStateManager)
[2022-05-04 17:42:32,786] INFO [ProducerStateManager partition=__consumer_offsets-34] Wrote producer snapshot at offset 3 with 0 producer ids in 1 ms. (kafka.log.ProducerStateManager)
[2022-05-04 17:42:32,796] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-04 17:42:32,810] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:42:32,810] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:42:32,810] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:42:32,810] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:42:32,932] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,932] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,937] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-05-04 17:42:32,938] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,939] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,939] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,942] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 17:42:32,942] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,943] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,943] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,944] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 17:42:32,945] INFO Shutting down. (kafka.log.LogManager)
[2022-05-04 17:42:32,955] INFO [ExpirationReaper-5-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,955] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,955] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,955] INFO [ExpirationReaper-5-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,956] INFO [ExpirationReaper-5-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:32,959] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-04 17:42:32,959] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,960] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,960] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,962] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 17:42:32,962] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,963] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,963] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:32,963] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 17:42:32,964] INFO Shutting down. (kafka.log.LogManager)
[2022-05-04 17:42:32,966] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-04 17:42:32,970] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:42:32,971] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:42:32,971] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:42:32,971] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:42:32,983] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-04 17:42:32,986] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:42:32,986] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:42:32,986] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:42:32,987] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:42:33,039] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:42:33,039] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:42:33,040] WARN An exception was thrown while closing send thread for session 0x1000131dada0003. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-04 17:42:33,143] INFO Session: 0x1000131dada0003 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:42:33,143] INFO EventThread shut down for session: 0x1000131dada0003 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:42:33,144] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:42:33,145] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,156] INFO [ExpirationReaper-5-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:33,156] INFO [ExpirationReaper-5-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-04 17:42:33,160] INFO [ReplicaManager broker=5] Shut down completely (kafka.server.ReplicaManager)
[2022-05-04 17:42:33,160] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:33,161] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:33,161] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:33,163] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 17:42:33,163] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:33,164] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:33,164] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-04 17:42:33,164] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-04 17:42:33,165] INFO Shutting down. (kafka.log.LogManager)
[2022-05-04 17:42:33,183] INFO [ProducerStateManager partition=__consumer_offsets-24] Wrote producer snapshot at offset 3 with 0 producer ids in 1 ms. (kafka.log.ProducerStateManager)
[2022-05-04 17:42:33,192] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-04 17:42:33,198] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:42:33,198] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:42:33,198] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-04 17:42:33,199] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:42:33,291] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,291] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,291] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,301] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,301] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,302] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,341] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:42:33,341] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:42:33,341] WARN An exception was thrown while closing send thread for session 0x1000131dada0007. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-04 17:42:33,362] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:42:33,362] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:42:33,363] WARN An exception was thrown while closing send thread for session 0x1000131dada0008. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-04 17:42:33,444] INFO Session: 0x1000131dada0007 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:42:33,444] INFO EventThread shut down for session: 0x1000131dada0007 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:42:33,446] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:42:33,446] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,449] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:42:33,449] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:42:33,450] WARN An exception was thrown while closing send thread for session 0x1000131dada0004. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-04 17:42:33,465] INFO EventThread shut down for session: 0x1000131dada0008 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:42:33,465] INFO Session: 0x1000131dada0008 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:42:33,468] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:42:33,468] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,553] INFO Session: 0x1000131dada0004 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:42:33,553] INFO EventThread shut down for session: 0x1000131dada0004 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:42:33,555] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:42:33,555] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,649] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:42:33,649] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:42:33,650] WARN An exception was thrown while closing send thread for session 0x1000131dada0005. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-04 17:42:33,753] INFO Session: 0x1000131dada0005 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:42:33,754] INFO EventThread shut down for session: 0x1000131dada0005 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:42:33,756] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:42:33,757] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,818] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:42:33,818] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:42:33,819] WARN An exception was thrown while closing send thread for session 0x1000131dada0006. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-04 17:42:33,890] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,890] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,890] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,890] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,890] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,890] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,921] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,921] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,921] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,922] INFO Session: 0x1000131dada0006 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-04 17:42:33,922] INFO EventThread shut down for session: 0x1000131dada0006 (org.apache.zookeeper.ClientCnxn)
[2022-05-04 17:42:33,924] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-04 17:42:33,925] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,935] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,935] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,935] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,940] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,940] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:33,942] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:34,184] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:34,184] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:34,184] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:34,291] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:34,291] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:34,291] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:34,890] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:34,890] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:34,890] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:34,890] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:34,890] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:34,890] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:34,934] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:34,935] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:34,936] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutting down socket server (kafka.network.SocketServer)
[2022-05-04 17:42:34,940] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:34,940] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:34,940] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:34,959] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutdown completed (kafka.network.SocketServer)
[2022-05-04 17:42:34,959] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:42:34,959] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:42:34,959] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:42:34,961] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 17:42:34,961] INFO App info kafka.server for 5 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:42:34,961] INFO [KafkaServer id=5] shut down completed (kafka.server.KafkaServer)
[2022-05-04 17:42:35,184] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:35,184] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:35,184] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:35,200] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:35,200] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:35,201] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:35,291] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:35,291] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:35,292] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutting down socket server (kafka.network.SocketServer)
[2022-05-04 17:42:35,316] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutdown completed (kafka.network.SocketServer)
[2022-05-04 17:42:35,317] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:42:35,317] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:42:35,317] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:42:35,318] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 17:42:35,318] INFO App info kafka.server for 3 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:42:35,318] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2022-05-04 17:42:35,890] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:35,890] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:35,890] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:35,890] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:35,891] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:35,891] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:35,941] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:35,941] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:35,941] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:36,201] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:36,201] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:36,202] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutting down socket server (kafka.network.SocketServer)
[2022-05-04 17:42:36,229] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutdown completed (kafka.network.SocketServer)
[2022-05-04 17:42:36,229] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:42:36,230] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:42:36,230] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:42:36,231] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 17:42:36,231] INFO App info kafka.server for 4 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:42:36,231] INFO [KafkaServer id=4] shut down completed (kafka.server.KafkaServer)
[2022-05-04 17:42:36,891] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:36,891] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:36,891] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:36,891] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:36,891] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:36,892] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-04 17:42:36,915] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-04 17:42:36,916] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:42:36,916] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:42:36,916] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:42:36,918] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 17:42:36,918] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:42:36,919] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-04 17:42:36,941] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:36,941] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:36,943] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-04 17:42:36,964] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-04 17:42:36,965] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:42:36,965] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:42:36,965] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:42:36,966] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 17:42:36,966] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:42:36,966] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-04 17:42:37,891] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:37,891] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-04 17:42:37,893] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-05-04 17:42:37,914] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-05-04 17:42:37,915] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:42:37,915] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:42:37,915] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-04 17:42:37,917] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-04 17:42:37,917] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-04 17:42:37,918] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
