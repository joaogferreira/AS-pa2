[2022-05-07 19:18:59,385] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:18:59,385] INFO [GroupCoordinator 4]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:18:59,412] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-5, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:18:59,412] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:18:59,412] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-5, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:18:59,412] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:18:59,420] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:18:59,421] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:18:59,422] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:18:59,422] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:18:59,424] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 2518 due to node 0 being disconnected (elapsed time since creation: 303ms, elapsed time since send: 303ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:18:59,425] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 2518 due to node 2 being disconnected (elapsed time since creation: 443ms, elapsed time since send: 443ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:18:59,425] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=753503231, epoch=2518) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-07 19:18:59,430] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:18:59,431] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:18:59,426] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=575657106, epoch=2518) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-07 19:18:59,433] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:18:59,433] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:18:59,440] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:18:59,441] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:18:59,441] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:18:59,441] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:18:59,441] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:18:59,442] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 2518 due to node 5 being disconnected (elapsed time since creation: 168ms, elapsed time since send: 168ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:18:59,442] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=1524708922, epoch=2518) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-07 19:18:59,443] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:18:59,443] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:18:59,445] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-5, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:18:59,445] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:18:59,446] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:18:59,449] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-5, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:18:59,466] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-2/Sensor-5.1af221875c3342ee8145e4b0b365a54c-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:18:59,467] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-4/Sensor-5.c26b72176694499999ba5c69b59f45eb-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:18:59,471] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-2/Sensor-2.fe8c510a72bc4b48b0590d08c511f65e-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:18:59,471] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-4/Sensor-3.ffad24e65c8742b0929f6abb1d8ec9bf-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:18:59,474] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-2/Sensor-1.4228fd7d738844118ffd72be3a2ea77a-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:18:59,475] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-4/Sensor-0.f389113946624a849813f8e297a79f23-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:18:59,747] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-07 19:18:59,748] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-07 19:18:59,749] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-07 19:18:59,751] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2022-05-07 19:18:59,751] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-07 19:18:59,752] INFO [KafkaServer id=4] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-07 19:18:59,775] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 12ms (kafka.server.KafkaServer)
[2022-05-07 19:18:59,778] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:18:59,778] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:18:59,778] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:18:59,779] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-07 19:18:59,781] INFO [KafkaServer id=4] Controlled shutdown request returned successfully after 15ms (kafka.server.KafkaServer)
[2022-05-07 19:18:59,783] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:18:59,784] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:18:59,784] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:18:59,786] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-07 19:18:59,791] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-07 19:18:59,793] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-07 19:18:59,797] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-07 19:18:59,801] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:18:59,804] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-07 19:18:59,805] INFO [data-plane Kafka Request Handler on Broker 4], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-07 19:18:59,807] INFO [data-plane Kafka Request Handler on Broker 4], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-07 19:18:59,810] INFO [ExpirationReaper-4-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:18:59,932] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:18:59,933] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:18:59,934] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-07 19:18:59,935] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:18:59,953] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:18:59,953] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:18:59,956] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:18:59,958] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-07 19:18:59,958] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:18:59,958] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:18:59,958] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:18:59,960] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:18:59,960] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:18:59,961] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:18:59,994] INFO [ExpirationReaper-4-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:18:59,994] INFO [ExpirationReaper-4-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:18:59,995] INFO [KafkaApi-4] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-07 19:18:59,997] INFO [ExpirationReaper-4-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,103] WARN Session 0x100012253ab0008 for sever localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x100012253ab0008, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-07 19:19:00,103] WARN Session 0x100012253ab0004 for sever localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x100012253ab0004, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-07 19:19:00,125] INFO [ExpirationReaper-4-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,125] INFO [ExpirationReaper-4-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,128] INFO [TransactionCoordinator id=4] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:19:00,129] INFO [Transaction State Manager 4]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-07 19:19:00,130] INFO [Transaction Marker Channel Manager 4]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:19:00,131] INFO [Transaction Marker Channel Manager 4]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:19:00,131] INFO [Transaction Marker Channel Manager 4]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:19:00,132] INFO [TransactionCoordinator id=4] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:19:00,132] INFO [GroupCoordinator 4]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:00,133] INFO [ExpirationReaper-4-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,137] INFO [ExpirationReaper-4-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,137] INFO [ExpirationReaper-4-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,138] INFO [ExpirationReaper-4-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,160] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,160] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,160] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,163] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,163] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,165] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:00,166] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-07 19:19:00,166] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:19:00,167] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:19:00,167] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:19:00,168] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:19:00,169] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:19:00,170] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:19:00,171] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:19:00,171] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,266] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,266] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,267] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,332] INFO [ExpirationReaper-4-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,332] INFO [ExpirationReaper-4-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,333] INFO [GroupCoordinator 4]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:00,334] INFO [ReplicaManager broker=4] Shutting down (kafka.server.ReplicaManager)
[2022-05-07 19:19:00,334] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:19:00,335] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:19:00,334] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:19:00,336] INFO [ReplicaFetcherManager on broker 4] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:19:00,337] INFO [ReplicaFetcherManager on broker 4] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:19:00,338] INFO [ReplicaAlterLogDirsManager on broker 4] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:19:00,338] INFO [ReplicaAlterLogDirsManager on broker 4] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:19:00,338] INFO [ExpirationReaper-4-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,451] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,451] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,452] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,496] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,496] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,497] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,506] INFO [ExpirationReaper-4-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,506] INFO [ExpirationReaper-4-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,507] INFO [ExpirationReaper-4-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,521] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,521] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,525] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-07 19:19:00,526] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:00,526] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:00,526] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:00,528] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-07 19:19:00,528] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:00,528] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:00,528] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:00,529] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-07 19:19:00,529] INFO Shutting down. (kafka.log.LogManager)
[2022-05-07 19:19:00,531] INFO [ExpirationReaper-4-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,531] INFO [ExpirationReaper-4-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,532] INFO [ExpirationReaper-4-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,556] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-07 19:19:00,559] INFO [ExpirationReaper-4-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,559] INFO [ExpirationReaper-4-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,559] INFO [ExpirationReaper-4-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,561] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:19:00,561] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:19:00,561] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:19:00,562] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:00,752] INFO [ExpirationReaper-4-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,752] INFO [ExpirationReaper-4-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:00,758] INFO [ReplicaManager broker=4] Shut down completely (kafka.server.ReplicaManager)
[2022-05-07 19:19:00,759] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:00,760] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:00,760] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:00,762] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-07 19:19:00,762] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:00,763] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:00,763] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:00,764] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-07 19:19:00,764] INFO Shutting down. (kafka.log.LogManager)
[2022-05-07 19:19:00,789] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-07 19:19:00,793] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:19:00,793] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:19:00,793] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:19:00,794] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:01,267] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:01,268] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:01,268] WARN An exception was thrown while closing send thread for session 0x100012253ab0004. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-07 19:19:01,372] INFO Session: 0x100012253ab0004 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:01,372] INFO EventThread shut down for session: 0x100012253ab0004 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:01,374] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:01,374] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:01,553] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:01,554] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:01,554] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:01,581] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:01,581] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:01,581] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:01,980] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:01,981] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:01,982] WARN An exception was thrown while closing send thread for session 0x100012253ab0008. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-07 19:19:02,084] INFO Session: 0x100012253ab0008 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:02,084] INFO EventThread shut down for session: 0x100012253ab0008 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:02,086] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:02,087] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:02,127] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:02,127] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:02,127] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:02,133] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:02,133] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:02,133] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:02,558] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:02,558] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:02,558] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:02,561] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:02,561] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:02,562] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutting down socket server (kafka.network.SocketServer)
[2022-05-07 19:19:02,585] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutdown completed (kafka.network.SocketServer)
[2022-05-07 19:19:02,586] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:19:02,586] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:19:02,586] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:19:02,587] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-07 19:19:02,587] INFO App info kafka.server for 4 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:19:02,588] INFO [KafkaServer id=4] shut down completed (kafka.server.KafkaServer)
[2022-05-07 19:19:03,121] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:03,121] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:03,121] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:03,122] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:03,122] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:03,123] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-07 19:19:03,137] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-07 19:19:03,138] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:19:03,138] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:19:03,138] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:19:03,139] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-07 19:19:03,140] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:19:03,140] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-07 19:19:04,344] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-07 19:19:04,351] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-07 19:19:04,351] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-07 19:19:04,351] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-07 19:19:04,351] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-07 19:19:04,353] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-07 19:19:04,353] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-07 19:19:04,353] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-07 19:19:04,353] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-07 19:19:04,356] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-07 19:19:04,368] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-07 19:19:04,368] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-07 19:19:04,368] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-07 19:19:04,368] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-07 19:19:04,368] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-07 19:19:04,369] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-07 19:19:04,384] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@6156496 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-07 19:19:04,388] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-07 19:19:04,397] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,397] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,397] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,397] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,397] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,397] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,397] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,397] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,397] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,397] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,398] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,398] INFO Server environment:host.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,398] INFO Server environment:java.version=11.0.15 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,398] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,398] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,398] INFO Server environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,399] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,399] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,399] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,399] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,399] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,399] INFO Server environment:os.version=5.13.0-40-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,399] INFO Server environment:user.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,399] INFO Server environment:user.home=/home/joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,399] INFO Server environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,399] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,399] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,399] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,399] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,399] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,399] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,400] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,400] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,400] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,400] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,401] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-07 19:19:04,402] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,402] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,403] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-07 19:19:04,403] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-07 19:19:04,404] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-07 19:19:04,404] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-07 19:19:04,404] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-07 19:19:04,404] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-07 19:19:04,404] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-07 19:19:04,404] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-07 19:19:04,408] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,408] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,408] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,417] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-07 19:19:04,418] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-07 19:19:04,419] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-07 19:19:04,424] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-07 19:19:04,437] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-07 19:19:04,438] INFO Using org.apache.zookeeper.server.watch.WatchManager as watch manager (org.apache.zookeeper.server.watch.WatchManagerFactory)
[2022-05-07 19:19:04,439] INFO zookeeper.snapshotSizeFactor = 0.33 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-07 19:19:04,439] INFO zookeeper.commitLogCount=500 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-07 19:19:04,443] INFO zookeeper.snapshot.compression.method = CHECKED (org.apache.zookeeper.server.persistence.SnapStream)
[2022-05-07 19:19:04,443] INFO Reading snapshot /tmp/zookeeper/version-2/snapshot.116 (org.apache.zookeeper.server.persistence.FileSnap)
[2022-05-07 19:19:04,457] INFO The digest in the snapshot has digest version of 2, , with zxid as 0x116, and digest value as 290042639590 (org.apache.zookeeper.server.DataTree)
[2022-05-07 19:19:04,476] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-07 19:19:04,501] INFO 338 txns loaded in 33 ms (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-07 19:19:04,501] INFO Snapshot loaded in 62 ms, highest zxid is 0x268, digest is 279620302243 (org.apache.zookeeper.server.ZKDatabase)
[2022-05-07 19:19:04,501] INFO Snapshotting: 0x268 to /tmp/zookeeper/version-2/snapshot.268 (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-07 19:19:04,504] INFO Snapshot taken in 3 ms (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:04,513] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2022-05-07 19:19:04,513] INFO PrepRequestProcessor (sid:0) started, reconfigEnabled=false (org.apache.zookeeper.server.PrepRequestProcessor)
[2022-05-07 19:19:04,529] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
[2022-05-07 19:19:09,355] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-07 19:19:09,578] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-07 19:19:09,646] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-07 19:19:09,650] INFO starting (kafka.server.KafkaServer)
[2022-05-07 19:19:09,651] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-07 19:19:09,663] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:09,668] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:09,668] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:09,668] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:09,668] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:09,668] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:09,668] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:09,668] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:09,668] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:09,668] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:09,668] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:09,669] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:09,669] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:09,669] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:09,669] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:09,669] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:09,669] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:09,669] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:09,669] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:09,670] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:09,675] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-07 19:19:09,690] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:09,694] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:09,699] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:09,700] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:09,704] INFO Socket connection established, initiating session, client: /127.0.0.1:38908, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:09,715] INFO Creating new log file: log.269 (org.apache.zookeeper.server.persistence.FileTxnLog)
[2022-05-07 19:19:09,728] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000136dc780000, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:09,734] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:09,840] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:19:09,969] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-07 19:19:09,978] INFO Cluster ID = n1BTqOAPRy-Kw9b_q_-DTA (kafka.server.KafkaServer)
[2022-05-07 19:19:10,024] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:19:10,033] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:19:10,081] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:10,082] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:10,084] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:10,086] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:10,124] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:19:10,128] INFO Skipping recovery for all logs in /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2022-05-07 19:19:10,199] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:10,225] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-46, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 83ms (1/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:19:10,231] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:10,234] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-10, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (2/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:19:10,240] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:10,244] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-28, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (3/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:19:10,246] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:10,250] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-3.1a22bce5666b4806b46db98b307a9aec-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (4/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:19:10,254] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:10,257] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-1.b30ab7e5444e48a089d1b692fef17441-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (5/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:19:10,270] INFO Deleted producer state snapshot /tmp/kafka-logs/__consumer_offsets-22/00000000000001423895.snapshot (kafka.log.SnapshotFile)
[2022-05-07 19:19:10,272] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 1473198 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:10,273] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 1473198 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:10,274] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs/__consumer_offsets-22/00000000000001473198.snapshot,1473198)' (kafka.log.ProducerStateManager)
[2022-05-07 19:19:10,280] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 1473198 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:10,283] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-22, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1473198) with 2 segments in 25ms (6/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:19:10,287] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:10,290] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-16, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:19:10,295] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:10,298] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-4.a1144cbaeaaf49f984864a0c7a63cfe4-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (8/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:19:10,302] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:10,305] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-40, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (9/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:19:10,309] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:10,312] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-34, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:19:10,318] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:10,320] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-4, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (11/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:19:10,324] INFO Loaded 11 logs in 200ms. (kafka.log.LogManager)
[2022-05-07 19:19:10,325] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-07 19:19:10,327] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-07 19:19:10,555] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:10,663] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-07 19:19:10,667] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-07 19:19:10,689] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-07 19:19:10,695] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:10,710] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:10,711] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:10,713] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:10,714] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:10,724] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:19:10,783] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-07 19:19:10,810] ERROR Error while creating ephemeral at /brokers/ids/0, node already exists and owner '72058840982159366' does not match current session '72058929176641536' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2022-05-07 19:19:10,814] ERROR [KafkaServer id=0] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:324)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-05-07 19:19:10,817] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-05-07 19:19:10,818] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-07 19:19:10,821] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-07 19:19:10,828] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-05-07 19:19:10,829] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:19:10,830] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:19:10,830] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:19:10,830] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:19:10,831] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:19:10,831] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:19:10,831] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:19:10,831] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:10,912] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:10,912] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:10,913] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:11,111] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:11,111] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:11,112] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:11,113] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:11,113] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:11,114] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:11,315] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:11,315] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:11,322] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-05-07 19:19:11,322] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:11,323] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:11,323] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:11,329] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-07 19:19:11,329] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:11,330] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:11,330] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:11,331] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-07 19:19:11,332] INFO Shutting down. (kafka.log.LogManager)
[2022-05-07 19:19:11,363] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-07 19:19:11,364] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:19:11,365] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:19:11,365] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:19:11,366] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:11,472] INFO Session: 0x1000136dc780000 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:11,472] INFO EventThread shut down for session: 0x1000136dc780000 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:11,474] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:11,474] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:12,083] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:12,083] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:12,084] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:12,084] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:12,084] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:12,085] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:12,085] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:12,085] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:12,085] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:12,088] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:12,088] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:12,089] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-05-07 19:19:12,107] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-05-07 19:19:12,108] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:19:12,109] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:19:12,109] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:19:12,112] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-07 19:19:12,117] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:19:12,117] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-05-07 19:19:12,117] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-05-07 19:19:12,118] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-05-07 19:19:14,386] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-07 19:19:14,640] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-07 19:19:14,721] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-07 19:19:14,724] INFO starting (kafka.server.KafkaServer)
[2022-05-07 19:19:14,724] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-07 19:19:14,738] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:14,742] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:14,743] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:14,743] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:14,743] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:14,743] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:14,743] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:14,743] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:14,743] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:14,743] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:14,743] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:14,743] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:14,743] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:14,743] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:14,743] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:14,743] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:14,743] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:14,743] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:14,743] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:14,745] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:14,749] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-07 19:19:14,753] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:14,768] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:14,772] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:14,773] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:14,777] INFO Socket connection established, initiating session, client: /127.0.0.1:38910, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:14,784] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000136dc780001, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:14,788] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:14,874] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:19:14,997] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-07 19:19:15,002] INFO Cluster ID = n1BTqOAPRy-Kw9b_q_-DTA (kafka.server.KafkaServer)
[2022-05-07 19:19:15,047] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:19:15,056] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:19:15,100] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:15,101] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:15,104] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:15,105] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:15,143] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:19:15,147] INFO Skipping recovery for all logs in /tmp/kafka-logs-1 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-07 19:19:15,212] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:15,232] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-24, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 72ms (1/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:19:15,238] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:15,242] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-12, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (2/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:19:15,247] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:15,251] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-30, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (3/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:19:15,256] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:15,260] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-0.ddcd7ae57580402da215f4a730a59239-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (4/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:19:15,265] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:15,268] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-36, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:19:15,271] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:15,274] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-1.9f152cf79eac4fa4b00b8d1846a84a57-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (6/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:19:15,279] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:15,282] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-42, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:19:15,286] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:15,289] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-0, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:19:15,295] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:15,298] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-18, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (9/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:19:15,303] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:15,305] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-6, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:19:15,310] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:15,312] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-4.13ea7229ece0495fb77230d235172068-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:19:15,317] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:15,319] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-48, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (12/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:19:15,323] INFO Loaded 12 logs in 179ms. (kafka.log.LogManager)
[2022-05-07 19:19:15,324] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-07 19:19:15,325] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-07 19:19:15,551] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:15,666] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-07 19:19:15,670] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-07 19:19:15,695] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-07 19:19:15,700] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:15,716] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:15,717] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:15,718] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:15,720] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:15,730] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:19:15,788] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-07 19:19:15,807] ERROR Error while creating ephemeral at /brokers/ids/1, node already exists and owner '72058840982159367' does not match current session '72058929176641537' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2022-05-07 19:19:15,812] ERROR [KafkaServer id=1] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:324)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-05-07 19:19:15,815] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-07 19:19:15,816] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-07 19:19:15,819] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-07 19:19:15,826] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-07 19:19:15,828] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:19:15,828] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:19:15,828] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:19:15,829] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:19:15,832] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:19:15,833] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:19:15,834] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:19:15,834] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:15,917] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:15,918] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:15,919] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:16,116] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:16,117] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:16,117] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:16,119] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:16,119] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:16,120] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:16,120] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:16,120] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:16,129] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-07 19:19:16,130] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:16,131] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:16,131] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:16,136] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-07 19:19:16,136] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:16,137] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:16,137] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:16,138] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-07 19:19:16,139] INFO Shutting down. (kafka.log.LogManager)
[2022-05-07 19:19:16,172] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-07 19:19:16,173] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:19:16,173] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:19:16,173] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:19:16,174] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:16,279] INFO Session: 0x1000136dc780001 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:16,279] INFO EventThread shut down for session: 0x1000136dc780001 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:16,282] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:16,284] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:17,102] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:17,102] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:17,103] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:17,103] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:17,103] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:17,103] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:17,104] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:17,104] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:17,104] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:17,106] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:17,106] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:17,108] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-07 19:19:17,134] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-07 19:19:17,134] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:19:17,135] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:19:17,135] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:19:17,136] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-07 19:19:17,140] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:19:17,140] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-07 19:19:17,140] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-05-07 19:19:17,141] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-07 19:19:19,375] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-07 19:19:19,601] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-07 19:19:19,672] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-07 19:19:19,675] INFO starting (kafka.server.KafkaServer)
[2022-05-07 19:19:19,675] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-07 19:19:19,689] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:19,693] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:19,693] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:19,694] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:19,694] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:19,694] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:19,694] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:19,694] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:19,694] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:19,695] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:19,695] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:19,695] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:19,695] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:19,695] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:19,695] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:19,695] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:19,695] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:19,695] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:19,695] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:19,697] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:19,701] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-07 19:19:19,705] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:19,717] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:19,725] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:19,727] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:19,731] INFO Socket connection established, initiating session, client: /127.0.0.1:38912, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:19,739] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000136dc780002, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:19,744] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:19,828] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:19:19,955] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-07 19:19:19,963] INFO Cluster ID = n1BTqOAPRy-Kw9b_q_-DTA (kafka.server.KafkaServer)
[2022-05-07 19:19:20,003] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:19:20,011] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:19:20,056] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:20,057] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:20,059] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:20,061] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:20,098] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:19:20,102] INFO Skipping recovery for all logs in /tmp/kafka-logs-2 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-07 19:19:20,170] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:20,192] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-14, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 77ms (1/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:19:20,197] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:20,203] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-38, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (2/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:19:20,205] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:20,208] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-1.4228fd7d738844118ffd72be3a2ea77a-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (3/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:19:20,213] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:20,217] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-8, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (4/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:19:20,223] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:20,226] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-2, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (5/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:19:20,232] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:20,236] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-26, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (6/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:19:20,241] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:20,244] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-20, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (7/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:19:20,249] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:20,252] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-32, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (8/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:19:20,257] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:20,260] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-5.1af221875c3342ee8145e4b0b365a54c-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (9/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:19:20,264] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:20,268] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-44, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:19:20,269] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:20,271] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-2.fe8c510a72bc4b48b0590d08c511f65e-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (11/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:19:20,275] INFO Loaded 11 logs in 177ms. (kafka.log.LogManager)
[2022-05-07 19:19:20,276] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-07 19:19:20,277] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-07 19:19:20,491] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:20,586] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-07 19:19:20,589] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-07 19:19:20,613] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-07 19:19:20,619] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:20,633] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:20,634] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:20,636] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:20,637] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:20,648] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:19:20,706] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-07 19:19:20,725] ERROR Error while creating ephemeral at /brokers/ids/2, node already exists and owner '72058840982159368' does not match current session '72058929176641538' (kafka.zk.KafkaZkClient$CheckedEphemeral)
[2022-05-07 19:19:20,729] ERROR [KafkaServer id=2] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:126)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.getAfterNodeExists(KafkaZkClient.scala:1904)
	at kafka.zk.KafkaZkClient$CheckedEphemeral.create(KafkaZkClient.scala:1842)
	at kafka.zk.KafkaZkClient.checkedEphemeralCreate(KafkaZkClient.scala:1809)
	at kafka.zk.KafkaZkClient.registerBroker(KafkaZkClient.scala:96)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:324)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-05-07 19:19:20,731] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-07 19:19:20,732] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-07 19:19:20,736] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-07 19:19:20,742] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-07 19:19:20,743] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:19:20,744] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:19:20,744] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:19:20,744] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:19:20,745] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:19:20,746] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:19:20,746] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:19:20,746] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:20,835] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:20,835] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:20,836] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:21,034] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:21,034] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:21,035] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:21,036] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:21,037] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:21,037] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:21,238] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:21,238] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:21,248] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-07 19:19:21,249] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:21,250] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:21,250] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:21,254] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-07 19:19:21,255] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:21,255] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:21,255] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:21,256] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-07 19:19:21,257] INFO Shutting down. (kafka.log.LogManager)
[2022-05-07 19:19:21,289] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-07 19:19:21,289] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:19:21,290] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:19:21,290] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:19:21,291] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:21,396] INFO Session: 0x1000136dc780002 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:21,396] INFO EventThread shut down for session: 0x1000136dc780002 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:21,398] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:21,399] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:22,057] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:22,057] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:22,058] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:22,059] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:22,059] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:22,060] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:22,906] INFO Expiring session 0x100012253ab0004, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:22,907] INFO Expiring session 0x100012253ab0006, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:22,907] INFO Expiring session 0x100012253ab0007, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:22,908] INFO Expiring session 0x100012253ab0008, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:22,908] INFO Expiring session 0x100012253ab0003, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:22,908] INFO Expiring session 0x100012253ab0005, timeout of 18000ms exceeded (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:19:23,060] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:23,060] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:23,061] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:23,062] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:23,062] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:23,063] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-07 19:19:23,083] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-07 19:19:23,084] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:19:23,085] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:19:23,085] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:19:23,086] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-07 19:19:23,090] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:19:23,091] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-07 19:19:23,091] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-05-07 19:19:23,092] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-07 19:19:24,389] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-07 19:19:24,620] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-07 19:19:24,691] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-07 19:19:24,694] INFO starting (kafka.server.KafkaServer)
[2022-05-07 19:19:24,695] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-07 19:19:24,707] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:24,711] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:24,711] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:24,711] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:24,711] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:24,712] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:24,712] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:24,712] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:24,712] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:24,713] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:24,713] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:24,713] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:24,713] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:24,713] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:24,713] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:24,713] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:24,713] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:24,713] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:24,713] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:24,715] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:24,719] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-07 19:19:24,737] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:24,740] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:24,746] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:24,747] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:24,750] INFO Socket connection established, initiating session, client: /127.0.0.1:38914, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:24,759] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000136dc780003, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:24,764] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:24,847] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:19:24,960] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-07 19:19:24,966] INFO Cluster ID = n1BTqOAPRy-Kw9b_q_-DTA (kafka.server.KafkaServer)
[2022-05-07 19:19:25,018] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:19:25,028] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:19:25,081] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:25,083] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:25,085] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:25,087] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:25,123] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-07 19:19:25,127] INFO Skipping recovery for all logs in /tmp/kafka-logs-3 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-07 19:19:25,191] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:25,212] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-21, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 72ms (1/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-07 19:19:25,217] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:25,222] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-0.961cc0753d574f659a0d5ac6b88295c1-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (2/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-07 19:19:25,227] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:25,232] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-39, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (3/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-07 19:19:25,237] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:25,241] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-15, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (4/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-07 19:19:25,243] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:25,245] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-2.ec2e5fecfd33499fa8143b5725184533-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (5/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-07 19:19:25,248] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:25,252] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-3.f494773bf42744db8251a40ab12d691d-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (6/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-07 19:19:25,257] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:25,261] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-45, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (7/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-07 19:19:25,265] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:25,269] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-33, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-07 19:19:25,274] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:25,277] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-27, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (9/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-07 19:19:25,281] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:25,284] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-3, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-07 19:19:25,289] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:25,292] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-9, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (11/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-07 19:19:25,295] INFO Loaded 11 logs in 171ms. (kafka.log.LogManager)
[2022-05-07 19:19:25,296] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-07 19:19:25,297] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-07 19:19:25,512] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:25,628] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-07 19:19:25,631] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-05-07 19:19:25,654] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-07 19:19:25,659] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:25,674] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:25,675] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:25,676] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:25,678] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:25,689] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:19:25,737] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-07 19:19:25,757] INFO Stat of the created znode at /brokers/ids/3 is: 689,689,1651947565747,1651947565747,1,0,0,72058929176641539,192,0,689
 (kafka.zk.KafkaZkClient)
[2022-05-07 19:19:25,758] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://joao:9095, czxid (broker epoch): 689 (kafka.zk.KafkaZkClient)
[2022-05-07 19:19:25,811] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:25,816] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:25,818] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:25,834] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:25,852] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:25,876] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:19:25,890] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:19:25,890] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:19:25,921] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:25,939] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:19:25,965] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-07 19:19:25,974] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-07 19:19:25,974] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-07 19:19:25,980] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:19:25,981] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:19:25,981] INFO Kafka startTimeMs: 1651947565974 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:19:25,984] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-05-07 19:19:26,063] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:26,078] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-3, __consumer_offsets-15, __consumer_offsets-39, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:19:26,099] INFO [Partition __consumer_offsets-3 broker=3] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:26,109] INFO [Partition __consumer_offsets-21 broker=3] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:26,112] INFO [Partition __consumer_offsets-39 broker=3] Log loaded for partition __consumer_offsets-39 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:26,115] INFO [Partition __consumer_offsets-9 broker=3] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:26,119] INFO [Partition __consumer_offsets-27 broker=3] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:26,122] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:26,123] INFO [Partition __consumer_offsets-45 broker=3] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:26,126] INFO [Partition __consumer_offsets-15 broker=3] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:26,129] INFO [Partition __consumer_offsets-33 broker=3] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:26,137] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 3 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:26,139] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:26,142] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 21 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:26,142] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:26,142] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 39 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:26,142] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:26,142] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 9 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:26,142] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:26,142] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 27 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:26,142] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:26,142] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 45 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:26,142] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:26,142] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 15 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:26,142] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:26,142] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 33 in epoch 0 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:26,143] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:26,149] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-3 in 9 milliseconds for epoch 0, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:26,150] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-21 in 8 milliseconds for epoch 0, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:26,151] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-39 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:26,152] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-9 in 9 milliseconds for epoch 0, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:26,152] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-27 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:26,152] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-45 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:26,153] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-15 in 11 milliseconds for epoch 0, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:26,153] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-33 in 10 milliseconds for epoch 0, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:29,418] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-07 19:19:29,657] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-07 19:19:29,734] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-07 19:19:29,737] INFO starting (kafka.server.KafkaServer)
[2022-05-07 19:19:29,738] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-07 19:19:29,752] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:29,756] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:29,756] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:29,756] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:29,756] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:29,756] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:29,756] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:29,757] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:29,757] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:29,757] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:29,757] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:29,757] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:29,757] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:29,757] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:29,757] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:29,757] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:29,757] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:29,758] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:29,758] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:29,760] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:29,764] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-07 19:19:29,768] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:29,780] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:29,786] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:29,787] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:29,791] INFO Socket connection established, initiating session, client: /127.0.0.1:38916, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:29,799] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000136dc780004, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:29,804] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:29,887] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:19:30,008] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-07 19:19:30,016] INFO Cluster ID = n1BTqOAPRy-Kw9b_q_-DTA (kafka.server.KafkaServer)
[2022-05-07 19:19:30,056] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:19:30,064] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:19:30,110] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:30,111] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:30,114] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:30,115] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:30,150] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-07 19:19:30,153] INFO Skipping recovery for all logs in /tmp/kafka-logs-4 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-07 19:19:30,222] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:30,245] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-49, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 80ms (1/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-07 19:19:30,252] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:30,257] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-19, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (2/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-07 19:19:30,262] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:30,266] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-7, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (3/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-07 19:19:30,270] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:30,275] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-0.f389113946624a849813f8e297a79f23-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-07 19:19:30,279] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:30,282] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-13, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-07 19:19:30,286] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:30,289] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-37, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (6/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-07 19:19:30,293] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:30,296] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-43, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-07 19:19:30,300] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:30,305] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-1, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (8/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-07 19:19:30,308] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:30,311] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-5.c26b72176694499999ba5c69b59f45eb-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (9/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-07 19:19:30,315] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:30,319] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-3.ffad24e65c8742b0929f6abb1d8ec9bf-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-07 19:19:30,324] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:30,328] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-31, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (11/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-07 19:19:30,333] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:30,338] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-25, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (12/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-07 19:19:30,341] INFO Loaded 12 logs in 191ms. (kafka.log.LogManager)
[2022-05-07 19:19:30,341] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-07 19:19:30,342] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-07 19:19:30,562] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:30,681] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-07 19:19:30,684] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.Acceptor)
[2022-05-07 19:19:30,709] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-07 19:19:30,714] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:30,730] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:30,731] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:30,732] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:30,733] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:30,743] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:19:30,800] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-07 19:19:30,822] INFO Stat of the created znode at /brokers/ids/4 is: 749,749,1651947570812,1651947570812,1,0,0,72058929176641540,192,0,749
 (kafka.zk.KafkaZkClient)
[2022-05-07 19:19:30,823] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://joao:9096, czxid (broker epoch): 749 (kafka.zk.KafkaZkClient)
[2022-05-07 19:19:30,895] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:30,901] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:30,902] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:30,915] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:30,927] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:30,946] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:19:30,956] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:19:30,956] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:19:30,978] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:30,993] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:19:31,015] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-07 19:19:31,022] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-07 19:19:31,022] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-07 19:19:31,027] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:19:31,027] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:19:31,027] INFO Kafka startTimeMs: 1651947571023 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:19:31,030] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2022-05-07 19:19:31,119] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:31,119] INFO [Partition __consumer_offsets-19 broker=4] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:31,119] INFO [Partition __consumer_offsets-37 broker=4] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:31,120] INFO [Partition __consumer_offsets-7 broker=4] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:31,120] INFO [Partition __consumer_offsets-25 broker=4] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:31,120] INFO [Partition __consumer_offsets-43 broker=4] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:31,120] INFO [Partition __consumer_offsets-13 broker=4] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:31,120] INFO [Partition __consumer_offsets-31 broker=4] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:31,120] INFO [Partition __consumer_offsets-1 broker=4] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:31,120] INFO [Partition __consumer_offsets-49 broker=4] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:31,145] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(__consumer_offsets-7, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:19:31,171] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:31,182] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 19 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:31,183] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:31,185] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 37 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:31,185] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:31,185] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 7 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:31,185] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:31,185] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 25 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:31,185] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:31,185] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 43 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:31,185] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:31,185] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 13 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:31,186] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:31,186] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 31 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:31,186] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:31,186] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 1 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:31,186] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:31,186] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 49 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:31,186] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:31,193] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-19 in 9 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:31,194] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-37 in 9 milliseconds for epoch 4, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:31,194] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-7 in 9 milliseconds for epoch 4, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:31,194] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-25 in 9 milliseconds for epoch 4, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:31,195] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-43 in 10 milliseconds for epoch 4, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:31,195] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-13 in 9 milliseconds for epoch 4, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:31,195] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-31 in 9 milliseconds for epoch 4, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:31,195] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-1 in 9 milliseconds for epoch 4, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:31,195] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-49 in 9 milliseconds for epoch 4, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:34,427] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-07 19:19:34,651] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-07 19:19:34,723] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-07 19:19:34,726] INFO starting (kafka.server.KafkaServer)
[2022-05-07 19:19:34,727] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-07 19:19:34,740] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:34,745] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:34,746] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:34,746] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:34,746] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:34,746] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:34,746] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:34,746] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:34,746] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:34,746] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:34,746] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:34,746] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:34,746] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:34,746] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:34,746] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:34,746] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:34,747] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:34,747] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:34,747] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:34,757] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:19:34,761] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-07 19:19:34,766] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:34,770] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:34,774] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:34,775] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:34,779] INFO Socket connection established, initiating session, client: /127.0.0.1:38918, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:34,786] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000136dc780005, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:19:34,790] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:19:34,872] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:19:34,986] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-07 19:19:34,993] INFO Cluster ID = n1BTqOAPRy-Kw9b_q_-DTA (kafka.server.KafkaServer)
[2022-05-07 19:19:35,038] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:19:35,045] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:19:35,101] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:35,102] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:35,104] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:35,105] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:19:35,141] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-07 19:19:35,144] INFO Skipping recovery for all logs in /tmp/kafka-logs-5 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-07 19:19:35,213] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:35,234] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-17, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 77ms (1/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-07 19:19:35,238] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:35,242] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-35, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (2/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-07 19:19:35,247] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:35,251] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-41, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (3/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-07 19:19:35,255] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:35,258] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-2.b148ed20eda84772a5502008dcd9e744-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (4/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-07 19:19:35,260] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:35,263] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-5.c8c70384e8984b019d63f1ff51ec7f87-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (5/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-07 19:19:35,268] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:35,272] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-29, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-07 19:19:35,277] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:35,282] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-11, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (7/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-07 19:19:35,287] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:35,292] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-23, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (8/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-07 19:19:35,297] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:35,300] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-47, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (9/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-07 19:19:35,304] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:35,307] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-4.8646eb6134254afd9c7f4164d2e69639-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-07 19:19:35,312] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:19:35,315] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-5, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-07 19:19:35,317] INFO Loaded 11 logs in 177ms. (kafka.log.LogManager)
[2022-05-07 19:19:35,319] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-07 19:19:35,320] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-07 19:19:35,552] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:35,680] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-07 19:19:35,684] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.Acceptor)
[2022-05-07 19:19:35,711] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-07 19:19:35,718] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:35,734] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:35,735] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:35,737] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:35,738] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:35,750] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:19:35,812] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-07 19:19:35,832] INFO Stat of the created znode at /brokers/ids/5 is: 774,774,1651947575824,1651947575824,1,0,0,72058929176641541,192,0,774
 (kafka.zk.KafkaZkClient)
[2022-05-07 19:19:35,833] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://joao:9097, czxid (broker epoch): 774 (kafka.zk.KafkaZkClient)
[2022-05-07 19:19:35,903] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:35,908] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:35,910] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:35,926] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:35,938] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:35,959] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:19:35,967] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:19:35,967] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:19:35,992] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:19:36,009] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:19:36,032] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-07 19:19:36,037] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-07 19:19:36,038] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-07 19:19:36,044] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:19:36,045] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:19:36,045] INFO Kafka startTimeMs: 1651947576038 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:19:36,047] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2022-05-07 19:19:36,123] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:36,144] INFO [Partition __consumer_offsets-35 broker=5] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:36,144] INFO [Partition __consumer_offsets-5 broker=5] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:36,145] INFO [Partition __consumer_offsets-23 broker=5] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:36,145] INFO [Partition __consumer_offsets-41 broker=5] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:36,145] INFO [Partition __consumer_offsets-11 broker=5] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:36,145] INFO [Partition __consumer_offsets-29 broker=5] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:36,145] INFO [Partition __consumer_offsets-47 broker=5] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:36,146] INFO [Partition __consumer_offsets-17 broker=5] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:19:36,165] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:19:36,172] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(__consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-5, __consumer_offsets-29, __consumer_offsets-41, __consumer_offsets-23) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:19:36,205] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 35 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:36,207] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:36,209] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 5 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:36,209] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:36,209] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 23 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:36,209] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:36,209] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 41 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:36,209] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:36,209] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 11 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:36,209] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:36,209] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 29 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:36,209] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:36,209] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 47 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:36,209] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:36,209] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 17 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:19:36,209] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:36,219] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-35 in 11 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:36,220] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-5 in 11 milliseconds for epoch 4, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:36,220] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-23 in 11 milliseconds for epoch 4, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:36,220] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-41 in 11 milliseconds for epoch 4, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:36,220] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-11 in 11 milliseconds for epoch 4, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:36,221] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-29 in 12 milliseconds for epoch 4, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:36,221] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-47 in 12 milliseconds for epoch 4, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:19:36,221] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-17 in 12 milliseconds for epoch 4, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:02,903] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-07 19:20:02,909] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-07 19:20:02,909] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-07 19:20:02,909] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-07 19:20:02,910] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-07 19:20:02,911] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-07 19:20:02,911] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-07 19:20:02,911] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-07 19:20:02,911] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-07 19:20:02,914] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-07 19:20:02,926] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-07 19:20:02,927] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-07 19:20:02,927] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-07 19:20:02,927] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-07 19:20:02,927] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-07 19:20:02,927] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-07 19:20:02,937] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@6156496 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-07 19:20:02,940] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-07 19:20:02,949] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,949] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,949] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,949] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,949] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,949] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,949] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,949] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,950] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,950] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,951] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,951] INFO Server environment:host.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,951] INFO Server environment:java.version=11.0.15 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,951] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,951] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,951] INFO Server environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,951] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,951] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,951] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,951] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,951] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,951] INFO Server environment:os.version=5.13.0-40-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,952] INFO Server environment:user.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,952] INFO Server environment:user.home=/home/joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,952] INFO Server environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,952] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,952] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,952] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,952] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,952] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,952] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,952] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,952] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,952] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,952] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,953] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-07 19:20:02,954] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,955] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,955] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-07 19:20:02,955] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-07 19:20:02,956] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-07 19:20:02,956] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-07 19:20:02,956] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-07 19:20:02,956] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-07 19:20:02,956] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-07 19:20:02,956] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-07 19:20:02,959] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,959] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,959] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-07 19:20:02,964] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-07 19:20:02,965] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-07 19:20:02,966] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-07 19:20:02,970] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-07 19:20:02,971] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:459)
	at java.base/sun.nio.ch.Net.bind(Net.java:448)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:676)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:158)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:112)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:67)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:140)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:90)
[2022-05-07 19:20:02,973] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-07 19:20:02,975] ERROR Exiting JVM with code 1 (org.apache.zookeeper.util.ServiceUtils)
[2022-05-07 19:20:07,939] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-07 19:20:08,184] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-07 19:20:08,264] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-07 19:20:08,267] INFO starting (kafka.server.KafkaServer)
[2022-05-07 19:20:08,267] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-07 19:20:08,282] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:08,286] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:08,286] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:08,286] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:08,286] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:08,287] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:08,287] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:08,287] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:08,287] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:08,287] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:08,287] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:08,288] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:08,288] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:08,288] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:08,288] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:08,288] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:08,288] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:08,288] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:08,288] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:08,290] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:08,294] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-07 19:20:08,299] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:08,312] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:08,317] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:08,318] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:08,322] INFO Socket connection established, initiating session, client: /127.0.0.1:38920, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:08,328] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000136dc780006, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:08,332] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:08,412] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:20:08,532] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-07 19:20:08,536] INFO Cluster ID = n1BTqOAPRy-Kw9b_q_-DTA (kafka.server.KafkaServer)
[2022-05-07 19:20:08,585] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:20:08,593] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:20:08,640] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:08,641] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:08,643] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:08,645] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:08,683] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:20:08,688] INFO Skipping recovery for all logs in /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2022-05-07 19:20:08,749] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:08,773] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-46, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 71ms (1/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:20:08,776] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:08,779] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-10, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (2/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:20:08,782] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:08,785] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-28, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (3/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:20:08,788] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:08,793] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-3.1a22bce5666b4806b46db98b307a9aec-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (4/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:20:08,795] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:08,798] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-1.b30ab7e5444e48a089d1b692fef17441-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (5/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:20:08,816] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Loading producer state till offset 1473198 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:08,816] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 1473198 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:08,818] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs/__consumer_offsets-22/00000000000001473198.snapshot,1473198)' (kafka.log.ProducerStateManager)
[2022-05-07 19:20:08,823] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 1473198 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:08,826] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-22, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=1473198) with 2 segments in 28ms (6/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:20:08,829] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:08,833] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-16, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (7/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:20:08,835] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:08,839] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-4.a1144cbaeaaf49f984864a0c7a63cfe4-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (8/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:20:08,841] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:08,844] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-40, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (9/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:20:08,846] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:08,849] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-34, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (10/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:20:08,851] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:08,854] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-4, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (11/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-07 19:20:08,858] INFO Loaded 11 logs in 175ms. (kafka.log.LogManager)
[2022-05-07 19:20:08,859] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-07 19:20:08,861] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-07 19:20:09,078] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:20:09,175] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-07 19:20:09,178] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-07 19:20:09,203] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-07 19:20:09,208] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:20:09,224] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:09,226] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:09,227] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:09,228] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:09,238] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:20:09,306] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-07 19:20:09,325] INFO Stat of the created znode at /brokers/ids/0 is: 798,798,1651947609318,1651947609318,1,0,0,72058929176641542,192,0,798
 (kafka.zk.KafkaZkClient)
[2022-05-07 19:20:09,326] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://joao:9092, czxid (broker epoch): 798 (kafka.zk.KafkaZkClient)
[2022-05-07 19:20:09,398] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:09,402] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:09,404] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:09,418] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:09,438] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:09,452] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:20:09,456] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:20:09,456] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:20:09,480] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:09,499] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:20:09,518] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-07 19:20:09,524] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-07 19:20:09,524] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-07 19:20:09,529] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:20:09,530] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:20:09,530] INFO Kafka startTimeMs: 1651947609525 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:20:09,532] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-07 19:20:09,613] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:20:09,636] INFO [Partition __consumer_offsets-34 broker=0] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:09,637] INFO [Partition __consumer_offsets-4 broker=0] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:09,637] INFO [Partition __consumer_offsets-22 broker=0] Log loaded for partition __consumer_offsets-22 with initial high watermark 1473198 (kafka.cluster.Partition)
[2022-05-07 19:20:09,638] INFO [Partition __consumer_offsets-40 broker=0] Log loaded for partition __consumer_offsets-40 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:09,638] INFO [Partition __consumer_offsets-10 broker=0] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:09,639] INFO [Partition __consumer_offsets-28 broker=0] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:09,639] INFO [Partition __consumer_offsets-46 broker=0] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:09,640] INFO [Partition __consumer_offsets-16 broker=0] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:09,666] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:09,688] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:20:09,696] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 34 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:09,697] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:09,699] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 4 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:09,700] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:09,700] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 22 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:09,700] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:09,700] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 40 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:09,700] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:09,700] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 10 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:09,700] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:09,700] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 28 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:09,700] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:09,700] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 46 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:09,700] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:09,700] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 16 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:09,700] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:09,707] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-34 in 8 milliseconds for epoch 4, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:09,708] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 8 milliseconds for epoch 4, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:09,727] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-2ca06ebe-0c9d-45ca-8857-23417b571f73, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 37. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,727] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-1f107b5d-25b3-470d-b9d6-7f1f0c568a48, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 37. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,727] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-050b56eb-6c7b-4ef6-a3c4-fc1334262900, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 37. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,727] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-b2da5a93-57b1-44ae-9f91-2fbfbb8f1abd, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 37. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,727] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-3ef8af2a-bc34-4cda-9a2a-1d852b46477c, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 37. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,727] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-8b95076d-e05f-4a78-9931-7f03945c00bf, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 37. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,915] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-8d276c92-1f98-46da-8f3f-e5fdb8a0b74a, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 40. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,915] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-82c81965-0efa-438e-bb37-71065937d3a4, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 40. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,915] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-bd366739-96c7-4096-b942-0957afa776e6, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 40. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,915] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-3a577a96-38bf-45ea-8405-5951d61e1add, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 40. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,915] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-05af5454-78a9-42d5-b375-2aea26768d2f, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 40. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,915] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-262596b2-12b0-42af-bc57-183b675d4698, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 40. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,929] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-dc817e5a-d817-418f-9ce2-0a90a56c0a0c, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 41. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,930] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-e79baa85-3757-44f4-bacc-32aadf56c364, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 41. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,930] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-0056c090-5e25-40fb-a6fa-e0c654fdfa83, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 41. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,930] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-a3190332-d870-4c6e-bfd1-84a43be6a755, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 41. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,930] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-e32c8e04-8317-4c3d-ad8b-400d8bb69e15, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 41. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,930] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-944c6fd1-7e7e-4a37-820c-61c4df157049, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 41. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,957] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-b1d7f953-b5d1-4aba-8b65-c4be8b24a55c, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 44. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,957] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-d962040d-ee99-4068-bb40-eb164097f6d0, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 44. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,957] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-67d0bced-66d1-46e4-af1a-1d8b48f6be63, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 44. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,957] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-0497f098-d284-4fb5-a29b-862ea33577a2, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 44. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,957] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-58a24cb8-5a56-43d1-9a4e-621ed80a5cb4, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 44. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,957] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-830e93c3-e255-40da-a8cb-1454adba23b2, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 44. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,961] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-3abb8725-e5f3-421c-9e95-f6b69dc702ef, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 48. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,961] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-e1ce6bd7-33d7-41a1-81c4-ce742d2582db, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 48. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,961] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-b643a5a1-51a6-41bc-9c3a-ac5fc6bde9ea, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 48. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,961] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-9b2e049a-1fef-4f2c-b696-c3ec5b2da70c, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 48. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,962] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-b9ac6f97-7299-4277-876a-abd8797e1f64, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 48. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,962] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-c417b099-45e1-43be-962e-7313378b0e25, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 48. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,988] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-5da74304-eace-4124-aa89-a4286629f266, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 49. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,988] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-3b52e7bb-847d-4155-9b1d-fd0eda7cf5f9, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 49. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,988] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-597fa83f-50f3-471b-a918-0017bd8b0a9c, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 49. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,988] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-b5ef671d-cdee-42e7-8c1c-795384c9fc58, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 49. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,988] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-f5c32677-1ff9-493a-82af-7f3c2c5c945b, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 49. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:09,988] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-a47fd8a3-6d14-4405-aef3-884b8817adb1, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 49. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,023] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-211c7cc7-dda4-4784-a05b-4834ae36fd3c, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 50. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,024] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-e84231a0-e164-41bb-8230-4d980b599b2d, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 50. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,024] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-725f2177-3597-403e-b898-1c17ef98c796, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 50. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,024] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-cdd66b41-39e1-4c96-ba76-c2c585fe2c77, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 50. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,024] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-c0d26bd2-98a1-4f5d-9d94-1a2a5ba2aedb, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 50. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,024] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-e68b7f45-7a63-4157-8c88-74f0794b2f7c, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 50. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,058] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-5be23956-6494-478d-a345-c2ac2ad3b655, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 53. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,058] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-ebccf6ef-114d-43e7-9276-0e40ddf1b974, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 53. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,058] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-1ed7ca26-cb5b-41c4-b8e4-10c808d1c252, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 53. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,058] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-3522427b-19ed-43ea-8d99-83d507ee3b74, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 53. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,059] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-90d3e2bb-2a92-452a-a10f-7a99ef7d457b, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 53. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,059] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-81f69ac9-fd31-4b1c-8129-c890fdcb33ac, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 53. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,059] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-a781cd4a-1576-4044-a3db-648962a7e55c, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 56. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,059] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-811204c4-a2e4-43a5-aac8-bd65c114f52f, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 56. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,059] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-a72ad21e-a9be-4510-b213-7e54b2d3013a, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 56. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,060] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-ad5c5b33-2353-4657-90f1-07b3adc1bb13, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 56. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,060] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-e5076b6a-3cbe-4f18-ab44-1aeefe30ca8e, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 56. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,060] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-bbc9f577-1483-4120-b030-ae03653576dc, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 56. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,078] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-ffee6473-2fae-4d16-8b34-b1b23b6845c5, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 59. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,078] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-419add31-c3fe-43ed-b8aa-c8af6257f8cc, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 59. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,078] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-927f0c1b-fd17-4740-87f3-beb85dfdfb77, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 59. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,078] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-af4bece8-6c03-4aa1-99a9-8462ac165dd1, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 59. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,078] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-6e48833a-1962-481b-a505-36568c97efc6, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 59. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,078] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-75517ca8-c0ea-43c0-b626-4242e260018a, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 59. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,092] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-d3224cbc-b030-4341-8c00-7bdf74eb154c, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 62. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,092] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-ecd2d17a-c92f-495a-af3c-58c48a660189, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 62. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,092] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-edfd30e1-a454-419f-ba68-09577af230a0, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 62. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,093] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-f752784d-5527-4d87-b59e-88ee1289ffd8, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 62. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,093] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-be2a1521-a61e-4220-a0e9-db904fc3eb04, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 62. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,093] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-fdc4fec0-8101-4610-90f4-a03baa09638b, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 62. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,094] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-cd75689f-5aa3-449a-8244-f90668505389, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 65. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,094] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-c4e33040-b576-4821-bc3c-485130d9465c, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 65. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,094] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-27bfff1e-d1ff-4d1b-89cc-6e80ffdba4c6, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 65. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,094] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-4c72cc31-ac55-468b-96b2-9bb83121df1c, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 65. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,094] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-30d76700-3e60-4999-9ac2-ccef10fd7535, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 65. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,094] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-e0d19938-a13d-4394-840d-cb15e42e890b, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 65. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,113] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-33579734-2b42-4dcd-895b-f075585a21ea, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 68. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,113] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-76fb16e0-069c-4091-af81-c9b7a686c931, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 68. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,113] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-d36b3940-2b06-4b35-b3ee-b00b81726ec3, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 68. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,113] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-ec56251c-74b2-4d09-a897-1e5a6fe22073, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 68. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,113] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-b32f2ddc-6be8-4868-bedf-4cb59c1159be, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 68. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,113] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-73181068-2542-4989-ac73-bc49c3f2b061, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 68. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,114] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-00862058-ca79-4520-967e-ea880b743e49, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 69. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,114] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-26b5a065-9d6c-44b5-9da5-1fbc3f02bb79, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 69. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,114] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-fa56f721-92cf-4dde-ae19-f22a722935b7, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 69. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,114] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-3a895d71-5dbd-4330-b500-1db69a1e89c2, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 69. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,114] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-7fdf43fe-5d16-436e-b8e9-0b63824b6fba, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 69. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,114] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-ea1df30f-a55f-48f2-88b8-3bcaea6f58e3, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 69. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,116] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-84e4a4c8-8743-49a2-883c-a231d9c624ec, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 72. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,116] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-e9d9bbb6-cece-41ec-a447-f041cf56c958, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 72. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,116] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-9e8e4638-afc2-4972-b1f0-3d315576715a, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 72. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,116] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-a07a54ef-5a1b-4d7a-a145-e6e4982d0a2d, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 72. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,116] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-8eaf555e-7185-4efa-82dd-e02fb41ecedb, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 72. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,116] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-f86ee926-961c-4789-9e53-410816d5ecdf, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 72. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,126] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-ca572b15-3ee1-4179-a20b-bbe39e398afe, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 74. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,127] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-5b64c01f-a93a-4dc6-b2a1-d93cb8574159, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 75. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,128] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-d0ebdff4-5a14-4a63-ae07-bd578407ea74, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 78. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,128] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-75af3381-a98c-4aa5-b5f1-d5c0c71dd570, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 78. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,128] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-235d01d0-a31d-458b-bee2-7618586baed0, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 78. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,128] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-36ab9068-80a0-4734-a5cd-dfdcb4a4612a, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 78. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,128] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-ff886e67-fa91-4178-abc9-cb5135478db8, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 78. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,128] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-f97b5e72-099a-4088-91ef-281f0e1fcca0, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 78. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,136] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-4a81dc54-0228-4b66-8a4c-223f51d025ee, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 81. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,136] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-f6b4acde-5d74-4f2d-8683-14c415c45c38, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 81. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,136] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-a74ef117-fadc-4989-a3be-dfa93446fbb2, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 81. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,136] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-6fa14f9d-87f3-458c-ab00-fd339ebcee6a, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 81. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,136] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-f57b23d6-171b-45a8-9bad-3aa3d39eb562, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 81. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,136] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-5a775f7f-0e92-4b74-a66c-e06c99013996, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 81. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,150] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-b54a91da-2791-42e7-96a0-eb0f5a8193e8, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 85. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,150] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-47f06c71-c824-499c-9b83-922de4f38038, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 85. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,150] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-073eb357-3025-4a98-93c3-87bbf959b19e, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 85. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,150] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-0ea1be36-213f-4845-af05-c6fcca126714, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 85. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,150] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-8edcb724-a78e-4c1c-b6a4-5a9bb2488eef, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 85. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,150] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-3842587a-92b2-41b0-84b3-addc7882c744, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 85. (kafka.coordinator.group.GroupMetadata$)
[2022-05-07 19:20:10,159] INFO [GroupCoordinator 0]: Loading group metadata for consumer with generation 85 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:10,165] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-22 in 465 milliseconds for epoch 4, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:10,165] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-40 in 465 milliseconds for epoch 4, of which 465 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:10,166] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-10 in 466 milliseconds for epoch 4, of which 465 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:10,166] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-28 in 466 milliseconds for epoch 4, of which 466 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:10,166] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-46 in 466 milliseconds for epoch 4, of which 466 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:10,166] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-16 in 466 milliseconds for epoch 4, of which 466 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:13,071] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-07 19:20:13,368] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-07 19:20:13,452] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-07 19:20:13,456] INFO starting (kafka.server.KafkaServer)
[2022-05-07 19:20:13,456] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-07 19:20:13,480] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:13,486] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:13,486] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:13,486] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:13,486] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:13,486] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:13,487] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:13,487] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:13,487] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:13,487] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:13,487] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:13,487] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:13,487] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:13,487] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:13,487] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:13,487] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:13,487] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:13,487] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:13,487] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:13,489] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:13,496] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-07 19:20:13,503] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:13,520] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:13,526] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:13,526] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:13,530] INFO Socket connection established, initiating session, client: /127.0.0.1:38922, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:13,536] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000136dc780007, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:13,540] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:13,627] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:20:13,784] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-07 19:20:13,790] INFO Cluster ID = n1BTqOAPRy-Kw9b_q_-DTA (kafka.server.KafkaServer)
[2022-05-07 19:20:13,844] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:20:13,854] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:20:13,913] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:13,915] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:13,916] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:13,918] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:13,955] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:20:13,959] INFO Skipping recovery for all logs in /tmp/kafka-logs-1 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-07 19:20:14,024] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:14,048] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-24, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 71ms (1/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:20:14,050] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:14,053] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-12, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (2/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:20:14,055] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:14,058] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-30, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (3/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:20:14,061] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:14,064] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-0.ddcd7ae57580402da215f4a730a59239-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (4/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:20:14,066] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:14,068] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-36, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (5/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:20:14,070] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:14,073] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-1.9f152cf79eac4fa4b00b8d1846a84a57-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (6/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:20:14,076] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:14,079] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-42, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (7/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:20:14,082] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:14,086] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-0, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:20:14,088] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:14,090] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-18, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (9/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:20:14,093] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:14,095] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-6, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (10/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:20:14,097] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:14,098] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-4.13ea7229ece0495fb77230d235172068-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (11/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:20:14,101] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:14,103] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-48, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (12/12 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-07 19:20:14,108] INFO Loaded 12 logs in 152ms. (kafka.log.LogManager)
[2022-05-07 19:20:14,109] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-07 19:20:14,110] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-07 19:20:14,367] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:20:14,468] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-07 19:20:14,471] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-07 19:20:14,499] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-07 19:20:14,504] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:20:14,521] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:14,522] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:14,524] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:14,526] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:14,539] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:20:14,596] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-07 19:20:14,616] INFO Stat of the created znode at /brokers/ids/1 is: 822,822,1651947614607,1651947614607,1,0,0,72058929176641543,192,0,822
 (kafka.zk.KafkaZkClient)
[2022-05-07 19:20:14,617] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://joao:9093, czxid (broker epoch): 822 (kafka.zk.KafkaZkClient)
[2022-05-07 19:20:14,681] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:14,687] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:14,688] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:14,704] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:14,716] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:14,730] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:20:14,735] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:20:14,735] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:20:14,768] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:14,784] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:20:14,807] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-07 19:20:14,814] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-07 19:20:14,814] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-07 19:20:14,818] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:20:14,818] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:20:14,818] INFO Kafka startTimeMs: 1651947614814 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:20:14,821] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-07 19:20:14,878] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:20:14,907] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:20:14,926] INFO [Partition __consumer_offsets-18 broker=1] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:14,926] INFO [Partition __consumer_offsets-36 broker=1] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:14,927] INFO [Partition __consumer_offsets-6 broker=1] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:14,927] INFO [Partition __consumer_offsets-24 broker=1] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:14,927] INFO [Partition __consumer_offsets-42 broker=1] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:14,927] INFO [Partition __consumer_offsets-12 broker=1] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:14,928] INFO [Partition __consumer_offsets-30 broker=1] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:14,928] INFO [Partition __consumer_offsets-0 broker=1] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:14,928] INFO [Partition __consumer_offsets-48 broker=1] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:14,952] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-12, __consumer_offsets-42, __consumer_offsets-18) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:14,989] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 18 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:14,991] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:14,994] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 36 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:14,994] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:14,994] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 6 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:14,994] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:14,994] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 24 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:14,994] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:14,994] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 42 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:14,994] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:14,994] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 12 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:14,994] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:14,994] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 30 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:14,994] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:14,995] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 0 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:14,995] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:14,995] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 48 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:14,995] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:15,004] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-18 in 12 milliseconds for epoch 4, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:15,005] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-36 in 11 milliseconds for epoch 4, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:15,005] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-6 in 11 milliseconds for epoch 4, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:15,006] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-24 in 12 milliseconds for epoch 4, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:15,006] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-42 in 12 milliseconds for epoch 4, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:15,006] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-12 in 12 milliseconds for epoch 4, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:15,007] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-30 in 12 milliseconds for epoch 4, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:15,007] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-0 in 12 milliseconds for epoch 4, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:15,007] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-48 in 12 milliseconds for epoch 4, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:18,002] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-07 19:20:18,343] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-07 19:20:18,447] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-07 19:20:18,452] INFO starting (kafka.server.KafkaServer)
[2022-05-07 19:20:18,452] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-07 19:20:18,470] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:18,478] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:18,479] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:18,479] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:18,479] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:18,479] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:18,479] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:18,479] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:18,479] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:18,479] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:18,479] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:18,479] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:18,479] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:18,479] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:18,479] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:18,479] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:18,480] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:18,480] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:18,480] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:18,482] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:18,487] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-07 19:20:18,494] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:18,505] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:18,512] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:18,512] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:18,518] INFO Socket connection established, initiating session, client: /127.0.0.1:38924, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:18,527] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000136dc780008, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:18,531] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:18,610] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:20:18,743] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-07 19:20:18,749] INFO Cluster ID = n1BTqOAPRy-Kw9b_q_-DTA (kafka.server.KafkaServer)
[2022-05-07 19:20:18,796] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:20:18,804] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:20:18,851] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:18,852] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:18,854] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:18,856] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:18,896] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:20:18,900] INFO Skipping recovery for all logs in /tmp/kafka-logs-2 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-07 19:20:18,972] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:19,003] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-14, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 88ms (1/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:20:19,007] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:19,012] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-38, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (2/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:20:19,014] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:19,020] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-1.4228fd7d738844118ffd72be3a2ea77a-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (3/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:20:19,023] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:19,028] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-8, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (4/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:20:19,032] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:19,035] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-2, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (5/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:20:19,038] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:19,041] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-26, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (6/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:20:19,044] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:19,047] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-20, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (7/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:20:19,049] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:19,053] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-32, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (8/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:20:19,056] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:19,059] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-5.1af221875c3342ee8145e4b0b365a54c-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (9/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:20:19,063] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:19,066] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-44, topicId=jBnZtzBSTVuLaU62fl2A5Q, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (10/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:20:19,067] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:19,072] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-2.fe8c510a72bc4b48b0590d08c511f65e-delete, topicId=6Q9HxPPzQvWcICuWm1Eyrg, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (11/11 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-07 19:20:19,076] INFO Loaded 11 logs in 180ms. (kafka.log.LogManager)
[2022-05-07 19:20:19,077] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-07 19:20:19,078] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-07 19:20:19,392] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:20:19,512] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-07 19:20:19,515] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-07 19:20:19,539] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-07 19:20:19,544] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:20:19,559] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:19,560] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:19,561] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:19,562] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:19,572] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:20:19,626] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-07 19:20:19,643] INFO Stat of the created znode at /brokers/ids/2 is: 847,847,1651947619636,1651947619636,1,0,0,72058929176641544,192,0,847
 (kafka.zk.KafkaZkClient)
[2022-05-07 19:20:19,643] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://joao:9094, czxid (broker epoch): 847 (kafka.zk.KafkaZkClient)
[2022-05-07 19:20:19,714] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:19,718] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:19,720] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:19,732] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:19,743] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:19,757] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:20:19,763] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:20:19,763] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:20:19,797] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:20:19,812] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:20:19,834] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-07 19:20:19,839] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-07 19:20:19,840] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-07 19:20:19,844] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:20:19,845] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:20:19,845] INFO Kafka startTimeMs: 1651947619840 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:20:19,847] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-07 19:20:19,902] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:20:19,939] INFO [Partition __consumer_offsets-2 broker=2] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:19,940] INFO [Partition __consumer_offsets-20 broker=2] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:19,940] INFO [Partition __consumer_offsets-38 broker=2] Log loaded for partition __consumer_offsets-38 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:19,941] INFO [Partition __consumer_offsets-8 broker=2] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:19,941] INFO [Partition __consumer_offsets-26 broker=2] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:19,941] INFO [Partition __consumer_offsets-44 broker=2] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:19,942] INFO [Partition __consumer_offsets-14 broker=2] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:19,942] INFO [Partition __consumer_offsets-32 broker=2] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:19,947] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker joao:9095 (id: 3 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:20:19,966] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-26, __consumer_offsets-32, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:19,996] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 2 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:19,998] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:20,000] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 20 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:20,001] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:20,001] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 38 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:20,001] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:20,001] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 8 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:20,002] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:20,002] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 26 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:20,002] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:20,002] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 44 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:20,002] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:20,002] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 14 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:20,003] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:20,003] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 32 in epoch 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:20,003] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 4 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:20,010] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-2 in 10 milliseconds for epoch 4, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:20,011] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-20 in 10 milliseconds for epoch 4, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:20,011] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-38 in 10 milliseconds for epoch 4, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:20,012] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-8 in 10 milliseconds for epoch 4, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:20,012] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-26 in 10 milliseconds for epoch 4, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:20,012] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-44 in 10 milliseconds for epoch 4, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:20,012] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-14 in 9 milliseconds for epoch 4, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:20,012] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-32 in 9 milliseconds for epoch 4, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:20:22,996] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-07 19:20:23,237] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-07 19:20:23,327] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-07 19:20:23,330] INFO starting (kafka.server.KafkaServer)
[2022-05-07 19:20:23,331] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-07 19:20:23,345] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:23,350] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:23,350] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:23,350] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:23,350] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:23,350] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:23,350] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:23,351] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:23,351] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:23,351] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:23,351] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:23,351] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:23,351] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:23,351] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:23,351] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:23,351] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:23,351] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:23,351] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:23,351] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:23,353] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:23,358] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-07 19:20:23,362] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:23,374] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:23,379] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:23,379] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:23,383] INFO Socket connection established, initiating session, client: /127.0.0.1:38926, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:23,390] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000136dc780009, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:23,394] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:23,475] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:20:23,598] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-07 19:20:23,606] INFO Cluster ID = n1BTqOAPRy-Kw9b_q_-DTA (kafka.server.KafkaServer)
[2022-05-07 19:20:23,646] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:20:23,656] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:20:23,703] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:23,704] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:23,706] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:23,708] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:23,728] ERROR [KafkaServer id=3] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs-3. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:241)
	at scala.collection.StrictOptimizedIterableOps.flatMap(StrictOptimizedIterableOps.scala:117)
	at scala.collection.StrictOptimizedIterableOps.flatMap$(StrictOptimizedIterableOps.scala:104)
	at scala.collection.mutable.ArraySeq.flatMap(ArraySeq.scala:37)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:236)
	at kafka.log.LogManager.<init>(LogManager.scala:112)
	at kafka.log.LogManager$.apply(LogManager.scala:1315)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:259)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-05-07 19:20:23,731] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-05-07 19:20:23,734] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:20:23,735] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:20:23,735] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:20:23,736] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:23,842] INFO Session: 0x1000136dc780009 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:23,842] INFO EventThread shut down for session: 0x1000136dc780009 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:23,846] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:23,846] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:24,704] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:24,704] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:24,705] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:25,227] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=2503095, lastModifiedTime=1651947483623, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-07 19:20:25,230] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=2503095, lastModifiedTime=1651947483623, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-07 19:20:25,232] INFO Deleted log /tmp/kafka-logs-3/Sensor-0.961cc0753d574f659a0d5ac6b88295c1-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:25,233] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-0.961cc0753d574f659a0d5ac6b88295c1-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:25,235] INFO Deleted time index /tmp/kafka-logs-3/Sensor-0.961cc0753d574f659a0d5ac6b88295c1-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:25,238] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-3/Sensor-0.961cc0753d574f659a0d5ac6b88295c1-delete. (kafka.log.LogManager)
[2022-05-07 19:20:25,246] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275891, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-07 19:20:25,246] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275891, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-07 19:20:25,247] INFO Deleted log /tmp/kafka-logs-3/Sensor-2.ec2e5fecfd33499fa8143b5725184533-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:25,247] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-2.ec2e5fecfd33499fa8143b5725184533-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:25,247] INFO Deleted time index /tmp/kafka-logs-3/Sensor-2.ec2e5fecfd33499fa8143b5725184533-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:25,248] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-3/Sensor-2.ec2e5fecfd33499fa8143b5725184533-delete. (kafka.log.LogManager)
[2022-05-07 19:20:25,252] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275883, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-07 19:20:25,252] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275883, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-07 19:20:25,253] INFO Deleted log /tmp/kafka-logs-3/Sensor-3.f494773bf42744db8251a40ab12d691d-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:25,253] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-3.f494773bf42744db8251a40ab12d691d-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:25,253] INFO Deleted time index /tmp/kafka-logs-3/Sensor-3.f494773bf42744db8251a40ab12d691d-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:25,254] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-3/Sensor-3.f494773bf42744db8251a40ab12d691d-delete. (kafka.log.LogManager)
[2022-05-07 19:20:25,706] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:25,706] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:25,706] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:25,707] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:25,707] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:25,708] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:25,709] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:25,709] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:25,711] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:20:25,712] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:20:25,712] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:20:25,718] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-07 19:20:25,723] INFO App info kafka.server for 3 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:20:25,724] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2022-05-07 19:20:25,724] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-05-07 19:20:25,725] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-05-07 19:20:27,967] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-07 19:20:28,207] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-07 19:20:28,283] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-07 19:20:28,287] INFO starting (kafka.server.KafkaServer)
[2022-05-07 19:20:28,287] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-07 19:20:28,300] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:28,304] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:28,304] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:28,304] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:28,304] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:28,305] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:28,305] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:28,305] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:28,305] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:28,305] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:28,305] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:28,305] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:28,305] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:28,305] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:28,305] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:28,305] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:28,305] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:28,305] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:28,306] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:28,307] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:28,312] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-07 19:20:28,316] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:28,334] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:28,339] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:28,340] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:28,343] INFO Socket connection established, initiating session, client: /127.0.0.1:38928, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:28,351] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000136dc78000a, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:28,355] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:28,439] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:20:28,555] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-07 19:20:28,561] INFO Cluster ID = n1BTqOAPRy-Kw9b_q_-DTA (kafka.server.KafkaServer)
[2022-05-07 19:20:28,602] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:20:28,610] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:20:28,656] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:28,657] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:28,658] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:28,660] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:28,677] ERROR [KafkaServer id=4] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs-4. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:241)
	at scala.collection.StrictOptimizedIterableOps.flatMap(StrictOptimizedIterableOps.scala:117)
	at scala.collection.StrictOptimizedIterableOps.flatMap$(StrictOptimizedIterableOps.scala:104)
	at scala.collection.mutable.ArraySeq.flatMap(ArraySeq.scala:37)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:236)
	at kafka.log.LogManager.<init>(LogManager.scala:112)
	at kafka.log.LogManager$.apply(LogManager.scala:1315)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:259)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-05-07 19:20:28,679] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2022-05-07 19:20:28,682] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:20:28,683] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:20:28,683] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:20:28,685] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:28,790] INFO Session: 0x1000136dc78000a closed (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:28,791] INFO EventThread shut down for session: 0x1000136dc78000a (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:28,794] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:28,795] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:29,657] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:29,658] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:29,658] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:30,281] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=2503095, lastModifiedTime=1651947483623, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-07 19:20:30,283] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=2503095, lastModifiedTime=1651947483623, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-07 19:20:30,285] INFO Deleted log /tmp/kafka-logs-4/Sensor-0.f389113946624a849813f8e297a79f23-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:30,286] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-0.f389113946624a849813f8e297a79f23-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:30,289] INFO Deleted time index /tmp/kafka-logs-4/Sensor-0.f389113946624a849813f8e297a79f23-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:30,293] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-4/Sensor-0.f389113946624a849813f8e297a79f23-delete. (kafka.log.LogManager)
[2022-05-07 19:20:30,312] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275899, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-07 19:20:30,312] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275899, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-07 19:20:30,314] INFO Deleted log /tmp/kafka-logs-4/Sensor-5.c26b72176694499999ba5c69b59f45eb-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:30,314] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-5.c26b72176694499999ba5c69b59f45eb-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:30,314] INFO Deleted time index /tmp/kafka-logs-4/Sensor-5.c26b72176694499999ba5c69b59f45eb-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:30,314] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-4/Sensor-5.c26b72176694499999ba5c69b59f45eb-delete. (kafka.log.LogManager)
[2022-05-07 19:20:30,320] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275863, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-07 19:20:30,321] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275863, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-07 19:20:30,321] INFO Deleted log /tmp/kafka-logs-4/Sensor-3.ffad24e65c8742b0929f6abb1d8ec9bf-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:30,322] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-3.ffad24e65c8742b0929f6abb1d8ec9bf-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:30,322] INFO Deleted time index /tmp/kafka-logs-4/Sensor-3.ffad24e65c8742b0929f6abb1d8ec9bf-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:30,322] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-4/Sensor-3.ffad24e65c8742b0929f6abb1d8ec9bf-delete. (kafka.log.LogManager)
[2022-05-07 19:20:30,658] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:30,658] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:30,659] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:31,659] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:31,659] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:31,660] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:31,661] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:31,661] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:31,663] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:20:31,663] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:20:31,664] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:20:31,670] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-07 19:20:31,674] INFO App info kafka.server for 4 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:20:31,674] INFO [KafkaServer id=4] shut down completed (kafka.server.KafkaServer)
[2022-05-07 19:20:31,675] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-05-07 19:20:31,676] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2022-05-07 19:20:32,997] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-07 19:20:33,230] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-07 19:20:33,304] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-07 19:20:33,307] INFO starting (kafka.server.KafkaServer)
[2022-05-07 19:20:33,307] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-07 19:20:33,322] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:33,327] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:33,327] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:33,327] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:33,327] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:33,327] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:33,327] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:33,328] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:33,328] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:33,328] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:33,328] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:33,328] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:33,328] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:33,328] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:33,328] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:33,328] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:33,328] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:33,328] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:33,328] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:33,330] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:33,342] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-07 19:20:33,347] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:33,352] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:33,358] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:33,359] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:33,363] INFO Socket connection established, initiating session, client: /127.0.0.1:38930, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:33,370] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x1000136dc78000b, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:33,374] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:33,445] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:20:33,569] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-07 19:20:33,574] INFO Cluster ID = n1BTqOAPRy-Kw9b_q_-DTA (kafka.server.KafkaServer)
[2022-05-07 19:20:33,621] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:20:33,630] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-07 19:20:33,677] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:33,678] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:33,680] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:33,681] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:33,698] ERROR [KafkaServer id=5] Fatal error during KafkaServer startup. Prepare to shutdown (kafka.server.KafkaServer)
org.apache.kafka.common.KafkaException: Failed to acquire lock on file .lock in /tmp/kafka-logs-5. A Kafka instance in another process or thread is using this directory.
	at kafka.log.LogManager.$anonfun$lockLogDirs$1(LogManager.scala:241)
	at scala.collection.StrictOptimizedIterableOps.flatMap(StrictOptimizedIterableOps.scala:117)
	at scala.collection.StrictOptimizedIterableOps.flatMap$(StrictOptimizedIterableOps.scala:104)
	at scala.collection.mutable.ArraySeq.flatMap(ArraySeq.scala:37)
	at kafka.log.LogManager.lockLogDirs(LogManager.scala:236)
	at kafka.log.LogManager.<init>(LogManager.scala:112)
	at kafka.log.LogManager$.apply(LogManager.scala:1315)
	at kafka.server.KafkaServer.startup(KafkaServer.scala:259)
	at kafka.Kafka$.main(Kafka.scala:109)
	at kafka.Kafka.main(Kafka.scala)
[2022-05-07 19:20:33,701] INFO [KafkaServer id=5] shutting down (kafka.server.KafkaServer)
[2022-05-07 19:20:33,703] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:20:33,704] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:20:33,704] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:20:33,705] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:33,811] INFO Session: 0x1000136dc78000b closed (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:20:33,811] INFO EventThread shut down for session: 0x1000136dc78000b (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:20:33,814] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:20:33,814] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:34,678] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:34,678] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:34,679] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:34,679] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:34,679] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:34,680] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:34,680] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:34,680] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:34,681] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:34,682] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:34,682] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:20:34,684] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:20:34,685] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:20:34,685] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:20:34,688] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-07 19:20:34,692] INFO App info kafka.server for 5 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:20:34,693] INFO [KafkaServer id=5] shut down completed (kafka.server.KafkaServer)
[2022-05-07 19:20:34,693] ERROR Exiting Kafka. (kafka.Kafka$)
[2022-05-07 19:20:34,694] INFO [KafkaServer id=5] shutting down (kafka.server.KafkaServer)
[2022-05-07 19:20:35,265] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275855, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-07 19:20:35,268] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275855, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-07 19:20:35,271] INFO Deleted log /tmp/kafka-logs-5/Sensor-2.b148ed20eda84772a5502008dcd9e744-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:35,272] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-2.b148ed20eda84772a5502008dcd9e744-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:35,274] INFO Deleted time index /tmp/kafka-logs-5/Sensor-2.b148ed20eda84772a5502008dcd9e744-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:35,278] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-5/Sensor-2.b148ed20eda84772a5502008dcd9e744-delete. (kafka.log.LogManager)
[2022-05-07 19:20:35,279] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275891, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-07 19:20:35,279] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275891, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-07 19:20:35,280] INFO Deleted log /tmp/kafka-logs-5/Sensor-5.c8c70384e8984b019d63f1ff51ec7f87-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:35,280] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-5.c8c70384e8984b019d63f1ff51ec7f87-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:35,280] INFO Deleted time index /tmp/kafka-logs-5/Sensor-5.c8c70384e8984b019d63f1ff51ec7f87-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:35,280] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-5/Sensor-5.c8c70384e8984b019d63f1ff51ec7f87-delete. (kafka.log.LogManager)
[2022-05-07 19:20:35,308] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=1773621, lastModifiedTime=1651947483635, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-07 19:20:35,309] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=1773621, lastModifiedTime=1651947483635, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-07 19:20:35,310] INFO Deleted log /tmp/kafka-logs-5/Sensor-4.8646eb6134254afd9c7f4164d2e69639-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:35,311] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-4.8646eb6134254afd9c7f4164d2e69639-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:35,311] INFO Deleted time index /tmp/kafka-logs-5/Sensor-4.8646eb6134254afd9c7f4164d2e69639-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-07 19:20:35,312] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-5/Sensor-4.8646eb6134254afd9c7f4164d2e69639-delete. (kafka.log.LogManager)
[2022-05-07 19:20:38,583] INFO Creating topic Sensor with configuration {min.insync.replicas=2} and initial partition assignment HashMap(0 -> ArrayBuffer(5, 2, 3), 1 -> ArrayBuffer(4, 3, 0), 2 -> ArrayBuffer(1, 0, 5), 3 -> ArrayBuffer(2, 5, 4), 4 -> ArrayBuffer(3, 4, 1), 5 -> ArrayBuffer(0, 1, 2)) (kafka.zk.AdminZkClient)
[2022-05-07 19:20:38,640] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,641] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,644] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-4) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,644] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,645] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,645] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,652] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:38,656] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:38,657] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:38,658] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-2/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-07 19:20:38,658] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:38,659] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:38,660] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:38,660] INFO [Partition Sensor-3 broker=2] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-07 19:20:38,660] INFO [Partition Sensor-3 broker=2] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:38,663] INFO Created log for partition Sensor-5 in /tmp/kafka-logs/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-07 19:20:38,663] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-4/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-07 19:20:38,664] INFO [Partition Sensor-5 broker=0] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-07 19:20:38,664] INFO [Partition Sensor-1 broker=4] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-07 19:20:38,665] INFO [Partition Sensor-5 broker=0] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:38,665] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-3/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-07 19:20:38,665] INFO [Partition Sensor-1 broker=4] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:38,666] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-5/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-07 19:20:38,666] INFO [Partition Sensor-4 broker=3] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-07 19:20:38,667] INFO [Partition Sensor-4 broker=3] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:38,668] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-1/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-07 19:20:38,668] INFO [Partition Sensor-0 broker=5] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-07 19:20:38,669] INFO [Partition Sensor-0 broker=5] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:38,673] INFO [Partition Sensor-2 broker=1] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-07 19:20:38,674] INFO [Partition Sensor-2 broker=1] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:38,675] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:38,677] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-2/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-07 19:20:38,678] INFO [Partition Sensor-5 broker=2] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-07 19:20:38,678] INFO [Partition Sensor-5 broker=2] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:38,679] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:38,679] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:38,682] INFO Created log for partition Sensor-2 in /tmp/kafka-logs/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-07 19:20:38,682] INFO [Partition Sensor-2 broker=0] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-07 19:20:38,682] INFO [Partition Sensor-2 broker=0] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:38,683] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-4/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-07 19:20:38,683] INFO [Partition Sensor-4 broker=4] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-07 19:20:38,683] INFO [Partition Sensor-4 broker=4] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:38,684] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:38,684] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:38,686] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-3/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-07 19:20:38,686] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-5/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-07 19:20:38,686] INFO [Partition Sensor-0 broker=3] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-07 19:20:38,686] INFO [Partition Sensor-0 broker=3] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:38,686] INFO [Partition Sensor-3 broker=5] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-07 19:20:38,686] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:38,686] INFO [Partition Sensor-3 broker=5] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:38,689] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-2/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-07 19:20:38,689] INFO [Partition Sensor-0 broker=2] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-07 19:20:38,689] INFO [Partition Sensor-0 broker=2] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:38,689] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(Sensor-5, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,690] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:38,691] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:38,692] INFO Created log for partition Sensor-1 in /tmp/kafka-logs/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-07 19:20:38,692] INFO [Partition Sensor-1 broker=0] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-07 19:20:38,692] INFO [Partition Sensor-1 broker=0] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:38,693] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,693] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-4/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-07 19:20:38,693] INFO [Partition Sensor-3 broker=4] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-07 19:20:38,693] INFO [Partition Sensor-3 broker=4] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:38,694] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(Sensor-4, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,696] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:38,697] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:38,698] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-3/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-07 19:20:38,699] INFO [Partition Sensor-1 broker=3] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-07 19:20:38,699] INFO [Partition Sensor-1 broker=3] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:38,699] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-5/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-07 19:20:38,699] INFO [Partition Sensor-2 broker=5] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-07 19:20:38,699] INFO [Partition Sensor-2 broker=5] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:38,699] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,700] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,700] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:38,705] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-1/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-07 19:20:38,706] INFO [Partition Sensor-4 broker=1] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-07 19:20:38,706] INFO [Partition Sensor-4 broker=1] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:38,717] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-07 19:20:38,719] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-1/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-07 19:20:38,719] INFO [Partition Sensor-5 broker=1] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-07 19:20:38,720] INFO [Partition Sensor-5 broker=1] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-07 19:20:38,721] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(Sensor-4, Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,722] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,726] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 4 for partitions Map(Sensor-1 -> InitialFetchState(Some(aoC145RiSG2B-wtx3SQ4qg),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,727] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,729] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,730] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,731] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,731] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 1 for partitions Map(Sensor-2 -> InitialFetchState(Some(aoC145RiSG2B-wtx3SQ4qg),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,731] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,733] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,734] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,734] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions Map(Sensor-5 -> InitialFetchState(Some(aoC145RiSG2B-wtx3SQ4qg),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,734] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-07 19:20:38,735] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 2 for partitions Map(Sensor-3 -> InitialFetchState(Some(aoC145RiSG2B-wtx3SQ4qg),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,734] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-07 19:20:38,737] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,738] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,739] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 5 for partitions Map(Sensor-0 -> InitialFetchState(Some(aoC145RiSG2B-wtx3SQ4qg),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,739] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,740] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 4 for partitions Map(Sensor-1 -> InitialFetchState(Some(aoC145RiSG2B-wtx3SQ4qg),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,740] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,741] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 3 for partitions Map(Sensor-4 -> InitialFetchState(Some(aoC145RiSG2B-wtx3SQ4qg),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,741] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-07 19:20:38,743] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 2 for partitions Map(Sensor-3 -> InitialFetchState(Some(aoC145RiSG2B-wtx3SQ4qg),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,743] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-07 19:20:38,743] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,743] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,744] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,744] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-07 19:20:38,741] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-07 19:20:38,748] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 1 for partitions Map(Sensor-2 -> InitialFetchState(Some(aoC145RiSG2B-wtx3SQ4qg),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,749] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,750] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 5 for partitions Map(Sensor-0 -> InitialFetchState(Some(aoC145RiSG2B-wtx3SQ4qg),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,750] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,747] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,751] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-07 19:20:38,753] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-07 19:20:38,754] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,754] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,757] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-07 19:20:38,757] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-07 19:20:38,778] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,785] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(Sensor-5 -> InitialFetchState(Some(aoC145RiSG2B-wtx3SQ4qg),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,801] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 3 for partitions Map(Sensor-4 -> InitialFetchState(Some(aoC145RiSG2B-wtx3SQ4qg),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:20:38,829] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,832] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,837] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-07 19:20:38,838] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,838] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-07 19:20:38,855] WARN [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-3. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,856] WARN [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-4. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,864] WARN [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-0. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,886] WARN [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-2. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:38,886] WARN [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-2. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:20:45,503] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group consumer in Stable state. Created a new member id consumer-consumer-5-2c9bba6f-86ff-4556-8bfd-f4d8eae52faa and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:45,507] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group consumer in Stable state. Created a new member id consumer-consumer-3-94d6a12a-64a1-4028-9c0e-391e17e5a117 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:45,511] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group consumer in Stable state. Created a new member id consumer-consumer-2-0396f927-41b7-4d33-a00b-f2504deaa6d4 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:45,511] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group consumer in Stable state. Created a new member id consumer-consumer-6-d94f41f6-d1d9-457f-a107-056ab55ff399 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:45,512] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group consumer in Stable state. Created a new member id consumer-consumer-1-8280d1db-a9f4-47b4-8de5-08c6e6b80a55 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:45,513] INFO [GroupCoordinator 0]: Dynamic member with unknown member id joins group consumer in Stable state. Created a new member id consumer-consumer-4-0f697592-6a39-4599-8661-3898bd6f068b and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:45,521] INFO [GroupCoordinator 0]: Preparing to rebalance group consumer in state PreparingRebalance with old generation 85 (__consumer_offsets-22) (reason: Adding new member consumer-consumer-5-2c9bba6f-86ff-4556-8bfd-f4d8eae52faa with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:55,167] INFO [GroupCoordinator 0]: Member consumer-consumer-6-b54a91da-2791-42e7-96a0-eb0f5a8193e8 in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:55,171] INFO [GroupCoordinator 0]: Member consumer-consumer-2-073eb357-3025-4a98-93c3-87bbf959b19e in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:55,171] INFO [GroupCoordinator 0]: Member consumer-consumer-5-0ea1be36-213f-4845-af05-c6fcca126714 in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:55,171] INFO [GroupCoordinator 0]: Member consumer-consumer-4-8edcb724-a78e-4c1c-b6a4-5a9bb2488eef in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:55,172] INFO [GroupCoordinator 0]: Member consumer-consumer-1-3842587a-92b2-41b0-84b3-addc7882c744 in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:55,172] INFO [GroupCoordinator 0]: Member consumer-consumer-3-47f06c71-c824-499c-9b83-922de4f38038 in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:55,179] INFO [GroupCoordinator 0]: Stabilized group consumer generation 86 (__consumer_offsets-22) with 6 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:20:55,207] INFO [GroupCoordinator 0]: Assignment received from leader consumer-consumer-6-d94f41f6-d1d9-457f-a107-056ab55ff399 for group consumer for generation 86. The group has 6 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:21:08,797] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275891, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-07 19:21:08,801] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275891, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-07 19:21:08,805] INFO Deleted log /tmp/kafka-logs/Sensor-3.1a22bce5666b4806b46db98b307a9aec-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:08,807] INFO Deleted offset index /tmp/kafka-logs/Sensor-3.1a22bce5666b4806b46db98b307a9aec-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:08,812] INFO Deleted time index /tmp/kafka-logs/Sensor-3.1a22bce5666b4806b46db98b307a9aec-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:08,823] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs/Sensor-3.1a22bce5666b4806b46db98b307a9aec-delete. (kafka.log.LogManager)
[2022-05-07 19:21:08,824] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275855, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-07 19:21:08,825] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275855, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-07 19:21:08,826] INFO Deleted log /tmp/kafka-logs/Sensor-1.b30ab7e5444e48a089d1b692fef17441-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:08,826] INFO Deleted offset index /tmp/kafka-logs/Sensor-1.b30ab7e5444e48a089d1b692fef17441-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:08,827] INFO Deleted time index /tmp/kafka-logs/Sensor-1.b30ab7e5444e48a089d1b692fef17441-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:08,828] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs/Sensor-1.b30ab7e5444e48a089d1b692fef17441-delete. (kafka.log.LogManager)
[2022-05-07 19:21:08,840] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=1773621, lastModifiedTime=1651947483635, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-07 19:21:08,841] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=1773621, lastModifiedTime=1651947483635, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-07 19:21:08,844] INFO Deleted log /tmp/kafka-logs/Sensor-4.a1144cbaeaaf49f984864a0c7a63cfe4-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:08,845] INFO Deleted offset index /tmp/kafka-logs/Sensor-4.a1144cbaeaaf49f984864a0c7a63cfe4-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:08,845] INFO Deleted time index /tmp/kafka-logs/Sensor-4.a1144cbaeaaf49f984864a0c7a63cfe4-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:08,846] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs/Sensor-4.a1144cbaeaaf49f984864a0c7a63cfe4-delete. (kafka.log.LogManager)
[2022-05-07 19:21:14,069] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=2503095, lastModifiedTime=1651947483623, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-07 19:21:14,071] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=2503095, lastModifiedTime=1651947483623, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-07 19:21:14,079] INFO Deleted log /tmp/kafka-logs-1/Sensor-0.ddcd7ae57580402da215f4a730a59239-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:14,080] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-0.ddcd7ae57580402da215f4a730a59239-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:14,084] INFO Deleted time index /tmp/kafka-logs-1/Sensor-0.ddcd7ae57580402da215f4a730a59239-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:14,091] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-1/Sensor-0.ddcd7ae57580402da215f4a730a59239-delete. (kafka.log.LogManager)
[2022-05-07 19:21:14,091] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275895, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-07 19:21:14,092] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275895, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-07 19:21:14,093] INFO Deleted log /tmp/kafka-logs-1/Sensor-1.9f152cf79eac4fa4b00b8d1846a84a57-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:14,093] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-1.9f152cf79eac4fa4b00b8d1846a84a57-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:14,093] INFO Deleted time index /tmp/kafka-logs-1/Sensor-1.9f152cf79eac4fa4b00b8d1846a84a57-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:14,094] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-1/Sensor-1.9f152cf79eac4fa4b00b8d1846a84a57-delete. (kafka.log.LogManager)
[2022-05-07 19:21:14,099] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=1773621, lastModifiedTime=1651947483635, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-07 19:21:14,100] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=1773621, lastModifiedTime=1651947483635, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-07 19:21:14,100] INFO Deleted log /tmp/kafka-logs-1/Sensor-4.13ea7229ece0495fb77230d235172068-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:14,101] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-4.13ea7229ece0495fb77230d235172068-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:14,101] INFO Deleted time index /tmp/kafka-logs-1/Sensor-4.13ea7229ece0495fb77230d235172068-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:14,102] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-1/Sensor-4.13ea7229ece0495fb77230d235172068-delete. (kafka.log.LogManager)
[2022-05-07 19:21:19,026] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275895, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-07 19:21:19,028] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275895, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-07 19:21:19,032] INFO Deleted log /tmp/kafka-logs-2/Sensor-1.4228fd7d738844118ffd72be3a2ea77a-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:19,033] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-1.4228fd7d738844118ffd72be3a2ea77a-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:19,036] INFO Deleted time index /tmp/kafka-logs-2/Sensor-1.4228fd7d738844118ffd72be3a2ea77a-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:19,041] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-2/Sensor-1.4228fd7d738844118ffd72be3a2ea77a-delete. (kafka.log.LogManager)
[2022-05-07 19:21:19,060] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275855, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-07 19:21:19,060] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275855, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-07 19:21:19,061] INFO Deleted log /tmp/kafka-logs-2/Sensor-5.1af221875c3342ee8145e4b0b365a54c-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:19,061] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-5.1af221875c3342ee8145e4b0b365a54c-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:19,061] INFO Deleted time index /tmp/kafka-logs-2/Sensor-5.1af221875c3342ee8145e4b0b365a54c-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:19,062] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-2/Sensor-5.1af221875c3342ee8145e4b0b365a54c-delete. (kafka.log.LogManager)
[2022-05-07 19:21:19,073] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275887, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-07 19:21:19,074] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=0, lastModifiedTime=1651946275887, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-07 19:21:19,076] INFO Deleted log /tmp/kafka-logs-2/Sensor-2.fe8c510a72bc4b48b0590d08c511f65e-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:19,077] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-2.fe8c510a72bc4b48b0590d08c511f65e-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:19,077] INFO Deleted time index /tmp/kafka-logs-2/Sensor-2.fe8c510a72bc4b48b0590d08c511f65e-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-07 19:21:19,078] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-2/Sensor-2.fe8c510a72bc4b48b0590d08c511f65e-delete. (kafka.log.LogManager)
[2022-05-07 19:23:26,204] INFO [GroupCoordinator 0]: Member consumer-consumer-5-2c9bba6f-86ff-4556-8bfd-f4d8eae52faa in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:23:26,204] INFO [GroupCoordinator 0]: Preparing to rebalance group consumer in state PreparingRebalance with old generation 86 (__consumer_offsets-22) (reason: removing member consumer-consumer-5-2c9bba6f-86ff-4556-8bfd-f4d8eae52faa on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:23:26,215] INFO [GroupCoordinator 0]: Member consumer-consumer-6-d94f41f6-d1d9-457f-a107-056ab55ff399 in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:23:26,216] INFO [GroupCoordinator 0]: Member consumer-consumer-2-0396f927-41b7-4d33-a00b-f2504deaa6d4 in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:23:26,217] INFO [GroupCoordinator 0]: Member consumer-consumer-1-8280d1db-a9f4-47b4-8de5-08c6e6b80a55 in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:23:26,218] INFO [GroupCoordinator 0]: Member consumer-consumer-4-0f697592-6a39-4599-8661-3898bd6f068b in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:23:26,219] INFO [GroupCoordinator 0]: Member consumer-consumer-3-94d6a12a-64a1-4028-9c0e-391e17e5a117 in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:23:26,220] INFO [GroupCoordinator 0]: Group consumer with generation 87 is now empty (__consumer_offsets-22) (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:25:31,743] INFO [GroupCoordinator 3]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:25:31,744] INFO [GroupCoordinator 4]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:25:31,745] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:25:31,745] INFO [GroupMetadataManager brokerId=0] Group consumer transitioned to Dead in generation 87 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-07 19:25:31,745] INFO [GroupCoordinator 5]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:25:31,746] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:25:31,750] INFO [GroupCoordinator 0]: Removed 6 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:25:31,782] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:31,782] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:31,783] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:31,784] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:31,784] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:31,784] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:31,784] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:31,784] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:31,785] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:31,785] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:31,785] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:31,786] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-2) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:31,789] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,790] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,792] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,793] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,794] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,794] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,794] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,794] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 583 due to node 4 being disconnected (elapsed time since creation: 255ms, elapsed time since send: 255ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,794] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,794] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=1367363451, epoch=583) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-07 19:25:31,795] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,795] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,795] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,796] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,797] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 583 due to node 1 being disconnected (elapsed time since creation: 114ms, elapsed time since send: 114ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,798] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 583 due to node 2 being disconnected (elapsed time since creation: 200ms, elapsed time since send: 200ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,798] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,798] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 583 due to node 2 being disconnected (elapsed time since creation: 239ms, elapsed time since send: 239ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,799] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 583 due to node 0 being disconnected (elapsed time since creation: 382ms, elapsed time since send: 382ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,799] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,802] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 2568 due to node 3 being disconnected (elapsed time since creation: 254ms, elapsed time since send: 254ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,802] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,799] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1047796000, epoch=581) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-07 19:25:31,798] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=977852277, epoch=581) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-07 19:25:31,798] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=2105947710, epoch=583) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-07 19:25:31,803] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,803] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,803] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,803] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,803] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,799] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=1518689060, epoch=583) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-07 19:25:31,804] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,802] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,805] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,805] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,805] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 5056 due to node 5 being disconnected (elapsed time since creation: 314ms, elapsed time since send: 314ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,805] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=1226733738, epoch=5056) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-07 19:25:31,805] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,805] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,803] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=497772581, epoch=2568) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-07 19:25:31,808] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:31,808] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,808] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,809] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:31,809] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,810] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,810] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,810] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,810] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 583 due to node 1 being disconnected (elapsed time since creation: 147ms, elapsed time since send: 147ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,810] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 2558 due to node 3 being disconnected (elapsed time since creation: 270ms, elapsed time since send: 270ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,810] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=1873639273, epoch=581) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-07 19:25:31,811] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,811] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,812] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,812] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,811] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=2009277862, epoch=2556) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-07 19:25:31,813] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 583 due to node 4 being disconnected (elapsed time since creation: 150ms, elapsed time since send: 150ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,813] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,813] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,813] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,813] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:31,813] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=464095766, epoch=583) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-07 19:25:31,814] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,814] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,814] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,814] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:31,814] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 5019 due to node 5 being disconnected (elapsed time since creation: 346ms, elapsed time since send: 346ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,814] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=1696362203, epoch=5017) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-07 19:25:31,815] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,815] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,815] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:31,816] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:31,816] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:31,818] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:31,818] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:31,821] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:31,828] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-3/Sensor-4.e7f55f0dc5db4215af86c7c23bb0f787-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:25:31,828] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,828] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,829] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 584 due to node 0 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-07 19:25:31,829] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=1053140909, epoch=584) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-07 19:25:31,830] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,830] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-07 19:25:31,832] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-5/Sensor-2.413b0cf6e0804f71a5b3753560d1c67c-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:25:31,833] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-3/Sensor-0.17c33bbb01594046b960525d82708593-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:25:31,833] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:31,834] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-2) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:31,836] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-3/Sensor-1.077a272541c843baa613bf70a02fa445-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:25:31,836] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-5/Sensor-3.de01c0a114064a448e0e1cd1f3059a67-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:25:31,838] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs/Sensor-5.1bd13a15c77c4f65b4aeac05afac4f60-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:25:31,839] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-5/Sensor-0.76a5e4c60acb4bff8f7a2acbed866ea5-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:25:31,842] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs/Sensor-2.beaef001c77d4b75a26eaaacf2c1ba04-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:25:31,844] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-2/Sensor-5.913cc853257446629146331c05c27fe7-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:25:31,844] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-4/Sensor-4.65f7362fc9bc4f499a447631b40aeb53-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:25:31,845] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs/Sensor-1.42c8847515604004b20de9b93fec8207-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:25:31,849] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-2/Sensor-3.05226f3dd1f14afd89b8aa662e3eb1fb-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:25:31,849] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-4/Sensor-3.056f7e490ad44202999c0a13c0606f1c-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:25:31,852] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-2/Sensor-0.4c98eda112b64e868ad556dbc015d5bc-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:25:31,853] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-4/Sensor-1.01a18f0e12a747108d9e52d6c95c44b3-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:25:31,857] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-1/Sensor-4.eac3195a8e0348aab770c8bfbedbb77b-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:25:31,860] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-1/Sensor-5.32d84a51cf8249b1809d9e81e8536579-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:25:31,863] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-1/Sensor-2.74213ff8eef44a4a92bfa538916772e2-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-07 19:25:32,111] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-07 19:25:32,112] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-07 19:25:32,112] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-07 19:25:32,112] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-07 19:25:32,112] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-07 19:25:32,112] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-07 19:25:32,114] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-05-07 19:25:32,114] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-07 19:25:32,114] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-07 19:25:32,114] INFO [KafkaServer id=5] shutting down (kafka.server.KafkaServer)
[2022-05-07 19:25:32,114] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2022-05-07 19:25:32,115] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-07 19:25:32,115] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-05-07 19:25:32,115] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-07 19:25:32,115] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-07 19:25:32,116] INFO [KafkaServer id=5] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-07 19:25:32,116] INFO [KafkaServer id=4] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-07 19:25:32,117] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-07 19:25:32,136] INFO [KafkaServer id=3] Controlled shutdown request returned successfully after 15ms (kafka.server.KafkaServer)
[2022-05-07 19:25:32,139] INFO [KafkaServer id=4] Controlled shutdown request returned successfully after 15ms (kafka.server.KafkaServer)
[2022-05-07 19:25:32,139] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:25:32,139] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:25:32,139] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:25:32,141] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 15ms (kafka.server.KafkaServer)
[2022-05-07 19:25:32,142] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-07 19:25:32,142] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:25:32,142] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:25:32,142] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:25:32,144] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 17ms (kafka.server.KafkaServer)
[2022-05-07 19:25:32,144] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:25:32,145] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-07 19:25:32,145] INFO [KafkaServer id=5] Controlled shutdown request returned successfully after 18ms (kafka.server.KafkaServer)
[2022-05-07 19:25:32,146] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:25:32,146] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:25:32,146] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 19ms (kafka.server.KafkaServer)
[2022-05-07 19:25:32,148] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-07 19:25:32,148] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:25:32,149] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:25:32,148] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:25:32,149] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:25:32,149] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:25:32,149] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:25:32,150] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-07 19:25:32,150] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:25:32,151] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-07 19:25:32,151] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:25:32,152] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-07 19:25:32,154] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-07 19:25:32,160] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-07 19:25:32,163] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-07 19:25:32,163] INFO [data-plane Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-07 19:25:32,165] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-07 19:25:32,166] INFO [data-plane Kafka Request Handler on Broker 4], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-07 19:25:32,166] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-07 19:25:32,167] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-07 19:25:32,167] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-07 19:25:32,168] INFO [data-plane Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-07 19:25:32,169] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-07 19:25:32,170] INFO [data-plane Kafka Request Handler on Broker 5], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-07 19:25:32,170] INFO [data-plane Kafka Request Handler on Broker 4], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-07 19:25:32,170] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-07 19:25:32,171] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-07 19:25:32,171] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-07 19:25:32,174] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-07 19:25:32,175] INFO [ExpirationReaper-3-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,175] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-07 19:25:32,176] INFO [data-plane Kafka Request Handler on Broker 5], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-07 19:25:32,176] INFO [ExpirationReaper-4-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,179] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,180] INFO [ExpirationReaper-5-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,180] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,181] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,186] INFO [ExpirationReaper-4-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,186] INFO [ExpirationReaper-4-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,187] INFO [KafkaApi-4] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-07 19:25:32,187] INFO [ExpirationReaper-4-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,188] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,188] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,189] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-07 19:25:32,190] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,286] INFO [ExpirationReaper-3-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,286] INFO [ExpirationReaper-3-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,287] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-07 19:25:32,288] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,288] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,289] INFO [ExpirationReaper-4-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,289] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,289] INFO [ExpirationReaper-4-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,289] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-07 19:25:32,290] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,292] INFO [TransactionCoordinator id=4] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:25:32,294] INFO [Transaction State Manager 4]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-07 19:25:32,294] INFO [Transaction Marker Channel Manager 4]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:25:32,294] INFO [Transaction Marker Channel Manager 4]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:25:32,294] INFO [Transaction Marker Channel Manager 4]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:25:32,296] INFO [TransactionCoordinator id=4] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:25:32,296] INFO [GroupCoordinator 4]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:25:32,297] INFO [ExpirationReaper-4-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,317] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,317] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,319] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,319] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,320] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-07 19:25:32,320] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:25:32,321] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-07 19:25:32,321] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:25:32,321] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,321] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:25:32,321] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:25:32,323] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:25:32,323] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:25:32,323] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,332] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,332] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,334] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:25:32,335] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-07 19:25:32,335] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:25:32,335] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:25:32,335] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:25:32,336] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:25:32,338] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:25:32,338] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,356] INFO [ExpirationReaper-5-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,356] INFO [ExpirationReaper-5-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,357] INFO [KafkaApi-5] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-07 19:25:32,358] INFO [ExpirationReaper-5-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,388] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,389] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,389] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,412] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,412] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,412] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,412] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,412] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,412] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,412] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,415] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:25:32,415] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:25:32,417] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-07 19:25:32,417] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:25:32,417] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-07 19:25:32,417] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:25:32,417] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:25:32,417] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:25:32,417] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:25:32,417] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:25:32,419] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:25:32,419] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:25:32,419] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:25:32,420] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,420] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:25:32,421] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,455] INFO [ExpirationReaper-5-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,455] INFO [ExpirationReaper-5-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,458] INFO [TransactionCoordinator id=5] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:25:32,460] INFO [Transaction State Manager 5]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-07 19:25:32,460] INFO [Transaction Marker Channel Manager 5]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:25:32,460] INFO [Transaction Marker Channel Manager 5]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:25:32,460] INFO [Transaction Marker Channel Manager 5]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-07 19:25:32,461] INFO [TransactionCoordinator id=5] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-07 19:25:32,462] INFO [GroupCoordinator 5]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:25:32,462] INFO [ExpirationReaper-5-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,472] WARN Session 0x1000136dc780008 for sever localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x1000136dc780008, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-07 19:25:32,472] WARN Session 0x1000136dc780007 for sever localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x1000136dc780007, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-07 19:25:32,472] WARN Session 0x1000136dc780006 for sever localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x1000136dc780006, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-07 19:25:32,472] WARN Session 0x1000136dc780004 for sever localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x1000136dc780004, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-07 19:25:32,472] WARN Session 0x1000136dc780003 for sever localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x1000136dc780003, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-07 19:25:32,472] WARN Session 0x1000136dc780005 for sever localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x1000136dc780005, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-07 19:25:32,486] INFO [ExpirationReaper-4-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,486] INFO [ExpirationReaper-4-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,487] INFO [ExpirationReaper-4-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,589] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,589] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,590] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:25:32,591] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2022-05-07 19:25:32,591] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:25:32,591] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:25:32,591] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:25:32,592] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:32,595] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:32,595] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:32,596] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:32,596] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,612] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,612] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,612] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,612] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,613] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,614] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:25:32,614] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-05-07 19:25:32,614] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:25:32,615] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:25:32,615] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:25:32,615] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:32,616] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:32,616] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:32,616] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:32,616] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,618] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,618] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,618] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,655] INFO [ExpirationReaper-5-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,655] INFO [ExpirationReaper-5-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,656] INFO [ExpirationReaper-5-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,687] INFO [ExpirationReaper-4-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,687] INFO [ExpirationReaper-4-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,688] INFO [GroupCoordinator 4]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:25:32,690] INFO [ReplicaManager broker=4] Shutting down (kafka.server.ReplicaManager)
[2022-05-07 19:25:32,690] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:25:32,691] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:25:32,691] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:25:32,692] INFO [ReplicaFetcherManager on broker 4] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:32,695] INFO [ReplicaFetcherManager on broker 4] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:32,695] INFO [ReplicaAlterLogDirsManager on broker 4] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:32,696] INFO [ReplicaAlterLogDirsManager on broker 4] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:32,696] INFO [ExpirationReaper-4-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,706] INFO [ExpirationReaper-4-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,706] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,706] INFO [ExpirationReaper-4-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,706] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,706] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,706] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,707] INFO [ExpirationReaper-4-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,707] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,707] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,752] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,752] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,753] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,789] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,789] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,790] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:25:32,792] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-07 19:25:32,792] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:25:32,793] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:25:32,793] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:25:32,794] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:32,795] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:32,795] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:32,795] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:32,795] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,812] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,813] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,814] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:25:32,815] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-07 19:25:32,815] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:25:32,816] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:25:32,816] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:25:32,818] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:32,819] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:32,819] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:32,819] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:32,819] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,855] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,856] INFO [ExpirationReaper-5-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,856] INFO [ExpirationReaper-5-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,856] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,856] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,857] INFO [GroupCoordinator 5]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-07 19:25:32,858] INFO [ReplicaManager broker=5] Shutting down (kafka.server.ReplicaManager)
[2022-05-07 19:25:32,859] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:25:32,859] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:25:32,859] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-07 19:25:32,861] INFO [ReplicaFetcherManager on broker 5] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:32,863] INFO [ReplicaFetcherManager on broker 5] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-07 19:25:32,863] INFO [ReplicaAlterLogDirsManager on broker 5] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:32,863] INFO [ReplicaAlterLogDirsManager on broker 5] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-07 19:25:32,863] INFO [ExpirationReaper-5-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,889] INFO [ExpirationReaper-4-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,889] INFO [ExpirationReaper-4-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,890] INFO [ExpirationReaper-4-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,906] INFO [ExpirationReaper-5-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,906] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,906] INFO [ExpirationReaper-5-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,906] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,907] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,907] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,907] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,907] INFO [ExpirationReaper-5-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,908] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,909] INFO [ExpirationReaper-4-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,909] INFO [ExpirationReaper-4-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,909] INFO [ExpirationReaper-4-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,953] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,953] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,954] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,957] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,957] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:32,964] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-05-07 19:25:32,964] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:32,965] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:32,965] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:32,968] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-07 19:25:32,969] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:32,969] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:32,969] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:32,970] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-07 19:25:32,971] INFO Shutting down. (kafka.log.LogManager)
[2022-05-07 19:25:32,995] INFO [ProducerStateManager partition=__consumer_offsets-22] Wrote producer snapshot at offset 1492844 with 0 producer ids in 3 ms. (kafka.log.ProducerStateManager)
[2022-05-07 19:25:33,013] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,013] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,013] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,013] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,014] INFO [ExpirationReaper-3-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,014] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,014] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-07 19:25:33,022] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:25:33,023] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:25:33,023] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:25:33,024] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:25:33,056] INFO [ExpirationReaper-3-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,056] INFO [ExpirationReaper-3-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,062] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2022-05-07 19:25:33,063] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,063] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,063] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,066] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-07 19:25:33,067] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,068] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,068] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,069] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-07 19:25:33,070] INFO Shutting down. (kafka.log.LogManager)
[2022-05-07 19:25:33,076] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,076] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,077] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,089] INFO [ExpirationReaper-5-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,089] INFO [ExpirationReaper-4-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,089] INFO [ExpirationReaper-4-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,089] INFO [ExpirationReaper-5-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,090] INFO [ExpirationReaper-5-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,095] INFO [ReplicaManager broker=4] Shut down completely (kafka.server.ReplicaManager)
[2022-05-07 19:25:33,096] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,096] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,096] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,099] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-07 19:25:33,099] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-07 19:25:33,099] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,100] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,100] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,101] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-07 19:25:33,102] INFO Shutting down. (kafka.log.LogManager)
[2022-05-07 19:25:33,118] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:25:33,119] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:25:33,119] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:25:33,120] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:25:33,135] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-07 19:25:33,143] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:25:33,143] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:25:33,143] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:25:33,144] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:25:33,213] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,213] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,214] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,256] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,256] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,262] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-07 19:25:33,263] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,263] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,263] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,265] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-07 19:25:33,266] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,266] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,266] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,267] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-07 19:25:33,268] INFO Shutting down. (kafka.log.LogManager)
[2022-05-07 19:25:33,276] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,276] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,278] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,289] INFO [ExpirationReaper-5-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,289] INFO [ExpirationReaper-5-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,290] INFO [ExpirationReaper-5-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,302] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-07 19:25:33,314] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:25:33,314] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:25:33,314] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:25:33,316] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:25:33,476] INFO [ExpirationReaper-5-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,476] INFO [ExpirationReaper-5-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,476] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,476] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-07 19:25:33,483] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-07 19:25:33,484] INFO [ReplicaManager broker=5] Shut down completely (kafka.server.ReplicaManager)
[2022-05-07 19:25:33,484] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,485] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,485] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,485] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,485] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,485] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,488] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-07 19:25:33,488] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-07 19:25:33,489] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,489] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,490] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,490] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,490] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,490] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-07 19:25:33,491] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-07 19:25:33,491] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-07 19:25:33,492] INFO Shutting down. (kafka.log.LogManager)
[2022-05-07 19:25:33,492] INFO Shutting down. (kafka.log.LogManager)
[2022-05-07 19:25:33,523] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-07 19:25:33,523] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-07 19:25:33,532] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:25:33,532] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:25:33,532] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:25:33,533] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:25:33,534] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:25:33,534] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:25:33,534] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-07 19:25:33,535] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:25:33,579] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:25:33,579] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:25:33,580] WARN An exception was thrown while closing send thread for session 0x1000136dc780008. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-07 19:25:33,610] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:25:33,610] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:25:33,611] WARN An exception was thrown while closing send thread for session 0x1000136dc780003. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-07 19:25:33,682] INFO Session: 0x1000136dc780008 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:25:33,682] INFO EventThread shut down for session: 0x1000136dc780008 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:25:33,684] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:25:33,684] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:33,714] INFO Session: 0x1000136dc780003 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:25:33,714] INFO EventThread shut down for session: 0x1000136dc780003 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:25:33,715] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:25:33,715] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:33,910] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:33,910] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:33,910] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:34,049] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:25:34,049] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:25:34,051] WARN An exception was thrown while closing send thread for session 0x1000136dc780004. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-07 19:25:34,116] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:25:34,116] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:25:34,117] WARN An exception was thrown while closing send thread for session 0x1000136dc780006. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-07 19:25:34,153] INFO Session: 0x1000136dc780004 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:25:34,153] INFO EventThread shut down for session: 0x1000136dc780004 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:25:34,155] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:25:34,156] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:34,158] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:34,158] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:34,158] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:34,170] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:34,170] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:34,171] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:34,187] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:34,187] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:34,187] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:34,220] INFO Session: 0x1000136dc780006 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:25:34,220] INFO EventThread shut down for session: 0x1000136dc780006 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:25:34,222] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:25:34,222] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:34,447] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:25:34,447] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:25:34,448] WARN An exception was thrown while closing send thread for session 0x1000136dc780007. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-07 19:25:34,511] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:25:34,512] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:25:34,513] WARN An exception was thrown while closing send thread for session 0x1000136dc780005. (org.apache.zookeeper.ClientCnxn)
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-07 19:25:34,550] INFO Session: 0x1000136dc780007 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:25:34,550] INFO EventThread shut down for session: 0x1000136dc780007 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:25:34,552] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:25:34,553] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:34,617] INFO Session: 0x1000136dc780005 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-07 19:25:34,617] INFO EventThread shut down for session: 0x1000136dc780005 (org.apache.zookeeper.ClientCnxn)
[2022-05-07 19:25:34,619] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-07 19:25:34,619] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:34,705] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:34,705] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:34,705] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:34,910] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:34,910] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:34,910] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:34,976] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:34,976] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:34,976] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:35,158] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:35,158] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:35,158] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:35,169] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:35,169] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:35,170] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:35,170] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:35,171] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:35,171] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutting down socket server (kafka.network.SocketServer)
[2022-05-07 19:25:35,183] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:35,183] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:35,183] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:35,199] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutdown completed (kafka.network.SocketServer)
[2022-05-07 19:25:35,200] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:25:35,200] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:25:35,200] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:25:35,201] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-07 19:25:35,202] INFO App info kafka.server for 3 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:25:35,202] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2022-05-07 19:25:35,705] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:35,705] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:35,706] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:35,910] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:35,910] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:35,911] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:35,919] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:35,919] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:35,921] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-07 19:25:35,939] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-07 19:25:35,940] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:25:35,940] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:25:35,940] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:25:35,941] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-07 19:25:35,941] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:25:35,941] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-07 19:25:35,976] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:35,976] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:35,976] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:36,170] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:36,170] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:36,171] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:36,182] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:36,182] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:36,182] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:36,182] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:36,182] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:36,182] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:36,187] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:36,187] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:36,189] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutting down socket server (kafka.network.SocketServer)
[2022-05-07 19:25:36,209] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutdown completed (kafka.network.SocketServer)
[2022-05-07 19:25:36,209] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:25:36,209] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:25:36,209] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:25:36,210] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-07 19:25:36,210] INFO App info kafka.server for 4 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:25:36,211] INFO [KafkaServer id=4] shut down completed (kafka.server.KafkaServer)
[2022-05-07 19:25:36,705] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:36,705] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:36,705] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:36,707] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:36,708] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:36,710] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-05-07 19:25:36,735] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-05-07 19:25:36,736] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:25:36,736] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:25:36,736] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:25:36,738] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-07 19:25:36,739] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:25:36,739] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-05-07 19:25:36,976] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:36,976] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:36,976] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:37,179] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:37,179] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:37,181] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutting down socket server (kafka.network.SocketServer)
[2022-05-07 19:25:37,210] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutdown completed (kafka.network.SocketServer)
[2022-05-07 19:25:37,210] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:25:37,210] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:25:37,210] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:25:37,212] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-07 19:25:37,213] INFO App info kafka.server for 5 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:25:37,213] INFO [KafkaServer id=5] shut down completed (kafka.server.KafkaServer)
[2022-05-07 19:25:37,977] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:37,977] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-07 19:25:37,979] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-07 19:25:38,005] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-07 19:25:38,006] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:25:38,006] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:25:38,006] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-07 19:25:38,007] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-07 19:25:38,008] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-07 19:25:38,008] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
