[2022-05-15 23:15:03,712] INFO [GroupMetadataManager brokerId=3] Group consumer-group transitioned to Dead in generation 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:15:03,715] INFO [GroupCoordinator 3]: Removed 6 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:15:03,738] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:15:03,738] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:15:03,748] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:15:03,749] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:15:03,752] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 2751 due to node 2 being disconnected (elapsed time since creation: 229ms, elapsed time since send: 229ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:15:03,752] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1805435483, epoch=2751) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:15:03,757] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:15:03,757] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:15:03,763] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:15:03,763] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:15:03,764] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 2746 due to node 1 being disconnected (elapsed time since creation: 61ms, elapsed time since send: 61ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:15:03,764] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=496462258, epoch=2746) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:15:03,765] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:15:03,765] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:15:03,767] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:15:03,768] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:15:03,786] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-3/Sensor-2.cc97889eddb848648594c10d6d5586d7-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:15:03,790] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-3/Sensor-3.ddf3c7f5ba4f4cda9fa715e377bb6c9e-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:15:03,793] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-3/Sensor-1.5e9b29b7dbd645cf8d3b1743be71dc03-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:15:07,093] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:15:07,098] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:15:07,100] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:15:07,119] INFO [KafkaServer id=3] Controlled shutdown request returned successfully after 9ms (kafka.server.KafkaServer)
[2022-05-15 23:15:07,123] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:15:07,124] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:15:07,124] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:15:07,126] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:15:07,141] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:15:07,143] INFO [data-plane Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:15:07,155] INFO [data-plane Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:15:07,160] INFO [ExpirationReaper-3-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:07,240] INFO [ExpirationReaper-3-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:07,240] INFO [ExpirationReaper-3-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:07,241] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:15:07,243] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:07,309] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:07,309] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:07,313] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:15:07,315] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:15:07,315] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:15:07,316] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:15:07,316] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:15:07,318] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:15:07,319] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:15:07,319] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:07,391] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:07,391] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:07,392] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:07,507] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:07,507] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:07,509] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:15:07,510] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:15:07,511] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:15:07,511] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:15:07,511] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:15:07,512] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:15:07,514] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:15:07,514] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:15:07,515] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:15:07,515] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:07,648] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:07,648] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:07,648] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:07,814] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:07,814] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:07,814] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:07,996] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:07,996] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:07,997] INFO [ExpirationReaper-3-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:08,196] INFO [ExpirationReaper-3-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:08,196] INFO [ExpirationReaper-3-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:15:08,202] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:15:08,202] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:15:08,202] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:15:08,202] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:15:08,204] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:15:08,204] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:15:08,204] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:15:08,204] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:15:08,206] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:15:08,207] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:15:08,231] INFO [ProducerStateManager partition=__consumer_offsets-38] Wrote producer snapshot at offset 91906 with 0 producer ids in 3 ms. (kafka.log.ProducerStateManager)
[2022-05-15 23:15:08,248] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:15:08,259] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:15:08,259] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:15:08,259] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:15:08,261] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:15:08,264] WARN An exception was thrown while closing send thread for session 0x100000b00ad007b. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x100000b00ad007b, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 23:15:08,367] INFO Session: 0x100000b00ad007b closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:15:08,367] INFO EventThread shut down for session: 0x100000b00ad007b (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:15:08,370] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:15:08,370] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:15:08,699] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:15:08,699] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:15:08,699] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:15:08,700] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:15:08,700] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:15:08,701] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:15:08,709] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:15:08,709] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:15:08,709] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:15:09,699] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:15:09,699] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:15:09,702] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:15:09,728] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:15:09,728] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:15:09,729] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:15:09,729] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:15:09,730] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:15:09,731] INFO App info kafka.server for 3 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:15:09,731] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:25:51,093] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:25:51,104] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:25:51,105] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:25:51,105] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:25:51,105] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:25:51,107] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 23:25:51,107] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 23:25:51,107] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 23:25:51,107] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-15 23:25:51,111] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-15 23:25:51,127] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:25:51,127] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:25:51,128] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:25:51,128] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:25:51,128] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:25:51,128] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-15 23:25:51,144] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@6156496 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-15 23:25:51,148] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 23:25:51,166] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,166] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,166] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,166] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,166] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,166] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,166] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,166] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,166] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,166] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,168] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,168] INFO Server environment:host.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,168] INFO Server environment:java.version=11.0.15 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,168] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,168] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,168] INFO Server environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,168] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,168] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,168] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,168] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,168] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,169] INFO Server environment:os.version=5.13.0-40-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,169] INFO Server environment:user.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,169] INFO Server environment:user.home=/home/joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,169] INFO Server environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,169] INFO Server environment:os.memory.free=489MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,169] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,169] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,169] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,169] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,169] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,169] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,169] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,169] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,169] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,171] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-15 23:25:51,173] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,173] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,174] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 23:25:51,174] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 23:25:51,176] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:25:51,176] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:25:51,176] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:25:51,176] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:25:51,176] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:25:51,176] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:25:51,179] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,180] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,180] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:25:51,190] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 23:25:51,191] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 23:25:51,193] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 23:25:51,200] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 23:25:51,201] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:459)
	at java.base/sun.nio.ch.Net.bind(Net.java:448)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:676)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:158)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:112)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:67)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:140)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:90)
[2022-05-15 23:25:51,205] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-15 23:25:51,208] ERROR Exiting JVM with code 1 (org.apache.zookeeper.util.ServiceUtils)
[2022-05-15 23:25:56,076] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:25:56,380] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:25:56,472] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:25:56,475] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:25:56,476] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:25:56,492] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:25:56,496] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:25:56,496] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:25:56,496] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:25:56,496] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:25:56,496] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:25:56,496] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:25:56,497] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:25:56,497] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:25:56,497] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:25:56,497] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:25:56,497] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:25:56,497] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:25:56,497] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:25:56,497] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:25:56,498] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:25:56,498] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:25:56,498] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:25:56,498] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:25:56,500] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:25:56,505] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:25:56,510] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:25:56,527] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:25:56,538] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:25:56,540] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:25:56,546] INFO Socket connection established, initiating session, client: /127.0.0.1:58082, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:25:56,557] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad007e, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:25:56,563] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:25:56,659] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:25:56,820] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:25:56,827] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:25:56,879] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:25:56,892] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:25:56,955] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:25:56,957] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:25:56,961] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:25:56,963] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:25:57,011] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:25:57,016] INFO Skipping recovery for all logs in /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:25:57,096] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:25:57,126] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-2.44cdfc4b0705487ba315ffe94a55567d-delete, topicId=UMjsIZmlQHanX5LjYzg0Rw, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 92ms (1/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:25:57,145] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:25:57,151] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-21, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 24ms (2/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:25:57,158] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:25:57,163] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-4.e0372adf516d436f819a4745b68a127c-delete, topicId=UMjsIZmlQHanX5LjYzg0Rw, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (3/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:25:57,184] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 35579 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:25:57,184] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 35579 (kafka.log.UnifiedLog$)
[2022-05-15 23:25:57,186] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs/__consumer_offsets-39/00000000000000035579.snapshot,35579)' (kafka.log.ProducerStateManager)
[2022-05-15 23:25:57,192] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Producer state recovery took 7ms for snapshot load and 1ms for segment recovery from offset 35579 (kafka.log.UnifiedLog$)
[2022-05-15 23:25:57,198] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-39, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=35579) with 1 segments in 34ms (4/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:25:57,204] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:25:57,209] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-15, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (5/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:25:57,217] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:25:57,221] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-45, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (6/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:25:57,227] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:25:57,232] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-33, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (7/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:25:57,239] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:25:57,243] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-27, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (8/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:25:57,251] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:25:57,255] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-3, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (9/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:25:57,264] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:25:57,269] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-9, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (10/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:25:57,276] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:25:57,282] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-3.47b9a5921765492c813b12992672534f-delete, topicId=UMjsIZmlQHanX5LjYzg0Rw, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (11/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:25:57,287] INFO Loaded 11 logs in 275ms. (kafka.log.LogManager)
[2022-05-15 23:25:57,288] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:25:57,290] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:25:57,548] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:25:57,676] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:25:57,680] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-15 23:25:57,710] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:25:57,718] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:25:57,739] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:25:57,741] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:25:57,743] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:25:57,744] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:25:57,755] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:25:57,796] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:25:57,812] INFO Stat of the created znode at /brokers/ids/0 is: 6098,6098,1652653557805,1652653557805,1,0,0,72057641293906046,192,0,6098
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:25:57,813] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://joao:9092, czxid (broker epoch): 6098 (kafka.zk.KafkaZkClient)
[2022-05-15 23:25:57,865] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:25:57,869] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:25:57,870] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:25:57,884] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:25:57,897] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:25:57,922] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:25:57,927] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:25:57,927] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:25:57,955] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:25:57,974] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:25:57,995] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:25:58,001] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:25:58,002] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:25:58,008] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:25:58,008] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:25:58,008] INFO Kafka startTimeMs: 1652653558002 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:25:58,014] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-15 23:25:58,063] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:25:58,099] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-3, __consumer_offsets-15, __consumer_offsets-39, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:25:58,111] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:25:58,119] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:25:58,122] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 35579 (kafka.cluster.Partition)
[2022-05-15 23:25:58,122] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:25:58,122] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:25:58,124] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:25:58,126] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:25:58,129] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:25:58,132] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:25:58,139] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:25:58,141] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:25:58,143] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:25:58,143] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:25:58,144] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:25:58,144] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:25:58,144] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:25:58,144] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:25:58,144] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:25:58,144] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:25:58,144] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:25:58,144] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:25:58,144] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:25:58,144] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:25:58,144] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:25:58,144] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:25:58,155] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 13 milliseconds for epoch 36, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:25:58,156] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 12 milliseconds for epoch 36, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:25:58,264] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 120 milliseconds for epoch 36, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:25:58,265] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 121 milliseconds for epoch 36, of which 121 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:25:58,266] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 122 milliseconds for epoch 36, of which 122 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:25:58,266] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 122 milliseconds for epoch 36, of which 122 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:25:58,266] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 122 milliseconds for epoch 36, of which 122 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:25:58,266] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 122 milliseconds for epoch 36, of which 122 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:01,095] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:26:01,390] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:26:01,485] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:26:01,489] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:26:01,490] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:26:01,511] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:26:01,517] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:01,517] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:01,517] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:01,517] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:01,518] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:01,518] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:01,518] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:01,518] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:01,518] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:01,518] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:01,518] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:01,519] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:01,519] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:01,519] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:01,519] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:01,519] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:01,519] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:01,519] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:01,522] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:01,537] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:26:01,543] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:01,551] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:26:01,558] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:01,559] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:01,564] INFO Socket connection established, initiating session, client: /127.0.0.1:58084, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:01,573] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad007f, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:01,579] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:26:01,684] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:26:01,819] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:26:01,828] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:26:01,904] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:26:01,919] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:26:01,987] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:26:01,990] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:26:01,993] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:26:01,996] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:26:02,044] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:26:02,048] INFO Skipping recovery for all logs in /tmp/kafka-logs-1 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:26:02,127] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:02,150] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-17, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 82ms (1/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:26:02,157] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:02,160] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-35, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (2/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:26:02,166] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:02,171] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-41, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (3/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:26:02,177] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:02,180] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-1.d37e52900bea43bc8d4a48e3839c92d8-delete, topicId=UMjsIZmlQHanX5LjYzg0Rw, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (4/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:26:02,186] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:02,190] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-29, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (5/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:26:02,197] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:02,200] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-11, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (6/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:26:02,206] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:02,209] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-23, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (7/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:26:02,215] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:02,219] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-0.231aba50860f482f9abbf833e8cdaa75-delete, topicId=UMjsIZmlQHanX5LjYzg0Rw, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (8/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:26:02,224] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:02,227] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-5.76c50b7ecd784f4499a841ea829e116d-delete, topicId=UMjsIZmlQHanX5LjYzg0Rw, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (9/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:26:02,234] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:02,236] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-47, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (10/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:26:02,243] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:02,247] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-5, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (11/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:26:02,251] INFO Loaded 11 logs in 207ms. (kafka.log.LogManager)
[2022-05-15 23:26:02,253] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:26:02,255] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:26:02,516] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:26:02,644] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:26:02,647] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-15 23:26:02,674] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:26:02,680] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:26:02,695] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:02,696] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:02,698] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:02,699] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:02,710] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:26:02,769] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:26:02,788] INFO Stat of the created znode at /brokers/ids/1 is: 6158,6158,1652653562777,1652653562777,1,0,0,72057641293906047,192,0,6158
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:26:02,788] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://joao:9093, czxid (broker epoch): 6158 (kafka.zk.KafkaZkClient)
[2022-05-15 23:26:02,856] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:02,860] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:02,861] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:02,874] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:02,883] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:02,901] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:26:02,910] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:26:02,910] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:26:02,932] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:02,947] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:26:02,965] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:26:02,970] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:26:02,970] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:26:02,974] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:26:02,974] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:26:02,974] INFO Kafka startTimeMs: 1652653562970 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:26:02,976] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-15 23:26:03,031] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:26:03,061] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:03,061] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:03,062] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:03,062] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:03,063] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:03,063] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:03,063] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:03,064] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:03,083] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:26:03,090] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-5, __consumer_offsets-29, __consumer_offsets-41, __consumer_offsets-23) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:26:03,118] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 63 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:03,120] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 63 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:03,122] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 63 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:03,122] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 63 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:03,122] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 63 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:03,122] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 63 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:03,122] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 63 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:03,122] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 63 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:03,122] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 63 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:03,122] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 63 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:03,122] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 63 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:03,122] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 63 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:03,122] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 63 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:03,122] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 63 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:03,122] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 63 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:03,123] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 63 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:03,129] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 8 milliseconds for epoch 63, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:03,130] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 8 milliseconds for epoch 63, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:03,131] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 9 milliseconds for epoch 63, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:03,131] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 9 milliseconds for epoch 63, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:03,131] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 9 milliseconds for epoch 63, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:03,132] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 10 milliseconds for epoch 63, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:03,132] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 10 milliseconds for epoch 63, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:03,132] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 9 milliseconds for epoch 63, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:06,108] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:26:06,430] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:26:06,537] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:26:06,542] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:26:06,543] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:26:06,562] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:26:06,567] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:06,567] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:06,567] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:06,568] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:06,568] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:06,568] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:06,569] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:06,569] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:06,569] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:06,569] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:06,569] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:06,570] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:06,570] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:06,570] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:06,570] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:06,570] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:06,570] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:06,570] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:06,574] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:06,592] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:26:06,597] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:06,605] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:26:06,612] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:06,613] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:06,618] INFO Socket connection established, initiating session, client: /127.0.0.1:58086, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:06,629] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0080, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:06,636] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:26:06,737] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:26:06,885] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:26:06,893] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:26:06,958] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:26:06,974] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:26:07,039] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:26:07,040] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:26:07,044] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:26:07,046] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:26:07,099] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:26:07,105] INFO Skipping recovery for all logs in /tmp/kafka-logs-2 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:26:07,194] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:07,223] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-2.df6e38726d8845e88277468bb686bdae-delete, topicId=UMjsIZmlQHanX5LjYzg0Rw, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 96ms (1/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:26:07,229] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:07,233] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-0.1afde42cdf224fe78fca197ff7a64951-delete, topicId=UMjsIZmlQHanX5LjYzg0Rw, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (2/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:26:07,249] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:07,254] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-49, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 20ms (3/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:26:07,259] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:07,264] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-19, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (4/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:26:07,269] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:07,272] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-7, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:26:07,278] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:07,281] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-13, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:26:07,287] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:07,290] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-37, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:26:07,295] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:07,299] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-43, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (8/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:26:07,306] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:07,310] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-1, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (9/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:26:07,315] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:07,320] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-1.88a5bdbe37794583b61cda596745221e-delete, topicId=UMjsIZmlQHanX5LjYzg0Rw, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (10/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:26:07,327] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:07,331] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-31, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (11/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:26:07,338] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:07,341] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-25, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (12/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:26:07,346] INFO Loaded 12 logs in 247ms. (kafka.log.LogManager)
[2022-05-15 23:26:07,348] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:26:07,350] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:26:07,577] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:26:07,702] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:26:07,705] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-15 23:26:07,729] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:26:07,735] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:26:07,752] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:07,753] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:07,755] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:07,756] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:07,766] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:26:07,815] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:26:07,834] INFO Stat of the created znode at /brokers/ids/2 is: 6182,6182,1652653567823,1652653567823,1,0,0,72057641293906048,192,0,6182
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:26:07,835] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://joao:9094, czxid (broker epoch): 6182 (kafka.zk.KafkaZkClient)
[2022-05-15 23:26:07,895] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:07,902] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:07,903] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:07,916] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:07,927] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:07,946] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:26:07,955] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:26:07,955] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:26:07,976] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:07,992] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:26:08,012] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:26:08,018] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:26:08,018] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:26:08,024] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:26:08,024] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:26:08,024] INFO Kafka startTimeMs: 1652653568018 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:26:08,026] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-15 23:26:08,088] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:26:08,117] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:08,118] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:08,118] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:08,119] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:08,119] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:08,119] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:08,119] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:08,119] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:08,119] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:08,142] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:26:08,148] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-7, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:26:08,180] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 63 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:08,182] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 63 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:08,183] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 63 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:08,183] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 63 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:08,183] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 63 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:08,183] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 63 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:08,184] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 63 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:08,184] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 63 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:08,184] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 63 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:08,184] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 63 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:08,184] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 63 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:08,184] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 63 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:08,184] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 63 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:08,184] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 63 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:08,184] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 63 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:08,184] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 63 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:08,184] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 63 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:08,184] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 63 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:08,190] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 7 milliseconds for epoch 63, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:08,191] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 8 milliseconds for epoch 63, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:08,191] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 7 milliseconds for epoch 63, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:08,192] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 7 milliseconds for epoch 63, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:08,192] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 8 milliseconds for epoch 63, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:08,192] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 8 milliseconds for epoch 63, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:08,192] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 8 milliseconds for epoch 63, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:08,192] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 8 milliseconds for epoch 63, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:08,192] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 8 milliseconds for epoch 63, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:11,167] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:26:11,483] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:26:11,587] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:26:11,592] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:26:11,593] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:26:11,611] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:26:11,616] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:11,617] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:11,617] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:11,617] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:11,617] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:11,617] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:11,617] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:11,617] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:11,617] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:11,617] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:11,618] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:11,618] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:11,618] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:11,618] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:11,618] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:11,618] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:11,618] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:11,618] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:11,620] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:11,625] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:26:11,644] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:11,650] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:26:11,661] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:11,663] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:11,668] INFO Socket connection established, initiating session, client: /127.0.0.1:58088, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:11,679] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0081, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:11,686] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:26:11,788] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:26:11,939] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:26:11,947] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:26:12,024] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:26:12,039] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:26:12,104] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:26:12,106] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:26:12,109] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:26:12,112] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:26:12,163] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:26:12,168] INFO Skipping recovery for all logs in /tmp/kafka-logs-3 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:26:12,236] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:12,256] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-14, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 69ms (1/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:26:12,272] INFO Deleted producer state snapshot /tmp/kafka-logs-3/__consumer_offsets-38/00000000000000085518.snapshot (kafka.log.SnapshotFile)
[2022-05-15 23:26:12,274] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Loading producer state till offset 91906 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:12,274] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Reloading from producer snapshot and rebuilding producer state from offset 91906 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:12,275] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-3/__consumer_offsets-38/00000000000000091906.snapshot,91906)' (kafka.log.ProducerStateManager)
[2022-05-15 23:26:12,281] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 91906 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:12,284] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-38, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=91906) with 1 segments in 27ms (2/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:26:12,289] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:12,293] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-1.5e9b29b7dbd645cf8d3b1743be71dc03-delete, topicId=UMjsIZmlQHanX5LjYzg0Rw, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (3/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:26:12,299] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:12,302] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-8, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:26:12,307] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:12,310] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-2, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:26:12,314] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:12,317] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-3.ddf3c7f5ba4f4cda9fa715e377bb6c9e-delete, topicId=UMjsIZmlQHanX5LjYzg0Rw, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:26:12,321] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:12,324] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-2.cc97889eddb848648594c10d6d5586d7-delete, topicId=UMjsIZmlQHanX5LjYzg0Rw, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:26:12,329] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:12,333] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-26, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (8/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:26:12,337] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:12,340] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-20, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (9/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:26:12,344] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:12,347] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-32, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:26:12,351] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:12,353] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-44, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (11/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:26:12,356] INFO Loaded 11 logs in 193ms. (kafka.log.LogManager)
[2022-05-15 23:26:12,357] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:26:12,358] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:26:12,570] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:26:12,685] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:26:12,688] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-05-15 23:26:12,713] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:26:12,719] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:26:12,735] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:12,736] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:12,738] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:12,739] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:12,751] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:26:12,807] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:26:12,824] INFO Stat of the created znode at /brokers/ids/3 is: 6207,6207,1652653572817,1652653572817,1,0,0,72057641293906049,192,0,6207
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:26:12,826] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://joao:9095, czxid (broker epoch): 6207 (kafka.zk.KafkaZkClient)
[2022-05-15 23:26:12,893] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:12,898] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:12,899] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:12,915] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:12,936] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:12,949] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:26:12,953] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:26:12,954] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:26:12,976] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:12,992] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:26:13,011] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:26:13,016] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:26:13,016] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:26:13,021] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:26:13,021] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:26:13,021] INFO Kafka startTimeMs: 1652653573017 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:26:13,023] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-05-15 23:26:13,122] INFO [Partition __consumer_offsets-2 broker=3] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:13,123] INFO [Partition __consumer_offsets-20 broker=3] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:13,123] INFO [Partition __consumer_offsets-38 broker=3] Log loaded for partition __consumer_offsets-38 with initial high watermark 91906 (kafka.cluster.Partition)
[2022-05-15 23:26:13,123] INFO [Partition __consumer_offsets-8 broker=3] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:13,123] INFO [Partition __consumer_offsets-26 broker=3] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:13,123] INFO [Partition __consumer_offsets-44 broker=3] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:13,124] INFO [Partition __consumer_offsets-14 broker=3] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:13,124] INFO [Partition __consumer_offsets-32 broker=3] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:13,126] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:26:13,151] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-26, __consumer_offsets-32, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:26:13,180] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:26:13,184] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 2 in epoch 58 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:13,185] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 58 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:13,187] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 20 in epoch 58 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:13,187] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 58 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:13,188] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 38 in epoch 58 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:13,188] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 58 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:13,188] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 8 in epoch 58 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:13,188] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 58 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:13,188] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 26 in epoch 58 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:13,188] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 58 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:13,188] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 44 in epoch 58 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:13,188] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 58 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:13,189] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 14 in epoch 58 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:13,189] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 58 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:13,189] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 32 in epoch 58 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:13,189] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 58 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:13,195] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-2 in 8 milliseconds for epoch 58, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:13,196] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-20 in 8 milliseconds for epoch 58, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:13,335] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-38 in 147 milliseconds for epoch 58, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:13,335] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-8 in 147 milliseconds for epoch 58, of which 147 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:13,335] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-26 in 147 milliseconds for epoch 58, of which 147 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:13,336] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-44 in 148 milliseconds for epoch 58, of which 148 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:13,336] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-14 in 147 milliseconds for epoch 58, of which 147 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:13,336] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-32 in 147 milliseconds for epoch 58, of which 147 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:16,096] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:26:16,411] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:26:16,514] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:26:16,519] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:26:16,520] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:26:16,537] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:26:16,543] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:16,543] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:16,543] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:16,543] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:16,543] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:16,543] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:16,543] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:16,543] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:16,544] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:16,544] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:16,544] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:16,544] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:16,544] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:16,544] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:16,544] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:16,544] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:16,544] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:16,544] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:16,547] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:16,553] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:26:16,560] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:16,577] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:26:16,585] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:16,587] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:16,592] INFO Socket connection established, initiating session, client: /127.0.0.1:58090, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:16,603] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0082, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:16,609] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:26:16,703] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:26:16,839] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:26:16,843] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:26:16,886] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:26:16,895] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:26:16,940] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:26:16,942] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:26:16,944] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:26:16,946] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:26:16,983] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:26:16,986] INFO Skipping recovery for all logs in /tmp/kafka-logs-4 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:26:17,059] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:17,079] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-24, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 79ms (1/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:26:17,084] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:17,087] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-0.6d5656aa768548d0bb3e525e0fca9068-delete, topicId=UMjsIZmlQHanX5LjYzg0Rw, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (2/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:26:17,091] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:17,097] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-12, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (3/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:26:17,102] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:17,106] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-5.48fa72cb30444fe5b8bcdaa5c841e956-delete, topicId=UMjsIZmlQHanX5LjYzg0Rw, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (4/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:26:17,110] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:17,113] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-30, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:26:17,119] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:17,121] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-36, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:26:17,125] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:17,128] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-42, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:26:17,133] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:17,136] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-0, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:26:17,141] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:17,142] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-18, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (9/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:26:17,147] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:17,149] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-4.84519c0bc1754c1b9a44468911d4e091-delete, topicId=UMjsIZmlQHanX5LjYzg0Rw, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (10/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:26:17,154] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:17,155] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-6, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (11/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:26:17,161] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:17,163] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-48, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (12/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:26:17,165] INFO Loaded 12 logs in 182ms. (kafka.log.LogManager)
[2022-05-15 23:26:17,167] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:26:17,168] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:26:17,402] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:26:17,533] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:26:17,537] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.Acceptor)
[2022-05-15 23:26:17,565] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:26:17,575] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:26:17,593] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:17,595] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:17,596] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:17,598] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:17,610] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:26:17,660] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:26:17,678] INFO Stat of the created znode at /brokers/ids/4 is: 6231,6231,1652653577669,1652653577669,1,0,0,72057641293906050,192,0,6231
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:26:17,680] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://joao:9096, czxid (broker epoch): 6231 (kafka.zk.KafkaZkClient)
[2022-05-15 23:26:17,744] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:17,751] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:17,752] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:17,765] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:17,776] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:17,790] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:26:17,795] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:26:17,795] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:26:17,828] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:17,843] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:26:17,861] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:26:17,866] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:26:17,866] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:26:17,870] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:26:17,871] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:26:17,871] INFO Kafka startTimeMs: 1652653577866 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:26:17,873] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2022-05-15 23:26:17,971] INFO [Partition __consumer_offsets-18 broker=4] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:17,972] INFO [Partition __consumer_offsets-36 broker=4] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:17,972] INFO [Partition __consumer_offsets-6 broker=4] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:17,972] INFO [Partition __consumer_offsets-24 broker=4] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:17,972] INFO [Partition __consumer_offsets-42 broker=4] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:17,972] INFO [Partition __consumer_offsets-12 broker=4] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:17,973] INFO [Partition __consumer_offsets-30 broker=4] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:17,973] INFO [Partition __consumer_offsets-0 broker=4] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:17,973] INFO [Partition __consumer_offsets-48 broker=4] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:17,980] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:26:18,001] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-12, __consumer_offsets-42, __consumer_offsets-18) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:26:18,013] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:26:18,034] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 18 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:18,036] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:18,038] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 36 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:18,038] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:18,038] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 6 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:18,038] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:18,038] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 24 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:18,038] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:18,038] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 42 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:18,038] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:18,039] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 12 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:18,039] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:18,039] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 30 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:18,039] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:18,039] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 0 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:18,039] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:18,039] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 48 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:18,039] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:18,046] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-18 in 9 milliseconds for epoch 66, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:18,047] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-36 in 9 milliseconds for epoch 66, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:18,047] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-6 in 9 milliseconds for epoch 66, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:18,047] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-24 in 9 milliseconds for epoch 66, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:18,048] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-42 in 10 milliseconds for epoch 66, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:18,048] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-12 in 9 milliseconds for epoch 66, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:18,048] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-30 in 9 milliseconds for epoch 66, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:18,048] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-0 in 9 milliseconds for epoch 66, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:18,048] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-48 in 9 milliseconds for epoch 66, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:21,147] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:26:21,461] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:26:21,560] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:26:21,564] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:26:21,565] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:26:21,586] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:26:21,591] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:21,591] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:21,591] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:21,591] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:21,591] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:21,591] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:21,592] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:21,592] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:21,592] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:21,592] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:21,592] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:21,592] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:21,592] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:21,592] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:21,592] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:21,592] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:21,592] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:21,592] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:21,595] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:26:21,612] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:26:21,618] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:21,627] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:26:21,634] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:21,636] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:21,641] INFO Socket connection established, initiating session, client: /127.0.0.1:58092, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:21,650] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0083, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:26:21,657] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:26:21,763] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:26:21,888] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:26:21,894] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:26:21,937] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:26:21,945] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:26:21,987] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:26:21,988] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:26:21,990] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:26:21,992] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:26:22,024] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:26:22,028] INFO Skipping recovery for all logs in /tmp/kafka-logs-5 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:26:22,084] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:22,106] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-3.734631a469c14e5481d8cb064fe59a8f-delete, topicId=UMjsIZmlQHanX5LjYzg0Rw, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 65ms (1/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:26:22,118] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:22,122] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-46, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (2/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:26:22,127] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:22,130] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-10, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (3/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:26:22,134] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:22,137] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-4.e4b95cf71e154d589a89ceb5b69c299c-delete, topicId=UMjsIZmlQHanX5LjYzg0Rw, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:26:22,141] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:22,144] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-28, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:26:22,149] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:22,151] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-5.09bb27094fe948aca45139e1daf7caf3-delete, topicId=UMjsIZmlQHanX5LjYzg0Rw, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (6/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:26:22,167] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Loading producer state till offset 49539 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:22,167] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 49539 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:22,168] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-22/00000000000000049539.snapshot,49539)' (kafka.log.ProducerStateManager)
[2022-05-15 23:26:22,173] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 49539 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:22,175] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-22, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=49539) with 1 segments in 24ms (7/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:26:22,180] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:22,183] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-16, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (8/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:26:22,191] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Loading producer state till offset 35134 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:22,191] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 35134 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:22,192] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-40/00000000000000035134.snapshot,35134)' (kafka.log.ProducerStateManager)
[2022-05-15 23:26:22,192] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 35134 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:22,194] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-40, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=35134) with 1 segments in 11ms (9/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:26:22,199] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:22,202] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-34, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:26:22,206] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:22,209] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-4, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (11/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:26:22,212] INFO Loaded 11 logs in 187ms. (kafka.log.LogManager)
[2022-05-15 23:26:22,213] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:26:22,215] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:26:22,435] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:26:22,532] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:26:22,535] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.Acceptor)
[2022-05-15 23:26:22,560] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:26:22,566] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:26:22,581] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:22,583] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:22,584] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:22,586] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:22,597] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:26:22,651] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:26:22,669] INFO Stat of the created znode at /brokers/ids/5 is: 6256,6256,1652653582661,1652653582661,1,0,0,72057641293906051,192,0,6256
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:26:22,670] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://joao:9097, czxid (broker epoch): 6256 (kafka.zk.KafkaZkClient)
[2022-05-15 23:26:22,731] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:22,735] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:22,736] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:22,749] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:22,771] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:22,785] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:26:22,789] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:26:22,789] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:26:22,812] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:26:22,830] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:26:22,851] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:26:22,856] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:26:22,856] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:26:22,861] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:26:22,861] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:26:22,861] INFO Kafka startTimeMs: 1652653582856 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:26:22,864] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2022-05-15 23:26:22,945] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:26:22,952] INFO [Partition __consumer_offsets-34 broker=5] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:22,953] INFO [Partition __consumer_offsets-4 broker=5] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:22,953] INFO [Partition __consumer_offsets-22 broker=5] Log loaded for partition __consumer_offsets-22 with initial high watermark 49539 (kafka.cluster.Partition)
[2022-05-15 23:26:22,953] INFO [Partition __consumer_offsets-40 broker=5] Log loaded for partition __consumer_offsets-40 with initial high watermark 35134 (kafka.cluster.Partition)
[2022-05-15 23:26:22,953] INFO [Partition __consumer_offsets-10 broker=5] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:22,953] INFO [Partition __consumer_offsets-28 broker=5] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:22,953] INFO [Partition __consumer_offsets-46 broker=5] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:22,954] INFO [Partition __consumer_offsets-16 broker=5] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:22,970] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:26:22,976] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:26:23,006] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 34 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:23,008] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:23,009] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 4 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:23,009] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:23,009] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 22 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:23,009] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:23,009] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 40 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:23,009] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:23,010] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 10 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:23,010] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:23,010] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 28 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:23,010] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:23,010] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 46 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:23,010] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:23,010] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 16 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:23,010] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:23,016] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-34 in 7 milliseconds for epoch 69, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:23,016] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-4 in 7 milliseconds for epoch 69, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:23,037] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-9fa5abef-fdc9-4c05-8f09-7f9780632837, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:26:23,047] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-ed3a6d0d-54c4-4b54-b4a4-a5d0ecba6f8e, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:26:23,047] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-1038faf2-d998-4707-9799-897de83d6136, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:26:23,047] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-b283a5ee-70be-4bf9-b41c-74e089f12e34, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:26:23,047] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-360d1581-f79b-41e6-82d3-fe3577615014, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:26:23,047] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-9e173d1e-b47a-4b16-9874-bf5d2688c730, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:26:23,048] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-81fafa38-80dc-43ea-ac6c-e398b06565dc, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:26:23,077] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-d15976bc-df63-4682-8583-fd67cbb1d9df, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:26:23,077] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-a0d7c5c7-e384-4339-b0be-414878362e3e, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:26:23,077] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-ee781f71-f1c3-46d7-bd93-d90a4fe359ff, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:26:23,077] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-78575c72-7be8-4563-b114-53b271a8ef70, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:26:23,077] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-0287b15c-1acd-4475-b9ce-b994aebeeff2, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:26:23,078] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-45d54f6e-f1d8-43f7-8ace-1db96ac0cfac, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:26:23,128] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-954ef0dc-d124-405b-9bb6-119086dd08c0, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:26:23,129] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-3f51cd43-28ab-4459-969e-211543e6cd72, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:26:23,130] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-4b8634e2-92f3-4603-97c5-35df7219bd84, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 4. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:26:23,131] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-5f6ccebb-0352-4648-b98e-7613d791d352, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:26:23,144] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-22 in 135 milliseconds for epoch 69, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:23,176] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-40 in 167 milliseconds for epoch 69, of which 135 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:23,177] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-10 in 167 milliseconds for epoch 69, of which 167 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:23,178] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-28 in 168 milliseconds for epoch 69, of which 167 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:23,178] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-46 in 168 milliseconds for epoch 69, of which 168 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:23,179] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-16 in 169 milliseconds for epoch 69, of which 169 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:26:26,895] INFO Creating topic Sensor with configuration {min.insync.replicas=2} and initial partition assignment HashMap(0 -> ArrayBuffer(5, 4, 1)) (kafka.zk.AdminZkClient)
[2022-05-15 23:26:26,947] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:26:26,963] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:26,963] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:26,965] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:26:26,969] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-5/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:26:26,970] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-1/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:26:26,971] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-4/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:26:26,971] INFO [Partition Sensor-0 broker=5] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 23:26:26,972] INFO [Partition Sensor-0 broker=5] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:26,972] INFO [Partition Sensor-0 broker=1] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 23:26:26,972] INFO [Partition Sensor-0 broker=1] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:26,972] INFO [Partition Sensor-0 broker=4] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 23:26:26,973] INFO [Partition Sensor-0 broker=4] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:26:26,973] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:26:26,974] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:26:26,995] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:26:26,995] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:26:27,000] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 5 for partitions Map(Sensor-0 -> InitialFetchState(Some(sBeweSu0QKaG2aTZmcraTw),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:26:27,000] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 5 for partitions Map(Sensor-0 -> InitialFetchState(Some(sBeweSu0QKaG2aTZmcraTw),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:26:27,002] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:26:27,002] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:26:27,003] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:26:27,004] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:26:36,524] INFO [GroupCoordinator 5]: Dynamic member with unknown member id joins group consumer in Empty state. Created a new member id consumer-consumer-1-8863ee28-05fa-4d10-b813-b83668f9ecf8 and request the member to rejoin with this id. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:36,544] INFO [GroupCoordinator 5]: Preparing to rebalance group consumer in state PreparingRebalance with old generation 0 (__consumer_offsets-22) (reason: Adding new member consumer-consumer-1-8863ee28-05fa-4d10-b813-b83668f9ecf8 with group instance id None) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:36,558] INFO [GroupCoordinator 5]: Stabilized group consumer generation 1 (__consumer_offsets-22) with 1 members (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:36,589] INFO [GroupCoordinator 5]: Assignment received from leader consumer-consumer-1-8863ee28-05fa-4d10-b813-b83668f9ecf8 for group consumer for generation 1. The group has 1 members, 0 of which are static. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:26:57,129] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=65119, lastModifiedTime=1652651779155, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:26:57,132] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=65119, lastModifiedTime=1652651779155, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:26:57,136] INFO Deleted log /tmp/kafka-logs/Sensor-2.44cdfc4b0705487ba315ffe94a55567d-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:26:57,137] INFO Deleted offset index /tmp/kafka-logs/Sensor-2.44cdfc4b0705487ba315ffe94a55567d-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:26:57,141] INFO Deleted time index /tmp/kafka-logs/Sensor-2.44cdfc4b0705487ba315ffe94a55567d-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:26:57,148] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs/Sensor-2.44cdfc4b0705487ba315ffe94a55567d-delete. (kafka.log.LogManager)
[2022-05-15 23:26:57,164] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=40286, lastModifiedTime=1652651788039, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:26:57,165] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=40286, lastModifiedTime=1652651788039, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:26:57,167] INFO Deleted log /tmp/kafka-logs/Sensor-4.e0372adf516d436f819a4745b68a127c-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:26:57,167] INFO Deleted offset index /tmp/kafka-logs/Sensor-4.e0372adf516d436f819a4745b68a127c-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:26:57,168] INFO Deleted time index /tmp/kafka-logs/Sensor-4.e0372adf516d436f819a4745b68a127c-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:26:57,168] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs/Sensor-4.e0372adf516d436f819a4745b68a127c-delete. (kafka.log.LogManager)
[2022-05-15 23:26:57,283] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=77591, lastModifiedTime=1652651794099, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:26:57,284] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=77591, lastModifiedTime=1652651794099, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:26:57,285] INFO Deleted log /tmp/kafka-logs/Sensor-3.47b9a5921765492c813b12992672534f-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:26:57,285] INFO Deleted offset index /tmp/kafka-logs/Sensor-3.47b9a5921765492c813b12992672534f-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:26:57,285] INFO Deleted time index /tmp/kafka-logs/Sensor-3.47b9a5921765492c813b12992672534f-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:26:57,286] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs/Sensor-3.47b9a5921765492c813b12992672534f-delete. (kafka.log.LogManager)
[2022-05-15 23:27:02,186] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=63787, lastModifiedTime=1652651790435, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:27:02,190] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=63787, lastModifiedTime=1652651790435, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:27:02,197] INFO Deleted log /tmp/kafka-logs-1/Sensor-1.d37e52900bea43bc8d4a48e3839c92d8-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:02,197] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-1.d37e52900bea43bc8d4a48e3839c92d8-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:02,202] INFO Deleted time index /tmp/kafka-logs-1/Sensor-1.d37e52900bea43bc8d4a48e3839c92d8-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:02,211] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-1/Sensor-1.d37e52900bea43bc8d4a48e3839c92d8-delete. (kafka.log.LogManager)
[2022-05-15 23:27:02,219] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=75943, lastModifiedTime=1652651794087, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:27:02,219] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=75943, lastModifiedTime=1652651794087, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:27:02,220] INFO Deleted log /tmp/kafka-logs-1/Sensor-0.231aba50860f482f9abbf833e8cdaa75-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:02,221] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-0.231aba50860f482f9abbf833e8cdaa75-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:02,221] INFO Deleted time index /tmp/kafka-logs-1/Sensor-0.231aba50860f482f9abbf833e8cdaa75-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:02,222] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-1/Sensor-0.231aba50860f482f9abbf833e8cdaa75-delete. (kafka.log.LogManager)
[2022-05-15 23:27:02,228] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=43079, lastModifiedTime=1652651775871, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:27:02,229] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=43079, lastModifiedTime=1652651775871, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:27:02,231] INFO Deleted log /tmp/kafka-logs-1/Sensor-5.76c50b7ecd784f4499a841ea829e116d-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:02,231] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-5.76c50b7ecd784f4499a841ea829e116d-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:02,231] INFO Deleted time index /tmp/kafka-logs-1/Sensor-5.76c50b7ecd784f4499a841ea829e116d-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:02,232] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-1/Sensor-5.76c50b7ecd784f4499a841ea829e116d-delete. (kafka.log.LogManager)
[2022-05-15 23:27:07,227] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=65119, lastModifiedTime=1652651779155, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:27:07,230] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=65119, lastModifiedTime=1652651779155, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:27:07,235] INFO Deleted log /tmp/kafka-logs-2/Sensor-2.df6e38726d8845e88277468bb686bdae-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:07,237] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-2.df6e38726d8845e88277468bb686bdae-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:07,241] INFO Deleted time index /tmp/kafka-logs-2/Sensor-2.df6e38726d8845e88277468bb686bdae-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:07,251] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-2/Sensor-2.df6e38726d8845e88277468bb686bdae-delete. (kafka.log.LogManager)
[2022-05-15 23:27:07,252] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=75943, lastModifiedTime=1652651794083, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:27:07,253] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=75943, lastModifiedTime=1652651794083, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:27:07,254] INFO Deleted log /tmp/kafka-logs-2/Sensor-0.1afde42cdf224fe78fca197ff7a64951-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:07,255] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-0.1afde42cdf224fe78fca197ff7a64951-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:07,255] INFO Deleted time index /tmp/kafka-logs-2/Sensor-0.1afde42cdf224fe78fca197ff7a64951-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:07,256] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-2/Sensor-0.1afde42cdf224fe78fca197ff7a64951-delete. (kafka.log.LogManager)
[2022-05-15 23:27:07,321] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=63787, lastModifiedTime=1652651790435, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:27:07,321] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=63787, lastModifiedTime=1652651790435, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:27:07,323] INFO Deleted log /tmp/kafka-logs-2/Sensor-1.88a5bdbe37794583b61cda596745221e-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:07,323] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-1.88a5bdbe37794583b61cda596745221e-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:07,323] INFO Deleted time index /tmp/kafka-logs-2/Sensor-1.88a5bdbe37794583b61cda596745221e-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:07,324] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-2/Sensor-1.88a5bdbe37794583b61cda596745221e-delete. (kafka.log.LogManager)
[2022-05-15 23:27:12,296] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=63787, lastModifiedTime=1652651790435, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:27:12,298] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=63787, lastModifiedTime=1652651790435, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:27:12,307] INFO Deleted log /tmp/kafka-logs-3/Sensor-1.5e9b29b7dbd645cf8d3b1743be71dc03-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:12,307] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-1.5e9b29b7dbd645cf8d3b1743be71dc03-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:12,311] INFO Deleted time index /tmp/kafka-logs-3/Sensor-1.5e9b29b7dbd645cf8d3b1743be71dc03-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:12,319] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-3/Sensor-1.5e9b29b7dbd645cf8d3b1743be71dc03-delete. (kafka.log.LogManager)
[2022-05-15 23:27:12,320] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=77591, lastModifiedTime=1652651794095, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:27:12,320] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=77591, lastModifiedTime=1652651794095, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:27:12,321] INFO Deleted log /tmp/kafka-logs-3/Sensor-3.ddf3c7f5ba4f4cda9fa715e377bb6c9e-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:12,321] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-3.ddf3c7f5ba4f4cda9fa715e377bb6c9e-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:12,322] INFO Deleted time index /tmp/kafka-logs-3/Sensor-3.ddf3c7f5ba4f4cda9fa715e377bb6c9e-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:12,322] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-3/Sensor-3.ddf3c7f5ba4f4cda9fa715e377bb6c9e-delete. (kafka.log.LogManager)
[2022-05-15 23:27:12,325] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=65119, lastModifiedTime=1652651779155, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:27:12,326] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=65119, lastModifiedTime=1652651779155, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:27:12,327] INFO Deleted log /tmp/kafka-logs-3/Sensor-2.cc97889eddb848648594c10d6d5586d7-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:12,327] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-2.cc97889eddb848648594c10d6d5586d7-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:12,327] INFO Deleted time index /tmp/kafka-logs-3/Sensor-2.cc97889eddb848648594c10d6d5586d7-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:12,327] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-3/Sensor-2.cc97889eddb848648594c10d6d5586d7-delete. (kafka.log.LogManager)
[2022-05-15 23:27:17,094] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=75943, lastModifiedTime=1652651794083, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:27:17,096] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=75943, lastModifiedTime=1652651794083, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:27:17,099] INFO Deleted log /tmp/kafka-logs-4/Sensor-0.6d5656aa768548d0bb3e525e0fca9068-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:17,099] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-0.6d5656aa768548d0bb3e525e0fca9068-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:17,102] INFO Deleted time index /tmp/kafka-logs-4/Sensor-0.6d5656aa768548d0bb3e525e0fca9068-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:17,108] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-4/Sensor-0.6d5656aa768548d0bb3e525e0fca9068-delete. (kafka.log.LogManager)
[2022-05-15 23:27:17,109] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=43079, lastModifiedTime=1652651775867, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:27:17,109] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=43079, lastModifiedTime=1652651775867, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:27:17,110] INFO Deleted log /tmp/kafka-logs-4/Sensor-5.48fa72cb30444fe5b8bcdaa5c841e956-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:17,110] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-5.48fa72cb30444fe5b8bcdaa5c841e956-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:17,110] INFO Deleted time index /tmp/kafka-logs-4/Sensor-5.48fa72cb30444fe5b8bcdaa5c841e956-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:17,111] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-4/Sensor-5.48fa72cb30444fe5b8bcdaa5c841e956-delete. (kafka.log.LogManager)
[2022-05-15 23:27:17,150] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=40286, lastModifiedTime=1652651788039, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:27:17,152] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=40286, lastModifiedTime=1652651788039, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:27:17,153] INFO Deleted log /tmp/kafka-logs-4/Sensor-4.84519c0bc1754c1b9a44468911d4e091-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:17,154] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-4.84519c0bc1754c1b9a44468911d4e091-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:17,154] INFO Deleted time index /tmp/kafka-logs-4/Sensor-4.84519c0bc1754c1b9a44468911d4e091-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:17,155] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-4/Sensor-4.84519c0bc1754c1b9a44468911d4e091-delete. (kafka.log.LogManager)
[2022-05-15 23:27:22,111] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=77591, lastModifiedTime=1652651794099, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:27:22,114] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=77591, lastModifiedTime=1652651794099, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:27:22,120] INFO Deleted log /tmp/kafka-logs-5/Sensor-3.734631a469c14e5481d8cb064fe59a8f-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:22,121] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-3.734631a469c14e5481d8cb064fe59a8f-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:22,126] INFO Deleted time index /tmp/kafka-logs-5/Sensor-3.734631a469c14e5481d8cb064fe59a8f-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:22,135] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-5/Sensor-3.734631a469c14e5481d8cb064fe59a8f-delete. (kafka.log.LogManager)
[2022-05-15 23:27:22,138] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=40286, lastModifiedTime=1652651788043, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:27:22,139] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=40286, lastModifiedTime=1652651788043, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:27:22,140] INFO Deleted log /tmp/kafka-logs-5/Sensor-4.e4b95cf71e154d589a89ceb5b69c299c-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:22,140] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-4.e4b95cf71e154d589a89ceb5b69c299c-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:22,141] INFO Deleted time index /tmp/kafka-logs-5/Sensor-4.e4b95cf71e154d589a89ceb5b69c299c-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:22,142] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-5/Sensor-4.e4b95cf71e154d589a89ceb5b69c299c-delete. (kafka.log.LogManager)
[2022-05-15 23:27:22,152] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=43079, lastModifiedTime=1652651775867, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:27:22,153] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=43079, lastModifiedTime=1652651775867, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:27:22,154] INFO Deleted log /tmp/kafka-logs-5/Sensor-5.09bb27094fe948aca45139e1daf7caf3-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:22,155] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-5.09bb27094fe948aca45139e1daf7caf3-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:22,155] INFO Deleted time index /tmp/kafka-logs-5/Sensor-5.09bb27094fe948aca45139e1daf7caf3-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:27:22,156] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-5/Sensor-5.09bb27094fe948aca45139e1daf7caf3-delete. (kafka.log.LogManager)
[2022-05-15 23:29:56,652] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:29:56,654] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:29:56,655] INFO [GroupCoordinator 3]: Removed 0 offsets associated with deleted partitions: Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:29:56,657] INFO [GroupCoordinator 4]: Removed 0 offsets associated with deleted partitions: Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:29:56,658] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:29:56,667] INFO [GroupCoordinator 5]: Removed 1 offsets associated with deleted partitions: Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:29:56,684] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:29:56,684] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:29:56,686] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:29:56,686] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:29:56,686] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:29:56,687] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:29:56,695] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:29:56,694] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:29:56,695] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:29:56,696] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:29:56,696] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:29:56,698] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:29:56,700] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 6713 due to node 5 being disconnected (elapsed time since creation: 263ms, elapsed time since send: 263ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:29:56,703] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 6713 due to node 5 being disconnected (elapsed time since creation: 267ms, elapsed time since send: 267ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:29:56,701] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=1762361699, epoch=6713) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:29:56,707] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:29:56,707] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:29:56,705] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=1486938449, epoch=6713) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:29:56,710] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:29:56,710] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:29:56,715] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-5/Sensor-0.aef9f939206e46a7a16a06814b942b40-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:29:56,715] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:29:56,716] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:29:56,721] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:29:56,722] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:29:56,728] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-1/Sensor-0.2fbcf69c5a3b482281aa02bca70433ca-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:29:56,732] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-4/Sensor-0.3f3bf8622d1142c5a81392fbffd16450-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:30:00,042] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:30:00,042] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:30:00,042] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:30:00,042] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:30:00,042] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:30:00,042] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:30:00,045] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:30:00,046] INFO [KafkaServer id=4] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:30:00,046] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:30:00,046] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:30:00,047] INFO [KafkaServer id=5] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:30:00,048] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:30:00,046] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:30:00,049] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:30:00,049] INFO [KafkaServer id=5] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:30:00,049] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:30:00,051] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:30:00,053] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:30:00,082] INFO [KafkaServer id=4] Controlled shutdown request returned successfully after 23ms (kafka.server.KafkaServer)
[2022-05-15 23:30:00,084] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 24ms (kafka.server.KafkaServer)
[2022-05-15 23:30:00,086] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 19ms (kafka.server.KafkaServer)
[2022-05-15 23:30:00,086] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:30:00,087] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:30:00,087] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:30:00,088] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:30:00,089] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:30:00,089] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:30:00,089] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:30:00,091] INFO [KafkaServer id=5] Controlled shutdown request returned successfully after 22ms (kafka.server.KafkaServer)
[2022-05-15 23:30:00,091] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:30:00,094] INFO [KafkaServer id=3] Controlled shutdown request returned successfully after 18ms (kafka.server.KafkaServer)
[2022-05-15 23:30:00,095] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 16ms (kafka.server.KafkaServer)
[2022-05-15 23:30:00,096] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:30:00,099] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:30:00,099] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:30:00,101] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:30:00,101] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:30:00,103] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:30:00,103] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:30:00,103] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:30:00,104] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:30:00,105] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:30:00,105] INFO [data-plane Kafka Request Handler on Broker 4], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:30:00,106] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:30:00,106] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:30:00,107] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:30:00,108] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:30:00,109] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:30:00,109] INFO [data-plane Kafka Request Handler on Broker 4], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:30:00,110] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:30:00,109] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:30:00,111] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:30:00,112] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:30:00,118] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:30:00,119] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:30:00,119] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:30:00,120] INFO [data-plane Kafka Request Handler on Broker 5], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:30:00,121] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:30:00,126] INFO [data-plane Kafka Request Handler on Broker 5], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:30:00,127] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:30:00,127] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:30:00,128] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,129] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:30:00,129] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:30:00,129] INFO [ExpirationReaper-4-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,131] INFO [data-plane Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:30:00,132] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:30:00,132] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,133] INFO [ExpirationReaper-5-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,134] INFO [data-plane Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:30:00,137] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,138] INFO [ExpirationReaper-3-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,142] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,142] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,143] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:30:00,144] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,185] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,185] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,185] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,185] INFO [ExpirationReaper-3-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,185] INFO [ExpirationReaper-3-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,185] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,187] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:30:00,187] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:30:00,187] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:30:00,189] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,190] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,189] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,212] INFO [ExpirationReaper-5-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,212] INFO [ExpirationReaper-5-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,213] INFO [KafkaApi-5] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:30:00,216] INFO [ExpirationReaper-5-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,244] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,244] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,245] INFO [ExpirationReaper-4-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,246] INFO [ExpirationReaper-4-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,247] INFO [KafkaApi-4] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:30:00,248] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:30:00,249] INFO [ExpirationReaper-4-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,250] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:30:00,250] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:30:00,251] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:30:00,251] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:30:00,253] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:30:00,254] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:00,255] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,291] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,291] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,291] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,291] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,291] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,294] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:30:00,295] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:30:00,296] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:30:00,297] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:30:00,297] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:30:00,299] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:30:00,299] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:00,300] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,302] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,302] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,303] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,303] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,306] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:30:00,308] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:30:00,308] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:30:00,308] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:30:00,309] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:30:00,309] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:30:00,310] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:30:00,311] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:30:00,311] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:30:00,312] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:00,312] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,312] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:30:00,312] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:30:00,314] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:30:00,315] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:00,316] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,324] INFO [ExpirationReaper-5-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,324] INFO [ExpirationReaper-5-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,327] INFO [TransactionCoordinator id=5] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:30:00,329] INFO [Transaction State Manager 5]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:30:00,329] INFO [Transaction Marker Channel Manager 5]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:30:00,329] INFO [Transaction Marker Channel Manager 5]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:30:00,329] INFO [Transaction Marker Channel Manager 5]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:30:00,332] INFO [TransactionCoordinator id=5] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:30:00,332] INFO [GroupCoordinator 5]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:00,332] INFO [ExpirationReaper-5-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,348] INFO [ExpirationReaper-4-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,348] INFO [ExpirationReaper-4-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,352] INFO [TransactionCoordinator id=4] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:30:00,354] INFO [Transaction State Manager 4]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:30:00,354] INFO [Transaction Marker Channel Manager 4]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:30:00,355] INFO [Transaction Marker Channel Manager 4]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:30:00,356] INFO [Transaction Marker Channel Manager 4]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:30:00,358] INFO [TransactionCoordinator id=4] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:30:00,359] INFO [GroupCoordinator 4]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:00,360] INFO [ExpirationReaper-4-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,481] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,481] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,482] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,491] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,491] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,493] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:00,494] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:30:00,494] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:30:00,495] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:30:00,495] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:30:00,496] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:30:00,498] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:30:00,499] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:30:00,500] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:30:00,500] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,502] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,502] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,503] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,504] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,504] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,504] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,504] INFO [ExpirationReaper-5-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,504] INFO [ExpirationReaper-5-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,505] INFO [ExpirationReaper-5-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,524] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,525] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,525] INFO [ExpirationReaper-5-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,526] INFO [ExpirationReaper-5-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,526] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:00,527] INFO [GroupCoordinator 5]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:00,528] INFO [ReplicaManager broker=5] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:30:00,528] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:30:00,528] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:30:00,529] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:30:00,529] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:30:00,529] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:30:00,530] INFO [ReplicaFetcherManager on broker 5] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:30:00,531] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:30:00,531] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:30:00,532] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:30:00,533] INFO [ReplicaFetcherManager on broker 5] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:30:00,534] INFO [ReplicaAlterLogDirsManager on broker 5] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:30:00,534] INFO [ReplicaAlterLogDirsManager on broker 5] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:30:00,534] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:30:00,535] INFO [ExpirationReaper-5-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,535] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:30:00,536] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:30:00,536] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,543] INFO [ExpirationReaper-4-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,543] INFO [ExpirationReaper-4-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,544] INFO [ExpirationReaper-4-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,548] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,548] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,549] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,555] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,555] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,555] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,578] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,578] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,579] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,681] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,681] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,683] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:00,684] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:30:00,685] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:30:00,685] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:30:00,685] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:30:00,687] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:30:00,690] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:30:00,690] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:30:00,691] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:30:00,691] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,702] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,702] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,704] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:00,704] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,704] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,705] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,706] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:30:00,706] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:30:00,708] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:30:00,708] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:30:00,709] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:30:00,712] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:30:00,713] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:30:00,714] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:30:00,714] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,726] INFO [ExpirationReaper-5-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,726] INFO [ExpirationReaper-5-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,726] INFO [ExpirationReaper-5-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,735] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,735] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,736] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,736] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,736] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,737] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,743] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,743] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,743] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,743] INFO [ExpirationReaper-4-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,743] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,743] INFO [ExpirationReaper-4-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,744] INFO [ExpirationReaper-3-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,744] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,745] INFO [GroupCoordinator 4]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:00,746] INFO [ReplicaManager broker=4] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:30:00,746] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:30:00,747] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:30:00,747] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:30:00,749] INFO [ReplicaFetcherManager on broker 4] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:30:00,751] INFO [ReplicaFetcherManager on broker 4] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:30:00,751] INFO [ReplicaAlterLogDirsManager on broker 4] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:30:00,752] INFO [ReplicaAlterLogDirsManager on broker 4] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:30:00,752] INFO [ExpirationReaper-4-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,754] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,754] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,754] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,755] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,755] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,756] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,771] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,771] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,778] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:30:00,779] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,779] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,779] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,782] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:30:00,783] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,783] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,783] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,785] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:30:00,785] INFO [ExpirationReaper-4-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,786] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:30:00,785] INFO [ExpirationReaper-4-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,786] INFO [ExpirationReaper-4-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,818] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:30:00,841] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:30:00,842] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:30:00,842] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:30:00,843] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:00,905] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,905] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,906] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,911] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,911] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,912] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,922] INFO [ExpirationReaper-5-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,922] INFO [ExpirationReaper-5-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,922] INFO [ExpirationReaper-5-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,926] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,926] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,932] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:30:00,933] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,934] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,934] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,936] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:30:00,936] INFO [ExpirationReaper-3-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,937] INFO [ExpirationReaper-3-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,937] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,938] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,938] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,939] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:30:00,940] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:30:00,941] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:30:00,942] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,943] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,943] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,944] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,944] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,946] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:30:00,947] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,948] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,948] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,949] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:30:00,950] INFO Session: 0x100000b00ad007e closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:00,950] INFO EventThread shut down for session: 0x100000b00ad007e (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:00,951] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,951] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:30:00,951] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,952] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:00,952] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:30:00,953] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:00,952] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,956] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:30:00,957] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,958] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,958] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:00,959] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:30:00,960] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:30:00,978] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:30:00,985] INFO [ExpirationReaper-4-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,985] INFO [ExpirationReaper-4-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,986] INFO [ExpirationReaper-5-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,986] INFO [ExpirationReaper-5-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,986] INFO [ExpirationReaper-4-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,987] INFO [ExpirationReaper-5-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:00,990] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:30:00,990] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:30:00,990] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:30:00,990] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:30:00,991] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:00,999] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:30:01,000] INFO [ExpirationReaper-4-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:01,000] INFO [ExpirationReaper-4-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:01,001] INFO [ExpirationReaper-4-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:01,002] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:30:01,003] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:30:01,003] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:30:01,004] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:01,007] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:01,007] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:01,007] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:01,010] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:30:01,010] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:30:01,010] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:30:01,010] INFO [Controller id=5, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,010] INFO [Controller id=5, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,010] INFO [Controller id=5, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,010] INFO [Controller id=5, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,010] INFO [Controller id=5, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,011] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:01,012] INFO [ExpirationReaper-4-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:01,012] INFO [ExpirationReaper-4-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:01,014] WARN [Controller id=5, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,014] WARN [Controller id=5, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,015] WARN [Controller id=5, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,015] WARN [Controller id=5, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,015] WARN An exception was thrown while closing send thread for session 0x100000b00ad0080. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x100000b00ad0080, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 23:30:01,016] WARN [Controller id=5, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,017] INFO [ReplicaManager broker=4] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:30:01,018] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:01,018] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:01,018] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:01,020] INFO [Controller id=5, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,021] INFO [Controller id=5, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,021] INFO [Controller id=5, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,021] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:30:01,022] INFO [Controller id=5, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,022] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:01,022] INFO [Controller id=5, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,023] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:01,023] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:01,024] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:30:01,025] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:30:01,054] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:30:01,064] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:30:01,064] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:30:01,064] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:30:01,066] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:01,097] INFO Session: 0x100000b00ad007f closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:01,097] INFO EventThread shut down for session: 0x100000b00ad007f (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:01,100] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:01,101] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:01,110] INFO Session: 0x100000b00ad0081 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:01,110] INFO EventThread shut down for session: 0x100000b00ad0081 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:01,112] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:01,113] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:01,117] INFO Session: 0x100000b00ad0080 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:01,117] INFO EventThread shut down for session: 0x100000b00ad0080 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:01,120] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:01,121] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:01,122] INFO [Controller id=5, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,122] INFO [Controller id=5, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,122] INFO [Controller id=5, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,122] WARN [Controller id=5, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,122] WARN [Controller id=5, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,122] WARN [Controller id=5, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,124] INFO [Controller id=5, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,124] INFO [Controller id=5, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,124] INFO [Controller id=5, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,124] INFO [Controller id=5, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,124] INFO [Controller id=5, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,124] WARN [Controller id=5, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,124] WARN [Controller id=5, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,124] INFO [Controller id=5, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,124] INFO [Controller id=5, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,149] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:01,149] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:01,149] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:01,151] INFO [Controller id=5, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,155] INFO [Controller id=5, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,158] INFO [Controller id=5, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,162] INFO [Controller id=5, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,172] INFO EventThread shut down for session: 0x100000b00ad0082 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:01,172] INFO Session: 0x100000b00ad0082 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:01,176] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:01,177] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:01,179] INFO [ExpirationReaper-5-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:01,179] INFO [ExpirationReaper-5-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:01,185] INFO [ReplicaManager broker=5] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:30:01,186] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:01,186] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:01,186] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:01,188] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:30:01,189] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:01,190] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:01,190] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:01,191] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:30:01,191] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:30:01,217] INFO [ProducerStateManager partition=__consumer_offsets-22] Wrote producer snapshot at offset 49579 with 0 producer ids in 4 ms. (kafka.log.ProducerStateManager)
[2022-05-15 23:30:01,225] INFO [Controller id=5, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,225] WARN [Controller id=5, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,226] INFO [Controller id=5, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,237] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:30:01,251] INFO [Controller id=5, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:30:01,255] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:30:01,255] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:30:01,255] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:30:01,257] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:01,363] INFO Session: 0x100000b00ad0083 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:01,363] INFO EventThread shut down for session: 0x100000b00ad0083 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:01,366] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:01,366] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:01,982] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:01,982] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:01,982] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,004] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,004] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,005] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,007] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,007] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,008] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,009] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,009] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,011] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:30:02,027] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,027] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,027] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,035] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,035] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,036] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,040] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:30:02,040] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:30:02,040] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:30:02,041] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:30:02,042] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:30:02,043] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:30:02,043] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:30:02,083] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,083] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,084] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,149] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,149] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,150] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,154] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,154] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,154] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,160] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,160] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,162] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:30:02,184] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:30:02,185] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:30:02,185] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:30:02,185] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:30:02,187] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:30:02,188] INFO App info kafka.server for 3 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:30:02,189] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:30:02,981] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,981] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:02,982] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:03,027] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:03,027] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:03,028] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:03,036] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:03,036] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:03,036] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:03,083] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:03,083] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:03,084] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:03,981] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:03,981] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:03,982] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:03,990] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:03,990] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:03,992] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:30:04,014] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:30:04,015] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:30:04,015] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:30:04,015] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:30:04,017] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:30:04,018] INFO App info kafka.server for 4 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:30:04,018] INFO [KafkaServer id=4] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:30:04,027] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:04,027] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:04,028] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:04,032] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:04,032] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:04,034] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:30:04,036] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:04,036] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:04,037] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:04,042] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:04,042] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:04,044] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:30:04,064] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:30:04,065] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:30:04,065] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:30:04,065] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:30:04,068] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:30:04,070] INFO App info kafka.server for 5 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:30:04,071] INFO [KafkaServer id=5] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:30:04,072] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:30:04,073] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:30:04,073] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:30:04,073] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:30:04,075] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:30:04,076] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:30:04,076] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:30:04,084] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:04,084] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:04,084] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:04,086] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:04,086] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:04,088] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:30:04,109] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:30:04,110] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:30:04,111] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:30:04,111] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:30:04,114] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:30:04,115] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:30:04,115] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:30:34,610] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:30:34,620] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:30:34,621] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:30:34,621] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:30:34,621] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:30:34,623] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 23:30:34,623] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 23:30:34,623] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 23:30:34,623] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-15 23:30:34,628] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-15 23:30:34,645] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:30:34,646] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:30:34,646] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:30:34,646] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:30:34,646] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:30:34,646] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-15 23:30:34,661] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@6156496 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-15 23:30:34,665] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 23:30:34,679] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,679] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,679] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,679] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,679] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,679] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,680] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,680] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,680] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,680] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,682] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,682] INFO Server environment:host.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,682] INFO Server environment:java.version=11.0.15 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,682] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,682] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,682] INFO Server environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,682] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,682] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,683] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,683] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,683] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,683] INFO Server environment:os.version=5.13.0-40-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,683] INFO Server environment:user.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,683] INFO Server environment:user.home=/home/joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,683] INFO Server environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,683] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,683] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,683] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,683] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,683] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,683] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,683] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,683] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,683] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,684] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,685] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-15 23:30:34,687] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,687] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,688] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 23:30:34,688] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 23:30:34,689] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:30:34,689] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:30:34,689] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:30:34,689] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:30:34,689] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:30:34,690] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:30:34,693] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,693] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,693] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:30:34,702] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 23:30:34,703] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 23:30:34,705] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 23:30:34,711] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 23:30:34,712] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:459)
	at java.base/sun.nio.ch.Net.bind(Net.java:448)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:676)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:158)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:112)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:67)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:140)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:90)
[2022-05-15 23:30:34,715] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-15 23:30:34,717] ERROR Exiting JVM with code 1 (org.apache.zookeeper.util.ServiceUtils)
[2022-05-15 23:30:39,604] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:30:39,906] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:30:40,007] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:30:40,012] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:30:40,012] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:30:40,030] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:40,035] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:40,035] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:40,035] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:40,035] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:40,035] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:40,035] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:40,036] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:40,036] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:40,036] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:40,036] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:40,036] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:40,036] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:40,036] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:40,036] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:40,036] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:40,036] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:40,036] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:40,036] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:40,053] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:40,059] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:30:40,064] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:40,072] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:40,081] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:40,084] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:40,090] INFO Socket connection established, initiating session, client: /127.0.0.1:58096, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:40,101] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0084, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:40,108] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:40,204] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:30:40,367] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:30:40,375] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:30:40,425] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:30:40,436] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:30:40,497] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:40,499] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:40,502] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:40,504] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:40,552] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:30:40,556] INFO Skipping recovery for all logs in /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:30:40,644] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:40,674] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-21, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 100ms (1/8 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:30:40,694] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 35579 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:40,694] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 35579 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:40,696] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs/__consumer_offsets-39/00000000000000035579.snapshot,35579)' (kafka.log.ProducerStateManager)
[2022-05-15 23:30:40,704] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Producer state recovery took 10ms for snapshot load and 0ms for segment recovery from offset 35579 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:40,711] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-39, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=35579) with 1 segments in 36ms (2/8 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:30:40,717] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:40,724] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-15, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (3/8 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:30:40,731] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:40,735] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-45, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (4/8 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:30:40,742] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:40,746] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-33, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (5/8 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:30:40,752] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:40,758] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-27, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (6/8 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:30:40,764] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:40,768] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-3, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (7/8 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:30:40,775] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:40,781] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-9, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (8/8 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:30:40,785] INFO Loaded 8 logs in 233ms. (kafka.log.LogManager)
[2022-05-15 23:30:40,786] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:30:40,789] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:30:41,086] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:41,287] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:30:41,291] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-15 23:30:41,326] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:30:41,334] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:41,355] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:41,357] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:41,359] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:41,361] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:41,376] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:30:41,419] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:30:41,435] INFO Stat of the created znode at /brokers/ids/0 is: 6350,6350,1652653841428,1652653841428,1,0,0,72057641293906052,192,0,6350
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:30:41,436] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://joao:9092, czxid (broker epoch): 6350 (kafka.zk.KafkaZkClient)
[2022-05-15 23:30:41,488] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:41,492] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:41,494] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:41,509] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:41,532] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:41,549] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:30:41,552] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:30:41,552] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:30:41,580] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:41,599] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:30:41,618] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:30:41,624] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:30:41,625] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:30:41,632] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:30:41,632] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:30:41,632] INFO Kafka startTimeMs: 1652653841625 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:30:41,636] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-15 23:30:41,701] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:41,731] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:41,732] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:41,732] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 35579 (kafka.cluster.Partition)
[2022-05-15 23:30:41,732] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:41,732] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:41,732] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:41,732] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:41,733] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:41,738] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:41,792] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-3, __consumer_offsets-15, __consumer_offsets-39, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:30:41,823] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:41,825] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:41,827] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:41,827] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:41,827] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:41,827] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:41,827] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:41,827] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:41,827] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:41,827] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:41,827] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:41,827] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:41,827] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:41,827] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:41,827] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:41,827] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:41,834] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 9 milliseconds for epoch 38, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:41,835] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 8 milliseconds for epoch 38, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:41,926] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 98 milliseconds for epoch 38, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:41,926] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 99 milliseconds for epoch 38, of which 99 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:41,927] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 100 milliseconds for epoch 38, of which 99 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:41,927] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 100 milliseconds for epoch 38, of which 100 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:41,928] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 100 milliseconds for epoch 38, of which 100 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:41,928] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 101 milliseconds for epoch 38, of which 101 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:44,652] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:30:44,933] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:30:45,022] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:30:45,025] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:30:45,026] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:30:45,041] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:45,046] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:45,046] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:45,046] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:45,046] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:45,046] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:45,046] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:45,047] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:45,047] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:45,047] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:45,047] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:45,047] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:45,047] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:45,047] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:45,047] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:45,047] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:45,047] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:45,047] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:45,047] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:45,050] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:45,055] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:30:45,060] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:45,078] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:45,089] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:45,091] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:45,097] INFO Socket connection established, initiating session, client: /127.0.0.1:58098, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:45,110] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0085, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:45,119] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:45,221] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:30:45,384] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:30:45,393] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:30:45,450] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:30:45,460] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:30:45,522] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:45,524] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:45,527] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:45,530] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:45,584] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:30:45,590] INFO Skipping recovery for all logs in /tmp/kafka-logs-1 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:30:45,678] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:45,707] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-17, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 99ms (1/9 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:30:45,715] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:45,721] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-35, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (2/9 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:30:45,727] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:45,734] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-41, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (3/9 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:30:45,741] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:45,748] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-29, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (4/9 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:30:45,755] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:45,760] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-11, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (5/9 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:30:45,767] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:45,772] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-0.2fbcf69c5a3b482281aa02bca70433ca-delete, topicId=sBeweSu0QKaG2aTZmcraTw, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (6/9 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:30:45,777] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:45,782] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-23, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (7/9 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:30:45,787] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:45,794] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-47, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (8/9 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:30:45,801] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:45,805] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-5, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (9/9 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:30:45,809] INFO Loaded 9 logs in 224ms. (kafka.log.LogManager)
[2022-05-15 23:30:45,810] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:30:45,812] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:30:46,070] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:46,190] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:30:46,193] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-15 23:30:46,217] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:30:46,224] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:46,240] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:46,241] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:46,243] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:46,244] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:46,256] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:30:46,315] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:30:46,333] INFO Stat of the created znode at /brokers/ids/1 is: 6418,6418,1652653846325,1652653846325,1,0,0,72057641293906053,192,0,6418
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:30:46,334] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://joao:9093, czxid (broker epoch): 6418 (kafka.zk.KafkaZkClient)
[2022-05-15 23:30:46,400] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:46,405] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:46,407] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:46,420] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:46,432] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:46,457] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:30:46,464] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:30:46,464] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:30:46,485] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:46,501] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:30:46,524] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:30:46,530] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:30:46,530] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:30:46,536] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:30:46,536] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:30:46,536] INFO Kafka startTimeMs: 1652653846530 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:30:46,538] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-15 23:30:46,628] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:46,631] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:46,631] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:46,631] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:46,632] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:46,632] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:46,632] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:46,632] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:46,633] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:46,656] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-5, __consumer_offsets-29, __consumer_offsets-41, __consumer_offsets-23) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:30:46,680] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:46,690] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:46,692] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:46,694] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:46,694] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:46,694] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:46,694] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:46,694] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:46,694] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:46,694] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:46,694] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:46,694] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:46,694] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:46,694] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:46,694] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:46,694] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:46,694] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:46,701] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 8 milliseconds for epoch 66, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:46,702] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 8 milliseconds for epoch 66, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:46,702] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 8 milliseconds for epoch 66, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:46,703] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 9 milliseconds for epoch 66, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:46,703] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 9 milliseconds for epoch 66, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:46,704] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 10 milliseconds for epoch 66, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:46,704] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 10 milliseconds for epoch 66, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:46,704] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 10 milliseconds for epoch 66, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:49,605] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:30:49,925] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:30:50,027] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:30:50,032] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:30:50,034] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:30:50,055] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:50,062] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:50,062] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:50,062] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:50,062] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:50,063] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:50,063] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:50,063] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:50,063] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:50,063] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:50,063] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:50,063] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:50,063] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:50,063] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:50,063] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:50,063] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:50,063] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:50,063] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:50,063] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:50,066] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:50,073] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:30:50,079] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:50,100] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:50,107] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:50,109] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:50,114] INFO Socket connection established, initiating session, client: /127.0.0.1:58100, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:50,122] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0086, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:50,128] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:50,230] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:30:50,384] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:30:50,394] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:30:50,461] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:30:50,472] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:30:50,541] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:50,543] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:50,547] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:50,550] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:50,602] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:30:50,606] INFO Skipping recovery for all logs in /tmp/kafka-logs-2 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:30:50,691] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:50,718] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-49, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 93ms (1/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:30:50,725] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:50,730] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-19, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (2/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:30:50,736] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:50,740] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-7, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (3/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:30:50,748] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:50,752] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-13, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (4/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:30:50,760] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:50,764] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-37, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (5/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:30:50,771] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:50,773] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-43, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (6/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:30:50,778] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:50,781] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-1, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:30:50,785] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:50,788] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-31, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (8/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:30:50,792] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:50,795] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-25, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (9/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:30:50,797] INFO Loaded 9 logs in 196ms. (kafka.log.LogManager)
[2022-05-15 23:30:50,798] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:30:50,799] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:30:51,013] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:51,132] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:30:51,135] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-15 23:30:51,162] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:30:51,169] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:51,185] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:51,187] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:51,188] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:51,189] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:51,200] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:30:51,249] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:30:51,266] INFO Stat of the created znode at /brokers/ids/2 is: 6442,6442,1652653851259,1652653851259,1,0,0,72057641293906054,192,0,6442
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:30:51,267] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://joao:9094, czxid (broker epoch): 6442 (kafka.zk.KafkaZkClient)
[2022-05-15 23:30:51,321] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:51,324] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:51,326] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:51,338] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:51,349] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:51,372] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:30:51,378] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:30:51,378] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:30:51,399] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:51,414] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:30:51,432] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:30:51,437] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:30:51,438] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:30:51,443] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:30:51,443] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:30:51,443] INFO Kafka startTimeMs: 1652653851438 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:30:51,445] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-15 23:30:51,527] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:51,539] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:51,540] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:51,540] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:51,540] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:51,540] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:51,541] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:51,541] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:51,541] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:51,541] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:51,565] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-7, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:30:51,573] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:51,601] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:51,602] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:51,603] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:51,603] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:51,603] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:51,603] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:51,603] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:51,604] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:51,604] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:51,604] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:51,604] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:51,604] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:51,604] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:51,604] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:51,604] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:51,604] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:51,604] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 66 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:51,604] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 66 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:51,611] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 8 milliseconds for epoch 66, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:51,612] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 9 milliseconds for epoch 66, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:51,612] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 9 milliseconds for epoch 66, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:51,612] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 8 milliseconds for epoch 66, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:51,612] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 8 milliseconds for epoch 66, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:51,612] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 8 milliseconds for epoch 66, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:51,613] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 9 milliseconds for epoch 66, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:51,613] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 9 milliseconds for epoch 66, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:51,613] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 9 milliseconds for epoch 66, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:54,652] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:30:54,985] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:30:55,098] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:30:55,102] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:30:55,103] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:30:55,125] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:55,132] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:55,132] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:55,132] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:55,132] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:55,132] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:55,132] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:55,133] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:55,133] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:55,133] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:55,133] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:55,133] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:55,133] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:55,133] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:55,133] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:55,133] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:55,133] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:55,133] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:55,133] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:55,135] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:30:55,141] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:30:55,148] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:55,166] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:55,174] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:55,176] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:55,182] INFO Socket connection established, initiating session, client: /127.0.0.1:58102, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:55,192] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0087, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:30:55,197] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:30:55,292] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:30:55,458] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:30:55,467] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:30:55,504] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:30:55,512] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:30:55,556] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:55,557] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:55,559] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:55,561] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:30:55,595] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:30:55,599] INFO Skipping recovery for all logs in /tmp/kafka-logs-3 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:30:55,664] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:55,686] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-14, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 75ms (1/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:30:55,702] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Loading producer state till offset 91906 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:55,702] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Reloading from producer snapshot and rebuilding producer state from offset 91906 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:55,704] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-3/__consumer_offsets-38/00000000000000091906.snapshot,91906)' (kafka.log.ProducerStateManager)
[2022-05-15 23:30:55,709] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 91906 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:55,713] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-38, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=91906) with 1 segments in 26ms (2/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:30:55,717] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:55,721] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-8, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (3/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:30:55,727] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:55,732] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-2, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (4/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:30:55,737] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:55,740] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-26, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:30:55,746] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:55,748] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-20, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:30:55,753] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:55,756] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-32, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:30:55,761] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:30:55,764] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-44, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:30:55,767] INFO Loaded 8 logs in 172ms. (kafka.log.LogManager)
[2022-05-15 23:30:55,768] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:30:55,770] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:30:55,993] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:56,118] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:30:56,122] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-05-15 23:30:56,150] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:30:56,156] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:56,171] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:56,172] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:56,173] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:56,175] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:56,187] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:30:56,248] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:30:56,269] INFO Stat of the created znode at /brokers/ids/3 is: 6467,6467,1652653856261,1652653856261,1,0,0,72057641293906055,192,0,6467
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:30:56,270] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://joao:9095, czxid (broker epoch): 6467 (kafka.zk.KafkaZkClient)
[2022-05-15 23:30:56,332] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:56,339] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:56,341] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:56,354] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:56,364] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:56,392] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:30:56,397] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:30:56,398] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:30:56,425] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:30:56,441] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:30:56,462] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:30:56,466] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:30:56,467] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:30:56,472] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:30:56,472] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:30:56,472] INFO Kafka startTimeMs: 1652653856467 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:30:56,475] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-05-15 23:30:56,561] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:56,572] INFO [Partition __consumer_offsets-2 broker=3] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:56,572] INFO [Partition __consumer_offsets-20 broker=3] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:56,572] INFO [Partition __consumer_offsets-38 broker=3] Log loaded for partition __consumer_offsets-38 with initial high watermark 91906 (kafka.cluster.Partition)
[2022-05-15 23:30:56,573] INFO [Partition __consumer_offsets-8 broker=3] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:56,573] INFO [Partition __consumer_offsets-26 broker=3] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:56,574] INFO [Partition __consumer_offsets-44 broker=3] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:56,574] INFO [Partition __consumer_offsets-14 broker=3] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:56,574] INFO [Partition __consumer_offsets-32 broker=3] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:30:56,600] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-26, __consumer_offsets-32, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:30:56,603] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:30:56,634] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 2 in epoch 61 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:56,635] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 61 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:56,637] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 20 in epoch 61 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:56,637] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 61 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:56,637] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 38 in epoch 61 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:56,637] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 61 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:56,637] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 8 in epoch 61 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:56,637] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 61 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:56,637] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 26 in epoch 61 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:56,637] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 61 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:56,638] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 44 in epoch 61 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:56,638] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 61 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:56,638] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 14 in epoch 61 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:56,638] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 61 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:56,638] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 32 in epoch 61 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:30:56,638] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 61 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:56,646] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-2 in 10 milliseconds for epoch 61, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:56,647] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-20 in 10 milliseconds for epoch 61, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:56,779] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-38 in 142 milliseconds for epoch 61, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:56,779] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-8 in 142 milliseconds for epoch 61, of which 142 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:56,779] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-26 in 142 milliseconds for epoch 61, of which 142 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:56,780] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-44 in 141 milliseconds for epoch 61, of which 141 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:56,780] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-14 in 142 milliseconds for epoch 61, of which 142 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:56,780] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-32 in 142 milliseconds for epoch 61, of which 142 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:30:59,713] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:31:00,060] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:31:00,171] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:31:00,175] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:31:00,176] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:31:00,193] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:31:00,199] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:00,199] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:00,199] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:00,199] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:00,199] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:00,199] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:00,199] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:00,200] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:00,200] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:00,200] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:00,200] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:00,200] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:00,200] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:00,200] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:00,200] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:00,200] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:00,200] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:00,200] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:00,202] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:00,208] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:31:00,215] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:31:00,232] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:31:00,242] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:31:00,244] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:31:00,250] INFO Socket connection established, initiating session, client: /127.0.0.1:58104, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:31:00,262] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0088, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:31:00,269] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:31:00,371] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:31:00,528] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:31:00,535] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:31:00,604] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:31:00,617] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:31:00,682] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:31:00,684] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:31:00,687] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:31:00,690] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:31:00,740] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:31:00,746] INFO Skipping recovery for all logs in /tmp/kafka-logs-4 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:31:00,822] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:00,842] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-24, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 79ms (1/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:31:00,847] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:00,851] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-12, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (2/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:31:00,855] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:00,859] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-30, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (3/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:31:00,864] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:00,867] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-36, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:31:00,872] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:00,875] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-42, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:31:00,879] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:00,882] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-0, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (6/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:31:00,886] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:00,889] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-0.3f3bf8622d1142c5a81392fbffd16450-delete, topicId=sBeweSu0QKaG2aTZmcraTw, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:31:00,893] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:00,896] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-18, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:31:00,903] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:00,905] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-6, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (9/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:31:00,910] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:00,913] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-48, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:31:00,915] INFO Loaded 10 logs in 175ms. (kafka.log.LogManager)
[2022-05-15 23:31:00,916] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:31:00,916] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:31:01,124] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:31:01,235] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:31:01,238] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.Acceptor)
[2022-05-15 23:31:01,266] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:31:01,271] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:31:01,286] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:31:01,287] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:31:01,289] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:31:01,290] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:31:01,300] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:31:01,354] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:31:01,373] INFO Stat of the created znode at /brokers/ids/4 is: 6491,6491,1652653861365,1652653861365,1,0,0,72057641293906056,192,0,6491
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:31:01,374] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://joao:9096, czxid (broker epoch): 6491 (kafka.zk.KafkaZkClient)
[2022-05-15 23:31:01,432] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:31:01,436] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:31:01,437] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:31:01,450] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:01,460] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:01,480] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:31:01,489] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:31:01,490] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:31:01,511] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:31:01,527] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:31:01,546] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:31:01,551] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:31:01,551] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:31:01,555] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:31:01,555] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:31:01,555] INFO Kafka startTimeMs: 1652653861551 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:31:01,557] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2022-05-15 23:31:01,636] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:31:01,653] INFO [Partition __consumer_offsets-18 broker=4] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:01,654] INFO [Partition __consumer_offsets-36 broker=4] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:01,654] INFO [Partition __consumer_offsets-6 broker=4] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:01,654] INFO [Partition __consumer_offsets-24 broker=4] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:01,655] INFO [Partition __consumer_offsets-42 broker=4] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:01,655] INFO [Partition __consumer_offsets-12 broker=4] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:01,655] INFO [Partition __consumer_offsets-30 broker=4] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:01,655] INFO [Partition __consumer_offsets-0 broker=4] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:01,656] INFO [Partition __consumer_offsets-48 broker=4] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:01,677] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:31:01,688] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-12, __consumer_offsets-42, __consumer_offsets-18) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:01,731] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 18 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:01,733] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:01,735] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 36 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:01,735] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:01,735] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 6 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:01,735] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:01,736] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 24 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:01,736] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:01,736] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 42 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:01,736] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:01,736] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 12 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:01,736] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:01,736] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 30 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:01,736] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:01,736] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 0 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:01,736] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:01,736] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 48 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:01,736] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:01,746] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-18 in 11 milliseconds for epoch 69, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:01,747] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-36 in 12 milliseconds for epoch 69, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:01,747] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-6 in 11 milliseconds for epoch 69, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:01,747] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-24 in 11 milliseconds for epoch 69, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:01,747] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-42 in 11 milliseconds for epoch 69, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:01,748] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-12 in 12 milliseconds for epoch 69, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:01,748] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-30 in 12 milliseconds for epoch 69, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:01,748] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-0 in 12 milliseconds for epoch 69, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:01,748] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-48 in 12 milliseconds for epoch 69, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:04,665] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:31:04,980] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:31:05,089] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:31:05,094] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:31:05,095] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:31:05,116] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:31:05,123] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:05,123] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:05,123] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:05,123] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:05,123] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:05,124] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:05,124] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:05,124] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:05,124] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:05,124] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:05,124] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:05,124] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:05,124] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:05,124] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:05,125] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:05,125] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:05,125] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:05,125] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:05,127] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:31:05,133] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:31:05,138] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:31:05,159] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:31:05,167] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:31:05,168] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:31:05,175] INFO Socket connection established, initiating session, client: /127.0.0.1:58106, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:31:05,184] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0089, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:31:05,189] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:31:05,293] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:31:05,458] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:31:05,467] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:31:05,525] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:31:05,536] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:31:05,580] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:31:05,581] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:31:05,584] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:31:05,586] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:31:05,622] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:31:05,626] INFO Skipping recovery for all logs in /tmp/kafka-logs-5 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:31:05,692] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:05,712] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-46, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 75ms (1/9 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:31:05,718] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:05,723] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-10, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (2/9 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:31:05,728] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:05,733] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-0.aef9f939206e46a7a16a06814b942b40-delete, topicId=sBeweSu0QKaG2aTZmcraTw, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (3/9 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:31:05,738] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:05,743] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-28, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (4/9 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:31:05,756] INFO Deleted producer state snapshot /tmp/kafka-logs-5/__consumer_offsets-22/00000000000000049539.snapshot (kafka.log.SnapshotFile)
[2022-05-15 23:31:05,758] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Loading producer state till offset 49579 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:05,758] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 49579 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:05,759] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-22/00000000000000049579.snapshot,49579)' (kafka.log.ProducerStateManager)
[2022-05-15 23:31:05,764] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 49579 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:05,767] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-22, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=49579) with 1 segments in 24ms (5/9 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:31:05,773] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:05,776] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-16, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/9 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:31:05,785] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Loading producer state till offset 35134 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:05,785] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 35134 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:05,785] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-40/00000000000000035134.snapshot,35134)' (kafka.log.ProducerStateManager)
[2022-05-15 23:31:05,785] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 35134 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:05,788] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-40, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=35134) with 1 segments in 13ms (7/9 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:31:05,793] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:05,797] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-34, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (8/9 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:31:05,802] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:05,804] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-4, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (9/9 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:31:05,807] INFO Loaded 9 logs in 184ms. (kafka.log.LogManager)
[2022-05-15 23:31:05,808] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:31:05,809] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:31:06,024] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:31:06,138] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:31:06,142] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.Acceptor)
[2022-05-15 23:31:06,165] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:31:06,171] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:31:06,187] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:31:06,189] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:31:06,190] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:31:06,192] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:31:06,204] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:31:06,258] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:31:06,275] INFO Stat of the created znode at /brokers/ids/5 is: 6516,6516,1652653866268,1652653866268,1,0,0,72057641293906057,192,0,6516
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:31:06,275] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://joao:9097, czxid (broker epoch): 6516 (kafka.zk.KafkaZkClient)
[2022-05-15 23:31:06,332] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:31:06,336] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:31:06,338] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:31:06,350] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:06,360] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:06,378] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:31:06,382] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:31:06,382] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:31:06,407] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:31:06,424] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:31:06,444] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:31:06,448] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:31:06,449] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:31:06,454] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:31:06,454] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:31:06,454] INFO Kafka startTimeMs: 1652653866449 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:31:06,456] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2022-05-15 23:31:06,536] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:31:06,541] INFO [Partition __consumer_offsets-34 broker=5] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:06,541] INFO [Partition __consumer_offsets-4 broker=5] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:06,542] INFO [Partition __consumer_offsets-22 broker=5] Log loaded for partition __consumer_offsets-22 with initial high watermark 49579 (kafka.cluster.Partition)
[2022-05-15 23:31:06,542] INFO [Partition __consumer_offsets-40 broker=5] Log loaded for partition __consumer_offsets-40 with initial high watermark 35134 (kafka.cluster.Partition)
[2022-05-15 23:31:06,542] INFO [Partition __consumer_offsets-10 broker=5] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:06,543] INFO [Partition __consumer_offsets-28 broker=5] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:06,543] INFO [Partition __consumer_offsets-46 broker=5] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:06,543] INFO [Partition __consumer_offsets-16 broker=5] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:06,570] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:06,578] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:31:06,598] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 34 in epoch 71 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:06,600] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 71 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:06,602] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 4 in epoch 71 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:06,602] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 71 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:06,602] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 22 in epoch 71 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:06,602] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 71 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:06,602] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 40 in epoch 71 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:06,602] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 71 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:06,602] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 10 in epoch 71 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:06,602] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 71 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:06,603] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 28 in epoch 71 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:06,603] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 71 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:06,603] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 46 in epoch 71 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:06,603] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 71 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:06,603] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 16 in epoch 71 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:06,603] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 71 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:06,610] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-34 in 9 milliseconds for epoch 71, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:06,610] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-4 in 8 milliseconds for epoch 71, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:06,630] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-9fa5abef-fdc9-4c05-8f09-7f9780632837, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:31:06,639] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-ed3a6d0d-54c4-4b54-b4a4-a5d0ecba6f8e, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:31:06,639] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-1038faf2-d998-4707-9799-897de83d6136, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:31:06,640] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-b283a5ee-70be-4bf9-b41c-74e089f12e34, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:31:06,640] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-360d1581-f79b-41e6-82d3-fe3577615014, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:31:06,640] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-9e173d1e-b47a-4b16-9874-bf5d2688c730, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:31:06,640] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-81fafa38-80dc-43ea-ac6c-e398b06565dc, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:31:06,672] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-d15976bc-df63-4682-8583-fd67cbb1d9df, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:31:06,672] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-a0d7c5c7-e384-4339-b0be-414878362e3e, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:31:06,672] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-ee781f71-f1c3-46d7-bd93-d90a4fe359ff, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:31:06,672] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-78575c72-7be8-4563-b114-53b271a8ef70, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:31:06,672] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-0287b15c-1acd-4475-b9ce-b994aebeeff2, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:31:06,672] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-45d54f6e-f1d8-43f7-8ace-1db96ac0cfac, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:31:06,727] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-954ef0dc-d124-405b-9bb6-119086dd08c0, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:31:06,728] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-3f51cd43-28ab-4459-969e-211543e6cd72, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:31:06,729] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-4b8634e2-92f3-4603-97c5-35df7219bd84, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 4. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:31:06,730] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-5f6ccebb-0352-4648-b98e-7613d791d352, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:31:06,744] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-8863ee28-05fa-4d10-b813-b83668f9ecf8, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:31:06,748] INFO [GroupCoordinator 5]: Loading group metadata for consumer with generation 1 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:06,755] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-22 in 153 milliseconds for epoch 71, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:06,784] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-40 in 182 milliseconds for epoch 71, of which 154 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:06,784] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-10 in 182 milliseconds for epoch 71, of which 182 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:06,784] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-28 in 181 milliseconds for epoch 71, of which 181 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:06,784] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-46 in 181 milliseconds for epoch 71, of which 181 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:06,785] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-16 in 182 milliseconds for epoch 71, of which 182 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:31:10,449] INFO Creating topic Sensor with configuration {min.insync.replicas=2} and initial partition assignment HashMap(0 -> ArrayBuffer(0, 4, 2), 1 -> ArrayBuffer(5, 2, 3), 2 -> ArrayBuffer(1, 3, 0), 3 -> ArrayBuffer(4, 0, 5), 4 -> ArrayBuffer(2, 5, 1), 5 -> ArrayBuffer(3, 1, 4)) (kafka.zk.AdminZkClient)
[2022-05-15 23:31:10,494] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,496] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,496] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-4) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,496] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,498] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,498] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,507] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:10,507] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:10,508] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:10,508] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:10,512] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:10,513] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-1/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:31:10,512] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:10,514] INFO Created log for partition Sensor-0 in /tmp/kafka-logs/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:31:10,514] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-4/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:31:10,515] INFO [Partition Sensor-2 broker=1] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 23:31:10,516] INFO [Partition Sensor-2 broker=1] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:10,516] INFO [Partition Sensor-0 broker=0] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 23:31:10,516] INFO [Partition Sensor-0 broker=0] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:10,516] INFO [Partition Sensor-3 broker=4] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 23:31:10,517] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-2/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:31:10,517] INFO [Partition Sensor-3 broker=4] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:10,519] INFO [Partition Sensor-4 broker=2] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 23:31:10,519] INFO [Partition Sensor-4 broker=2] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:10,520] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-5/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:31:10,520] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-3/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:31:10,521] INFO [Partition Sensor-1 broker=5] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 23:31:10,522] INFO [Partition Sensor-1 broker=5] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:10,522] INFO [Partition Sensor-5 broker=3] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 23:31:10,522] INFO [Partition Sensor-5 broker=3] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:10,528] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:10,529] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:10,530] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-1/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:31:10,530] INFO [Partition Sensor-4 broker=1] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 23:31:10,530] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:10,530] INFO [Partition Sensor-4 broker=1] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:10,531] INFO Created log for partition Sensor-3 in /tmp/kafka-logs/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:31:10,531] INFO [Partition Sensor-3 broker=0] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 23:31:10,531] INFO [Partition Sensor-3 broker=0] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:10,534] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-4/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:31:10,534] INFO [Partition Sensor-5 broker=4] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 23:31:10,534] INFO [Partition Sensor-5 broker=4] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:10,537] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:10,538] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:10,538] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:10,539] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-1/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:31:10,540] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-5/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:31:10,540] INFO Created log for partition Sensor-2 in /tmp/kafka-logs/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:31:10,540] INFO [Partition Sensor-5 broker=1] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 23:31:10,540] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:10,540] INFO [Partition Sensor-4 broker=5] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 23:31:10,540] INFO [Partition Sensor-2 broker=0] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 23:31:10,540] INFO [Partition Sensor-5 broker=1] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:10,540] INFO [Partition Sensor-2 broker=0] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:10,540] INFO [Partition Sensor-4 broker=5] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:10,540] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,540] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(Sensor-4, Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,542] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:10,542] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:10,543] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-4/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:31:10,544] INFO [Partition Sensor-0 broker=4] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 23:31:10,544] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-3/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:31:10,544] INFO [Partition Sensor-0 broker=4] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:10,544] INFO [Partition Sensor-2 broker=3] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 23:31:10,544] INFO [Partition Sensor-2 broker=3] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:10,544] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(Sensor-5, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,547] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-2/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:31:10,547] INFO [Partition Sensor-0 broker=2] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 23:31:10,547] INFO [Partition Sensor-0 broker=2] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:10,549] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:10,551] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-5/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:31:10,551] INFO [Partition Sensor-3 broker=5] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 23:31:10,551] INFO [Partition Sensor-3 broker=5] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:10,552] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(Sensor-4, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,553] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:10,555] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-3/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:31:10,555] INFO [Partition Sensor-1 broker=3] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 23:31:10,555] INFO [Partition Sensor-1 broker=3] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:10,555] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,556] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:31:10,558] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-2/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:31:10,558] INFO [Partition Sensor-1 broker=2] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 23:31:10,558] INFO [Partition Sensor-1 broker=2] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:31:10,559] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,569] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,574] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 4 for partitions Map(Sensor-3 -> InitialFetchState(Some(5_SsL5clR-yWzgw3MTtH1g),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,578] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 1 for partitions Map(Sensor-2 -> InitialFetchState(Some(5_SsL5clR-yWzgw3MTtH1g),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,578] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,578] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,579] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,580] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,583] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:31:10,583] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions Map(Sensor-4 -> InitialFetchState(Some(5_SsL5clR-yWzgw3MTtH1g),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,583] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:31:10,584] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,587] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,589] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,590] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 3 for partitions Map(Sensor-5 -> InitialFetchState(Some(5_SsL5clR-yWzgw3MTtH1g),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,591] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 0 for partitions Map(Sensor-0 -> InitialFetchState(Some(5_SsL5clR-yWzgw3MTtH1g),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,591] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,592] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,595] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:31:10,595] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,595] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,596] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:31:10,597] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 4 for partitions Map(Sensor-3 -> InitialFetchState(Some(5_SsL5clR-yWzgw3MTtH1g),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,598] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 1 for partitions Map(Sensor-2 -> InitialFetchState(Some(5_SsL5clR-yWzgw3MTtH1g),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,599] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:31:10,599] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,601] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,603] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 3 for partitions Map(Sensor-5 -> InitialFetchState(Some(5_SsL5clR-yWzgw3MTtH1g),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,603] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:31:10,604] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,604] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,604] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,605] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 2 for partitions Map(Sensor-4 -> InitialFetchState(Some(5_SsL5clR-yWzgw3MTtH1g),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,605] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,605] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,605] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:31:10,606] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,607] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:31:10,606] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:31:10,607] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 5 for partitions Map(Sensor-1 -> InitialFetchState(Some(5_SsL5clR-yWzgw3MTtH1g),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,606] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:31:10,610] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,619] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,619] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions Map(Sensor-0 -> InitialFetchState(Some(5_SsL5clR-yWzgw3MTtH1g),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,623] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:31:10,633] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 5 for partitions Map(Sensor-1 -> InitialFetchState(Some(5_SsL5clR-yWzgw3MTtH1g),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:31:10,637] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,638] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,640] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:31:10,709] WARN [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-2. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,709] WARN [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-3. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,744] WARN [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-4. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:10,745] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-4. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:31:45,777] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=631941, lastModifiedTime=1652653756807, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:31:45,780] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=631941, lastModifiedTime=1652653756807, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:31:45,784] INFO Deleted log /tmp/kafka-logs-1/Sensor-0.2fbcf69c5a3b482281aa02bca70433ca-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:31:45,784] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-0.2fbcf69c5a3b482281aa02bca70433ca-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:31:45,787] INFO Deleted time index /tmp/kafka-logs-1/Sensor-0.2fbcf69c5a3b482281aa02bca70433ca-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:31:45,791] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-1/Sensor-0.2fbcf69c5a3b482281aa02bca70433ca-delete. (kafka.log.LogManager)
[2022-05-15 23:31:51,760] INFO [GroupCoordinator 5]: Member consumer-consumer-1-8863ee28-05fa-4d10-b813-b83668f9ecf8 in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:51,766] INFO [GroupCoordinator 5]: Preparing to rebalance group consumer in state PreparingRebalance with old generation 1 (__consumer_offsets-22) (reason: removing member consumer-consumer-1-8863ee28-05fa-4d10-b813-b83668f9ecf8 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:31:51,768] INFO [GroupCoordinator 5]: Group consumer with generation 2 is now empty (__consumer_offsets-22) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:32:00,894] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=631941, lastModifiedTime=1652653756807, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:32:00,896] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=631941, lastModifiedTime=1652653756807, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:32:00,903] INFO Deleted log /tmp/kafka-logs-4/Sensor-0.3f3bf8622d1142c5a81392fbffd16450-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:32:00,904] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-0.3f3bf8622d1142c5a81392fbffd16450-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:32:00,911] INFO Deleted time index /tmp/kafka-logs-4/Sensor-0.3f3bf8622d1142c5a81392fbffd16450-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:32:00,923] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-4/Sensor-0.3f3bf8622d1142c5a81392fbffd16450-delete. (kafka.log.LogManager)
[2022-05-15 23:32:05,745] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=631941, lastModifiedTime=1652653756807, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:32:05,749] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=631941, lastModifiedTime=1652653756807, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:32:05,763] INFO Deleted log /tmp/kafka-logs-5/Sensor-0.aef9f939206e46a7a16a06814b942b40-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:32:05,765] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-0.aef9f939206e46a7a16a06814b942b40-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:32:05,772] INFO Deleted time index /tmp/kafka-logs-5/Sensor-0.aef9f939206e46a7a16a06814b942b40-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:32:05,790] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-5/Sensor-0.aef9f939206e46a7a16a06814b942b40-delete. (kafka.log.LogManager)
[2022-05-15 23:33:03,454] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:33:03,456] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:33:03,456] INFO [GroupCoordinator 4]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:33:03,457] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:33:03,458] INFO [GroupCoordinator 3]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:33:03,461] INFO [GroupMetadataManager brokerId=5] Group consumer transitioned to Dead in generation 2 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:33:03,468] INFO [GroupCoordinator 5]: Removed 6 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:33:03,490] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:03,490] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:03,491] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:03,491] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:03,491] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-4, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:03,491] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-2) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:03,491] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-4, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:03,491] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:03,492] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-5, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:03,492] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:03,493] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-5, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:03,493] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:03,496] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,497] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,498] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,498] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,499] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,499] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,499] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,500] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,501] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,502] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1516 due to node 1 being disconnected (elapsed time since creation: 399ms, elapsed time since send: 399ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,502] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1502 due to node 0 being disconnected (elapsed time since creation: 169ms, elapsed time since send: 169ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,502] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1511 due to node 1 being disconnected (elapsed time since creation: 397ms, elapsed time since send: 397ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,502] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=424284623, epoch=1514) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:33:03,502] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,503] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,503] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,503] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 770 due to node 2 being disconnected (elapsed time since creation: 322ms, elapsed time since send: 322ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,503] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,504] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,505] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 831 due to node 3 being disconnected (elapsed time since creation: 101ms, elapsed time since send: 101ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,503] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=281578460, epoch=1502) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:33:03,503] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=830982171, epoch=1511) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:33:03,507] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 778 due to node 2 being disconnected (elapsed time since creation: 336ms, elapsed time since send: 336ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,508] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,504] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1213476153, epoch=768) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:33:03,508] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,508] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,508] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,509] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,509] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,509] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,510] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,511] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1580 due to node 4 being disconnected (elapsed time since creation: 153ms, elapsed time since send: 153ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,506] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1366253029, epoch=831) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:33:03,511] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=769445212, epoch=1578) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:33:03,511] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,511] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,508] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=440175141, epoch=776) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:33:03,512] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,513] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,513] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,513] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,514] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,515] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,515] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,516] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,516] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,516] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 826 due to node 3 being disconnected (elapsed time since creation: 114ms, elapsed time since send: 114ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,516] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1526 due to node 5 being disconnected (elapsed time since creation: 146ms, elapsed time since send: 146ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,515] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,517] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:03,516] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=569999007, epoch=826) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:33:03,518] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:03,516] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=593812621, epoch=1526) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:33:03,518] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,518] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,518] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,518] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1540 due to node 5 being disconnected (elapsed time since creation: 150ms, elapsed time since send: 150ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,519] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,519] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,520] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1487 due to node 0 being disconnected (elapsed time since creation: 188ms, elapsed time since send: 188ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,518] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=1305510612, epoch=1540) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:33:03,520] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,520] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,520] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:03,521] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,521] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-2) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:03,520] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=1802802158, epoch=1487) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:33:03,522] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,522] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,522] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,523] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:03,523] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,524] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1585 due to node 4 being disconnected (elapsed time since creation: 157ms, elapsed time since send: 157ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:03,524] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:03,524] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=2051229970, epoch=1585) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:33:03,526] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,526] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:33:03,528] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-5, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:03,528] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-5, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:03,528] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:03,529] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:03,530] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-4, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:03,530] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-4, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:03,541] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs/Sensor-2.4999166fbd6a439884af71ef5fa76ac6-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:33:03,545] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs/Sensor-3.55f56872278344fd825c9840c5b2df94-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:33:03,548] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-1/Sensor-4.7055a841a5e640d8b2854066072bd121-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:33:03,548] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs/Sensor-0.faebf763023a42faa6c475bfb8c56747-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:33:03,548] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-5/Sensor-4.19afe84b16dc49d0874e30cb74d0364a-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:33:03,549] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-3/Sensor-5.baa10c5ca4b74b87a7681b78bda988ce-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:33:03,551] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-4/Sensor-5.69735b49d1da4ee9a93e7fa167096b9e-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:33:03,552] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-1/Sensor-5.ded6cc69afa64a52bbf3d9591b178d90-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:33:03,554] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-5/Sensor-3.f11b31c0dfdc4c8aa5558d85209ea8b4-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:33:03,554] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-4/Sensor-3.6a9ea80a5c97444a9e71d04d6e1504b7-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:33:03,555] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-1/Sensor-2.17c97f8b7b2a44c881c5348bbbdc035e-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:33:03,555] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-3/Sensor-2.3983dd26589b4f51a81f5092a1c6efb0-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:33:03,556] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-2/Sensor-4.b5f82e6480fd4b669a106d781b5d2cfa-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:33:03,556] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-5/Sensor-1.87d2bc8bfbf7497cb2dfc8f18e349f90-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:33:03,557] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-4/Sensor-0.bdcc0a18fdfc494ea5a175eb75727104-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:33:03,559] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-3/Sensor-1.8f172618122640ad9d52ee879167a963-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:33:03,560] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-2/Sensor-0.d44c13b0149f48aca3a8c6eadde96a2c-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:33:03,563] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-2/Sensor-1.cc7be4d68e294152b79460b409ee024a-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:33:06,842] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:33:06,842] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:33:06,842] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:33:06,842] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:33:06,842] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:33:06,842] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:33:06,845] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:33:06,845] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:33:06,845] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:33:06,845] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:33:06,845] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:33:06,846] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:33:06,846] INFO [KafkaServer id=4] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:33:06,847] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:33:06,847] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:33:06,848] INFO [KafkaServer id=5] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:33:06,849] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:33:06,851] INFO [KafkaServer id=5] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:33:06,872] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 17ms (kafka.server.KafkaServer)
[2022-05-15 23:33:06,875] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:33:06,875] INFO [KafkaServer id=4] Controlled shutdown request returned successfully after 21ms (kafka.server.KafkaServer)
[2022-05-15 23:33:06,875] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:33:06,875] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:33:06,877] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:33:06,877] INFO [KafkaServer id=5] Controlled shutdown request returned successfully after 18ms (kafka.server.KafkaServer)
[2022-05-15 23:33:06,879] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:33:06,879] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:33:06,880] INFO [KafkaServer id=3] Controlled shutdown request returned successfully after 22ms (kafka.server.KafkaServer)
[2022-05-15 23:33:06,880] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:33:06,882] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:33:06,882] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:33:06,882] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 24ms (kafka.server.KafkaServer)
[2022-05-15 23:33:06,882] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:33:06,882] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:33:06,884] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:33:06,884] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:33:06,885] INFO [KafkaServer id=2] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:06,885] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:33:06,885] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:33:06,888] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:33:06,888] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:33:06,890] INFO [KafkaServer id=2] Cancelled in-flight CONTROLLED_SHUTDOWN request with correlation id 0 due to node 0 being disconnected (elapsed time since creation: 24ms, elapsed time since send: 24ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:06,889] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:33:06,891] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:33:06,892] WARN [KafkaServer id=2] Error during controlled shutdown, possibly because leader movement took longer than the configured controller.socket.timeout.ms and/or request.timeout.ms: Connection to 0 was disconnected before the response was read (kafka.server.KafkaServer)
[2022-05-15 23:33:06,893] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:33:06,896] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:33:06,897] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:33:06,898] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:33:06,898] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:33:06,899] INFO [data-plane Kafka Request Handler on Broker 4], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:33:06,900] INFO [data-plane Kafka Request Handler on Broker 5], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:33:06,904] INFO [data-plane Kafka Request Handler on Broker 5], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:33:06,905] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:33:06,906] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:33:06,906] INFO [data-plane Kafka Request Handler on Broker 4], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:33:06,907] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:33:06,907] INFO [data-plane Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:33:06,907] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:33:06,910] INFO [ExpirationReaper-4-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:06,911] INFO [ExpirationReaper-5-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:06,912] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:33:06,913] INFO [data-plane Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:33:06,915] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:06,916] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:06,917] INFO [ExpirationReaper-3-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:06,959] INFO [ExpirationReaper-5-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:06,960] INFO [ExpirationReaper-5-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:06,961] INFO [KafkaApi-5] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:33:06,962] INFO [ExpirationReaper-5-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:06,982] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:06,982] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:06,983] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:33:06,985] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,004] INFO [ExpirationReaper-3-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,004] INFO [ExpirationReaper-3-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,005] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:33:07,007] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,033] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,033] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,036] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:33:07,038] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:33:07,038] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:33:07,038] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:33:07,039] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:33:07,041] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:33:07,041] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:33:07,042] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,052] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,053] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,054] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:33:07,056] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,074] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,074] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,075] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,080] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,080] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,081] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:33:07,083] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:33:07,083] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:33:07,084] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:33:07,084] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:33:07,086] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:07,088] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:07,089] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:07,090] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:07,090] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,095] INFO [ExpirationReaper-4-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,095] INFO [ExpirationReaper-4-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,097] INFO [KafkaApi-4] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:33:07,098] INFO [ExpirationReaper-4-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,099] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,099] INFO [ExpirationReaper-5-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,099] INFO [ExpirationReaper-5-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,099] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,102] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:33:07,103] INFO [TransactionCoordinator id=5] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:33:07,104] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:33:07,104] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:33:07,104] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:33:07,105] INFO [Transaction State Manager 5]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:33:07,105] INFO [Transaction Marker Channel Manager 5]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:33:07,104] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:33:07,106] INFO [Transaction Marker Channel Manager 5]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:33:07,106] INFO [Transaction Marker Channel Manager 5]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:33:07,107] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:33:07,108] INFO [TransactionCoordinator id=5] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:33:07,108] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:33:07,109] INFO [GroupCoordinator 5]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:33:07,109] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,110] INFO [ExpirationReaper-5-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,140] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,140] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,141] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,195] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,195] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,199] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:33:07,201] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:33:07,201] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:33:07,202] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:33:07,202] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:33:07,205] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:33:07,206] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:33:07,206] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,207] INFO [ExpirationReaper-4-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,207] INFO [ExpirationReaper-4-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,210] INFO [TransactionCoordinator id=4] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:33:07,211] INFO [Transaction State Manager 4]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:33:07,211] INFO [Transaction Marker Channel Manager 4]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:33:07,212] INFO [Transaction Marker Channel Manager 4]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:33:07,212] INFO [Transaction Marker Channel Manager 4]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:33:07,214] INFO [TransactionCoordinator id=4] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:33:07,214] INFO [GroupCoordinator 4]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:33:07,215] INFO [ExpirationReaper-4-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,226] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,226] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,226] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,257] INFO [ExpirationReaper-4-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,257] INFO [ExpirationReaper-4-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,258] INFO [ExpirationReaper-4-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,276] INFO [ExpirationReaper-5-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,276] INFO [ExpirationReaper-5-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,276] INFO [ExpirationReaper-5-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,336] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,336] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,337] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:33:07,339] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:33:07,339] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:33:07,340] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:33:07,340] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:33:07,341] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:07,343] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:07,344] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:07,345] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:07,345] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,352] INFO [ExpirationReaper-5-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,352] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,352] INFO [ExpirationReaper-5-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,352] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,353] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,354] INFO [GroupCoordinator 5]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:33:07,355] INFO [ReplicaManager broker=5] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:33:07,355] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:33:07,355] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:33:07,355] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:33:07,357] INFO [ReplicaFetcherManager on broker 5] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:07,358] INFO [ReplicaFetcherManager on broker 5] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:07,358] INFO [ReplicaAlterLogDirsManager on broker 5] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:07,360] INFO [ReplicaAlterLogDirsManager on broker 5] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:07,360] INFO [ExpirationReaper-5-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,384] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,384] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,385] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,417] INFO [ExpirationReaper-4-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,417] INFO [ExpirationReaper-4-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,418] INFO [GroupCoordinator 4]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:33:07,420] INFO [ReplicaManager broker=4] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:33:07,420] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:33:07,421] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:33:07,420] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:33:07,422] INFO [ReplicaFetcherManager on broker 4] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:07,423] INFO [ReplicaFetcherManager on broker 4] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:07,423] INFO [ReplicaAlterLogDirsManager on broker 4] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:07,424] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,424] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,425] INFO [ReplicaAlterLogDirsManager on broker 4] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:07,425] INFO [ExpirationReaper-4-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,425] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:33:07,427] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:33:07,427] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:33:07,428] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:33:07,428] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:33:07,429] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:07,431] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:07,431] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:07,432] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:07,432] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,466] INFO [ExpirationReaper-4-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,466] INFO [ExpirationReaper-4-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,466] INFO [ExpirationReaper-5-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,466] INFO [ExpirationReaper-5-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,467] INFO [ExpirationReaper-4-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,468] INFO [ExpirationReaper-5-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,507] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,507] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,507] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,550] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,550] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,551] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,552] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,552] INFO [ExpirationReaper-5-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,552] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,552] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,552] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,552] INFO [ExpirationReaper-5-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,553] INFO [ExpirationReaper-3-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,553] INFO [ExpirationReaper-5-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,553] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,607] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,607] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,608] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,634] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,634] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,635] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,664] INFO [ExpirationReaper-4-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,665] INFO [ExpirationReaper-4-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,665] INFO [ExpirationReaper-4-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,668] INFO [ExpirationReaper-4-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,668] INFO [ExpirationReaper-4-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,669] INFO [ExpirationReaper-4-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,697] INFO [ExpirationReaper-4-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,697] INFO [ExpirationReaper-4-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,703] INFO [ReplicaManager broker=4] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:33:07,704] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,705] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,705] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,708] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:33:07,709] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,710] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,710] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,711] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:33:07,712] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:33:07,740] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:33:07,744] INFO [ExpirationReaper-3-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,744] INFO [ExpirationReaper-3-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,746] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:33:07,746] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:33:07,746] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:33:07,747] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:33:07,750] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:33:07,751] WARN An exception was thrown while closing send thread for session 0x100000b00ad0088. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x100000b00ad0088, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 23:33:07,752] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,752] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,752] INFO [ExpirationReaper-5-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,752] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,752] INFO [ExpirationReaper-5-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,752] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,752] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,753] INFO [ExpirationReaper-5-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,755] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:33:07,756] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,757] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,757] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,759] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:33:07,759] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:33:07,759] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,760] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,760] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,760] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:33:07,762] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:33:07,762] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,762] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,762] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,763] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:33:07,764] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:33:07,791] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,792] INFO [Controller id=0, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,792] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,792] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,792] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:33:07,795] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,795] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,796] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,795] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,795] INFO [Controller id=0, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,796] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,797] WARN [Controller id=0, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,797] WARN [Controller id=0, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,797] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,797] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,798] INFO [Controller id=0, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,798] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,800] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:33:07,800] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,803] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,807] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,808] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:33:07,808] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:33:07,808] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:33:07,810] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:33:07,815] INFO [Controller id=0, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,816] WARN An exception was thrown while closing send thread for session 0x100000b00ad0087. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x100000b00ad0087, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 23:33:07,817] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,817] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,818] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,819] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:33:07,819] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:33:07,819] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:33:07,820] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:33:07,823] WARN An exception was thrown while closing send thread for session 0x100000b00ad0084. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x100000b00ad0084, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 23:33:07,849] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,849] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,852] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:33:07,853] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,853] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,853] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,854] INFO Session: 0x100000b00ad0088 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:33:07,854] INFO EventThread shut down for session: 0x100000b00ad0088 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:33:07,856] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:33:07,856] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:33:07,856] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:07,857] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,857] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,857] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,858] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:33:07,858] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:33:07,887] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:33:07,918] INFO Session: 0x100000b00ad0087 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:33:07,918] INFO EventThread shut down for session: 0x100000b00ad0087 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:33:07,920] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:33:07,921] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:07,925] INFO Session: 0x100000b00ad0084 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:33:07,925] INFO EventThread shut down for session: 0x100000b00ad0084 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:33:07,927] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:33:07,928] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:07,940] INFO [Controller id=1, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,940] INFO [Controller id=1, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,944] WARN [Controller id=1, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,944] WARN [Controller id=1, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,946] INFO [Controller id=1, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,946] INFO [Controller id=1, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:07,952] INFO [ExpirationReaper-5-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,952] INFO [ExpirationReaper-5-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:07,957] INFO [ReplicaManager broker=5] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:33:07,958] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,958] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,958] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,960] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:33:07,961] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,962] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,962] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:07,963] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:33:07,963] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:33:07,986] INFO [ProducerStateManager partition=__consumer_offsets-22] Wrote producer snapshot at offset 56709 with 0 producer ids in 3 ms. (kafka.log.ProducerStateManager)
[2022-05-15 23:33:08,000] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:33:08,007] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:33:08,007] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:33:08,007] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:33:08,008] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:33:08,048] INFO [Controller id=1, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:08,048] INFO [Controller id=1, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:08,048] WARN [Controller id=1, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:08,048] WARN [Controller id=1, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:08,049] INFO [Controller id=1, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:08,050] INFO [Controller id=1, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:08,114] INFO Session: 0x100000b00ad0089 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:33:08,114] INFO EventThread shut down for session: 0x100000b00ad0089 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:33:08,114] INFO [Controller id=1, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:08,116] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:33:08,118] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,120] INFO [Controller id=1, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:08,124] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:33:08,124] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:33:08,124] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:33:08,126] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:33:08,130] WARN An exception was thrown while closing send thread for session 0x100000b00ad0085. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x100000b00ad0085, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 23:33:08,233] INFO Session: 0x100000b00ad0085 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:33:08,233] INFO EventThread shut down for session: 0x100000b00ad0085 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:33:08,235] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:33:08,236] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,538] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,538] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,538] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,563] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,563] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,563] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,591] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,591] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,592] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,596] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,596] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,597] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,605] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,605] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,606] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,616] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,617] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,617] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,620] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,620] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,620] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,630] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,630] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,630] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,640] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,641] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,642] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:33:08,668] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:33:08,669] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:33:08,670] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:33:08,670] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:33:08,671] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:33:08,672] INFO App info kafka.server for 5 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:33:08,673] INFO [KafkaServer id=5] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:33:08,720] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,720] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:08,721] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:09,539] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:09,539] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:09,539] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:09,548] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:09,548] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:09,548] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:09,561] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:09,561] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:09,562] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:09,563] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:09,563] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:09,564] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:09,572] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:09,572] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:09,574] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:33:09,597] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:33:09,598] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:33:09,598] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:33:09,598] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:33:09,599] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:33:09,600] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:33:09,601] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:33:09,603] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:09,604] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:09,605] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:33:09,631] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:33:09,631] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:33:09,632] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:33:09,632] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:33:09,633] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:33:09,634] INFO App info kafka.server for 3 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:33:09,634] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:33:09,718] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:09,718] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:09,718] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:10,539] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:10,539] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:10,541] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:33:10,566] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:33:10,567] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:33:10,567] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:33:10,567] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:33:10,568] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:33:10,569] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:33:10,570] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:33:10,712] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:10,712] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:10,713] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:10,718] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:10,719] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:10,720] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:33:10,742] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:33:10,743] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:33:10,743] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:33:10,743] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:33:10,745] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:33:10,746] INFO App info kafka.server for 4 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:33:10,746] INFO [KafkaServer id=4] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:33:11,893] INFO [KafkaServer id=2] Retrying controlled shutdown (2 retries remaining) (kafka.server.KafkaServer)
[2022-05-15 23:33:11,894] INFO [KafkaServer id=2] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:33:11,911] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 15ms (kafka.server.KafkaServer)
[2022-05-15 23:33:11,915] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:33:11,915] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:33:11,915] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:33:11,918] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:33:11,928] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:33:11,930] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:33:11,934] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:33:11,939] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:11,999] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:11,999] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:12,000] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:33:12,002] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:12,106] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:12,106] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:12,109] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:33:12,111] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:33:12,111] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:33:12,112] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:33:12,112] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:33:12,115] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:33:12,116] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:33:12,117] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:12,315] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:12,316] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:12,316] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:12,325] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:12,325] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:12,326] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:33:12,328] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:33:12,328] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:33:12,329] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:33:12,329] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:33:12,330] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:12,332] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:33:12,332] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:12,333] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:33:12,334] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:12,473] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:12,474] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:12,474] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:12,600] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:12,600] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:12,601] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:12,634] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:12,634] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:12,634] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:12,834] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:12,834] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:33:12,846] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:33:12,846] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:12,847] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:12,847] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:12,849] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:33:12,850] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:12,850] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:12,850] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:33:12,851] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:33:12,852] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:33:12,887] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:33:12,900] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:33:12,900] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:33:12,900] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:33:12,902] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:33:12,907] WARN An exception was thrown while closing send thread for session 0x100000b00ad0086. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x100000b00ad0086, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 23:33:13,009] INFO Session: 0x100000b00ad0086 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:33:13,009] INFO EventThread shut down for session: 0x100000b00ad0086 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:33:13,011] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:33:13,012] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:13,588] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:13,588] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:13,588] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:14,582] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:14,582] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:14,582] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:14,584] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:14,584] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:14,584] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:14,597] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:14,597] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:33:14,599] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:33:14,624] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:33:14,625] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:33:14,625] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:33:14,626] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:33:14,627] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:33:14,628] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:33:14,628] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:34:50,283] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:34:50,293] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:34:50,294] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:34:50,294] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:34:50,294] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:34:50,296] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 23:34:50,296] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 23:34:50,296] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 23:34:50,297] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-15 23:34:50,301] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-15 23:34:50,318] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:34:50,319] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:34:50,319] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:34:50,319] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:34:50,319] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:34:50,319] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-15 23:34:50,335] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@6156496 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-15 23:34:50,339] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 23:34:50,350] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,350] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,350] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,350] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,350] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,350] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,350] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,350] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,350] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,350] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,352] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,352] INFO Server environment:host.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,352] INFO Server environment:java.version=11.0.15 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,352] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,352] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,352] INFO Server environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,353] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,353] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,353] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,353] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,353] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,353] INFO Server environment:os.version=5.13.0-40-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,353] INFO Server environment:user.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,353] INFO Server environment:user.home=/home/joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,353] INFO Server environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,353] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,353] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,353] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,353] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,354] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,354] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,354] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,354] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,354] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,354] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,355] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-15 23:34:50,358] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,358] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,359] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 23:34:50,359] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 23:34:50,360] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:34:50,360] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:34:50,360] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:34:50,360] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:34:50,360] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:34:50,360] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:34:50,363] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,363] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,363] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:34:50,372] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 23:34:50,373] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 23:34:50,375] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 23:34:50,379] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 23:34:50,380] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:459)
	at java.base/sun.nio.ch.Net.bind(Net.java:448)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:676)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:158)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:112)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:67)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:140)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:90)
[2022-05-15 23:34:50,384] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-15 23:34:50,387] ERROR Exiting JVM with code 1 (org.apache.zookeeper.util.ServiceUtils)
[2022-05-15 23:34:55,295] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:34:55,591] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:34:55,687] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:34:55,691] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:34:55,692] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:34:55,710] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:34:55,715] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:34:55,715] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:34:55,715] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:34:55,715] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:34:55,716] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:34:55,716] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:34:55,716] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:34:55,716] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:34:55,716] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:34:55,716] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:34:55,716] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:34:55,716] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:34:55,716] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:34:55,716] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:34:55,716] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:34:55,716] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:34:55,716] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:34:55,717] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:34:55,719] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:34:55,724] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:34:55,731] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:34:55,746] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:34:55,756] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:34:55,758] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:34:55,764] INFO Socket connection established, initiating session, client: /127.0.0.1:58108, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:34:55,774] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad008a, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:34:55,780] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:34:55,878] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:34:56,039] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:34:56,045] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:34:56,101] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:34:56,113] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:34:56,176] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:34:56,179] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:34:56,182] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:34:56,186] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:34:56,240] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:34:56,245] INFO Skipping recovery for all logs in /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:34:56,322] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:34:56,345] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-2.4999166fbd6a439884af71ef5fa76ac6-delete, topicId=5_SsL5clR-yWzgw3MTtH1g, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 80ms (1/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:34:56,362] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:34:56,366] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-21, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (2/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:34:56,372] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:34:56,378] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-0.faebf763023a42faa6c475bfb8c56747-delete, topicId=5_SsL5clR-yWzgw3MTtH1g, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (3/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:34:56,401] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 35579 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:34:56,401] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 35579 (kafka.log.UnifiedLog$)
[2022-05-15 23:34:56,403] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs/__consumer_offsets-39/00000000000000035579.snapshot,35579)' (kafka.log.ProducerStateManager)
[2022-05-15 23:34:56,407] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 35579 (kafka.log.UnifiedLog$)
[2022-05-15 23:34:56,411] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-39, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=35579) with 1 segments in 33ms (4/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:34:56,418] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:34:56,420] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-15, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (5/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:34:56,427] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:34:56,431] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-45, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (6/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:34:56,435] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:34:56,439] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-3.55f56872278344fd825c9840c5b2df94-delete, topicId=5_SsL5clR-yWzgw3MTtH1g, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:34:56,444] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:34:56,447] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-33, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (8/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:34:56,454] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:34:56,456] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-27, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (9/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:34:56,462] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:34:56,465] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-3, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (10/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:34:56,471] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:34:56,475] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-9, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (11/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:34:56,481] INFO Loaded 11 logs in 240ms. (kafka.log.LogManager)
[2022-05-15 23:34:56,482] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:34:56,484] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:34:56,786] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:34:56,964] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:34:56,969] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-15 23:34:57,006] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:34:57,014] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:34:57,030] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:34:57,031] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:34:57,033] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:34:57,034] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:34:57,046] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:34:57,097] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:34:57,116] INFO Stat of the created znode at /brokers/ids/0 is: 6678,6678,1652654097108,1652654097108,1,0,0,72057641293906058,192,0,6678
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:34:57,117] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://joao:9092, czxid (broker epoch): 6678 (kafka.zk.KafkaZkClient)
[2022-05-15 23:34:57,176] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:34:57,182] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:34:57,183] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:34:57,199] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:34:57,225] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:34:57,243] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:34:57,248] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:34:57,248] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:34:57,280] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:34:57,302] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:34:57,327] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:34:57,335] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:34:57,336] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:34:57,342] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:34:57,343] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:34:57,343] INFO Kafka startTimeMs: 1652654097336 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:34:57,346] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-15 23:34:57,408] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:34:57,419] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:34:57,420] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:34:57,420] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:34:57,420] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 35579 (kafka.cluster.Partition)
[2022-05-15 23:34:57,420] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:34:57,420] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:34:57,420] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:34:57,421] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:34:57,421] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:34:57,470] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-3, __consumer_offsets-15, __consumer_offsets-39, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:34:57,502] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 41 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:34:57,503] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 41 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:34:57,505] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 41 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:34:57,505] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 41 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:34:57,505] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 41 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:34:57,505] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 41 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:34:57,505] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 41 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:34:57,505] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 41 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:34:57,505] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 41 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:34:57,505] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 41 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:34:57,505] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 41 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:34:57,505] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 41 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:34:57,505] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 41 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:34:57,505] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 41 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:34:57,505] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 41 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:34:57,505] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 41 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:34:57,511] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 6 milliseconds for epoch 41, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:34:57,512] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 7 milliseconds for epoch 41, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:34:57,596] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 91 milliseconds for epoch 41, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:34:57,597] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 92 milliseconds for epoch 41, of which 92 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:34:57,598] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 93 milliseconds for epoch 41, of which 92 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:34:57,598] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 93 milliseconds for epoch 41, of which 93 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:34:57,599] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 93 milliseconds for epoch 41, of which 93 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:34:57,599] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 94 milliseconds for epoch 41, of which 94 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:00,285] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:35:00,559] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:35:00,646] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:35:00,651] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:35:00,651] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:35:00,672] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:35:00,678] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:00,678] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:00,678] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:00,678] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:00,679] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:00,679] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:00,679] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:00,679] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:00,679] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:00,679] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:00,679] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:00,679] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:00,679] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:00,679] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:00,679] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:00,679] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:00,679] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:00,679] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:00,682] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:00,688] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:35:00,707] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:00,715] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:35:00,722] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:00,724] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:00,733] INFO Socket connection established, initiating session, client: /127.0.0.1:58110, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:00,742] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad008b, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:00,748] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:35:00,860] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:35:01,016] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:35:01,024] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:35:01,081] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:35:01,092] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:35:01,157] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:35:01,159] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:35:01,163] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:35:01,166] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:35:01,221] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:35:01,227] INFO Skipping recovery for all logs in /tmp/kafka-logs-1 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:35:01,318] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:01,345] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-17, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 99ms (1/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:35:01,352] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:01,357] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-35, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (2/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:35:01,363] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:01,367] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-41, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (3/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:35:01,374] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:01,378] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-29, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (4/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:35:01,384] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:01,387] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-11, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (5/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:35:01,393] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:01,397] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-23, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (6/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:35:01,402] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:01,406] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-2.17c97f8b7b2a44c881c5348bbbdc035e-delete, topicId=5_SsL5clR-yWzgw3MTtH1g, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:35:01,411] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:01,416] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-5.ded6cc69afa64a52bbf3d9591b178d90-delete, topicId=5_SsL5clR-yWzgw3MTtH1g, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (8/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:35:01,423] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:01,427] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-47, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (9/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:35:01,432] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:01,437] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-4.7055a841a5e640d8b2854066072bd121-delete, topicId=5_SsL5clR-yWzgw3MTtH1g, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (10/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:35:01,443] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:01,446] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-5, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (11/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:35:01,451] INFO Loaded 11 logs in 229ms. (kafka.log.LogManager)
[2022-05-15 23:35:01,452] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:35:01,454] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:35:01,722] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:35:01,819] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:35:01,822] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-15 23:35:01,845] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:35:01,850] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:35:01,865] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:01,866] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:01,867] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:01,869] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:01,879] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:35:01,932] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:35:01,950] INFO Stat of the created znode at /brokers/ids/1 is: 6746,6746,1652654101942,1652654101942,1,0,0,72057641293906059,192,0,6746
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:35:01,952] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://joao:9093, czxid (broker epoch): 6746 (kafka.zk.KafkaZkClient)
[2022-05-15 23:35:02,016] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:02,020] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:02,022] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:02,036] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:02,047] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:02,066] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:35:02,075] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:35:02,076] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:35:02,098] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:02,114] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:35:02,131] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:35:02,136] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:35:02,137] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:35:02,141] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:35:02,142] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:35:02,143] INFO Kafka startTimeMs: 1652654102137 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:35:02,144] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-15 23:35:02,232] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:35:02,239] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:02,239] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:02,239] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:02,239] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:02,240] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:02,240] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:02,240] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:02,240] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:02,253] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:35:02,264] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-5, __consumer_offsets-29, __consumer_offsets-41, __consumer_offsets-23) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:35:02,297] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:02,298] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:02,300] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:02,300] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:02,300] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:02,300] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:02,300] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:02,300] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:02,300] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:02,300] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:02,300] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:02,300] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:02,300] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:02,300] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:02,301] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 69 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:02,301] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 69 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:02,310] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 10 milliseconds for epoch 69, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:02,310] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 10 milliseconds for epoch 69, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:02,311] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 11 milliseconds for epoch 69, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:02,311] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 11 milliseconds for epoch 69, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:02,311] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 11 milliseconds for epoch 69, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:02,311] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 11 milliseconds for epoch 69, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:02,311] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 11 milliseconds for epoch 69, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:02,311] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 10 milliseconds for epoch 69, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:05,301] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:35:05,603] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:35:05,712] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:35:05,717] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:35:05,719] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:35:05,738] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:35:05,745] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:05,745] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:05,745] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:05,746] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:05,746] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:05,746] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:05,747] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:05,747] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:05,747] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:05,747] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:05,747] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:05,747] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:05,747] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:05,747] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:05,747] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:05,748] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:05,748] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:05,748] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:05,751] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:05,757] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:35:05,763] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:05,782] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:35:05,790] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:05,792] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:05,797] INFO Socket connection established, initiating session, client: /127.0.0.1:58112, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:05,807] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad008c, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:05,814] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:35:05,915] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:35:06,070] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:35:06,076] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:35:06,139] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:35:06,152] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:35:06,216] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:35:06,219] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:35:06,222] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:35:06,225] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:35:06,274] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:35:06,279] INFO Skipping recovery for all logs in /tmp/kafka-logs-2 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:35:06,357] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:06,376] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-49, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 78ms (1/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:35:06,381] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:06,384] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-19, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (2/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:35:06,389] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:06,392] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-1.cc7be4d68e294152b79460b409ee024a-delete, topicId=5_SsL5clR-yWzgw3MTtH1g, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (3/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:35:06,397] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:06,399] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-7, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (4/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:35:06,405] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:06,408] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-13, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:35:06,413] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:06,416] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-37, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:35:06,421] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:06,423] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-43, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:35:06,427] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:06,431] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-1, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:35:06,435] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:06,437] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-0.d44c13b0149f48aca3a8c6eadde96a2c-delete, topicId=5_SsL5clR-yWzgw3MTtH1g, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (9/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:35:06,441] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:06,444] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-31, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:35:06,449] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:06,451] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-4.b5f82e6480fd4b669a106d781b5d2cfa-delete, topicId=5_SsL5clR-yWzgw3MTtH1g, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:35:06,456] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:06,458] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-25, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (12/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:35:06,461] INFO Loaded 12 logs in 187ms. (kafka.log.LogManager)
[2022-05-15 23:35:06,462] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:35:06,463] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:35:06,685] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:35:06,786] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:35:06,788] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-15 23:35:06,811] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:35:06,817] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:35:06,833] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:06,834] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:06,836] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:06,837] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:06,848] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:35:06,900] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:35:06,916] INFO Stat of the created znode at /brokers/ids/2 is: 6770,6770,1652654106908,1652654106908,1,0,0,72057641293906060,192,0,6770
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:35:06,917] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://joao:9094, czxid (broker epoch): 6770 (kafka.zk.KafkaZkClient)
[2022-05-15 23:35:06,975] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:06,980] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:06,981] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:06,995] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:07,006] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:07,024] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:35:07,032] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:35:07,032] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:35:07,055] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:07,070] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:35:07,087] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:35:07,092] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:35:07,092] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:35:07,097] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:35:07,097] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:35:07,097] INFO Kafka startTimeMs: 1652654107092 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:35:07,099] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-15 23:35:07,194] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:07,194] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:07,195] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:35:07,195] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:07,195] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:07,195] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:07,195] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:07,196] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:07,196] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:07,196] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:07,220] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-7, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:35:07,222] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:35:07,253] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 68 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:07,255] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 68 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:07,256] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 68 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:07,256] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 68 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:07,256] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 68 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:07,257] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 68 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:07,257] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 68 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:07,257] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 68 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:07,257] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 68 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:07,257] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 68 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:07,257] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 68 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:07,258] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 68 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:07,258] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 68 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:07,258] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 68 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:07,258] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 68 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:07,258] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 68 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:07,258] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 68 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:07,258] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 68 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:07,262] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 7 milliseconds for epoch 68, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:07,263] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 7 milliseconds for epoch 68, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:07,264] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 7 milliseconds for epoch 68, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:07,264] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 7 milliseconds for epoch 68, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:07,264] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 7 milliseconds for epoch 68, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:07,265] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 7 milliseconds for epoch 68, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:07,265] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 7 milliseconds for epoch 68, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:07,265] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 7 milliseconds for epoch 68, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:07,266] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 8 milliseconds for epoch 68, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:10,299] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:35:10,606] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:35:10,708] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:35:10,713] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:35:10,714] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:35:10,736] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:35:10,742] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:10,742] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:10,742] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:10,743] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:10,743] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:10,743] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:10,743] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:10,743] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:10,743] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:10,743] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:10,743] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:10,743] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:10,743] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:10,744] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:10,744] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:10,744] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:10,744] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:10,744] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:10,746] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:10,752] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:35:10,757] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:10,779] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:35:10,784] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:10,788] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:10,793] INFO Socket connection established, initiating session, client: /127.0.0.1:58114, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:10,800] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad008d, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:10,805] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:35:10,902] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:35:11,066] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:35:11,075] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:35:11,141] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:35:11,154] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:35:11,217] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:35:11,219] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:35:11,222] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:35:11,224] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:35:11,271] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:35:11,276] INFO Skipping recovery for all logs in /tmp/kafka-logs-3 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:35:11,363] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:11,394] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-2.3983dd26589b4f51a81f5092a1c6efb0-delete, topicId=5_SsL5clR-yWzgw3MTtH1g, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 98ms (1/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:35:11,413] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:11,419] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-14, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 23ms (2/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:35:11,443] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Loading producer state till offset 91906 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:11,443] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Reloading from producer snapshot and rebuilding producer state from offset 91906 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:11,445] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-3/__consumer_offsets-38/00000000000000091906.snapshot,91906)' (kafka.log.ProducerStateManager)
[2022-05-15 23:35:11,452] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Producer state recovery took 9ms for snapshot load and 0ms for segment recovery from offset 91906 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:11,457] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-38, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=91906) with 1 segments in 38ms (3/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:35:11,463] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:11,468] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-8, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (4/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:35:11,472] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:11,475] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-2, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:35:11,479] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:11,481] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-26, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (6/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:35:11,486] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:11,490] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-20, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:35:11,494] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:11,496] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-5.baa10c5ca4b74b87a7681b78bda988ce-delete, topicId=5_SsL5clR-yWzgw3MTtH1g, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:35:11,501] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:11,504] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-1.8f172618122640ad9d52ee879167a963-delete, topicId=5_SsL5clR-yWzgw3MTtH1g, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:35:11,508] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:11,512] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-32, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:35:11,516] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:11,519] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-44, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:35:11,522] INFO Loaded 11 logs in 250ms. (kafka.log.LogManager)
[2022-05-15 23:35:11,522] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:35:11,523] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:35:11,724] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:35:11,819] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:35:11,823] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-05-15 23:35:11,844] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:35:11,851] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:35:11,865] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:11,867] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:11,868] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:11,870] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:11,880] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:35:11,928] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:35:11,945] INFO Stat of the created znode at /brokers/ids/3 is: 6795,6795,1652654111935,1652654111935,1,0,0,72057641293906061,192,0,6795
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:35:11,946] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://joao:9095, czxid (broker epoch): 6795 (kafka.zk.KafkaZkClient)
[2022-05-15 23:35:12,011] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:12,015] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:12,016] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:12,029] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:12,039] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:12,062] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:35:12,066] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:35:12,067] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:35:12,090] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:12,109] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:35:12,128] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:35:12,134] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:35:12,135] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:35:12,142] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:35:12,143] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:35:12,143] INFO Kafka startTimeMs: 1652654112135 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:35:12,146] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-05-15 23:35:12,229] INFO [Partition __consumer_offsets-2 broker=3] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:12,230] INFO [Partition __consumer_offsets-20 broker=3] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:12,230] INFO [Partition __consumer_offsets-38 broker=3] Log loaded for partition __consumer_offsets-38 with initial high watermark 91906 (kafka.cluster.Partition)
[2022-05-15 23:35:12,230] INFO [Partition __consumer_offsets-8 broker=3] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:12,231] INFO [Partition __consumer_offsets-26 broker=3] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:12,231] INFO [Partition __consumer_offsets-44 broker=3] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:12,231] INFO [Partition __consumer_offsets-14 broker=3] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:12,232] INFO [Partition __consumer_offsets-32 broker=3] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:12,234] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:35:12,254] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:35:12,257] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-26, __consumer_offsets-32, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:35:12,287] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 2 in epoch 65 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:12,288] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 65 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:12,291] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 20 in epoch 65 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:12,291] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 65 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:12,291] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 38 in epoch 65 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:12,291] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 65 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:12,291] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 8 in epoch 65 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:12,291] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 65 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:12,291] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 26 in epoch 65 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:12,291] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 65 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:12,291] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 44 in epoch 65 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:12,291] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 65 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:12,291] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 14 in epoch 65 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:12,291] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 65 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:12,291] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 32 in epoch 65 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:12,291] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 65 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:12,299] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-2 in 10 milliseconds for epoch 65, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:12,299] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-20 in 8 milliseconds for epoch 65, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:12,439] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-38 in 148 milliseconds for epoch 65, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:12,439] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-8 in 148 milliseconds for epoch 65, of which 148 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:12,439] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-26 in 148 milliseconds for epoch 65, of which 148 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:12,439] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-44 in 148 milliseconds for epoch 65, of which 148 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:12,440] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-14 in 149 milliseconds for epoch 65, of which 149 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:12,440] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-32 in 149 milliseconds for epoch 65, of which 149 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:15,342] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:35:15,686] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:35:15,808] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:35:15,813] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:35:15,814] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:35:15,840] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:35:15,850] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:15,850] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:15,850] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:15,850] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:15,851] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:15,851] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:15,852] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:15,852] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:15,852] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:15,852] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:15,852] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:15,852] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:15,852] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:15,852] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:15,852] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:15,852] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:15,852] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:15,852] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:15,855] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:15,863] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:35:15,870] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:15,894] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:35:15,900] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:15,901] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:15,906] INFO Socket connection established, initiating session, client: /127.0.0.1:58116, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:15,915] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad008e, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:15,919] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:35:16,020] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:35:16,178] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:35:16,184] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:35:16,256] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:35:16,270] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:35:16,324] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:35:16,325] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:35:16,327] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:35:16,328] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:35:16,365] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:35:16,369] INFO Skipping recovery for all logs in /tmp/kafka-logs-4 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:35:16,432] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:16,452] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-24, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 67ms (1/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:35:16,459] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:16,462] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-5.69735b49d1da4ee9a93e7fa167096b9e-delete, topicId=5_SsL5clR-yWzgw3MTtH1g, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (2/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:35:16,466] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:16,469] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-12, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (3/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:35:16,473] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:16,476] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-30, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (4/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:35:16,480] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:16,483] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-36, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:35:16,487] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:16,489] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-3.6a9ea80a5c97444a9e71d04d6e1504b7-delete, topicId=5_SsL5clR-yWzgw3MTtH1g, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (6/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:35:16,493] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:16,495] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-42, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (7/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:35:16,500] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:16,503] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-0, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:35:16,507] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:16,509] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-18, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (9/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:35:16,513] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:16,517] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-6, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (10/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:35:16,524] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:16,526] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-48, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (11/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:35:16,530] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:16,532] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-0.bdcc0a18fdfc494ea5a175eb75727104-delete, topicId=5_SsL5clR-yWzgw3MTtH1g, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (12/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:35:16,535] INFO Loaded 12 logs in 170ms. (kafka.log.LogManager)
[2022-05-15 23:35:16,536] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:35:16,537] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:35:16,757] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:35:16,885] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:35:16,888] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.Acceptor)
[2022-05-15 23:35:16,914] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:35:16,922] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:35:16,936] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:16,938] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:16,939] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:16,940] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:16,952] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:35:17,011] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:35:17,031] INFO Stat of the created znode at /brokers/ids/4 is: 6819,6819,1652654117023,1652654117023,1,0,0,72057641293906062,192,0,6819
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:35:17,033] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://joao:9096, czxid (broker epoch): 6819 (kafka.zk.KafkaZkClient)
[2022-05-15 23:35:17,096] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:17,102] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:17,103] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:17,118] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:17,131] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:17,156] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:35:17,162] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:35:17,162] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:35:17,185] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:17,202] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:35:17,221] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:35:17,227] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:35:17,227] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:35:17,232] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:35:17,232] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:35:17,232] INFO Kafka startTimeMs: 1652654117227 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:35:17,234] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2022-05-15 23:35:17,325] INFO [Partition __consumer_offsets-18 broker=4] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:17,326] INFO [Partition __consumer_offsets-36 broker=4] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:17,326] INFO [Partition __consumer_offsets-6 broker=4] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:17,327] INFO [Partition __consumer_offsets-24 broker=4] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:17,328] INFO [Partition __consumer_offsets-42 broker=4] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:17,328] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:35:17,328] INFO [Partition __consumer_offsets-12 broker=4] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:17,328] INFO [Partition __consumer_offsets-30 broker=4] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:17,329] INFO [Partition __consumer_offsets-0 broker=4] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:17,329] INFO [Partition __consumer_offsets-48 broker=4] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:17,356] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-12, __consumer_offsets-42, __consumer_offsets-18) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:35:17,368] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:35:17,390] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 18 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:17,392] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:17,394] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 36 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:17,394] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:17,394] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 6 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:17,394] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:17,394] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 24 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:17,394] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:17,394] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 42 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:17,394] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:17,394] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 12 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:17,394] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:17,394] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 30 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:17,394] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:17,394] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 0 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:17,394] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:17,394] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 48 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:17,395] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:17,401] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-18 in 8 milliseconds for epoch 74, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:17,401] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-36 in 7 milliseconds for epoch 74, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:17,402] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-6 in 8 milliseconds for epoch 74, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:17,402] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-24 in 8 milliseconds for epoch 74, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:17,402] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-42 in 8 milliseconds for epoch 74, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:17,403] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-12 in 9 milliseconds for epoch 74, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:17,403] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-30 in 9 milliseconds for epoch 74, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:17,403] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-0 in 9 milliseconds for epoch 74, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:17,404] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-48 in 9 milliseconds for epoch 74, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:20,366] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:35:20,715] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:35:20,823] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:35:20,827] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:35:20,828] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:35:20,847] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:35:20,853] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:20,854] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:20,854] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:20,854] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:20,854] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:20,854] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:20,854] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:20,855] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:20,855] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:20,855] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:20,855] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:20,855] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:20,855] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:20,855] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:20,855] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:20,855] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:20,855] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:20,855] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:20,857] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:35:20,863] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:35:20,870] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:20,888] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:35:20,897] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:20,899] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:20,904] INFO Socket connection established, initiating session, client: /127.0.0.1:58118, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:20,916] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad008f, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:35:20,923] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:35:21,024] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:35:21,174] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:35:21,178] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:35:21,217] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:35:21,225] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:35:21,267] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:35:21,268] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:35:21,270] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:35:21,271] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:35:21,304] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:35:21,307] INFO Skipping recovery for all logs in /tmp/kafka-logs-5 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:35:21,374] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:21,395] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-46, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 75ms (1/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:35:21,400] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:21,406] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-3.f11b31c0dfdc4c8aa5558d85209ea8b4-delete, topicId=5_SsL5clR-yWzgw3MTtH1g, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (2/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:35:21,410] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:21,413] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-10, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (3/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:35:21,417] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:21,420] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-1.87d2bc8bfbf7497cb2dfc8f18e349f90-delete, topicId=5_SsL5clR-yWzgw3MTtH1g, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (4/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:35:21,425] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:21,428] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-28, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:35:21,440] INFO Deleted producer state snapshot /tmp/kafka-logs-5/__consumer_offsets-22/00000000000000049579.snapshot (kafka.log.SnapshotFile)
[2022-05-15 23:35:21,442] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Loading producer state till offset 56709 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:21,442] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 56709 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:21,443] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-22/00000000000000056709.snapshot,56709)' (kafka.log.ProducerStateManager)
[2022-05-15 23:35:21,449] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 56709 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:21,452] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-22, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=56709) with 1 segments in 23ms (6/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:35:21,456] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:21,458] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-16, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:35:21,462] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:21,465] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-4.19afe84b16dc49d0874e30cb74d0364a-delete, topicId=5_SsL5clR-yWzgw3MTtH1g, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (8/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:35:21,473] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Loading producer state till offset 35134 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:21,474] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 35134 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:21,474] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-40/00000000000000035134.snapshot,35134)' (kafka.log.ProducerStateManager)
[2022-05-15 23:35:21,474] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 35134 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:21,476] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-40, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=35134) with 1 segments in 11ms (9/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:35:21,480] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:21,483] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-34, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (10/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:35:21,488] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:21,490] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-4, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (11/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:35:21,492] INFO Loaded 11 logs in 188ms. (kafka.log.LogManager)
[2022-05-15 23:35:21,494] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:35:21,495] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:35:21,703] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:35:21,804] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:35:21,807] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.Acceptor)
[2022-05-15 23:35:21,831] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:35:21,836] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:35:21,851] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:21,853] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:21,855] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:21,857] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:21,870] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:35:21,921] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:35:21,939] INFO Stat of the created znode at /brokers/ids/5 is: 6844,6844,1652654121930,1652654121930,1,0,0,72057641293906063,192,0,6844
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:35:21,940] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://joao:9097, czxid (broker epoch): 6844 (kafka.zk.KafkaZkClient)
[2022-05-15 23:35:22,002] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:22,007] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:22,008] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:22,021] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:22,032] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:22,052] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:35:22,056] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:35:22,056] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:35:22,086] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:35:22,103] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:35:22,123] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:35:22,129] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:35:22,129] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:35:22,134] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:35:22,134] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:35:22,134] INFO Kafka startTimeMs: 1652654122129 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:35:22,137] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2022-05-15 23:35:22,215] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:35:22,226] INFO [Partition __consumer_offsets-34 broker=5] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:22,226] INFO [Partition __consumer_offsets-4 broker=5] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:22,227] INFO [Partition __consumer_offsets-22 broker=5] Log loaded for partition __consumer_offsets-22 with initial high watermark 56709 (kafka.cluster.Partition)
[2022-05-15 23:35:22,227] INFO [Partition __consumer_offsets-40 broker=5] Log loaded for partition __consumer_offsets-40 with initial high watermark 35134 (kafka.cluster.Partition)
[2022-05-15 23:35:22,227] INFO [Partition __consumer_offsets-10 broker=5] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:22,228] INFO [Partition __consumer_offsets-28 broker=5] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:22,228] INFO [Partition __consumer_offsets-46 broker=5] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:22,228] INFO [Partition __consumer_offsets-16 broker=5] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:22,239] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:35:22,249] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:35:22,281] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 34 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:22,282] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:22,283] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 4 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:22,283] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:22,283] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 22 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:22,283] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:22,283] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 40 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:22,283] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:22,284] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 10 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:22,284] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:22,284] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 28 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:22,284] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:22,284] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 46 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:22,284] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:22,284] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 16 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:35:22,284] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:22,290] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-34 in 8 milliseconds for epoch 74, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:22,291] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-4 in 8 milliseconds for epoch 74, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:22,313] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-9fa5abef-fdc9-4c05-8f09-7f9780632837, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:35:22,324] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-ed3a6d0d-54c4-4b54-b4a4-a5d0ecba6f8e, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:35:22,324] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-1038faf2-d998-4707-9799-897de83d6136, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:35:22,324] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-b283a5ee-70be-4bf9-b41c-74e089f12e34, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:35:22,324] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-360d1581-f79b-41e6-82d3-fe3577615014, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:35:22,324] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-9e173d1e-b47a-4b16-9874-bf5d2688c730, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:35:22,324] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-81fafa38-80dc-43ea-ac6c-e398b06565dc, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:35:22,349] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-d15976bc-df63-4682-8583-fd67cbb1d9df, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:35:22,349] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-a0d7c5c7-e384-4339-b0be-414878362e3e, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:35:22,350] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-ee781f71-f1c3-46d7-bd93-d90a4fe359ff, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:35:22,350] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-78575c72-7be8-4563-b114-53b271a8ef70, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:35:22,350] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-0287b15c-1acd-4475-b9ce-b994aebeeff2, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:35:22,350] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-45d54f6e-f1d8-43f7-8ace-1db96ac0cfac, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:35:22,401] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-954ef0dc-d124-405b-9bb6-119086dd08c0, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:35:22,402] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-3f51cd43-28ab-4459-969e-211543e6cd72, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:35:22,402] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-4b8634e2-92f3-4603-97c5-35df7219bd84, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 4. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:35:22,403] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-5f6ccebb-0352-4648-b98e-7613d791d352, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:35:22,414] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-8863ee28-05fa-4d10-b813-b83668f9ecf8, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:35:22,420] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-22 in 137 milliseconds for epoch 74, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:22,451] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-40 in 168 milliseconds for epoch 74, of which 137 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:22,452] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-10 in 168 milliseconds for epoch 74, of which 168 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:22,452] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-28 in 168 milliseconds for epoch 74, of which 168 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:22,452] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-46 in 168 milliseconds for epoch 74, of which 168 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:22,452] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-16 in 168 milliseconds for epoch 74, of which 168 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:35:26,070] INFO Creating topic Sensor with configuration {min.insync.replicas=2} and initial partition assignment HashMap(0 -> ArrayBuffer(0, 5, 4), 1 -> ArrayBuffer(5, 4, 1), 2 -> ArrayBuffer(4, 1, 2)) (kafka.zk.AdminZkClient)
[2022-05-15 23:35:26,106] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:35:26,108] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:35:26,110] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:35:26,118] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:26,120] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:26,121] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:26,121] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:26,122] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:26,122] INFO Created log for partition Sensor-0 in /tmp/kafka-logs/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:35:26,125] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-5/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:35:26,124] INFO [Partition Sensor-0 broker=0] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 23:35:26,125] INFO [Partition Sensor-0 broker=0] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:26,126] INFO [Partition Sensor-1 broker=5] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 23:35:26,126] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-1/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:35:26,126] INFO [Partition Sensor-1 broker=5] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:26,128] INFO [Partition Sensor-2 broker=1] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 23:35:26,128] INFO [Partition Sensor-2 broker=1] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:26,128] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-4/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:35:26,129] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-2/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:35:26,130] INFO [Partition Sensor-2 broker=4] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 23:35:26,130] INFO [Partition Sensor-2 broker=4] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:26,131] INFO [Partition Sensor-2 broker=2] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 23:35:26,131] INFO [Partition Sensor-2 broker=2] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:26,133] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:35:26,135] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:26,136] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-1/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:35:26,136] INFO [Partition Sensor-1 broker=1] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 23:35:26,136] INFO [Partition Sensor-1 broker=1] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:26,136] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:35:26,138] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:26,139] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-5/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:35:26,140] INFO [Partition Sensor-0 broker=5] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 23:35:26,140] INFO [Partition Sensor-0 broker=5] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:26,141] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:35:26,144] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:26,145] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-4/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:35:26,145] INFO [Partition Sensor-0 broker=4] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 23:35:26,146] INFO [Partition Sensor-0 broker=4] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:26,152] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:35:26,154] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-4/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:35:26,154] INFO [Partition Sensor-1 broker=4] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 23:35:26,154] INFO [Partition Sensor-1 broker=4] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:35:26,155] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:35:26,162] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:35:26,163] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:35:26,167] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 4 for partitions Map(Sensor-2 -> InitialFetchState(Some(wToOuBQ5Qj6iZZl5PbLQAw),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:35:26,168] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 4 for partitions Map(Sensor-2 -> InitialFetchState(Some(wToOuBQ5Qj6iZZl5PbLQAw),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:35:26,169] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:35:26,170] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:35:26,171] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:35:26,173] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:35:26,173] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 5 for partitions Map(Sensor-1 -> InitialFetchState(Some(wToOuBQ5Qj6iZZl5PbLQAw),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:35:26,174] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:35:26,173] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:35:26,175] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:35:26,175] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:35:26,177] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 0 for partitions Map(Sensor-0 -> InitialFetchState(Some(wToOuBQ5Qj6iZZl5PbLQAw),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:35:26,179] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:35:26,181] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:35:26,188] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:35:26,193] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 0 for partitions Map(Sensor-0 -> InitialFetchState(Some(wToOuBQ5Qj6iZZl5PbLQAw),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:35:26,196] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:35:26,201] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:35:26,202] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:35:26,202] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 5 for partitions Map(Sensor-1 -> InitialFetchState(Some(wToOuBQ5Qj6iZZl5PbLQAw),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:35:26,204] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:35:26,210] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:35:26,256] WARN [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-2. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:35:26,256] WARN [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-2. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:35:56,346] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=157009, lastModifiedTime=1652653952992, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:35:56,348] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=157009, lastModifiedTime=1652653952992, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:35:56,352] INFO Deleted log /tmp/kafka-logs/Sensor-2.4999166fbd6a439884af71ef5fa76ac6-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:35:56,353] INFO Deleted offset index /tmp/kafka-logs/Sensor-2.4999166fbd6a439884af71ef5fa76ac6-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:35:56,357] INFO Deleted time index /tmp/kafka-logs/Sensor-2.4999166fbd6a439884af71ef5fa76ac6-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:35:56,363] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs/Sensor-2.4999166fbd6a439884af71ef5fa76ac6-delete. (kafka.log.LogManager)
[2022-05-15 23:35:56,378] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=154252, lastModifiedTime=1652653952224, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:35:56,379] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=154252, lastModifiedTime=1652653952224, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:35:56,380] INFO Deleted log /tmp/kafka-logs/Sensor-0.faebf763023a42faa6c475bfb8c56747-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:35:56,380] INFO Deleted offset index /tmp/kafka-logs/Sensor-0.faebf763023a42faa6c475bfb8c56747-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:35:56,381] INFO Deleted time index /tmp/kafka-logs/Sensor-0.faebf763023a42faa6c475bfb8c56747-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:35:56,382] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs/Sensor-0.faebf763023a42faa6c475bfb8c56747-delete. (kafka.log.LogManager)
[2022-05-15 23:35:56,439] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=163769, lastModifiedTime=1652653953752, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:35:56,440] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=163769, lastModifiedTime=1652653953752, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:35:56,441] INFO Deleted log /tmp/kafka-logs/Sensor-3.55f56872278344fd825c9840c5b2df94-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:35:56,441] INFO Deleted offset index /tmp/kafka-logs/Sensor-3.55f56872278344fd825c9840c5b2df94-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:35:56,442] INFO Deleted time index /tmp/kafka-logs/Sensor-3.55f56872278344fd825c9840c5b2df94-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:35:56,443] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs/Sensor-3.55f56872278344fd825c9840c5b2df94-delete. (kafka.log.LogManager)
[2022-05-15 23:36:01,412] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=157009, lastModifiedTime=1652653952988, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:36:01,415] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=157009, lastModifiedTime=1652653952988, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:36:01,420] INFO Deleted log /tmp/kafka-logs-1/Sensor-2.17c97f8b7b2a44c881c5348bbbdc035e-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:01,421] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-2.17c97f8b7b2a44c881c5348bbbdc035e-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:01,424] INFO Deleted time index /tmp/kafka-logs-1/Sensor-2.17c97f8b7b2a44c881c5348bbbdc035e-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:01,428] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-1/Sensor-2.17c97f8b7b2a44c881c5348bbbdc035e-delete. (kafka.log.LogManager)
[2022-05-15 23:36:01,429] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=77795, lastModifiedTime=1652653935707, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:36:01,430] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=77795, lastModifiedTime=1652653935707, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:36:01,431] INFO Deleted log /tmp/kafka-logs-1/Sensor-5.ded6cc69afa64a52bbf3d9591b178d90-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:01,431] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-5.ded6cc69afa64a52bbf3d9591b178d90-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:01,432] INFO Deleted time index /tmp/kafka-logs-1/Sensor-5.ded6cc69afa64a52bbf3d9591b178d90-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:01,432] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-1/Sensor-5.ded6cc69afa64a52bbf3d9591b178d90-delete. (kafka.log.LogManager)
[2022-05-15 23:36:01,438] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=72235, lastModifiedTime=1652653934491, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:36:01,439] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=72235, lastModifiedTime=1652653934491, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:36:01,440] INFO Deleted log /tmp/kafka-logs-1/Sensor-4.7055a841a5e640d8b2854066072bd121-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:01,440] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-4.7055a841a5e640d8b2854066072bd121-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:01,440] INFO Deleted time index /tmp/kafka-logs-1/Sensor-4.7055a841a5e640d8b2854066072bd121-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:01,441] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-1/Sensor-4.7055a841a5e640d8b2854066072bd121-delete. (kafka.log.LogManager)
[2022-05-15 23:36:06,398] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=158486, lastModifiedTime=1652653953268, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:36:06,401] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=158486, lastModifiedTime=1652653953268, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:36:06,406] INFO Deleted log /tmp/kafka-logs-2/Sensor-1.cc7be4d68e294152b79460b409ee024a-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:06,407] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-1.cc7be4d68e294152b79460b409ee024a-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:06,411] INFO Deleted time index /tmp/kafka-logs-2/Sensor-1.cc7be4d68e294152b79460b409ee024a-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:06,418] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-2/Sensor-1.cc7be4d68e294152b79460b409ee024a-delete. (kafka.log.LogManager)
[2022-05-15 23:36:06,438] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=154252, lastModifiedTime=1652653952224, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:36:06,439] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=154252, lastModifiedTime=1652653952224, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:36:06,440] INFO Deleted log /tmp/kafka-logs-2/Sensor-0.d44c13b0149f48aca3a8c6eadde96a2c-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:06,441] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-0.d44c13b0149f48aca3a8c6eadde96a2c-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:06,441] INFO Deleted time index /tmp/kafka-logs-2/Sensor-0.d44c13b0149f48aca3a8c6eadde96a2c-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:06,442] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-2/Sensor-0.d44c13b0149f48aca3a8c6eadde96a2c-delete. (kafka.log.LogManager)
[2022-05-15 23:36:06,453] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=72235, lastModifiedTime=1652653934491, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:36:06,453] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=72235, lastModifiedTime=1652653934491, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:36:06,455] INFO Deleted log /tmp/kafka-logs-2/Sensor-4.b5f82e6480fd4b669a106d781b5d2cfa-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:06,455] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-4.b5f82e6480fd4b669a106d781b5d2cfa-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:06,455] INFO Deleted time index /tmp/kafka-logs-2/Sensor-4.b5f82e6480fd4b669a106d781b5d2cfa-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:06,456] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-2/Sensor-4.b5f82e6480fd4b669a106d781b5d2cfa-delete. (kafka.log.LogManager)
[2022-05-15 23:36:11,398] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=157009, lastModifiedTime=1652653952988, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:36:11,402] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=157009, lastModifiedTime=1652653952988, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:36:11,407] INFO Deleted log /tmp/kafka-logs-3/Sensor-2.3983dd26589b4f51a81f5092a1c6efb0-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:11,408] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-2.3983dd26589b4f51a81f5092a1c6efb0-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:11,411] INFO Deleted time index /tmp/kafka-logs-3/Sensor-2.3983dd26589b4f51a81f5092a1c6efb0-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:11,416] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-3/Sensor-2.3983dd26589b4f51a81f5092a1c6efb0-delete. (kafka.log.LogManager)
[2022-05-15 23:36:11,498] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=77795, lastModifiedTime=1652653935703, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:36:11,498] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=77795, lastModifiedTime=1652653935703, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:36:11,500] INFO Deleted log /tmp/kafka-logs-3/Sensor-5.baa10c5ca4b74b87a7681b78bda988ce-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:11,500] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-5.baa10c5ca4b74b87a7681b78bda988ce-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:11,501] INFO Deleted time index /tmp/kafka-logs-3/Sensor-5.baa10c5ca4b74b87a7681b78bda988ce-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:11,501] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-3/Sensor-5.baa10c5ca4b74b87a7681b78bda988ce-delete. (kafka.log.LogManager)
[2022-05-15 23:36:11,505] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=158486, lastModifiedTime=1652653953268, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:36:11,505] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=158486, lastModifiedTime=1652653953268, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:36:11,507] INFO Deleted log /tmp/kafka-logs-3/Sensor-1.8f172618122640ad9d52ee879167a963-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:11,507] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-1.8f172618122640ad9d52ee879167a963-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:11,507] INFO Deleted time index /tmp/kafka-logs-3/Sensor-1.8f172618122640ad9d52ee879167a963-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:11,508] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-3/Sensor-1.8f172618122640ad9d52ee879167a963-delete. (kafka.log.LogManager)
[2022-05-15 23:36:16,469] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=77795, lastModifiedTime=1652653935707, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:36:16,471] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=77795, lastModifiedTime=1652653935707, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:36:16,475] INFO Deleted log /tmp/kafka-logs-4/Sensor-5.69735b49d1da4ee9a93e7fa167096b9e-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:16,476] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-5.69735b49d1da4ee9a93e7fa167096b9e-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:16,479] INFO Deleted time index /tmp/kafka-logs-4/Sensor-5.69735b49d1da4ee9a93e7fa167096b9e-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:16,484] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-4/Sensor-5.69735b49d1da4ee9a93e7fa167096b9e-delete. (kafka.log.LogManager)
[2022-05-15 23:36:16,490] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=163769, lastModifiedTime=1652653953752, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:36:16,491] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=163769, lastModifiedTime=1652653953752, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:36:16,492] INFO Deleted log /tmp/kafka-logs-4/Sensor-3.6a9ea80a5c97444a9e71d04d6e1504b7-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:16,492] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-3.6a9ea80a5c97444a9e71d04d6e1504b7-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:16,493] INFO Deleted time index /tmp/kafka-logs-4/Sensor-3.6a9ea80a5c97444a9e71d04d6e1504b7-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:16,493] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-4/Sensor-3.6a9ea80a5c97444a9e71d04d6e1504b7-delete. (kafka.log.LogManager)
[2022-05-15 23:36:16,533] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=154252, lastModifiedTime=1652653952224, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:36:16,533] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=154252, lastModifiedTime=1652653952224, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:36:16,535] INFO Deleted log /tmp/kafka-logs-4/Sensor-0.bdcc0a18fdfc494ea5a175eb75727104-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:16,535] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-0.bdcc0a18fdfc494ea5a175eb75727104-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:16,536] INFO Deleted time index /tmp/kafka-logs-4/Sensor-0.bdcc0a18fdfc494ea5a175eb75727104-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:16,537] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-4/Sensor-0.bdcc0a18fdfc494ea5a175eb75727104-delete. (kafka.log.LogManager)
[2022-05-15 23:36:21,411] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=163769, lastModifiedTime=1652653953752, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:36:21,413] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=163769, lastModifiedTime=1652653953752, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:36:21,419] INFO Deleted log /tmp/kafka-logs-5/Sensor-3.f11b31c0dfdc4c8aa5558d85209ea8b4-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:21,420] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-3.f11b31c0dfdc4c8aa5558d85209ea8b4-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:21,423] INFO Deleted time index /tmp/kafka-logs-5/Sensor-3.f11b31c0dfdc4c8aa5558d85209ea8b4-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:21,430] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-5/Sensor-3.f11b31c0dfdc4c8aa5558d85209ea8b4-delete. (kafka.log.LogManager)
[2022-05-15 23:36:21,430] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=158486, lastModifiedTime=1652653953264, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:36:21,431] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=158486, lastModifiedTime=1652653953264, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:36:21,432] INFO Deleted log /tmp/kafka-logs-5/Sensor-1.87d2bc8bfbf7497cb2dfc8f18e349f90-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:21,432] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-1.87d2bc8bfbf7497cb2dfc8f18e349f90-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:21,433] INFO Deleted time index /tmp/kafka-logs-5/Sensor-1.87d2bc8bfbf7497cb2dfc8f18e349f90-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:21,434] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-5/Sensor-1.87d2bc8bfbf7497cb2dfc8f18e349f90-delete. (kafka.log.LogManager)
[2022-05-15 23:36:21,466] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=72235, lastModifiedTime=1652653934491, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:36:21,466] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=72235, lastModifiedTime=1652653934491, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:36:21,468] INFO Deleted log /tmp/kafka-logs-5/Sensor-4.19afe84b16dc49d0874e30cb74d0364a-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:21,468] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-4.19afe84b16dc49d0874e30cb74d0364a-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:21,468] INFO Deleted time index /tmp/kafka-logs-5/Sensor-4.19afe84b16dc49d0874e30cb74d0364a-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:36:21,469] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-5/Sensor-4.19afe84b16dc49d0874e30cb74d0364a-delete. (kafka.log.LogManager)
[2022-05-15 23:38:26,278] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: Sensor-2, Sensor-1, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:38:26,279] INFO [GroupCoordinator 5]: Removed 0 offsets associated with deleted partitions: Sensor-2, Sensor-1, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:38:26,280] INFO [GroupCoordinator 4]: Removed 0 offsets associated with deleted partitions: Sensor-2, Sensor-1, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:38:26,281] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: Sensor-2, Sensor-1, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:38:26,282] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: Sensor-2, Sensor-1, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:38:26,284] INFO [GroupMetadataManager brokerId=3] Group consumer-group transitioned to Dead in generation 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:38:26,291] INFO [GroupCoordinator 3]: Removed 3 offsets associated with deleted partitions: Sensor-2, Sensor-1, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:38:26,306] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:38:26,309] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:38:26,310] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:38:26,310] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:38:26,310] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:38:26,316] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:38:26,315] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:38:26,318] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:38:26,318] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:26,318] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-2, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:38:26,318] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:38:26,319] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:38:26,319] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:38:26,319] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:26,319] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 743 due to node 0 being disconnected (elapsed time since creation: 317ms, elapsed time since send: 317ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:26,321] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 621 due to node 4 being disconnected (elapsed time since creation: 75ms, elapsed time since send: 75ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:26,320] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=1480431664, epoch=743) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:38:26,323] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:38:26,323] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:38:26,322] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=274543782, epoch=619) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:38:26,325] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:38:26,325] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:38:26,327] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:38:26,326] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:38:26,327] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:38:26,327] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:26,328] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:38:26,329] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 621 due to node 4 being disconnected (elapsed time since creation: 96ms, elapsed time since send: 96ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:26,329] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:26,330] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:38:26,330] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:38:26,332] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 743 due to node 0 being disconnected (elapsed time since creation: 329ms, elapsed time since send: 329ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:26,330] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=1770027330, epoch=619) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:38:26,333] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:38:26,334] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:38:26,334] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:38:26,334] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:38:26,333] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=1793848998, epoch=743) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:38:26,337] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:38:26,337] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:38:26,339] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:38:26,340] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:26,340] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 618 due to node 5 being disconnected (elapsed time since creation: 162ms, elapsed time since send: 162ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:26,340] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=703908986, epoch=618) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:38:26,342] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:38:26,342] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:38:26,343] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs/Sensor-0.f13e68dae330484783b79f51b1427edd-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:38:26,343] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:38:26,343] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:26,344] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 619 due to node 5 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:26,344] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:38:26,345] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-2, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:38:26,345] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-2/Sensor-2.d90ddc6cdf124f27bef9fc487becc9dd-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:38:26,344] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=1296197988, epoch=619) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:38:26,345] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:38:26,345] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:38:26,347] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-5/Sensor-0.7a3a5c90733b4c178c1e63b875bec022-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:38:26,347] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:38:26,347] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:38:26,350] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-5/Sensor-1.08870319a4764802b7bcb544fe7a5b3c-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:38:26,355] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-1/Sensor-2.a50d72eff0c14124b2f2159973619053-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:38:26,357] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-1/Sensor-1.7637d6c9826140dd8c27420a88be7f8c-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:38:26,359] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-4/Sensor-2.4308dd2ebb524ecd85f701df4d85127e-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:38:26,361] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-4/Sensor-0.6e2c8517ed024c60be59a9f0a11274e6-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:38:26,363] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-4/Sensor-1.b4845c43b80e41cba957c30f2677705a-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:38:29,662] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:38:29,662] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:38:29,662] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:38:29,662] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:38:29,662] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:38:29,666] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:38:29,669] INFO [KafkaServer id=4] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:38:29,669] INFO [KafkaServer id=5] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:38:29,666] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:38:29,673] INFO [KafkaServer id=5] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:38:29,673] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:38:29,674] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:38:29,672] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:38:29,673] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:38:29,677] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:38:29,677] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:38:29,679] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:38:29,681] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:38:29,698] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 9ms (kafka.server.KafkaServer)
[2022-05-15 23:38:29,700] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 13ms (kafka.server.KafkaServer)
[2022-05-15 23:38:29,701] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 17ms (kafka.server.KafkaServer)
[2022-05-15 23:38:29,703] INFO [KafkaServer id=4] Controlled shutdown request returned successfully after 18ms (kafka.server.KafkaServer)
[2022-05-15 23:38:29,704] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:38:29,704] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:38:29,704] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:38:29,705] INFO [KafkaServer id=5] Controlled shutdown request returned successfully after 16ms (kafka.server.KafkaServer)
[2022-05-15 23:38:29,705] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:38:29,706] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:38:29,706] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:38:29,707] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:38:29,706] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:38:29,707] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:38:29,707] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:38:29,708] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:38:29,708] INFO [KafkaServer id=3] Controlled shutdown request returned successfully after 15ms (kafka.server.KafkaServer)
[2022-05-15 23:38:29,709] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:38:29,709] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:38:29,709] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:38:29,709] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:38:29,711] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:38:29,710] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:38:29,713] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:38:29,713] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:38:29,716] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:38:29,719] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:38:29,721] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:38:29,721] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:38:29,722] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:38:29,723] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:38:29,726] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:38:29,727] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:38:29,728] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:38:29,729] INFO [data-plane Kafka Request Handler on Broker 4], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:38:29,729] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:38:29,729] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:38:29,730] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:38:29,730] INFO [data-plane Kafka Request Handler on Broker 5], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:38:29,731] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:38:29,732] INFO [data-plane Kafka Request Handler on Broker 4], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:38:29,734] INFO [data-plane Kafka Request Handler on Broker 5], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:38:29,734] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:38:29,736] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:38:29,736] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:38:29,739] INFO [ExpirationReaper-4-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,739] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:38:29,741] INFO [data-plane Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:38:29,742] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,743] INFO [ExpirationReaper-5-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,744] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,744] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,745] INFO [data-plane Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:38:29,748] INFO [ExpirationReaper-3-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,820] INFO [ExpirationReaper-4-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,820] INFO [ExpirationReaper-4-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,821] INFO [KafkaApi-4] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:38:29,823] INFO [ExpirationReaper-4-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,879] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,879] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,881] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:38:29,882] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,892] INFO [ExpirationReaper-5-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,892] INFO [ExpirationReaper-5-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,894] INFO [KafkaApi-5] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:38:29,896] INFO [ExpirationReaper-5-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,906] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,906] INFO [ExpirationReaper-3-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,906] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,906] INFO [ExpirationReaper-3-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,907] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:38:29,908] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:38:29,909] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,910] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,924] INFO [ExpirationReaper-4-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,924] INFO [ExpirationReaper-4-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,927] INFO [TransactionCoordinator id=4] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:38:29,929] INFO [Transaction State Manager 4]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:38:29,930] INFO [Transaction Marker Channel Manager 4]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:38:29,930] INFO [Transaction Marker Channel Manager 4]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:38:29,930] INFO [Transaction Marker Channel Manager 4]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:38:29,932] INFO [TransactionCoordinator id=4] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:38:29,934] INFO [GroupCoordinator 4]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:38:29,934] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,934] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,934] INFO [ExpirationReaper-4-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,935] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:38:29,936] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,995] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,995] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,998] INFO [ExpirationReaper-5-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:29,999] INFO [ExpirationReaper-5-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,000] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:38:30,002] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:38:30,002] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:38:30,002] INFO [TransactionCoordinator id=5] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:38:30,004] INFO [Transaction State Manager 5]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:38:30,004] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:38:30,005] INFO [Transaction Marker Channel Manager 5]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:38:30,004] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:38:30,006] INFO [Transaction Marker Channel Manager 5]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:38:30,006] INFO [Transaction Marker Channel Manager 5]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:38:30,007] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:38:30,008] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:38:30,008] INFO [TransactionCoordinator id=5] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:38:30,009] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,010] INFO [GroupCoordinator 5]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:38:30,011] INFO [ExpirationReaper-5-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,016] INFO [ExpirationReaper-5-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,016] INFO [ExpirationReaper-5-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,017] INFO [ExpirationReaper-5-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,020] INFO [ExpirationReaper-5-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,020] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,020] INFO [ExpirationReaper-5-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,020] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,021] INFO [GroupCoordinator 5]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:38:30,023] INFO [ReplicaManager broker=5] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:38:30,023] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:38:30,023] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:38:30,023] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:38:30,024] INFO [ReplicaFetcherManager on broker 5] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:38:30,024] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:38:30,026] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:38:30,026] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:38:30,028] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:38:30,028] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:38:30,028] INFO [ReplicaFetcherManager on broker 5] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:38:30,029] INFO [ReplicaAlterLogDirsManager on broker 5] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:38:30,029] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:38:30,030] INFO [ReplicaAlterLogDirsManager on broker 5] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:38:30,030] INFO [ExpirationReaper-5-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,031] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:38:30,031] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,037] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,037] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,039] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:38:30,041] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:38:30,041] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:38:30,042] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:38:30,041] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:38:30,045] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:38:30,046] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:38:30,047] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,067] INFO [ExpirationReaper-5-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,068] INFO [ExpirationReaper-5-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,068] INFO [ExpirationReaper-5-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,073] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,073] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,076] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:38:30,078] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:38:30,078] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:38:30,080] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:38:30,080] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:38:30,082] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:38:30,083] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:38:30,084] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,106] INFO [ExpirationReaper-4-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,107] INFO [ExpirationReaper-4-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,107] INFO [ExpirationReaper-4-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,195] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,195] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,196] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,203] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,203] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,204] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,212] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,212] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,214] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:38:30,215] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:38:30,216] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:38:30,216] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:38:30,216] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:38:30,217] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:38:30,219] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:38:30,220] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:38:30,220] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,220] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,220] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:38:30,221] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,221] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,234] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,234] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,234] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,234] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,234] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,235] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:38:30,237] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:38:30,238] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:38:30,240] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:38:30,239] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:38:30,241] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:38:30,242] INFO [ExpirationReaper-5-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,243] INFO [ExpirationReaper-5-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,243] INFO [ExpirationReaper-5-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,244] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:38:30,244] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:38:30,245] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:38:30,245] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,251] INFO [ExpirationReaper-5-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,251] INFO [ExpirationReaper-5-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,252] INFO [ExpirationReaper-5-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,272] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,272] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,273] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,276] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,276] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,277] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,307] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,307] INFO [ExpirationReaper-4-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,307] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,307] INFO [ExpirationReaper-4-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,308] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,308] INFO [GroupCoordinator 4]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:38:30,310] INFO [ReplicaManager broker=4] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:38:30,311] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:38:30,312] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:38:30,312] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:38:30,313] INFO [ReplicaFetcherManager on broker 4] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:38:30,316] INFO [ReplicaFetcherManager on broker 4] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:38:30,317] INFO [ReplicaAlterLogDirsManager on broker 4] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:38:30,318] INFO [ReplicaAlterLogDirsManager on broker 4] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:38:30,318] INFO [ExpirationReaper-4-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,395] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,395] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,397] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:38:30,398] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:38:30,399] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:38:30,399] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:38:30,400] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:38:30,401] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:38:30,403] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:38:30,404] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:38:30,405] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:38:30,405] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,434] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,434] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,435] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:38:30,436] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:38:30,436] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:38:30,437] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:38:30,437] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:38:30,438] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:38:30,440] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:38:30,440] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:38:30,441] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:38:30,441] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,451] INFO [ExpirationReaper-5-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,451] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,451] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,451] INFO [ExpirationReaper-5-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,451] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,451] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,452] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,452] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,455] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,455] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,456] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,457] INFO [ReplicaManager broker=5] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:38:30,457] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,458] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,458] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,460] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:38:30,462] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,462] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,462] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,464] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:38:30,464] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:38:30,472] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,472] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,473] INFO [ExpirationReaper-3-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,481] INFO [ExpirationReaper-3-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,481] INFO [ExpirationReaper-3-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,485] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,485] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,486] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,486] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:38:30,487] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,487] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,488] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,490] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:38:30,491] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,492] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,492] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,493] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:38:30,494] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:38:30,498] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:38:30,506] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:38:30,506] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:38:30,506] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:38:30,507] INFO [ExpirationReaper-4-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,507] INFO [ExpirationReaper-4-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,508] INFO [ExpirationReaper-4-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,508] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:38:30,524] INFO [ProducerStateManager partition=__consumer_offsets-38] Wrote producer snapshot at offset 98382 with 0 producer ids in 4 ms. (kafka.log.ProducerStateManager)
[2022-05-15 23:38:30,543] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:38:30,551] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:38:30,552] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:38:30,552] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:38:30,552] INFO [ExpirationReaper-4-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,552] INFO [ExpirationReaper-4-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,553] INFO [ExpirationReaper-4-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,554] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:38:30,561] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,561] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,561] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,561] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,561] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,565] INFO [ExpirationReaper-4-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,565] INFO [ExpirationReaper-4-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,566] INFO [ExpirationReaper-4-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,568] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,568] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,568] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,568] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,568] WARN [Controller id=0, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,569] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,568] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,569] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,568] WARN [Controller id=0, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,569] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,571] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,571] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,571] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,571] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,571] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,573] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,614] INFO Session: 0x100000b00ad008f closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:38:30,614] INFO EventThread shut down for session: 0x100000b00ad008f (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:38:30,616] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:38:30,617] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:30,634] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,634] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,634] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,652] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,652] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,658] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:38:30,658] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,659] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,659] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,660] INFO Session: 0x100000b00ad008d closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:38:30,660] INFO EventThread shut down for session: 0x100000b00ad008d (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:38:30,663] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:38:30,663] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:38:30,663] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,664] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:30,664] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,664] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,665] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:38:30,666] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:38:30,672] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,672] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,672] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,672] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,673] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,673] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,673] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,673] WARN [Controller id=0, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,674] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,674] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,674] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,675] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,685] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,685] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,686] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,695] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:38:30,700] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,705] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,707] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,709] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,712] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:38:30,712] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:38:30,712] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:38:30,713] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:38:30,718] WARN An exception was thrown while closing send thread for session 0x100000b00ad008a. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x100000b00ad008a, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 23:38:30,765] INFO [ExpirationReaper-4-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,765] INFO [ExpirationReaper-4-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,770] INFO [ReplicaManager broker=4] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:38:30,770] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,771] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,771] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,773] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:38:30,774] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,774] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,774] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,775] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:38:30,776] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:38:30,810] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:38:30,820] INFO EventThread shut down for session: 0x100000b00ad008a (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:38:30,820] INFO Session: 0x100000b00ad008a closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:38:30,822] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:38:30,823] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:30,834] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,834] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,835] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,852] INFO [Controller id=4, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,852] INFO [Controller id=4, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,852] INFO [Controller id=4, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,856] WARN [Controller id=4, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,856] WARN [Controller id=4, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,856] WARN [Controller id=4, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,858] INFO [Controller id=4, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,858] INFO [Controller id=4, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,858] INFO [Controller id=4, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,876] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,877] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,877] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,880] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,880] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:30,887] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:38:30,888] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,888] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,888] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,892] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:38:30,892] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,893] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,893] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:30,894] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:38:30,895] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:38:30,927] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:38:30,935] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:38:30,936] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:38:30,936] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:38:30,938] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:38:30,959] INFO [Controller id=4, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,959] INFO [Controller id=4, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,959] INFO [Controller id=4, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,959] WARN [Controller id=4, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,959] WARN [Controller id=4, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,960] WARN [Controller id=4, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,960] INFO [Controller id=4, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,960] INFO [Controller id=4, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:30,960] INFO [Controller id=4, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:31,015] INFO [Controller id=4, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:31,017] INFO [Controller id=4, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:31,020] INFO [Controller id=4, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:31,023] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:38:31,024] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:38:31,024] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:38:31,025] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:38:31,029] WARN An exception was thrown while closing send thread for session 0x100000b00ad008e. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x100000b00ad008e, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 23:38:31,034] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:31,034] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:38:31,040] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:38:31,040] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:31,042] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:31,042] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:31,043] INFO EventThread shut down for session: 0x100000b00ad008b (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:38:31,043] INFO Session: 0x100000b00ad008b closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:38:31,044] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:38:31,045] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:31,045] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:38:31,046] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:31,046] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:38:31,046] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,047] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:38:31,048] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:38:31,079] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:38:31,132] INFO EventThread shut down for session: 0x100000b00ad008e (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:38:31,132] INFO Session: 0x100000b00ad008e closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:38:31,134] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:38:31,134] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,138] INFO [Controller id=2, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:31,150] WARN [Controller id=2, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:31,152] INFO [Controller id=2, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:31,202] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,202] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,203] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,208] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,208] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,208] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,211] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,211] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,212] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,224] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,224] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,224] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,227] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,227] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,227] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,228] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,228] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,228] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,230] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,230] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,232] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:38:31,253] INFO [Controller id=2, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:31,254] WARN [Controller id=2, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:31,255] INFO [Controller id=2, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:31,260] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,260] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,260] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,261] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,261] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,262] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,264] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:38:31,265] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,265] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:38:31,265] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,265] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:38:31,265] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,266] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:38:31,267] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:38:31,267] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:38:31,268] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:38:31,310] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,310] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,310] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,312] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,312] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,313] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,346] INFO [Controller id=2, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:38:31,349] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:38:31,349] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:38:31,349] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:38:31,351] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:38:31,365] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,365] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,365] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:31,457] INFO Session: 0x100000b00ad008c closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:38:31,457] INFO EventThread shut down for session: 0x100000b00ad008c (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:38:31,460] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:38:31,461] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:32,211] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:32,211] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:32,214] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:38:32,235] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:38:32,236] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:38:32,236] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:38:32,236] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:38:32,238] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:38:32,238] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:38:32,239] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:38:32,260] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:32,261] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:32,261] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:32,262] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:32,262] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:32,264] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:38:32,271] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:32,271] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:32,272] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:32,288] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:38:32,289] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:38:32,289] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:38:32,289] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:38:32,291] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:38:32,292] INFO App info kafka.server for 3 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:38:32,293] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:38:32,310] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:32,310] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:32,311] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:32,313] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:32,313] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:32,315] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:38:32,336] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:38:32,337] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:38:32,338] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:38:32,338] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:38:32,339] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:38:32,340] INFO App info kafka.server for 5 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:38:32,340] INFO [KafkaServer id=5] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:38:32,365] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:32,365] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:32,366] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:33,265] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:33,265] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:33,266] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:33,269] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:33,269] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:33,272] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:38:33,292] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:38:33,294] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:38:33,294] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:38:33,294] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:38:33,296] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:38:33,296] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:38:33,297] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:38:33,365] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:33,366] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:33,366] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:34,366] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:34,366] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:38:34,368] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:38:34,393] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:38:34,394] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:38:34,394] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:38:34,395] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:38:34,396] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:38:34,396] INFO App info kafka.server for 4 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:38:34,397] INFO [KafkaServer id=4] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:39:10,123] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:39:10,135] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:39:10,136] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:39:10,136] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:39:10,136] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:39:10,139] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 23:39:10,139] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 23:39:10,139] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 23:39:10,139] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-15 23:39:10,144] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-15 23:39:10,160] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:39:10,161] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:39:10,161] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:39:10,161] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:39:10,161] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:39:10,162] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-15 23:39:10,178] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@6156496 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-15 23:39:10,183] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 23:39:10,195] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,196] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,196] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,196] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,196] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,196] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,196] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,196] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,196] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,196] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,197] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,197] INFO Server environment:host.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,197] INFO Server environment:java.version=11.0.15 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,198] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,198] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,198] INFO Server environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,198] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,198] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,198] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,198] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,198] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,198] INFO Server environment:os.version=5.13.0-40-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,198] INFO Server environment:user.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,198] INFO Server environment:user.home=/home/joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,198] INFO Server environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,198] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,198] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,198] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,198] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,198] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,198] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,198] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,199] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,199] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,199] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,200] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-15 23:39:10,203] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,203] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,204] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 23:39:10,204] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 23:39:10,205] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:39:10,205] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:39:10,205] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:39:10,205] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:39:10,205] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:39:10,205] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:39:10,208] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,208] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,209] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:39:10,217] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 23:39:10,218] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 23:39:10,219] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 23:39:10,223] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 23:39:10,224] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:459)
	at java.base/sun.nio.ch.Net.bind(Net.java:448)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:676)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:158)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:112)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:67)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:140)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:90)
[2022-05-15 23:39:10,228] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-15 23:39:10,230] ERROR Exiting JVM with code 1 (org.apache.zookeeper.util.ServiceUtils)
[2022-05-15 23:39:15,069] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:39:15,376] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:39:15,478] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:39:15,483] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:39:15,483] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:39:15,503] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:39:15,510] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:15,510] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:15,510] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:15,510] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:15,511] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:15,511] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:15,511] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:15,511] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:15,511] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:15,511] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:15,511] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:15,511] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:15,511] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:15,511] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:15,512] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:15,512] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:15,512] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:15,512] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:15,515] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:15,525] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:39:15,531] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:15,553] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:39:15,560] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:15,561] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:15,566] INFO Socket connection established, initiating session, client: /127.0.0.1:58120, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:15,575] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0090, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:15,581] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:39:15,676] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:39:15,823] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:39:15,830] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:39:15,907] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:39:15,920] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:39:15,982] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:15,984] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:15,988] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:15,991] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:16,043] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:39:16,048] INFO Skipping recovery for all logs in /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:39:16,141] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:16,170] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-21, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 98ms (1/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:39:16,193] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 35579 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:16,194] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 35579 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:16,195] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs/__consumer_offsets-39/00000000000000035579.snapshot,35579)' (kafka.log.ProducerStateManager)
[2022-05-15 23:39:16,202] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Producer state recovery took 8ms for snapshot load and 0ms for segment recovery from offset 35579 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:16,205] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-39, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=35579) with 1 segments in 35ms (2/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:39:16,212] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:16,216] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-15, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (3/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:39:16,223] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:16,226] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-45, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (4/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:39:16,233] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:16,235] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-33, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (5/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:39:16,242] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:16,246] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-27, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (6/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:39:16,251] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:16,255] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-0.f13e68dae330484783b79f51b1427edd-delete, topicId=wToOuBQ5Qj6iZZl5PbLQAw, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (7/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:39:16,262] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:16,265] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-3, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (8/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:39:16,272] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:16,275] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-9, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (9/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:39:16,279] INFO Loaded 9 logs in 235ms. (kafka.log.LogManager)
[2022-05-15 23:39:16,279] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:39:16,281] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:39:16,553] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:16,703] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:39:16,706] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-15 23:39:16,738] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:39:16,745] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:16,766] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:16,767] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:16,769] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:16,770] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:16,780] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:39:16,817] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:39:16,834] INFO Stat of the created znode at /brokers/ids/0 is: 6991,6991,1652654356826,1652654356826,1,0,0,72057641293906064,192,0,6991
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:39:16,835] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://joao:9092, czxid (broker epoch): 6991 (kafka.zk.KafkaZkClient)
[2022-05-15 23:39:16,884] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:16,888] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:16,889] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:16,903] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:16,917] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:16,945] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:39:16,949] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:39:16,949] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:39:16,982] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:17,001] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:39:17,024] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:39:17,032] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:39:17,033] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:39:17,039] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:39:17,039] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:39:17,039] INFO Kafka startTimeMs: 1652654357033 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:39:17,043] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-15 23:39:17,142] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:17,143] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:17,143] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 35579 (kafka.cluster.Partition)
[2022-05-15 23:39:17,143] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:17,144] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:17,144] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:17,144] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:17,144] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:17,152] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:17,170] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:17,200] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-3, __consumer_offsets-15, __consumer_offsets-39, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:17,228] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 44 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:17,230] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 44 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:17,231] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 44 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:17,231] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 44 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:17,231] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 44 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:17,231] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 44 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:17,231] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 44 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:17,231] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 44 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:17,231] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 44 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:17,231] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 44 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:17,231] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 44 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:17,231] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 44 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:17,231] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 44 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:17,231] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 44 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:17,231] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 44 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:17,231] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 44 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:17,236] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 6 milliseconds for epoch 44, of which 2 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:17,237] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 6 milliseconds for epoch 44, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:17,336] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 105 milliseconds for epoch 44, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:17,336] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 105 milliseconds for epoch 44, of which 105 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:17,337] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 106 milliseconds for epoch 44, of which 105 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:17,337] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 106 milliseconds for epoch 44, of which 106 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:17,338] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 107 milliseconds for epoch 44, of which 107 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:17,339] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 107 milliseconds for epoch 44, of which 107 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:20,042] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:39:20,356] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:39:20,455] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:39:20,459] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:39:20,460] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:39:20,481] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:39:20,487] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:20,487] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:20,487] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:20,487] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:20,487] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:20,487] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:20,488] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:20,488] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:20,488] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:20,488] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:20,488] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:20,488] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:20,488] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:20,488] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:20,488] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:20,488] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:20,488] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:20,488] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:20,490] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:20,495] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:39:20,500] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:20,519] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:39:20,526] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:20,529] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:20,534] INFO Socket connection established, initiating session, client: /127.0.0.1:58122, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:20,543] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0091, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:20,547] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:39:20,644] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:39:20,784] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:39:20,792] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:39:20,854] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:39:20,864] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:39:20,924] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:20,927] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:20,930] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:20,933] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:20,983] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:39:20,990] INFO Skipping recovery for all logs in /tmp/kafka-logs-1 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:39:21,077] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:21,104] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-17, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 93ms (1/10 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:39:21,110] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:21,114] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-35, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (2/10 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:39:21,120] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:21,124] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-41, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (3/10 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:39:21,129] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:21,132] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-1.7637d6c9826140dd8c27420a88be7f8c-delete, topicId=wToOuBQ5Qj6iZZl5PbLQAw, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/10 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:39:21,138] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:21,141] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-2.a50d72eff0c14124b2f2159973619053-delete, topicId=wToOuBQ5Qj6iZZl5PbLQAw, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (5/10 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:39:21,149] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:21,153] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-29, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (6/10 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:39:21,159] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:21,162] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-11, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/10 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:39:21,167] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:21,172] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-23, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (8/10 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:39:21,178] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:21,181] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-47, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (9/10 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:39:21,187] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:21,191] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-5, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (10/10 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:39:21,195] INFO Loaded 10 logs in 211ms. (kafka.log.LogManager)
[2022-05-15 23:39:21,196] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:39:21,197] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:39:21,498] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:21,617] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:39:21,621] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-15 23:39:21,648] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:39:21,654] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:21,671] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:21,673] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:21,674] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:21,675] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:21,688] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:39:21,743] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:39:21,762] INFO Stat of the created znode at /brokers/ids/1 is: 7059,7059,1652654361754,1652654361754,1,0,0,72057641293906065,192,0,7059
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:39:21,763] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://joao:9093, czxid (broker epoch): 7059 (kafka.zk.KafkaZkClient)
[2022-05-15 23:39:21,823] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:21,830] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:21,831] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:21,845] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:21,856] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:21,876] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:39:21,884] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:39:21,884] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:39:21,906] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:21,922] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:39:21,942] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:39:21,947] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:39:21,948] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:39:21,953] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:39:21,953] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:39:21,953] INFO Kafka startTimeMs: 1652654361948 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:39:21,956] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-15 23:39:22,009] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:22,040] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:22,040] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:22,040] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:22,040] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:22,040] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:22,040] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:22,041] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:22,041] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:22,058] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:22,065] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-5, __consumer_offsets-29, __consumer_offsets-41, __consumer_offsets-23) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:22,096] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 72 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:22,097] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 72 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:22,099] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 72 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:22,099] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 72 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:22,099] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 72 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:22,099] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 72 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:22,099] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 72 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:22,100] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 72 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:22,100] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 72 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:22,100] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 72 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:22,100] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 72 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:22,100] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 72 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:22,100] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 72 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:22,100] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 72 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:22,100] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 72 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:22,100] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 72 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:22,107] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 9 milliseconds for epoch 72, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:22,108] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 9 milliseconds for epoch 72, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:22,108] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 9 milliseconds for epoch 72, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:22,109] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 9 milliseconds for epoch 72, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:22,109] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 9 milliseconds for epoch 72, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:22,109] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 9 milliseconds for epoch 72, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:22,109] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 9 milliseconds for epoch 72, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:22,110] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 10 milliseconds for epoch 72, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:25,127] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:39:25,426] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:39:25,523] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:39:25,526] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:39:25,527] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:39:25,543] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:39:25,547] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:25,548] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:25,548] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:25,548] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:25,548] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:25,548] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:25,548] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:25,548] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:25,548] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:25,548] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:25,548] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:25,548] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:25,548] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:25,548] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:25,548] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:25,548] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:25,548] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:25,548] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:25,551] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:25,557] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:39:25,563] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:25,582] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:39:25,591] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:25,593] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:25,597] INFO Socket connection established, initiating session, client: /127.0.0.1:58124, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:25,608] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0092, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:25,615] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:39:25,712] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:39:25,882] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:39:25,891] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:39:25,950] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:39:25,962] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:39:26,025] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:26,027] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:26,030] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:26,033] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:26,079] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:39:26,084] INFO Skipping recovery for all logs in /tmp/kafka-logs-2 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:39:26,182] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:26,215] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-49, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 113ms (1/10 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:39:26,224] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:26,231] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-19, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (2/10 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:39:26,240] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:26,247] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-7, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (3/10 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:39:26,255] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:26,262] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-13, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (4/10 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:39:26,267] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:26,273] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-37, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (5/10 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:39:26,280] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:26,285] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-43, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (6/10 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:39:26,292] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:26,297] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-1, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (7/10 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:39:26,303] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:26,309] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-2.d90ddc6cdf124f27bef9fc487becc9dd-delete, topicId=wToOuBQ5Qj6iZZl5PbLQAw, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (8/10 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:39:26,317] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:26,320] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-31, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (9/10 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:39:26,325] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:26,330] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-25, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (10/10 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:39:26,333] INFO Loaded 10 logs in 253ms. (kafka.log.LogManager)
[2022-05-15 23:39:26,334] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:39:26,335] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:39:26,551] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:26,669] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:39:26,672] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-15 23:39:26,697] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:39:26,704] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:26,720] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:26,721] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:26,722] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:26,724] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:26,735] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:39:26,789] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:39:26,807] INFO Stat of the created znode at /brokers/ids/2 is: 7083,7083,1652654366799,1652654366799,1,0,0,72057641293906066,192,0,7083
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:39:26,808] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://joao:9094, czxid (broker epoch): 7083 (kafka.zk.KafkaZkClient)
[2022-05-15 23:39:26,871] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:26,876] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:26,877] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:26,891] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:26,903] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:26,923] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:39:26,929] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:39:26,929] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:39:26,955] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:26,972] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:39:26,992] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:39:26,998] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:39:26,998] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:39:27,004] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:39:27,005] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:39:27,005] INFO Kafka startTimeMs: 1652654366998 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:39:27,008] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-15 23:39:27,109] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:27,110] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:27,110] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:27,110] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:27,111] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:27,111] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:27,111] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:27,111] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:27,112] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:27,113] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:27,138] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-7, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:27,163] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:27,175] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 70 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:27,176] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 70 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:27,178] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 70 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:27,178] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 70 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:27,178] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 70 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:27,178] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 70 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:27,178] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 70 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:27,178] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 70 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:27,178] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 70 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:27,178] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 70 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:27,178] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 70 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:27,178] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 70 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:27,178] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 70 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:27,178] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 70 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:27,178] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 70 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:27,178] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 70 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:27,178] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 70 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:27,178] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 70 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:27,184] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 7 milliseconds for epoch 70, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:27,185] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 7 milliseconds for epoch 70, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:27,186] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 8 milliseconds for epoch 70, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:27,186] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 8 milliseconds for epoch 70, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:27,186] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 8 milliseconds for epoch 70, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:27,186] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 8 milliseconds for epoch 70, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:27,186] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 8 milliseconds for epoch 70, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:27,186] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 8 milliseconds for epoch 70, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:27,186] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 8 milliseconds for epoch 70, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:30,129] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:39:30,438] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:39:30,542] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:39:30,546] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:39:30,546] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:39:30,566] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:39:30,583] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:30,583] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:30,583] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:30,583] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:30,584] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:30,584] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:30,584] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:30,584] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:30,584] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:30,584] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:30,584] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:30,584] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:30,584] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:30,584] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:30,584] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:30,584] INFO Client environment:os.memory.free=1016MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:30,584] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:30,584] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:30,587] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:30,593] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:39:30,599] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:30,607] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:39:30,614] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:30,616] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:30,623] INFO Socket connection established, initiating session, client: /127.0.0.1:58126, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:30,631] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0093, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:30,639] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:39:30,739] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:39:30,896] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:39:30,902] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:39:30,967] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:39:30,980] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:39:31,046] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:31,049] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:31,053] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:31,056] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:31,108] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:39:31,113] INFO Skipping recovery for all logs in /tmp/kafka-logs-3 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:39:31,205] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:31,235] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-14, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 105ms (1/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:39:31,251] INFO Deleted producer state snapshot /tmp/kafka-logs-3/__consumer_offsets-38/00000000000000091906.snapshot (kafka.log.SnapshotFile)
[2022-05-15 23:39:31,253] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Loading producer state till offset 98382 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:31,253] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Reloading from producer snapshot and rebuilding producer state from offset 98382 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:31,254] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-3/__consumer_offsets-38/00000000000000098382.snapshot,98382)' (kafka.log.ProducerStateManager)
[2022-05-15 23:39:31,259] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 98382 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:31,263] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-38, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=98382) with 1 segments in 26ms (2/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:39:31,268] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:31,272] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-8, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (3/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:39:31,277] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:31,281] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-2, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (4/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:39:31,286] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:31,292] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-26, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (5/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:39:31,297] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:31,301] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-20, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (6/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:39:31,305] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:31,309] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-32, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:39:31,314] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:31,317] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-44, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (8/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:39:31,319] INFO Loaded 8 logs in 211ms. (kafka.log.LogManager)
[2022-05-15 23:39:31,320] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:39:31,322] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:39:31,543] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:31,646] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:39:31,649] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-05-15 23:39:31,673] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:39:31,679] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:31,696] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:31,698] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:31,699] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:31,700] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:31,712] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:39:31,774] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:39:31,793] INFO Stat of the created znode at /brokers/ids/3 is: 7108,7108,1652654371786,1652654371786,1,0,0,72057641293906067,192,0,7108
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:39:31,794] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://joao:9095, czxid (broker epoch): 7108 (kafka.zk.KafkaZkClient)
[2022-05-15 23:39:31,859] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:31,863] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:31,865] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:31,877] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:31,889] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:31,914] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:39:31,919] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:39:31,919] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:39:31,942] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:31,965] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:39:31,983] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:39:31,988] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:39:31,988] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:39:31,992] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:39:31,994] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:39:31,994] INFO Kafka startTimeMs: 1652654371988 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:39:31,995] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-05-15 23:39:32,053] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:32,083] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:32,088] INFO [Partition __consumer_offsets-2 broker=3] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:32,088] INFO [Partition __consumer_offsets-20 broker=3] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:32,088] INFO [Partition __consumer_offsets-38 broker=3] Log loaded for partition __consumer_offsets-38 with initial high watermark 98382 (kafka.cluster.Partition)
[2022-05-15 23:39:32,088] INFO [Partition __consumer_offsets-8 broker=3] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:32,089] INFO [Partition __consumer_offsets-26 broker=3] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:32,089] INFO [Partition __consumer_offsets-44 broker=3] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:32,089] INFO [Partition __consumer_offsets-14 broker=3] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:32,090] INFO [Partition __consumer_offsets-32 broker=3] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:32,112] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-26, __consumer_offsets-32, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:32,144] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 2 in epoch 70 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:32,145] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 70 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:32,147] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 20 in epoch 70 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:32,147] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 70 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:32,147] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 38 in epoch 70 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:32,147] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 70 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:32,147] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 8 in epoch 70 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:32,147] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 70 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:32,147] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 26 in epoch 70 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:32,147] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 70 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:32,147] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 44 in epoch 70 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:32,148] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 70 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:32,148] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 14 in epoch 70 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:32,148] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 70 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:32,148] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 32 in epoch 70 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:32,148] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 70 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:32,155] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-2 in 9 milliseconds for epoch 70, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:32,156] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-20 in 9 milliseconds for epoch 70, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:32,300] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-38 in 153 milliseconds for epoch 70, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:32,301] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-8 in 154 milliseconds for epoch 70, of which 153 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:32,301] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-26 in 154 milliseconds for epoch 70, of which 154 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:32,302] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-44 in 154 milliseconds for epoch 70, of which 153 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:32,302] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-14 in 154 milliseconds for epoch 70, of which 154 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:32,302] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-32 in 154 milliseconds for epoch 70, of which 154 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:35,173] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:39:35,479] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:39:35,589] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:39:35,595] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:39:35,596] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:39:35,616] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:39:35,622] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:35,622] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:35,622] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:35,622] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:35,623] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:35,623] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:35,623] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:35,623] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:35,623] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:35,623] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:35,623] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:35,624] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:35,624] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:35,624] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:35,624] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:35,624] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:35,624] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:35,624] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:35,627] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:35,633] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:39:35,639] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:35,663] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:39:35,670] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:35,672] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:35,677] INFO Socket connection established, initiating session, client: /127.0.0.1:58128, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:35,686] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0094, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:35,692] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:39:35,790] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:39:35,944] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:39:35,952] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:39:36,009] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:39:36,020] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:39:36,083] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:36,085] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:36,089] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:36,091] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:36,137] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:39:36,140] INFO Skipping recovery for all logs in /tmp/kafka-logs-4 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:39:36,210] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:36,232] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-24, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 78ms (1/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:39:36,237] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:36,243] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-12, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (2/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:39:36,247] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:36,252] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-30, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (3/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:39:36,257] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:36,261] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-2.4308dd2ebb524ecd85f701df4d85127e-delete, topicId=wToOuBQ5Qj6iZZl5PbLQAw, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:39:36,265] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:36,269] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-36, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:39:36,275] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:36,279] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-1.b4845c43b80e41cba957c30f2677705a-delete, topicId=wToOuBQ5Qj6iZZl5PbLQAw, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (6/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:39:36,284] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:36,287] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-42, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:39:36,290] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:36,294] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-0, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (8/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:39:36,298] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:36,301] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-18, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (9/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:39:36,305] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:36,308] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-0.6e2c8517ed024c60be59a9f0a11274e6-delete, topicId=wToOuBQ5Qj6iZZl5PbLQAw, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (10/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:39:36,313] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:36,316] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-6, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:39:36,321] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:36,324] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-48, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (12/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:39:36,327] INFO Loaded 12 logs in 190ms. (kafka.log.LogManager)
[2022-05-15 23:39:36,328] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:39:36,328] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:39:36,540] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:36,651] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:39:36,654] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.Acceptor)
[2022-05-15 23:39:36,676] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:39:36,683] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:36,699] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:36,700] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:36,702] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:36,703] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:36,714] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:39:36,770] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:39:36,787] INFO Stat of the created znode at /brokers/ids/4 is: 7132,7132,1652654376779,1652654376779,1,0,0,72057641293906068,192,0,7132
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:39:36,788] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://joao:9096, czxid (broker epoch): 7132 (kafka.zk.KafkaZkClient)
[2022-05-15 23:39:36,849] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:36,855] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:36,856] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:36,870] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:36,882] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:36,905] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:39:36,911] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:39:36,911] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:39:36,933] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:36,947] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:39:36,972] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:39:36,978] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:39:36,978] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:39:36,983] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:39:36,983] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:39:36,983] INFO Kafka startTimeMs: 1652654376978 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:39:36,985] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2022-05-15 23:39:37,051] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:37,076] INFO [Partition __consumer_offsets-18 broker=4] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:37,076] INFO [Partition __consumer_offsets-36 broker=4] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:37,076] INFO [Partition __consumer_offsets-6 broker=4] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:37,076] INFO [Partition __consumer_offsets-24 broker=4] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:37,076] INFO [Partition __consumer_offsets-42 broker=4] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:37,077] INFO [Partition __consumer_offsets-12 broker=4] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:37,077] INFO [Partition __consumer_offsets-30 broker=4] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:37,077] INFO [Partition __consumer_offsets-0 broker=4] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:37,077] INFO [Partition __consumer_offsets-48 broker=4] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:37,086] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:37,102] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-12, __consumer_offsets-42, __consumer_offsets-18) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:37,137] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 18 in epoch 77 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:37,139] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 77 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:37,141] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 36 in epoch 77 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:37,141] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 77 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:37,141] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 6 in epoch 77 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:37,141] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 77 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:37,141] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 24 in epoch 77 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:37,141] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 77 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:37,141] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 42 in epoch 77 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:37,141] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 77 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:37,141] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 12 in epoch 77 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:37,141] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 77 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:37,142] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 30 in epoch 77 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:37,142] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 77 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:37,142] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 0 in epoch 77 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:37,142] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 77 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:37,142] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 48 in epoch 77 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:37,142] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 77 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:37,150] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-18 in 9 milliseconds for epoch 77, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:37,151] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-36 in 10 milliseconds for epoch 77, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:37,152] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-6 in 11 milliseconds for epoch 77, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:37,152] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-24 in 11 milliseconds for epoch 77, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:37,153] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-42 in 12 milliseconds for epoch 77, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:37,154] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-12 in 11 milliseconds for epoch 77, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:37,154] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-30 in 12 milliseconds for epoch 77, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:37,155] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-0 in 13 milliseconds for epoch 77, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:37,155] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-48 in 13 milliseconds for epoch 77, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:40,131] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:39:40,436] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:39:40,544] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:39:40,548] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:39:40,549] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:39:40,566] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:39:40,570] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:40,570] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:40,570] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:40,570] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:40,571] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:40,571] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:40,571] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:40,571] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:40,571] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:40,571] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:40,571] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:40,571] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:40,571] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:40,571] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:40,571] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:40,571] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:40,571] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:40,571] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:40,574] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:39:40,580] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:39:40,586] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:40,601] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:39:40,610] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:40,611] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:40,617] INFO Socket connection established, initiating session, client: /127.0.0.1:58130, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:40,628] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0095, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:39:40,635] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:39:40,734] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:39:40,865] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:39:40,869] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:39:40,912] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:39:40,922] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:39:40,968] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:40,970] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:40,972] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:40,973] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:39:41,007] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:39:41,010] INFO Skipping recovery for all logs in /tmp/kafka-logs-5 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:39:41,077] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:41,099] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-46, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 76ms (1/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:39:41,104] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:41,109] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-10, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (2/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:39:41,114] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:41,118] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-28, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (3/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:39:41,123] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:41,126] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-1.08870319a4764802b7bcb544fe7a5b3c-delete, topicId=wToOuBQ5Qj6iZZl5PbLQAw, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (4/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:39:41,142] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Loading producer state till offset 56709 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:41,143] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 56709 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:41,144] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-22/00000000000000056709.snapshot,56709)' (kafka.log.ProducerStateManager)
[2022-05-15 23:39:41,152] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Producer state recovery took 9ms for snapshot load and 0ms for segment recovery from offset 56709 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:41,155] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-22, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=56709) with 1 segments in 28ms (5/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:39:41,159] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:41,163] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-16, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:39:41,167] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:41,170] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-0.7a3a5c90733b4c178c1e63b875bec022-delete, topicId=wToOuBQ5Qj6iZZl5PbLQAw, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (7/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:39:41,177] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Loading producer state till offset 35134 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:41,177] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 35134 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:41,177] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-40/00000000000000035134.snapshot,35134)' (kafka.log.ProducerStateManager)
[2022-05-15 23:39:41,178] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 35134 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:41,181] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-40, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=35134) with 1 segments in 11ms (8/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:39:41,186] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:41,189] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-34, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:39:41,194] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:41,197] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-4, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:39:41,199] INFO Loaded 10 logs in 192ms. (kafka.log.LogManager)
[2022-05-15 23:39:41,200] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:39:41,201] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:39:41,420] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:41,534] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:39:41,537] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.Acceptor)
[2022-05-15 23:39:41,562] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:39:41,568] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:41,583] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:41,585] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:41,586] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:41,587] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:41,600] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:39:41,656] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:39:41,673] INFO Stat of the created znode at /brokers/ids/5 is: 7157,7157,1652654381665,1652654381665,1,0,0,72057641293906069,192,0,7157
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:39:41,674] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://joao:9097, czxid (broker epoch): 7157 (kafka.zk.KafkaZkClient)
[2022-05-15 23:39:41,736] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:41,743] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:41,744] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:41,757] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:41,769] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:41,790] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:39:41,796] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:39:41,796] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:39:41,819] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:39:41,838] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:39:41,856] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:39:41,861] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:39:41,861] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:39:41,867] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:39:41,867] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:39:41,867] INFO Kafka startTimeMs: 1652654381861 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:39:41,870] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2022-05-15 23:39:41,930] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:41,957] INFO [Partition __consumer_offsets-34 broker=5] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:41,957] INFO [Partition __consumer_offsets-4 broker=5] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:41,958] INFO [Partition __consumer_offsets-22 broker=5] Log loaded for partition __consumer_offsets-22 with initial high watermark 56709 (kafka.cluster.Partition)
[2022-05-15 23:39:41,958] INFO [Partition __consumer_offsets-40 broker=5] Log loaded for partition __consumer_offsets-40 with initial high watermark 35134 (kafka.cluster.Partition)
[2022-05-15 23:39:41,958] INFO [Partition __consumer_offsets-10 broker=5] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:41,958] INFO [Partition __consumer_offsets-28 broker=5] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:41,958] INFO [Partition __consumer_offsets-46 broker=5] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:41,958] INFO [Partition __consumer_offsets-16 broker=5] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:41,972] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:39:41,981] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:42,011] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 34 in epoch 79 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:42,013] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 79 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:42,015] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 4 in epoch 79 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:42,015] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 79 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:42,016] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 22 in epoch 79 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:42,016] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 79 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:42,016] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 40 in epoch 79 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:42,016] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 79 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:42,016] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 10 in epoch 79 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:42,016] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 79 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:42,016] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 28 in epoch 79 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:42,016] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 79 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:42,016] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 46 in epoch 79 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:42,016] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 79 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:42,016] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 16 in epoch 79 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:39:42,016] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 79 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:42,022] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-34 in 7 milliseconds for epoch 79, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:42,023] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-4 in 7 milliseconds for epoch 79, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:42,047] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-9fa5abef-fdc9-4c05-8f09-7f9780632837, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:39:42,058] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-ed3a6d0d-54c4-4b54-b4a4-a5d0ecba6f8e, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:39:42,058] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-1038faf2-d998-4707-9799-897de83d6136, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:39:42,059] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-b283a5ee-70be-4bf9-b41c-74e089f12e34, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:39:42,059] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-360d1581-f79b-41e6-82d3-fe3577615014, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:39:42,059] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-9e173d1e-b47a-4b16-9874-bf5d2688c730, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:39:42,059] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-81fafa38-80dc-43ea-ac6c-e398b06565dc, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:39:42,086] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-d15976bc-df63-4682-8583-fd67cbb1d9df, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:39:42,087] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-a0d7c5c7-e384-4339-b0be-414878362e3e, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:39:42,087] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-ee781f71-f1c3-46d7-bd93-d90a4fe359ff, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:39:42,087] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-78575c72-7be8-4563-b114-53b271a8ef70, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:39:42,088] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-0287b15c-1acd-4475-b9ce-b994aebeeff2, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:39:42,088] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-45d54f6e-f1d8-43f7-8ace-1db96ac0cfac, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:39:42,143] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-954ef0dc-d124-405b-9bb6-119086dd08c0, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:39:42,143] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-3f51cd43-28ab-4459-969e-211543e6cd72, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:39:42,143] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-4b8634e2-92f3-4603-97c5-35df7219bd84, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 4. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:39:42,144] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-5f6ccebb-0352-4648-b98e-7613d791d352, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:39:42,156] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-8863ee28-05fa-4d10-b813-b83668f9ecf8, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:39:42,164] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-22 in 148 milliseconds for epoch 79, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:42,196] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-40 in 180 milliseconds for epoch 79, of which 148 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:42,196] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-10 in 180 milliseconds for epoch 79, of which 180 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:42,196] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-28 in 180 milliseconds for epoch 79, of which 180 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:42,196] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-46 in 180 milliseconds for epoch 79, of which 180 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:42,197] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-16 in 181 milliseconds for epoch 79, of which 180 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:39:45,950] INFO Creating topic Sensor with configuration {min.insync.replicas=2} and initial partition assignment HashMap(0 -> ArrayBuffer(3, 5, 1), 1 -> ArrayBuffer(0, 1, 4), 2 -> ArrayBuffer(5, 4, 2), 3 -> ArrayBuffer(1, 2, 3), 4 -> ArrayBuffer(4, 3, 0), 5 -> ArrayBuffer(2, 0, 5)) (kafka.zk.AdminZkClient)
[2022-05-15 23:39:45,991] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:45,991] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:45,992] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:45,991] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:45,992] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-4) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:45,992] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:46,003] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:46,003] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:46,003] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:46,003] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:46,004] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:46,004] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:46,008] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-4/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:39:46,009] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-1/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:39:46,009] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-3/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:39:46,010] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-5/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:39:46,010] INFO Created log for partition Sensor-1 in /tmp/kafka-logs/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:39:46,010] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-2/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:39:46,010] INFO [Partition Sensor-4 broker=4] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 23:39:46,011] INFO [Partition Sensor-4 broker=4] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:46,010] INFO [Partition Sensor-3 broker=1] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 23:39:46,011] INFO [Partition Sensor-3 broker=1] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:46,011] INFO [Partition Sensor-0 broker=3] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 23:39:46,011] INFO [Partition Sensor-0 broker=3] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:46,012] INFO [Partition Sensor-1 broker=0] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 23:39:46,012] INFO [Partition Sensor-5 broker=2] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 23:39:46,012] INFO [Partition Sensor-2 broker=5] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 23:39:46,012] INFO [Partition Sensor-1 broker=0] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:46,013] INFO [Partition Sensor-5 broker=2] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:46,013] INFO [Partition Sensor-2 broker=5] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:46,022] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:46,022] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:46,022] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:46,023] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:46,023] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:46,023] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-3/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:39:46,024] INFO Created log for partition Sensor-4 in /tmp/kafka-logs/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:39:46,024] INFO [Partition Sensor-4 broker=3] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 23:39:46,024] INFO [Partition Sensor-4 broker=0] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 23:39:46,024] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-4/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:39:46,024] INFO [Partition Sensor-4 broker=3] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:46,024] INFO [Partition Sensor-4 broker=0] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:46,024] INFO [Partition Sensor-2 broker=4] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 23:39:46,024] INFO [Partition Sensor-2 broker=4] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:46,024] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-1/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:39:46,025] INFO [Partition Sensor-0 broker=1] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 23:39:46,025] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:46,025] INFO [Partition Sensor-0 broker=1] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:46,025] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-2/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:39:46,025] INFO [Partition Sensor-3 broker=2] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 23:39:46,025] INFO [Partition Sensor-3 broker=2] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:46,026] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-5/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:39:46,027] INFO [Partition Sensor-5 broker=5] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 23:39:46,027] INFO [Partition Sensor-5 broker=5] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:46,031] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:46,031] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:46,031] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:46,032] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:46,032] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:46,033] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-3/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:39:46,034] INFO [Partition Sensor-3 broker=3] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 23:39:46,034] INFO Created log for partition Sensor-5 in /tmp/kafka-logs/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:39:46,034] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-2/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:39:46,034] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-1/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:39:46,034] INFO [Partition Sensor-3 broker=3] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:46,034] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-4/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:39:46,034] INFO [Partition Sensor-5 broker=0] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 23:39:46,034] INFO [Partition Sensor-1 broker=1] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 23:39:46,034] INFO [Partition Sensor-2 broker=2] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 23:39:46,034] INFO [Partition Sensor-5 broker=0] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:46,034] INFO [Partition Sensor-1 broker=1] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:46,034] INFO [Partition Sensor-1 broker=4] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 23:39:46,034] INFO [Partition Sensor-2 broker=2] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:46,034] INFO [Partition Sensor-1 broker=4] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:46,034] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(Sensor-4, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:46,034] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:46,034] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:46,034] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:46,035] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(Sensor-4, Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:46,037] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:39:46,038] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-5/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:39:46,038] INFO [Partition Sensor-0 broker=5] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 23:39:46,039] INFO [Partition Sensor-0 broker=5] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:39:46,039] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(Sensor-5, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:46,059] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,059] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,060] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,064] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 4 for partitions Map(Sensor-4 -> InitialFetchState(Some(Advz1TV9QZCg-Xt7DY4JqA),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:46,065] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,066] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(Sensor-1 -> InitialFetchState(Some(Advz1TV9QZCg-Xt7DY4JqA),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:46,067] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(Sensor-3 -> InitialFetchState(Some(Advz1TV9QZCg-Xt7DY4JqA),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:46,068] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,069] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,070] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,070] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,070] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions Map(Sensor-5 -> InitialFetchState(Some(Advz1TV9QZCg-Xt7DY4JqA),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:46,070] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,071] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,071] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,072] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 4 for partitions Map(Sensor-4 -> InitialFetchState(Some(Advz1TV9QZCg-Xt7DY4JqA),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:46,073] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:39:46,074] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 5 for partitions Map(Sensor-2 -> InitialFetchState(Some(Advz1TV9QZCg-Xt7DY4JqA),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:46,074] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 0 for partitions Map(Sensor-1 -> InitialFetchState(Some(Advz1TV9QZCg-Xt7DY4JqA),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:46,073] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,076] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 3 for partitions Map(Sensor-0 -> InitialFetchState(Some(Advz1TV9QZCg-Xt7DY4JqA),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:46,076] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,076] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,076] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,077] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:39:46,077] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:39:46,078] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:39:46,078] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 2 for partitions Map(Sensor-5 -> InitialFetchState(Some(Advz1TV9QZCg-Xt7DY4JqA),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:46,079] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,080] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 5 for partitions Map(Sensor-2 -> InitialFetchState(Some(Advz1TV9QZCg-Xt7DY4JqA),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:46,080] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:39:46,075] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,080] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,081] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,081] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:39:46,081] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:39:46,078] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 1 for partitions Map(Sensor-3 -> InitialFetchState(Some(Advz1TV9QZCg-Xt7DY4JqA),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:46,082] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:39:46,077] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,084] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,084] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:39:46,080] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,085] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 3 for partitions Map(Sensor-0 -> InitialFetchState(Some(Advz1TV9QZCg-Xt7DY4JqA),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:39:46,088] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:39:46,086] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,091] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:39:46,093] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,094] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:39:46,204] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-0. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:39:46,232] WARN [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-2. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:40:16,260] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=104787, lastModifiedTime=1652654249259, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:40:16,263] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=104787, lastModifiedTime=1652654249259, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:40:16,268] INFO Deleted log /tmp/kafka-logs/Sensor-0.f13e68dae330484783b79f51b1427edd-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:16,269] INFO Deleted offset index /tmp/kafka-logs/Sensor-0.f13e68dae330484783b79f51b1427edd-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:16,271] INFO Deleted time index /tmp/kafka-logs/Sensor-0.f13e68dae330484783b79f51b1427edd-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:16,277] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs/Sensor-0.f13e68dae330484783b79f51b1427edd-delete. (kafka.log.LogManager)
[2022-05-15 23:40:21,137] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=72901, lastModifiedTime=1652654225794, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:40:21,140] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=72901, lastModifiedTime=1652654225794, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:40:21,145] INFO Deleted log /tmp/kafka-logs-1/Sensor-1.7637d6c9826140dd8c27420a88be7f8c-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:21,146] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-1.7637d6c9826140dd8c27420a88be7f8c-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:21,150] INFO Deleted time index /tmp/kafka-logs-1/Sensor-1.7637d6c9826140dd8c27420a88be7f8c-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:21,157] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-1/Sensor-1.7637d6c9826140dd8c27420a88be7f8c-delete. (kafka.log.LogManager)
[2022-05-15 23:40:21,158] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=73976, lastModifiedTime=1652654226362, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:40:21,158] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=73976, lastModifiedTime=1652654226362, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:40:21,159] INFO Deleted log /tmp/kafka-logs-1/Sensor-2.a50d72eff0c14124b2f2159973619053-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:21,160] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-2.a50d72eff0c14124b2f2159973619053-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:21,160] INFO Deleted time index /tmp/kafka-logs-1/Sensor-2.a50d72eff0c14124b2f2159973619053-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:21,161] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-1/Sensor-2.a50d72eff0c14124b2f2159973619053-delete. (kafka.log.LogManager)
[2022-05-15 23:40:26,314] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=73976, lastModifiedTime=1652654226362, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:40:26,317] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=73976, lastModifiedTime=1652654226362, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:40:26,323] INFO Deleted log /tmp/kafka-logs-2/Sensor-2.d90ddc6cdf124f27bef9fc487becc9dd-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:26,324] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-2.d90ddc6cdf124f27bef9fc487becc9dd-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:26,329] INFO Deleted time index /tmp/kafka-logs-2/Sensor-2.d90ddc6cdf124f27bef9fc487becc9dd-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:26,335] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-2/Sensor-2.d90ddc6cdf124f27bef9fc487becc9dd-delete. (kafka.log.LogManager)
[2022-05-15 23:40:36,267] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=73976, lastModifiedTime=1652654226358, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:40:36,269] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=73976, lastModifiedTime=1652654226358, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:40:36,273] INFO Deleted log /tmp/kafka-logs-4/Sensor-2.4308dd2ebb524ecd85f701df4d85127e-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:36,274] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-2.4308dd2ebb524ecd85f701df4d85127e-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:36,278] INFO Deleted time index /tmp/kafka-logs-4/Sensor-2.4308dd2ebb524ecd85f701df4d85127e-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:36,286] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-4/Sensor-2.4308dd2ebb524ecd85f701df4d85127e-delete. (kafka.log.LogManager)
[2022-05-15 23:40:36,287] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=72901, lastModifiedTime=1652654225794, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:40:36,287] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=72901, lastModifiedTime=1652654225794, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:40:36,289] INFO Deleted log /tmp/kafka-logs-4/Sensor-1.b4845c43b80e41cba957c30f2677705a-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:36,289] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-1.b4845c43b80e41cba957c30f2677705a-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:36,289] INFO Deleted time index /tmp/kafka-logs-4/Sensor-1.b4845c43b80e41cba957c30f2677705a-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:36,290] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-4/Sensor-1.b4845c43b80e41cba957c30f2677705a-delete. (kafka.log.LogManager)
[2022-05-15 23:40:36,309] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=104787, lastModifiedTime=1652654249263, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:40:36,310] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=104787, lastModifiedTime=1652654249263, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:40:36,311] INFO Deleted log /tmp/kafka-logs-4/Sensor-0.6e2c8517ed024c60be59a9f0a11274e6-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:36,311] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-0.6e2c8517ed024c60be59a9f0a11274e6-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:36,312] INFO Deleted time index /tmp/kafka-logs-4/Sensor-0.6e2c8517ed024c60be59a9f0a11274e6-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:36,313] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-4/Sensor-0.6e2c8517ed024c60be59a9f0a11274e6-delete. (kafka.log.LogManager)
[2022-05-15 23:40:41,132] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=72901, lastModifiedTime=1652654225790, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:40:41,134] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=72901, lastModifiedTime=1652654225790, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:40:41,139] INFO Deleted log /tmp/kafka-logs-5/Sensor-1.08870319a4764802b7bcb544fe7a5b3c-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:41,139] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-1.08870319a4764802b7bcb544fe7a5b3c-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:41,145] INFO Deleted time index /tmp/kafka-logs-5/Sensor-1.08870319a4764802b7bcb544fe7a5b3c-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:41,151] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-5/Sensor-1.08870319a4764802b7bcb544fe7a5b3c-delete. (kafka.log.LogManager)
[2022-05-15 23:40:41,171] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=104787, lastModifiedTime=1652654249263, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:40:41,172] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=104787, lastModifiedTime=1652654249263, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:40:41,173] INFO Deleted log /tmp/kafka-logs-5/Sensor-0.7a3a5c90733b4c178c1e63b875bec022-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:41,174] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-0.7a3a5c90733b4c178c1e63b875bec022-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:41,174] INFO Deleted time index /tmp/kafka-logs-5/Sensor-0.7a3a5c90733b4c178c1e63b875bec022-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:40:41,175] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-5/Sensor-0.7a3a5c90733b4c178c1e63b875bec022-delete. (kafka.log.LogManager)
[2022-05-15 23:42:18,296] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:42:18,298] INFO [GroupCoordinator 5]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:42:18,298] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:42:18,298] INFO [GroupCoordinator 3]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:42:18,299] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:42:18,299] INFO [GroupCoordinator 4]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:42:18,306] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_OR_PARTITION from the leader for partition Sensor-5. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,306] WARN [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_OR_PARTITION from the leader for partition Sensor-5. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,331] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:18,331] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:18,332] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:18,332] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:18,332] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:18,332] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:18,332] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-3, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:18,332] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:18,333] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:18,333] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:18,333] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-3, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:18,333] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:18,339] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,339] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,340] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,340] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,340] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,341] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:18,342] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,342] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:18,343] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,343] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,343] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:18,344] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:18,344] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,344] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,345] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1653 due to node 1 being disconnected (elapsed time since creation: 190ms, elapsed time since send: 190ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:18,345] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1560 due to node 3 being disconnected (elapsed time since creation: 406ms, elapsed time since send: 406ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:18,347] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1611 due to node 0 being disconnected (elapsed time since creation: 237ms, elapsed time since send: 237ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:18,347] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1653 due to node 1 being disconnected (elapsed time since creation: 192ms, elapsed time since send: 192ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:18,350] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,346] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=227475199, epoch=1653) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:42:18,347] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=2096230055, epoch=1611) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:42:18,350] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:18,347] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1095467484, epoch=1558) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:42:18,351] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,351] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,351] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,351] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,351] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,352] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,348] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=1746539034, epoch=1653) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:42:18,353] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,353] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:18,353] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,353] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,354] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 823 due to node 4 being disconnected (elapsed time since creation: 295ms, elapsed time since send: 295ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:18,354] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=1680129939, epoch=823) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:42:18,355] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,355] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,356] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1560 due to node 3 being disconnected (elapsed time since creation: 414ms, elapsed time since send: 414ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:18,357] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,358] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:18,358] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:18,358] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1611 due to node 0 being disconnected (elapsed time since creation: 249ms, elapsed time since send: 249ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:18,358] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,358] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,358] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:18,359] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:18,359] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:18,359] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1569 due to node 5 being disconnected (elapsed time since creation: 425ms, elapsed time since send: 425ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:18,359] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1569 due to node 5 being disconnected (elapsed time since creation: 424ms, elapsed time since send: 424ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:18,358] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=671273620, epoch=1611) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:42:18,360] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,360] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,360] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,356] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=2014173857, epoch=1560) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:42:18,360] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,359] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=702386759, epoch=1569) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:42:18,361] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,360] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:18,359] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=1824063841, epoch=1567) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:42:18,361] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,361] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,361] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,361] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 823 due to node 4 being disconnected (elapsed time since creation: 305ms, elapsed time since send: 305ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:18,362] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,362] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-3, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:18,363] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-3, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:18,361] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=789248618, epoch=823) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:42:18,363] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,363] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:42:18,364] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:18,364] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:18,364] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:18,364] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:18,365] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:18,366] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:18,369] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:18,370] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:18,380] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-2/Sensor-5.f8f5998aaec14e5293193b307a310791-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:42:18,384] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs/Sensor-4.36a77b814aaf478081b17096aed0ef2a-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:42:18,384] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-2/Sensor-2.cfc13167e38e4377ba9d44899dea9414-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:42:18,386] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-5/Sensor-5.f9d95fec8f24478cb87bf7eb0db333eb-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:42:18,387] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-1/Sensor-3.a60af897f3e74f1e819f352802df5065-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:42:18,388] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs/Sensor-5.11db6a62560c4521a5c820605546fca7-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:42:18,388] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-2/Sensor-3.cbcdb783caf749a5902cab2b0e655441-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:42:18,388] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-4/Sensor-4.62478e08c7984956882c57b4933d02d2-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:42:18,388] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-3/Sensor-4.8e7bfc57029741acb59a459b86da237f-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:42:18,390] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-5/Sensor-2.b53ebe71c6ae450cb9f550606b2dcc29-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:42:18,391] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs/Sensor-1.102513e6b6104d01b5a47aacdffb51e0-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:42:18,392] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-1/Sensor-0.09b14f8dd3f548d3a11653b542487c21-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:42:18,392] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-4/Sensor-2.d3a73eb541724d319af6784517e1970a-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:42:18,392] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-3/Sensor-3.7d1b310d9cef417aad00b820f3cfa0b9-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:42:18,393] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-5/Sensor-0.b4ddf1233cc441698b20549ec32786b7-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:42:18,395] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-4/Sensor-1.1f4314a217ed4f2ca2cb0fd7d1377f63-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:42:18,395] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-1/Sensor-1.ed79014edb8744e9aa3adbd6c3e8d9b8-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:42:18,396] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-3/Sensor-0.b92204fcbce84f319484e8da2c09d1be-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:42:21,672] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:42:21,672] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:42:21,672] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:42:21,672] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:42:21,672] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:42:21,672] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:42:21,675] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:42:21,675] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:42:21,676] INFO [KafkaServer id=5] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:42:21,676] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:42:21,676] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:42:21,677] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:42:21,677] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:42:21,677] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:42:21,678] INFO [KafkaServer id=5] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:42:21,678] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:42:21,678] INFO [KafkaServer id=4] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:42:21,679] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:42:21,704] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 18ms (kafka.server.KafkaServer)
[2022-05-15 23:42:21,706] INFO [KafkaServer id=4] Controlled shutdown request returned successfully after 15ms (kafka.server.KafkaServer)
[2022-05-15 23:42:21,708] INFO [KafkaServer id=3] Controlled shutdown request returned successfully after 18ms (kafka.server.KafkaServer)
[2022-05-15 23:42:21,708] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 20ms (kafka.server.KafkaServer)
[2022-05-15 23:42:21,708] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:42:21,709] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:42:21,709] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:42:21,710] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:42:21,711] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:42:21,711] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:42:21,711] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:42:21,711] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:42:21,711] INFO [KafkaServer id=5] Controlled shutdown request returned successfully after 24ms (kafka.server.KafkaServer)
[2022-05-15 23:42:21,712] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:42:21,712] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:42:21,712] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:42:21,712] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:42:21,713] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:42:21,712] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:42:21,714] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:42:21,714] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 23ms (kafka.server.KafkaServer)
[2022-05-15 23:42:21,715] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:42:21,715] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:42:21,715] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:42:21,715] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:42:21,719] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:42:21,720] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:42:21,721] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:42:21,722] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:42:21,724] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:42:21,736] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:42:21,737] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:42:21,737] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:42:21,738] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:42:21,738] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:42:21,739] INFO [data-plane Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:42:21,739] INFO [data-plane Kafka Request Handler on Broker 5], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:42:21,739] INFO [data-plane Kafka Request Handler on Broker 4], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:42:21,740] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:42:21,741] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:42:21,743] INFO [data-plane Kafka Request Handler on Broker 5], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:42:21,745] INFO [data-plane Kafka Request Handler on Broker 4], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:42:21,745] INFO [data-plane Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:42:21,746] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:42:21,746] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:42:21,748] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:42:21,750] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:42:21,751] INFO [ExpirationReaper-5-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,753] INFO [ExpirationReaper-4-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,753] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,754] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:42:21,755] INFO [ExpirationReaper-3-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,757] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,759] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,790] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,790] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,791] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:42:21,792] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,805] INFO [ExpirationReaper-3-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,805] INFO [ExpirationReaper-3-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,806] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:42:21,807] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,831] INFO [ExpirationReaper-5-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,831] INFO [ExpirationReaper-5-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,832] INFO [KafkaApi-5] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:42:21,834] INFO [ExpirationReaper-5-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,863] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,863] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,864] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:42:21,866] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,872] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,872] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,874] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:42:21,876] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:42:21,876] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:42:21,877] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:42:21,877] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:42:21,879] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:42:21,880] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:42:21,881] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,895] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,895] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,898] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:42:21,900] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:42:21,900] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:42:21,900] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:42:21,900] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:42:21,902] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:42:21,903] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:42:21,903] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,903] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,904] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,905] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,905] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,906] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,907] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:42:21,909] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:42:21,909] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:42:21,909] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:42:21,910] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:42:21,912] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:42:21,912] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:42:21,912] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,913] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,913] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,914] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:42:21,914] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:42:21,915] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:42:21,915] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:42:21,915] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:42:21,916] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:21,917] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:21,917] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:21,919] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:21,919] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,921] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,921] INFO [ExpirationReaper-4-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,921] INFO [ExpirationReaper-4-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,921] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,922] INFO [KafkaApi-4] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:42:21,922] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:42:21,923] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,923] INFO [ExpirationReaper-4-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,925] INFO [ExpirationReaper-5-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,925] INFO [ExpirationReaper-5-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,928] INFO [TransactionCoordinator id=5] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:42:21,930] INFO [Transaction State Manager 5]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:42:21,930] INFO [Transaction Marker Channel Manager 5]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:42:21,930] INFO [Transaction Marker Channel Manager 5]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:42:21,930] INFO [Transaction Marker Channel Manager 5]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:42:21,933] INFO [TransactionCoordinator id=5] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:42:21,934] INFO [GroupCoordinator 5]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:42:21,934] INFO [ExpirationReaper-5-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,941] INFO [ExpirationReaper-5-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,941] INFO [ExpirationReaper-5-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,941] INFO [ExpirationReaper-5-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,972] INFO [ExpirationReaper-5-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,972] INFO [ExpirationReaper-5-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:21,973] INFO [GroupCoordinator 5]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:42:21,974] INFO [ReplicaManager broker=5] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:42:21,975] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:42:21,975] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:42:21,976] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:42:21,977] INFO [ReplicaFetcherManager on broker 5] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:21,979] INFO [ReplicaFetcherManager on broker 5] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:21,979] INFO [ReplicaAlterLogDirsManager on broker 5] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:21,979] INFO [ReplicaAlterLogDirsManager on broker 5] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:21,979] INFO [ExpirationReaper-5-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,006] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,006] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,006] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,027] INFO [ExpirationReaper-5-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,027] INFO [ExpirationReaper-5-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,028] INFO [ExpirationReaper-5-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,051] INFO [ExpirationReaper-4-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,051] INFO [ExpirationReaper-4-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,055] INFO [TransactionCoordinator id=4] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:42:22,057] INFO [Transaction State Manager 4]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:42:22,057] INFO [Transaction Marker Channel Manager 4]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:42:22,058] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,058] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,058] INFO [Transaction Marker Channel Manager 4]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:42:22,058] INFO [Transaction Marker Channel Manager 4]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:42:22,060] INFO [TransactionCoordinator id=4] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:42:22,061] INFO [GroupCoordinator 4]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:42:22,062] INFO [ExpirationReaper-4-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,063] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:42:22,065] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:42:22,065] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:42:22,066] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:42:22,066] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:42:22,068] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:42:22,075] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:42:22,076] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,090] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,090] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,091] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,092] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,092] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,092] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,098] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,098] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,098] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,098] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,099] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:42:22,099] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:42:22,100] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:42:22,100] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:42:22,100] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:42:22,100] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:42:22,100] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:42:22,100] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:42:22,100] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:42:22,100] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:42:22,102] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:22,102] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:22,104] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:22,104] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:22,105] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:22,105] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:22,106] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:22,107] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,106] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:22,107] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,109] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,109] INFO [ExpirationReaper-5-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,109] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,109] INFO [ExpirationReaper-5-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,110] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,110] INFO [ExpirationReaper-5-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,150] INFO [ExpirationReaper-4-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,150] INFO [ExpirationReaper-4-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,151] INFO [ExpirationReaper-4-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,172] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,172] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,173] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,182] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,182] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,189] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:42:22,189] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,190] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,190] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,194] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:42:22,194] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,195] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,195] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,196] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:42:22,196] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:42:22,213] INFO [ExpirationReaper-5-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,213] INFO [ExpirationReaper-5-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,214] INFO [ExpirationReaper-5-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,227] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,227] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,228] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,232] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:42:22,263] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:42:22,264] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:42:22,264] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:42:22,265] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:42:22,275] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,275] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,276] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,280] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,280] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,281] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:42:22,283] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:42:22,283] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:42:22,284] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:42:22,284] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:42:22,285] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:22,287] INFO [ExpirationReaper-4-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,287] INFO [ExpirationReaper-4-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,289] INFO [GroupCoordinator 4]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:42:22,290] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:22,291] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:22,291] INFO [ReplicaManager broker=4] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:42:22,292] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:22,292] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:42:22,292] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,292] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:42:22,292] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:42:22,293] INFO [ReplicaFetcherManager on broker 4] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:22,298] INFO [ReplicaFetcherManager on broker 4] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:42:22,299] INFO [ReplicaAlterLogDirsManager on broker 4] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:22,300] INFO [ReplicaAlterLogDirsManager on broker 4] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:42:22,300] INFO [ExpirationReaper-4-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,306] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,306] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,307] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,309] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,309] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,310] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,332] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,332] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,333] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,337] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,337] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,338] INFO [ExpirationReaper-3-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,348] INFO [ExpirationReaper-4-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,348] INFO [ExpirationReaper-4-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,349] INFO [ExpirationReaper-4-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,371] INFO EventThread shut down for session: 0x100000b00ad0090 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:42:22,371] INFO Session: 0x100000b00ad0090 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:42:22,374] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:42:22,375] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:22,386] INFO [ExpirationReaper-5-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,386] INFO [ExpirationReaper-5-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,391] INFO [ReplicaManager broker=5] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:42:22,392] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,392] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,392] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,394] INFO [Controller id=3, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,394] INFO [Controller id=3, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,394] INFO [Controller id=3, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,394] INFO [Controller id=3, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,394] INFO [Controller id=3, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,396] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:42:22,397] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,397] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,397] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,398] WARN [Controller id=3, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,398] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:42:22,398] WARN [Controller id=3, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,398] WARN [Controller id=3, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,398] WARN [Controller id=3, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,398] WARN [Controller id=3, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,399] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:42:22,400] INFO [Controller id=3, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,400] INFO [Controller id=3, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,401] INFO [Controller id=3, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,401] INFO [Controller id=3, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,402] INFO [Controller id=3, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,432] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:42:22,443] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:42:22,443] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:42:22,443] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:42:22,445] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:42:22,448] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,448] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,450] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,501] INFO [Controller id=3, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,502] INFO [Controller id=3, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,502] WARN [Controller id=3, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,502] INFO [Controller id=3, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,502] WARN [Controller id=3, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,503] WARN [Controller id=3, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,503] INFO [Controller id=3, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,503] INFO [Controller id=3, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,504] WARN [Controller id=3, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,504] INFO [Controller id=3, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,504] INFO [Controller id=3, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,504] WARN [Controller id=3, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,504] INFO [Controller id=3, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,504] INFO [Controller id=3, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,505] INFO [Controller id=3, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,508] INFO [ExpirationReaper-3-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,508] INFO [ExpirationReaper-3-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,510] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,510] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,511] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,513] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:42:22,513] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,514] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,514] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,516] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:42:22,517] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,517] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,517] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,519] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:42:22,519] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:42:22,528] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,528] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,529] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,532] INFO [ExpirationReaper-4-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,532] INFO [ExpirationReaper-4-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,533] INFO [ExpirationReaper-4-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,551] INFO EventThread shut down for session: 0x100000b00ad0095 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:42:22,551] INFO Session: 0x100000b00ad0095 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:42:22,553] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:42:22,555] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:22,557] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:42:22,567] INFO [Controller id=3, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,568] INFO [ExpirationReaper-4-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,568] INFO [ExpirationReaper-4-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,569] INFO [ExpirationReaper-4-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,605] INFO [Controller id=3, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,605] INFO [Controller id=3, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,605] WARN [Controller id=3, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,605] WARN [Controller id=3, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,606] INFO [Controller id=3, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,606] WARN [Controller id=3, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,606] INFO [Controller id=3, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,606] INFO [Controller id=3, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,606] INFO [Controller id=3, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,606] WARN [Controller id=3, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,607] INFO [Controller id=3, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,607] INFO [Controller id=3, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,616] INFO [Controller id=3, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,619] INFO [Controller id=3, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,622] INFO [Controller id=3, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,625] INFO [Controller id=3, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,629] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:42:22,629] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:42:22,629] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:42:22,631] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:42:22,692] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,692] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,693] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,712] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,712] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,716] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:42:22,717] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,718] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,718] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,720] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:42:22,720] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,720] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,720] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,722] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:42:22,723] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:42:22,728] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,729] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,734] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:42:22,735] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,735] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,735] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,737] INFO Session: 0x100000b00ad0093 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:42:22,737] INFO EventThread shut down for session: 0x100000b00ad0093 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:42:22,740] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:42:22,740] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:42:22,740] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:22,741] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,742] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,742] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,743] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:42:22,745] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:42:22,755] INFO [ExpirationReaper-4-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,755] INFO [ExpirationReaper-4-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:42:22,761] INFO [Controller id=4, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,761] INFO [Controller id=4, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,761] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:42:22,761] INFO [Controller id=4, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,763] INFO [ReplicaManager broker=4] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:42:22,764] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,765] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,765] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,766] WARN [Controller id=4, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,766] WARN [Controller id=4, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,766] WARN [Controller id=4, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,768] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:42:22,768] INFO [Controller id=4, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,768] INFO [Controller id=4, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,769] INFO [Controller id=4, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,769] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,769] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,769] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:42:22,770] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:42:22,772] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:42:22,772] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:42:22,772] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:42:22,772] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:42:22,774] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:42:22,783] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:42:22,794] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:42:22,794] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:42:22,794] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:42:22,795] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:42:22,798] WARN An exception was thrown while closing send thread for session 0x100000b00ad0092. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x100000b00ad0092, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 23:42:22,804] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:42:22,870] INFO [Controller id=4, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,870] INFO [Controller id=4, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,870] INFO [Controller id=4, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,870] WARN [Controller id=4, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,870] WARN [Controller id=4, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,871] WARN [Controller id=4, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,871] INFO [Controller id=4, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,872] INFO [Controller id=4, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,872] INFO [Controller id=4, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,879] INFO EventThread shut down for session: 0x100000b00ad0091 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:42:22,879] INFO Session: 0x100000b00ad0091 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:42:22,883] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:42:22,883] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:22,901] INFO Session: 0x100000b00ad0092 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:42:22,901] INFO EventThread shut down for session: 0x100000b00ad0092 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:42:22,903] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:42:22,904] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:22,945] INFO [Controller id=4, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,948] INFO [Controller id=4, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,951] INFO [Controller id=4, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:42:22,954] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:42:22,955] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:42:22,955] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:42:22,963] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:42:22,966] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:22,966] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:22,967] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:22,972] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:22,972] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:22,972] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,018] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,018] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,018] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,036] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,036] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,036] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,037] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,037] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,037] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,038] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,038] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,039] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,070] INFO Session: 0x100000b00ad0094 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:42:23,070] INFO EventThread shut down for session: 0x100000b00ad0094 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:42:23,074] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:42:23,075] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,075] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,075] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,075] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,085] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,085] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,085] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,086] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,085] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,086] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,100] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,100] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,101] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,129] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,130] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,130] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,134] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,134] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,135] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,972] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,972] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,972] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,975] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,975] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:23,977] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:42:23,999] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:42:24,000] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:42:24,000] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:42:24,000] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:42:24,002] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:42:24,003] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:42:24,003] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:42:24,015] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:24,015] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:24,016] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:24,038] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:24,039] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:24,041] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:42:24,069] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:42:24,070] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:42:24,070] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:42:24,070] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:42:24,071] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:24,071] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:24,071] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:24,073] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:42:24,074] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:42:24,075] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:42:24,084] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:24,084] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:24,086] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:24,086] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:24,086] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:24,087] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:42:24,100] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:24,100] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:24,102] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:42:24,108] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:42:24,110] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:42:24,110] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:42:24,110] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:42:24,113] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:42:24,114] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:42:24,115] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:42:24,129] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:24,129] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:24,129] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:24,130] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:42:24,131] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:24,131] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:42:24,132] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:42:24,131] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:24,132] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:42:24,134] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:42:24,135] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:42:24,135] INFO App info kafka.server for 3 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:42:24,136] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:42:24,156] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:42:24,157] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:42:24,157] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:42:24,158] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:42:24,159] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:42:24,160] INFO App info kafka.server for 4 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:42:24,161] INFO [KafkaServer id=4] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:42:25,008] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:25,009] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:25,009] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:25,018] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:25,018] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:42:25,020] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:42:25,048] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:42:25,050] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:42:25,050] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:42:25,050] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:42:25,051] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:42:25,052] INFO App info kafka.server for 5 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:42:25,052] INFO [KafkaServer id=5] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:43:11,064] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:43:11,074] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:43:11,074] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:43:11,074] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:43:11,074] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:43:11,076] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 23:43:11,077] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 23:43:11,077] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 23:43:11,077] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-15 23:43:11,081] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-15 23:43:11,097] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:43:11,098] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:43:11,098] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:43:11,098] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:43:11,098] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:43:11,098] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-15 23:43:11,113] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@6156496 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-15 23:43:11,118] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 23:43:11,128] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,128] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,129] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,129] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,129] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,129] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,129] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,129] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,129] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,129] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,130] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,131] INFO Server environment:host.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,131] INFO Server environment:java.version=11.0.15 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,131] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,131] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,131] INFO Server environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,131] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,131] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,131] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,131] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,131] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,131] INFO Server environment:os.version=5.13.0-40-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,131] INFO Server environment:user.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,132] INFO Server environment:user.home=/home/joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,132] INFO Server environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,132] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,132] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,132] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,132] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,132] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,132] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,132] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,132] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,132] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,132] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,133] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-15 23:43:11,136] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,137] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,138] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 23:43:11,138] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 23:43:11,140] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:43:11,140] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:43:11,140] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:43:11,140] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:43:11,140] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:43:11,140] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:43:11,144] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,144] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,144] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:43:11,153] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 23:43:11,154] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 23:43:11,155] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 23:43:11,161] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 23:43:11,162] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:459)
	at java.base/sun.nio.ch.Net.bind(Net.java:448)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:676)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:158)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:112)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:67)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:140)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:90)
[2022-05-15 23:43:11,165] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-15 23:43:11,167] ERROR Exiting JVM with code 1 (org.apache.zookeeper.util.ServiceUtils)
[2022-05-15 23:43:16,062] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:43:16,371] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:43:16,465] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:43:16,469] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:43:16,471] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:43:16,491] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:43:16,497] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:16,498] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:16,498] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:16,498] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:16,499] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:16,499] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:16,499] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:16,499] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:16,499] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:16,500] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:16,500] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:16,500] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:16,500] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:16,500] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:16,500] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:16,500] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:16,500] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:16,500] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:16,503] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:16,509] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:43:16,515] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:16,533] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:43:16,544] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:16,547] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:16,554] INFO Socket connection established, initiating session, client: /127.0.0.1:58132, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:16,565] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0096, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:16,571] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:43:16,668] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:43:16,807] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:43:16,814] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:43:16,890] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:43:16,905] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:43:16,970] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:16,973] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:16,976] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:16,979] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:17,020] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:43:17,025] INFO Skipping recovery for all logs in /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:43:17,114] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:17,139] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-21, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 97ms (1/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:43:17,163] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 35579 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:17,163] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 35579 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:17,165] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs/__consumer_offsets-39/00000000000000035579.snapshot,35579)' (kafka.log.ProducerStateManager)
[2022-05-15 23:43:17,171] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Producer state recovery took 8ms for snapshot load and 0ms for segment recovery from offset 35579 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:17,175] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-39, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=35579) with 1 segments in 35ms (2/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:43:17,183] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:17,188] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-15, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (3/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:43:17,195] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:17,200] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-45, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (4/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:43:17,207] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:17,212] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-4.36a77b814aaf478081b17096aed0ef2a-delete, topicId=Advz1TV9QZCg-Xt7DY4JqA, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (5/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:43:17,220] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:17,223] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-33, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (6/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:43:17,229] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:17,234] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-1.102513e6b6104d01b5a47aacdffb51e0-delete, topicId=Advz1TV9QZCg-Xt7DY4JqA, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (7/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:43:17,240] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:17,245] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-27, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (8/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:43:17,252] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:17,255] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-3, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (9/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:43:17,262] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:17,265] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-9, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (10/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:43:17,271] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:17,273] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-5.11db6a62560c4521a5c820605546fca7-delete, topicId=Advz1TV9QZCg-Xt7DY4JqA, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (11/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:43:17,277] INFO Loaded 11 logs in 256ms. (kafka.log.LogManager)
[2022-05-15 23:43:17,279] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:43:17,280] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:43:17,541] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:17,669] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:43:17,673] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-15 23:43:17,701] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:43:17,706] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:17,720] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:17,722] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:17,723] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:17,724] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:17,735] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:43:17,775] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:43:17,792] INFO Stat of the created znode at /brokers/ids/0 is: 7288,7288,1652654597784,1652654597784,1,0,0,72057641293906070,192,0,7288
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:43:17,793] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://joao:9092, czxid (broker epoch): 7288 (kafka.zk.KafkaZkClient)
[2022-05-15 23:43:17,843] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:17,848] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:17,849] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:17,865] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:17,887] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:17,903] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:43:17,908] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:43:17,908] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:43:17,937] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:17,956] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:43:17,977] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:43:17,983] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:43:17,983] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:43:17,988] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:43:17,988] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:43:17,988] INFO Kafka startTimeMs: 1652654597983 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:43:17,991] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-15 23:43:18,055] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:18,104] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:18,105] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:18,105] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 35579 (kafka.cluster.Partition)
[2022-05-15 23:43:18,105] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:18,105] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:18,105] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:18,106] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:18,106] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:18,111] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:18,178] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-3, __consumer_offsets-15, __consumer_offsets-39, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:18,209] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 47 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:18,210] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 47 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:18,212] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 47 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:18,212] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 47 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:18,213] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 47 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:18,213] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 47 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:18,213] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 47 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:18,213] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 47 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:18,213] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 47 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:18,213] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 47 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:18,213] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 47 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:18,213] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 47 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:18,213] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 47 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:18,213] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 47 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:18,214] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 47 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:18,214] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 47 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:18,222] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 10 milliseconds for epoch 47, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:18,223] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 11 milliseconds for epoch 47, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:18,305] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 92 milliseconds for epoch 47, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:18,305] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 92 milliseconds for epoch 47, of which 92 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:18,306] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 93 milliseconds for epoch 47, of which 92 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:18,306] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 93 milliseconds for epoch 47, of which 93 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:18,306] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 92 milliseconds for epoch 47, of which 92 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:18,307] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 93 milliseconds for epoch 47, of which 93 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:21,067] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:43:21,359] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:43:21,443] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:43:21,447] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:43:21,448] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:43:21,467] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:43:21,472] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:21,472] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:21,472] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:21,472] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:21,472] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:21,472] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:21,473] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:21,473] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:21,473] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:21,473] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:21,473] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:21,473] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:21,473] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:21,473] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:21,473] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:21,473] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:21,473] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:21,473] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:21,489] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:21,496] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:43:21,500] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:21,507] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:43:21,516] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:21,519] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:21,526] INFO Socket connection established, initiating session, client: /127.0.0.1:58134, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:21,538] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0097, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:21,546] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:43:21,644] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:43:21,805] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:43:21,815] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:43:21,872] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:43:21,885] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:43:21,948] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:21,951] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:21,954] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:21,956] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:22,001] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:43:22,006] INFO Skipping recovery for all logs in /tmp/kafka-logs-1 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:43:22,089] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:22,112] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-17, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 90ms (1/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:43:22,120] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:22,125] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-35, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (2/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:43:22,132] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:22,137] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-41, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (3/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:43:22,142] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:22,147] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-1.ed79014edb8744e9aa3adbd6c3e8d9b8-delete, topicId=Advz1TV9QZCg-Xt7DY4JqA, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (4/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:43:22,153] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:22,156] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-29, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (5/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:43:22,163] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:22,167] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-11, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (6/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:43:22,173] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:22,177] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-23, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (7/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:43:22,183] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:22,187] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-3.a60af897f3e74f1e819f352802df5065-delete, topicId=Advz1TV9QZCg-Xt7DY4JqA, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (8/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:43:22,194] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:22,197] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-47, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (9/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:43:22,202] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:22,207] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-5, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (10/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:43:22,212] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:22,215] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-0.09b14f8dd3f548d3a11653b542487c21-delete, topicId=Advz1TV9QZCg-Xt7DY4JqA, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:43:22,219] INFO Loaded 11 logs in 217ms. (kafka.log.LogManager)
[2022-05-15 23:43:22,220] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:43:22,221] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:43:22,440] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:22,544] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:43:22,548] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-15 23:43:22,570] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:43:22,576] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:22,591] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:22,592] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:22,594] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:22,595] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:22,606] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:43:22,655] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:43:22,672] INFO Stat of the created znode at /brokers/ids/1 is: 7356,7356,1652654602664,1652654602664,1,0,0,72057641293906071,192,0,7356
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:43:22,673] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://joao:9093, czxid (broker epoch): 7356 (kafka.zk.KafkaZkClient)
[2022-05-15 23:43:22,738] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:22,743] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:22,744] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:22,757] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:22,767] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:22,786] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:43:22,795] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:43:22,796] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:43:22,816] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:22,832] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:43:22,852] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:43:22,857] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:43:22,858] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:43:22,863] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:43:22,863] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:43:22,863] INFO Kafka startTimeMs: 1652654602858 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:43:22,866] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-15 23:43:22,951] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:22,958] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:22,959] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:22,959] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:22,959] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:22,960] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:22,960] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:22,960] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:22,961] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:22,983] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:22,985] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-5, __consumer_offsets-29, __consumer_offsets-41, __consumer_offsets-23) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:23,020] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:23,022] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:23,024] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:23,024] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:23,024] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:23,024] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:23,024] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:23,024] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:23,024] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:23,024] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:23,024] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:23,025] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:23,025] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:23,025] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:23,025] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:23,025] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:23,031] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 9 milliseconds for epoch 74, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:23,032] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 8 milliseconds for epoch 74, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:23,032] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 8 milliseconds for epoch 74, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:23,032] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 8 milliseconds for epoch 74, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:23,032] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 8 milliseconds for epoch 74, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:23,032] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 7 milliseconds for epoch 74, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:23,032] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 7 milliseconds for epoch 74, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:23,033] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 8 milliseconds for epoch 74, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:26,089] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:43:26,405] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:43:26,510] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:43:26,514] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:43:26,515] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:43:26,535] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:43:26,540] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:26,540] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:26,540] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:26,540] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:26,540] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:26,541] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:26,541] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:26,541] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:26,541] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:26,541] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:26,541] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:26,541] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:26,542] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:26,542] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:26,542] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:26,542] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:26,542] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:26,542] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:26,544] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:26,550] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:43:26,556] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:26,575] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:43:26,583] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:26,586] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:26,592] INFO Socket connection established, initiating session, client: /127.0.0.1:58138, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:26,604] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0098, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:26,611] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:43:26,713] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:43:26,876] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:43:26,883] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:43:26,942] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:43:26,954] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:43:27,019] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:27,021] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:27,025] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:27,027] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:27,081] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:43:27,087] INFO Skipping recovery for all logs in /tmp/kafka-logs-2 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:43:27,151] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:27,173] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-3.cbcdb783caf749a5902cab2b0e655441-delete, topicId=Advz1TV9QZCg-Xt7DY4JqA, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 67ms (1/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:43:27,186] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:27,191] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-49, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (2/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:43:27,195] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:27,199] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-19, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (3/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:43:27,203] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:27,207] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-7, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:43:27,211] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:27,214] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-2.cfc13167e38e4377ba9d44899dea9414-delete, topicId=Advz1TV9QZCg-Xt7DY4JqA, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:43:27,220] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:27,224] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-13, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (6/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:43:27,229] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:27,233] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-37, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:43:27,238] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:27,242] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-43, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (8/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:43:27,246] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:27,248] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-1, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (9/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:43:27,253] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:27,256] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-31, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:43:27,260] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:27,263] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-25, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:43:27,267] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:27,270] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-5.f8f5998aaec14e5293193b307a310791-delete, topicId=Advz1TV9QZCg-Xt7DY4JqA, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (12/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:43:27,273] INFO Loaded 12 logs in 192ms. (kafka.log.LogManager)
[2022-05-15 23:43:27,273] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:43:27,274] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:43:27,494] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:27,599] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:43:27,603] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-15 23:43:27,627] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:43:27,632] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:27,648] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:27,650] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:27,651] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:27,652] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:27,664] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:43:27,715] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:43:27,732] INFO Stat of the created znode at /brokers/ids/2 is: 7380,7380,1652654607725,1652654607725,1,0,0,72057641293906072,192,0,7380
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:43:27,734] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://joao:9094, czxid (broker epoch): 7380 (kafka.zk.KafkaZkClient)
[2022-05-15 23:43:27,792] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:27,796] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:27,798] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:27,811] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:27,824] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:27,844] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:43:27,853] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:43:27,853] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:43:27,874] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:27,887] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:43:27,907] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:43:27,912] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:43:27,913] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:43:27,918] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:43:27,918] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:43:27,918] INFO Kafka startTimeMs: 1652654607913 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:43:27,921] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-15 23:43:28,004] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:28,006] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:28,006] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:28,007] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:28,007] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:28,008] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:28,008] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:28,008] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:28,008] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:28,008] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:28,030] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-7, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:28,036] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:28,064] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 72 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:28,066] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 72 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:28,068] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 72 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:28,068] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 72 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:28,068] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 72 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:28,068] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 72 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:28,068] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 72 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:28,068] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 72 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:28,068] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 72 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:28,068] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 72 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:28,068] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 72 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:28,069] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 72 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:28,069] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 72 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:28,069] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 72 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:28,069] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 72 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:28,069] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 72 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:28,069] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 72 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:28,069] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 72 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:28,075] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 8 milliseconds for epoch 72, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:28,076] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 8 milliseconds for epoch 72, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:28,076] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 8 milliseconds for epoch 72, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:28,077] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 8 milliseconds for epoch 72, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:28,077] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 9 milliseconds for epoch 72, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:28,077] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 8 milliseconds for epoch 72, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:28,078] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 9 milliseconds for epoch 72, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:28,078] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 9 milliseconds for epoch 72, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:28,078] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 9 milliseconds for epoch 72, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:31,025] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:43:31,343] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:43:31,447] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:43:31,453] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:43:31,454] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:43:31,473] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:43:31,478] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:31,479] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:31,479] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:31,479] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:31,479] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:31,479] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:31,479] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:31,479] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:31,479] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:31,479] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:31,479] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:31,479] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:31,479] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:31,479] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:31,480] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:31,480] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:31,480] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:31,480] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:31,482] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:31,489] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:43:31,496] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:31,517] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:43:31,526] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:31,529] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:31,535] INFO Socket connection established, initiating session, client: /127.0.0.1:58140, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:31,545] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0099, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:31,551] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:43:31,653] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:43:31,820] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:43:31,827] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:43:31,890] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:43:31,904] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:43:31,972] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:31,973] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:31,976] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:31,978] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:32,031] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:43:32,036] INFO Skipping recovery for all logs in /tmp/kafka-logs-3 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:43:32,130] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:32,160] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-14, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 105ms (1/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:43:32,167] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:32,174] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-4.8e7bfc57029741acb59a459b86da237f-delete, topicId=Advz1TV9QZCg-Xt7DY4JqA, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (2/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:43:32,198] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Loading producer state till offset 98382 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:32,198] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Reloading from producer snapshot and rebuilding producer state from offset 98382 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:32,200] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-3/__consumer_offsets-38/00000000000000098382.snapshot,98382)' (kafka.log.ProducerStateManager)
[2022-05-15 23:43:32,205] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 98382 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:32,209] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-38, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=98382) with 1 segments in 35ms (3/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:43:32,214] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:32,220] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-8, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (4/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:43:32,225] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:32,228] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-2, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (5/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:43:32,233] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:32,236] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-26, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:43:32,242] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:32,245] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-0.b92204fcbce84f319484e8da2c09d1be-delete, topicId=Advz1TV9QZCg-Xt7DY4JqA, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (7/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:43:32,250] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:32,253] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-20, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (8/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:43:32,259] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:32,262] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-32, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:43:32,266] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:32,269] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-3.7d1b310d9cef417aad00b820f3cfa0b9-delete, topicId=Advz1TV9QZCg-Xt7DY4JqA, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (10/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:43:32,274] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:32,277] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-44, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:43:32,280] INFO Loaded 11 logs in 249ms. (kafka.log.LogManager)
[2022-05-15 23:43:32,280] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:43:32,282] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:43:32,500] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:32,620] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:43:32,624] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-05-15 23:43:32,648] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:43:32,654] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:32,669] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:32,671] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:32,673] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:32,674] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:32,687] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:43:32,758] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:43:32,779] INFO Stat of the created znode at /brokers/ids/3 is: 7405,7405,1652654612771,1652654612771,1,0,0,72057641293906073,192,0,7405
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:43:32,780] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://joao:9095, czxid (broker epoch): 7405 (kafka.zk.KafkaZkClient)
[2022-05-15 23:43:32,844] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:32,849] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:32,850] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:32,864] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:32,876] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:32,900] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:43:32,905] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:43:32,905] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:43:32,928] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:32,945] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:43:32,963] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:43:32,968] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:43:32,968] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:43:32,974] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:43:32,974] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:43:32,974] INFO Kafka startTimeMs: 1652654612968 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:43:32,976] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-05-15 23:43:33,059] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:33,069] INFO [Partition __consumer_offsets-2 broker=3] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:33,069] INFO [Partition __consumer_offsets-20 broker=3] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:33,070] INFO [Partition __consumer_offsets-38 broker=3] Log loaded for partition __consumer_offsets-38 with initial high watermark 98382 (kafka.cluster.Partition)
[2022-05-15 23:43:33,070] INFO [Partition __consumer_offsets-8 broker=3] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:33,070] INFO [Partition __consumer_offsets-26 broker=3] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:33,070] INFO [Partition __consumer_offsets-44 broker=3] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:33,070] INFO [Partition __consumer_offsets-14 broker=3] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:33,070] INFO [Partition __consumer_offsets-32 broker=3] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:33,094] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-26, __consumer_offsets-32, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:33,109] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:33,129] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 2 in epoch 73 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:33,130] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 73 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:33,133] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 20 in epoch 73 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:33,133] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 73 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:33,133] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 38 in epoch 73 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:33,133] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 73 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:33,134] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 8 in epoch 73 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:33,134] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 73 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:33,134] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 26 in epoch 73 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:33,134] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 73 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:33,134] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 44 in epoch 73 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:33,134] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 73 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:33,134] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 14 in epoch 73 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:33,134] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 73 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:33,134] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 32 in epoch 73 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:33,134] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 73 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:33,142] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-2 in 11 milliseconds for epoch 73, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:33,143] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-20 in 10 milliseconds for epoch 73, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:33,281] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-38 in 147 milliseconds for epoch 73, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:33,282] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-8 in 148 milliseconds for epoch 73, of which 148 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:33,282] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-26 in 148 milliseconds for epoch 73, of which 148 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:33,282] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-44 in 148 milliseconds for epoch 73, of which 148 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:33,282] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-14 in 148 milliseconds for epoch 73, of which 148 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:33,282] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-32 in 148 milliseconds for epoch 73, of which 148 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:36,073] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:43:36,383] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:43:36,483] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:43:36,487] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:43:36,489] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:43:36,506] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:43:36,512] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:36,512] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:36,512] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:36,512] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:36,513] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:36,513] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:36,513] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:36,513] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:36,513] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:36,513] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:36,513] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:36,513] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:36,514] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:36,514] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:36,514] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:36,514] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:36,514] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:36,514] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:36,516] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:36,522] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:43:36,528] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:36,554] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:43:36,563] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:36,565] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:36,570] INFO Socket connection established, initiating session, client: /127.0.0.1:58142, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:36,581] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad009a, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:36,588] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:43:36,681] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:43:36,827] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:43:36,833] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:43:36,886] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:43:36,897] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:43:36,958] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:36,960] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:36,963] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:36,965] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:37,005] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:43:37,009] INFO Skipping recovery for all logs in /tmp/kafka-logs-4 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:43:37,072] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:37,099] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-2.d3a73eb541724d319af6784517e1970a-delete, topicId=Advz1TV9QZCg-Xt7DY4JqA, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 78ms (1/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:43:37,112] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:37,116] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-24, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (2/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:43:37,120] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:37,124] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-1.1f4314a217ed4f2ca2cb0fd7d1377f63-delete, topicId=Advz1TV9QZCg-Xt7DY4JqA, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (3/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:43:37,129] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:37,133] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-12, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:43:37,139] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:37,142] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-30, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (5/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:43:37,147] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:37,149] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-36, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (6/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:43:37,153] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:37,156] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-42, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:43:37,161] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:37,165] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-0, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (8/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:43:37,170] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:37,173] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-4.62478e08c7984956882c57b4933d02d2-delete, topicId=Advz1TV9QZCg-Xt7DY4JqA, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (9/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:43:37,177] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:37,181] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-18, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (10/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:43:37,185] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:37,188] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-6, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (11/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:43:37,193] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:37,196] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-48, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (12/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:43:37,199] INFO Loaded 12 logs in 193ms. (kafka.log.LogManager)
[2022-05-15 23:43:37,199] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:43:37,200] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:43:37,408] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:37,512] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:43:37,516] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.Acceptor)
[2022-05-15 23:43:37,542] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:43:37,547] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:37,562] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:37,564] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:37,565] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:37,567] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:37,577] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:43:37,631] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:43:37,646] INFO Stat of the created znode at /brokers/ids/4 is: 7429,7429,1652654617639,1652654617639,1,0,0,72057641293906074,192,0,7429
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:43:37,647] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://joao:9096, czxid (broker epoch): 7429 (kafka.zk.KafkaZkClient)
[2022-05-15 23:43:37,704] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:37,708] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:37,709] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:37,723] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:37,733] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:37,753] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:43:37,764] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:43:37,764] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:43:37,785] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:37,799] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:43:37,817] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:43:37,822] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:43:37,823] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:43:37,827] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:43:37,827] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:43:37,827] INFO Kafka startTimeMs: 1652654617823 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:43:37,829] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2022-05-15 23:43:37,920] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:37,928] INFO [Partition __consumer_offsets-18 broker=4] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:37,929] INFO [Partition __consumer_offsets-36 broker=4] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:37,929] INFO [Partition __consumer_offsets-6 broker=4] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:37,929] INFO [Partition __consumer_offsets-24 broker=4] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:37,930] INFO [Partition __consumer_offsets-42 broker=4] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:37,930] INFO [Partition __consumer_offsets-12 broker=4] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:37,930] INFO [Partition __consumer_offsets-30 broker=4] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:37,930] INFO [Partition __consumer_offsets-0 broker=4] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:37,931] INFO [Partition __consumer_offsets-48 broker=4] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:37,951] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:37,952] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-12, __consumer_offsets-42, __consumer_offsets-18) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:37,986] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 18 in epoch 79 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:37,988] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 79 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:37,990] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 36 in epoch 79 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:37,990] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 79 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:37,990] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 6 in epoch 79 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:37,990] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 79 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:37,990] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 24 in epoch 79 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:37,990] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 79 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:37,990] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 42 in epoch 79 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:37,991] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 79 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:37,991] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 12 in epoch 79 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:37,991] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 79 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:37,991] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 30 in epoch 79 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:37,991] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 79 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:37,991] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 0 in epoch 79 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:37,991] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 79 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:37,991] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 48 in epoch 79 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:37,991] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 79 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:37,998] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-18 in 9 milliseconds for epoch 79, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:37,999] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-36 in 9 milliseconds for epoch 79, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:37,999] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-6 in 9 milliseconds for epoch 79, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:38,000] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-24 in 10 milliseconds for epoch 79, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:38,000] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-42 in 9 milliseconds for epoch 79, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:38,000] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-12 in 9 milliseconds for epoch 79, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:38,000] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-30 in 9 milliseconds for epoch 79, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:38,001] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-0 in 10 milliseconds for epoch 79, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:38,001] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-48 in 10 milliseconds for epoch 79, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:41,122] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:43:41,450] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:43:41,567] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:43:41,572] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:43:41,574] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:43:41,597] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:43:41,603] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:41,603] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:41,603] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:41,603] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:41,603] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:41,603] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:41,604] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:41,604] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:41,604] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:41,604] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:41,604] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:41,604] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:41,604] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:41,604] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:41,604] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:41,605] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:41,605] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:41,605] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:41,607] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:43:41,613] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:43:41,620] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:41,646] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:43:41,654] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:41,656] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:41,662] INFO Socket connection established, initiating session, client: /127.0.0.1:58144, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:41,670] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad009b, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:43:41,675] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:43:41,773] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:43:41,943] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:43:41,951] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:43:41,992] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:43:41,999] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:43:42,045] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:42,047] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:42,048] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:42,050] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:43:42,085] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:43:42,089] INFO Skipping recovery for all logs in /tmp/kafka-logs-5 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:43:42,156] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:42,180] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-46, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 79ms (1/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:43:42,185] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:42,189] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-10, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (2/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:43:42,194] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:42,198] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-28, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (3/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:43:42,202] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:42,206] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-0.b4ddf1233cc441698b20549ec32786b7-delete, topicId=Advz1TV9QZCg-Xt7DY4JqA, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:43:42,224] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Loading producer state till offset 56709 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:42,224] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 56709 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:42,226] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-22/00000000000000056709.snapshot,56709)' (kafka.log.ProducerStateManager)
[2022-05-15 23:43:42,231] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Producer state recovery took 6ms for snapshot load and 1ms for segment recovery from offset 56709 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:42,233] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-22, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=56709) with 1 segments in 27ms (5/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:43:42,238] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:42,241] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-16, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:43:42,245] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:42,248] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-2.b53ebe71c6ae450cb9f550606b2dcc29-delete, topicId=Advz1TV9QZCg-Xt7DY4JqA, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (7/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:43:42,252] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:42,255] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-5.f9d95fec8f24478cb87bf7eb0db333eb-delete, topicId=Advz1TV9QZCg-Xt7DY4JqA, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:43:42,264] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Loading producer state till offset 35134 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:42,264] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 35134 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:42,264] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-40/00000000000000035134.snapshot,35134)' (kafka.log.ProducerStateManager)
[2022-05-15 23:43:42,264] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 35134 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:42,267] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-40, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=35134) with 1 segments in 11ms (9/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:43:42,271] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:42,275] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-34, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (10/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:43:42,280] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:42,282] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-4, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (11/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:43:42,284] INFO Loaded 11 logs in 199ms. (kafka.log.LogManager)
[2022-05-15 23:43:42,285] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:43:42,287] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:43:42,504] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:42,608] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:43:42,612] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.Acceptor)
[2022-05-15 23:43:42,637] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:43:42,643] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:42,659] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:42,660] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:42,662] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:42,663] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:42,675] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:43:42,731] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:43:42,750] INFO Stat of the created znode at /brokers/ids/5 is: 7454,7454,1652654622740,1652654622740,1,0,0,72057641293906075,192,0,7454
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:43:42,751] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://joao:9097, czxid (broker epoch): 7454 (kafka.zk.KafkaZkClient)
[2022-05-15 23:43:42,810] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:42,815] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:42,816] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:42,831] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:42,854] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:42,869] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:43:42,873] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:43:42,874] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:43:42,896] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:43:42,912] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:43:42,930] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:43:42,936] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:43:42,936] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:43:42,940] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:43:42,941] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:43:42,941] INFO Kafka startTimeMs: 1652654622936 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:43:42,943] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2022-05-15 23:43:43,015] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:43,046] INFO [Partition __consumer_offsets-34 broker=5] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:43,046] INFO [Partition __consumer_offsets-4 broker=5] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:43,047] INFO [Partition __consumer_offsets-22 broker=5] Log loaded for partition __consumer_offsets-22 with initial high watermark 56709 (kafka.cluster.Partition)
[2022-05-15 23:43:43,047] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:43:43,047] INFO [Partition __consumer_offsets-40 broker=5] Log loaded for partition __consumer_offsets-40 with initial high watermark 35134 (kafka.cluster.Partition)
[2022-05-15 23:43:43,047] INFO [Partition __consumer_offsets-10 broker=5] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:43,048] INFO [Partition __consumer_offsets-28 broker=5] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:43,048] INFO [Partition __consumer_offsets-46 broker=5] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:43,048] INFO [Partition __consumer_offsets-16 broker=5] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:43,077] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:43,107] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 34 in epoch 83 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:43,108] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 83 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:43,110] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 4 in epoch 83 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:43,110] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 83 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:43,110] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 22 in epoch 83 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:43,110] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 83 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:43,110] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 40 in epoch 83 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:43,110] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 83 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:43,110] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 10 in epoch 83 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:43,110] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 83 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:43,110] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 28 in epoch 83 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:43,110] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 83 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:43,110] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 46 in epoch 83 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:43,110] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 83 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:43,110] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 16 in epoch 83 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:43:43,110] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 83 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:43,117] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-34 in 8 milliseconds for epoch 83, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:43,118] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-4 in 8 milliseconds for epoch 83, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:43,140] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-9fa5abef-fdc9-4c05-8f09-7f9780632837, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:43:43,149] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-ed3a6d0d-54c4-4b54-b4a4-a5d0ecba6f8e, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:43:43,149] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-1038faf2-d998-4707-9799-897de83d6136, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:43:43,149] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-b283a5ee-70be-4bf9-b41c-74e089f12e34, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:43:43,150] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-360d1581-f79b-41e6-82d3-fe3577615014, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:43:43,150] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-9e173d1e-b47a-4b16-9874-bf5d2688c730, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:43:43,150] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-81fafa38-80dc-43ea-ac6c-e398b06565dc, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:43:43,175] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-d15976bc-df63-4682-8583-fd67cbb1d9df, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:43:43,176] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-a0d7c5c7-e384-4339-b0be-414878362e3e, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:43:43,176] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-ee781f71-f1c3-46d7-bd93-d90a4fe359ff, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:43:43,176] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-78575c72-7be8-4563-b114-53b271a8ef70, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:43:43,176] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-0287b15c-1acd-4475-b9ce-b994aebeeff2, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:43:43,176] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-45d54f6e-f1d8-43f7-8ace-1db96ac0cfac, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:43:43,235] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-954ef0dc-d124-405b-9bb6-119086dd08c0, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:43:43,236] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-3f51cd43-28ab-4459-969e-211543e6cd72, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:43:43,236] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-4b8634e2-92f3-4603-97c5-35df7219bd84, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 4. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:43:43,237] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-5f6ccebb-0352-4648-b98e-7613d791d352, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:43:43,252] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-8863ee28-05fa-4d10-b813-b83668f9ecf8, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:43:43,262] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-22 in 152 milliseconds for epoch 83, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:43,292] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-40 in 182 milliseconds for epoch 83, of which 152 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:43,292] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-10 in 182 milliseconds for epoch 83, of which 182 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:43,293] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-28 in 183 milliseconds for epoch 83, of which 183 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:43,293] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-46 in 183 milliseconds for epoch 83, of which 183 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:43,294] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-16 in 184 milliseconds for epoch 83, of which 184 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:43:46,930] INFO Creating topic Sensor with configuration {min.insync.replicas=2} and initial partition assignment HashMap(0 -> ArrayBuffer(0, 3, 5), 1 -> ArrayBuffer(5, 0, 4), 2 -> ArrayBuffer(4, 5, 1), 3 -> ArrayBuffer(1, 4, 2), 4 -> ArrayBuffer(2, 1, 3), 5 -> ArrayBuffer(3, 2, 0)) (kafka.zk.AdminZkClient)
[2022-05-15 23:43:46,968] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:46,969] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:46,970] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:46,970] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-4) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:46,971] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:46,972] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:46,982] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:46,982] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:46,982] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:46,982] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:46,985] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:46,985] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:46,987] INFO Created log for partition Sensor-0 in /tmp/kafka-logs/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:43:46,987] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-4/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:43:46,987] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-5/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:43:46,987] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-2/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:43:46,988] INFO [Partition Sensor-0 broker=0] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 23:43:46,989] INFO [Partition Sensor-1 broker=5] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 23:43:46,989] INFO [Partition Sensor-0 broker=0] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:46,989] INFO [Partition Sensor-1 broker=5] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:46,989] INFO [Partition Sensor-4 broker=2] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 23:43:46,990] INFO [Partition Sensor-4 broker=2] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:46,990] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-1/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:43:46,989] INFO [Partition Sensor-2 broker=4] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 23:43:46,991] INFO [Partition Sensor-2 broker=4] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:46,991] INFO [Partition Sensor-3 broker=1] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 23:43:46,991] INFO [Partition Sensor-3 broker=1] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:46,992] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-3/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:43:46,993] INFO [Partition Sensor-5 broker=3] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 23:43:46,994] INFO [Partition Sensor-5 broker=3] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:46,999] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:46,999] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:47,001] INFO Created log for partition Sensor-5 in /tmp/kafka-logs/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:43:47,001] INFO [Partition Sensor-5 broker=0] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 23:43:47,001] INFO [Partition Sensor-5 broker=0] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:47,001] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-5/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:43:47,002] INFO [Partition Sensor-0 broker=5] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 23:43:47,002] INFO [Partition Sensor-0 broker=5] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:47,002] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:47,004] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-2/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:43:47,004] INFO [Partition Sensor-3 broker=2] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 23:43:47,004] INFO [Partition Sensor-3 broker=2] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:47,005] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:47,006] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:47,007] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-4/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:43:47,007] INFO [Partition Sensor-3 broker=4] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 23:43:47,007] INFO [Partition Sensor-3 broker=4] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:47,007] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:47,008] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-1/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:43:47,008] INFO [Partition Sensor-4 broker=1] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 23:43:47,009] INFO [Partition Sensor-4 broker=1] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:47,009] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:47,010] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-5/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:43:47,010] INFO [Partition Sensor-2 broker=5] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 23:43:47,010] INFO [Partition Sensor-2 broker=5] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:47,011] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:47,011] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-3/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:43:47,011] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(Sensor-2, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:47,011] INFO [Partition Sensor-4 broker=3] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 23:43:47,011] INFO [Partition Sensor-4 broker=3] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:47,012] INFO Created log for partition Sensor-1 in /tmp/kafka-logs/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:43:47,012] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:47,012] INFO [Partition Sensor-1 broker=0] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 23:43:47,013] INFO [Partition Sensor-1 broker=0] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:47,013] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(Sensor-5, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:47,014] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-2/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:43:47,014] INFO [Partition Sensor-5 broker=2] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 23:43:47,014] INFO [Partition Sensor-5 broker=2] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:47,015] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(Sensor-5, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:47,016] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:47,017] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:47,018] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-4/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:43:47,018] INFO [Partition Sensor-1 broker=4] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 23:43:47,018] INFO [Partition Sensor-1 broker=4] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:47,018] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-1/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:43:47,018] INFO [Partition Sensor-2 broker=1] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 23:43:47,018] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(Sensor-3, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:47,019] INFO [Partition Sensor-2 broker=1] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:47,019] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(Sensor-4, Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:47,019] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:43:47,021] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-3/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:43:47,021] INFO [Partition Sensor-0 broker=3] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 23:43:47,021] INFO [Partition Sensor-0 broker=3] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:43:47,021] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(Sensor-4, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:47,035] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,035] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,040] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 3 for partitions Map(Sensor-5 -> InitialFetchState(Some(VVvCcK4FQJu1RWOwv5vuGQ),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:47,040] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 0 for partitions Map(Sensor-0 -> InitialFetchState(Some(VVvCcK4FQJu1RWOwv5vuGQ),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:47,043] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,044] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 5 for partitions Map(Sensor-1 -> InitialFetchState(Some(VVvCcK4FQJu1RWOwv5vuGQ),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:47,045] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 4 for partitions Map(Sensor-2 -> InitialFetchState(Some(VVvCcK4FQJu1RWOwv5vuGQ),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:47,046] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,047] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,047] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:43:47,048] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:43:47,052] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,053] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(Sensor-3 -> InitialFetchState(Some(VVvCcK4FQJu1RWOwv5vuGQ),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:47,054] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,056] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,055] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,057] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:43:47,057] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,057] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,057] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:43:47,058] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,058] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 0 for partitions Map(Sensor-0 -> InitialFetchState(Some(VVvCcK4FQJu1RWOwv5vuGQ),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:47,061] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 4 for partitions Map(Sensor-2 -> InitialFetchState(Some(VVvCcK4FQJu1RWOwv5vuGQ),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:47,060] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 3 for partitions Map(Sensor-5 -> InitialFetchState(Some(VVvCcK4FQJu1RWOwv5vuGQ),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:47,060] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,064] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 1 for partitions Map(Sensor-3 -> InitialFetchState(Some(VVvCcK4FQJu1RWOwv5vuGQ),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:47,065] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,065] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,064] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,067] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,067] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 2 for partitions Map(Sensor-4 -> InitialFetchState(Some(VVvCcK4FQJu1RWOwv5vuGQ),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:47,067] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,067] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,068] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions Map(Sensor-4 -> InitialFetchState(Some(VVvCcK4FQJu1RWOwv5vuGQ),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:47,069] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:43:47,067] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,070] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:43:47,067] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,071] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,070] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:43:47,071] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:43:47,071] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:43:47,070] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:43:47,076] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 5 for partitions Map(Sensor-1 -> InitialFetchState(Some(VVvCcK4FQJu1RWOwv5vuGQ),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:43:47,076] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:43:47,081] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,081] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,082] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:43:47,171] WARN [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-5. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:43:47,194] WARN [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-2. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:44:17,217] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=56314, lastModifiedTime=1652654486863, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:44:17,219] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=56314, lastModifiedTime=1652654486863, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:44:17,222] INFO Deleted log /tmp/kafka-logs/Sensor-4.36a77b814aaf478081b17096aed0ef2a-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:17,222] INFO Deleted offset index /tmp/kafka-logs/Sensor-4.36a77b814aaf478081b17096aed0ef2a-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:17,226] INFO Deleted time index /tmp/kafka-logs/Sensor-4.36a77b814aaf478081b17096aed0ef2a-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:17,232] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs/Sensor-4.36a77b814aaf478081b17096aed0ef2a-delete. (kafka.log.LogManager)
[2022-05-15 23:44:17,234] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=133941, lastModifiedTime=1652654505985, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:44:17,234] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=133941, lastModifiedTime=1652654505985, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:44:17,235] INFO Deleted log /tmp/kafka-logs/Sensor-1.102513e6b6104d01b5a47aacdffb51e0-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:17,235] INFO Deleted offset index /tmp/kafka-logs/Sensor-1.102513e6b6104d01b5a47aacdffb51e0-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:17,235] INFO Deleted time index /tmp/kafka-logs/Sensor-1.102513e6b6104d01b5a47aacdffb51e0-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:17,236] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs/Sensor-1.102513e6b6104d01b5a47aacdffb51e0-delete. (kafka.log.LogManager)
[2022-05-15 23:44:17,274] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=63009, lastModifiedTime=1652654488111, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:44:17,275] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=63009, lastModifiedTime=1652654488111, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:44:17,278] INFO Deleted log /tmp/kafka-logs/Sensor-5.11db6a62560c4521a5c820605546fca7-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:17,278] INFO Deleted offset index /tmp/kafka-logs/Sensor-5.11db6a62560c4521a5c820605546fca7-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:17,278] INFO Deleted time index /tmp/kafka-logs/Sensor-5.11db6a62560c4521a5c820605546fca7-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:17,279] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs/Sensor-5.11db6a62560c4521a5c820605546fca7-delete. (kafka.log.LogManager)
[2022-05-15 23:44:22,152] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=133941, lastModifiedTime=1652654505985, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:44:22,153] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=133941, lastModifiedTime=1652654505985, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:44:22,156] INFO Deleted log /tmp/kafka-logs-1/Sensor-1.ed79014edb8744e9aa3adbd6c3e8d9b8-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:22,157] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-1.ed79014edb8744e9aa3adbd6c3e8d9b8-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:22,160] INFO Deleted time index /tmp/kafka-logs-1/Sensor-1.ed79014edb8744e9aa3adbd6c3e8d9b8-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:22,165] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-1/Sensor-1.ed79014edb8744e9aa3adbd6c3e8d9b8-delete. (kafka.log.LogManager)
[2022-05-15 23:44:22,188] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=138586, lastModifiedTime=1652654506533, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:44:22,189] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=138586, lastModifiedTime=1652654506533, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:44:22,190] INFO Deleted log /tmp/kafka-logs-1/Sensor-3.a60af897f3e74f1e819f352802df5065-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:22,191] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-3.a60af897f3e74f1e819f352802df5065-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:22,191] INFO Deleted time index /tmp/kafka-logs-1/Sensor-3.a60af897f3e74f1e819f352802df5065-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:22,191] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-1/Sensor-3.a60af897f3e74f1e819f352802df5065-delete. (kafka.log.LogManager)
[2022-05-15 23:44:22,216] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=129298, lastModifiedTime=1652654504825, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:44:22,217] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=129298, lastModifiedTime=1652654504825, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:44:22,219] INFO Deleted log /tmp/kafka-logs-1/Sensor-0.09b14f8dd3f548d3a11653b542487c21-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:22,219] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-0.09b14f8dd3f548d3a11653b542487c21-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:22,219] INFO Deleted time index /tmp/kafka-logs-1/Sensor-0.09b14f8dd3f548d3a11653b542487c21-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:22,220] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-1/Sensor-0.09b14f8dd3f548d3a11653b542487c21-delete. (kafka.log.LogManager)
[2022-05-15 23:44:27,177] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=138586, lastModifiedTime=1652654506533, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:44:27,180] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=138586, lastModifiedTime=1652654506533, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:44:27,185] INFO Deleted log /tmp/kafka-logs-2/Sensor-3.cbcdb783caf749a5902cab2b0e655441-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:27,187] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-3.cbcdb783caf749a5902cab2b0e655441-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:27,193] INFO Deleted time index /tmp/kafka-logs-2/Sensor-3.cbcdb783caf749a5902cab2b0e655441-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:27,199] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-2/Sensor-3.cbcdb783caf749a5902cab2b0e655441-delete. (kafka.log.LogManager)
[2022-05-15 23:44:27,215] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=130375, lastModifiedTime=1652654505313, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:44:27,216] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=130375, lastModifiedTime=1652654505313, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:44:27,217] INFO Deleted log /tmp/kafka-logs-2/Sensor-2.cfc13167e38e4377ba9d44899dea9414-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:27,217] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-2.cfc13167e38e4377ba9d44899dea9414-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:27,218] INFO Deleted time index /tmp/kafka-logs-2/Sensor-2.cfc13167e38e4377ba9d44899dea9414-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:27,219] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-2/Sensor-2.cfc13167e38e4377ba9d44899dea9414-delete. (kafka.log.LogManager)
[2022-05-15 23:44:27,271] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=63009, lastModifiedTime=1652654488111, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:44:27,272] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=63009, lastModifiedTime=1652654488111, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:44:27,273] INFO Deleted log /tmp/kafka-logs-2/Sensor-5.f8f5998aaec14e5293193b307a310791-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:27,273] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-5.f8f5998aaec14e5293193b307a310791-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:27,274] INFO Deleted time index /tmp/kafka-logs-2/Sensor-5.f8f5998aaec14e5293193b307a310791-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:27,274] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-2/Sensor-5.f8f5998aaec14e5293193b307a310791-delete. (kafka.log.LogManager)
[2022-05-15 23:44:32,179] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=56314, lastModifiedTime=1652654486863, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:44:32,181] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=56314, lastModifiedTime=1652654486863, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:44:32,186] INFO Deleted log /tmp/kafka-logs-3/Sensor-4.8e7bfc57029741acb59a459b86da237f-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:32,187] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-4.8e7bfc57029741acb59a459b86da237f-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:32,190] INFO Deleted time index /tmp/kafka-logs-3/Sensor-4.8e7bfc57029741acb59a459b86da237f-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:32,195] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-3/Sensor-4.8e7bfc57029741acb59a459b86da237f-delete. (kafka.log.LogManager)
[2022-05-15 23:44:32,246] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=129298, lastModifiedTime=1652654504825, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:44:32,246] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=129298, lastModifiedTime=1652654504825, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:44:32,248] INFO Deleted log /tmp/kafka-logs-3/Sensor-0.b92204fcbce84f319484e8da2c09d1be-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:32,248] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-0.b92204fcbce84f319484e8da2c09d1be-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:32,248] INFO Deleted time index /tmp/kafka-logs-3/Sensor-0.b92204fcbce84f319484e8da2c09d1be-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:32,250] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-3/Sensor-0.b92204fcbce84f319484e8da2c09d1be-delete. (kafka.log.LogManager)
[2022-05-15 23:44:32,270] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=138586, lastModifiedTime=1652654506533, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:44:32,271] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=138586, lastModifiedTime=1652654506533, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:44:32,273] INFO Deleted log /tmp/kafka-logs-3/Sensor-3.7d1b310d9cef417aad00b820f3cfa0b9-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:32,274] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-3.7d1b310d9cef417aad00b820f3cfa0b9-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:32,275] INFO Deleted time index /tmp/kafka-logs-3/Sensor-3.7d1b310d9cef417aad00b820f3cfa0b9-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:32,275] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-3/Sensor-3.7d1b310d9cef417aad00b820f3cfa0b9-delete. (kafka.log.LogManager)
[2022-05-15 23:44:37,103] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=130375, lastModifiedTime=1652654505313, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:44:37,106] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=130375, lastModifiedTime=1652654505313, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:44:37,111] INFO Deleted log /tmp/kafka-logs-4/Sensor-2.d3a73eb541724d319af6784517e1970a-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:37,112] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-2.d3a73eb541724d319af6784517e1970a-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:37,114] INFO Deleted time index /tmp/kafka-logs-4/Sensor-2.d3a73eb541724d319af6784517e1970a-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:37,119] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-4/Sensor-2.d3a73eb541724d319af6784517e1970a-delete. (kafka.log.LogManager)
[2022-05-15 23:44:37,126] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=133941, lastModifiedTime=1652654505985, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:44:37,126] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=133941, lastModifiedTime=1652654505985, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:44:37,128] INFO Deleted log /tmp/kafka-logs-4/Sensor-1.1f4314a217ed4f2ca2cb0fd7d1377f63-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:37,128] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-1.1f4314a217ed4f2ca2cb0fd7d1377f63-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:37,128] INFO Deleted time index /tmp/kafka-logs-4/Sensor-1.1f4314a217ed4f2ca2cb0fd7d1377f63-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:37,130] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-4/Sensor-1.1f4314a217ed4f2ca2cb0fd7d1377f63-delete. (kafka.log.LogManager)
[2022-05-15 23:44:37,173] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=56314, lastModifiedTime=1652654486863, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:44:37,174] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=56314, lastModifiedTime=1652654486863, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:44:37,175] INFO Deleted log /tmp/kafka-logs-4/Sensor-4.62478e08c7984956882c57b4933d02d2-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:37,176] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-4.62478e08c7984956882c57b4933d02d2-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:37,176] INFO Deleted time index /tmp/kafka-logs-4/Sensor-4.62478e08c7984956882c57b4933d02d2-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:37,177] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-4/Sensor-4.62478e08c7984956882c57b4933d02d2-delete. (kafka.log.LogManager)
[2022-05-15 23:44:42,212] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=129298, lastModifiedTime=1652654504825, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:44:42,215] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=129298, lastModifiedTime=1652654504825, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:44:42,220] INFO Deleted log /tmp/kafka-logs-5/Sensor-0.b4ddf1233cc441698b20549ec32786b7-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:42,221] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-0.b4ddf1233cc441698b20549ec32786b7-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:42,225] INFO Deleted time index /tmp/kafka-logs-5/Sensor-0.b4ddf1233cc441698b20549ec32786b7-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:42,230] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-5/Sensor-0.b4ddf1233cc441698b20549ec32786b7-delete. (kafka.log.LogManager)
[2022-05-15 23:44:42,250] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=130375, lastModifiedTime=1652654505313, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:44:42,250] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=130375, lastModifiedTime=1652654505313, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:44:42,252] INFO Deleted log /tmp/kafka-logs-5/Sensor-2.b53ebe71c6ae450cb9f550606b2dcc29-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:42,252] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-2.b53ebe71c6ae450cb9f550606b2dcc29-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:42,252] INFO Deleted time index /tmp/kafka-logs-5/Sensor-2.b53ebe71c6ae450cb9f550606b2dcc29-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:42,253] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-5/Sensor-2.b53ebe71c6ae450cb9f550606b2dcc29-delete. (kafka.log.LogManager)
[2022-05-15 23:44:42,256] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=63009, lastModifiedTime=1652654488111, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:44:42,258] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=63009, lastModifiedTime=1652654488111, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:44:42,260] INFO Deleted log /tmp/kafka-logs-5/Sensor-5.f9d95fec8f24478cb87bf7eb0db333eb-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:42,261] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-5.f9d95fec8f24478cb87bf7eb0db333eb-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:42,261] INFO Deleted time index /tmp/kafka-logs-5/Sensor-5.f9d95fec8f24478cb87bf7eb0db333eb-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:44:42,262] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-5/Sensor-5.f9d95fec8f24478cb87bf7eb0db333eb-delete. (kafka.log.LogManager)
[2022-05-15 23:47:36,836] INFO [GroupMetadataManager brokerId=0] Group group2 transitioned to Dead in generation 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:47:36,837] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:47:36,838] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:47:36,838] INFO [GroupCoordinator 4]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:47:36,839] INFO [GroupMetadataManager brokerId=5] Group group1 transitioned to Dead in generation 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:47:36,840] INFO [GroupMetadataManager brokerId=3] Group group3 transitioned to Dead in generation 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:47:36,843] INFO [GroupCoordinator 0]: Removed 6 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:47:36,844] INFO [GroupCoordinator 3]: Removed 6 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:47:36,846] INFO [GroupCoordinator 5]: Removed 6 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:47:36,873] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:36,873] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:36,874] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:36,874] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:36,874] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:36,875] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:36,875] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:36,875] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:36,875] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:36,875] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:36,876] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:36,876] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:36,881] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,881] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,883] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,883] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,883] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,883] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,884] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 700 due to node 3 being disconnected (elapsed time since creation: 183ms, elapsed time since send: 183ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,884] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,885] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1478306869, epoch=698) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:47:36,886] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,886] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,886] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,886] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 686 due to node 2 being disconnected (elapsed time since creation: 256ms, elapsed time since send: 256ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,885] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,887] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,887] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,888] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 898 due to node 1 being disconnected (elapsed time since creation: 212ms, elapsed time since send: 212ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,888] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,889] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 804 due to node 4 being disconnected (elapsed time since creation: 321ms, elapsed time since send: 321ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,890] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 686 due to node 2 being disconnected (elapsed time since creation: 263ms, elapsed time since send: 263ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,891] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 898 due to node 1 being disconnected (elapsed time since creation: 216ms, elapsed time since send: 216ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,887] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1281789899, epoch=686) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:47:36,888] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=724165847, epoch=898) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:47:36,892] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,892] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,892] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,892] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,893] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,893] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 808 due to node 5 being disconnected (elapsed time since creation: 486ms, elapsed time since send: 486ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,893] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=1008246925, epoch=808) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:47:36,893] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,893] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,894] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,891] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=589162241, epoch=686) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:47:36,895] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:36,895] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,895] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,890] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=205892897, epoch=802) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:47:36,896] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:36,892] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=79952360, epoch=898) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:47:36,897] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,897] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,897] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,898] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,899] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,899] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,900] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 858 due to node 0 being disconnected (elapsed time since creation: 447ms, elapsed time since send: 447ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,900] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=124821691, epoch=858) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:47:36,900] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,900] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,901] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,901] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,901] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 700 due to node 3 being disconnected (elapsed time since creation: 202ms, elapsed time since send: 202ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,902] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:36,902] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=99830466, epoch=700) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:47:36,903] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:36,903] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,903] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,904] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,905] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,905] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,905] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,905] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 804 due to node 4 being disconnected (elapsed time since creation: 333ms, elapsed time since send: 333ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,905] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,906] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:36,906] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 808 due to node 5 being disconnected (elapsed time since creation: 498ms, elapsed time since send: 498ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,906] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:36,905] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=1696108683, epoch=804) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:47:36,907] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,908] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,906] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=1104245228, epoch=808) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:47:36,909] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,909] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,910] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 858 due to node 0 being disconnected (elapsed time since creation: 6ms, elapsed time since send: 6ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:36,910] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=1844250150, epoch=858) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:47:36,911] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,911] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,913] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:36,913] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:47:36,913] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:36,914] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:36,914] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:36,915] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs/Sensor-5.e8385236f1144253ba14f6f157ee3efb-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:47:36,919] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs/Sensor-0.1ecd84b4a8c545f89c27d1c458a55cdd-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:47:36,921] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs/Sensor-1.250e6f2501c3409294198957ef33cf6e-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:47:36,923] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:36,924] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:36,927] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-5/Sensor-2.ea4db75ebd8f483789bcba49129b3a18-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:47:36,932] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-5/Sensor-0.cc1cae6def4145b9b32e08af6b28d732-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:47:36,933] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-1/Sensor-4.c9a9367007f44515b8e09e49b024de77-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:47:36,935] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-5/Sensor-1.d07a8b7d4c064362abd249df82ec60ec-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:47:36,937] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-1/Sensor-2.744959a64dd14b27b1a6860e057daf4b-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:47:36,938] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-2/Sensor-4.2a61f10179254669b540ce0eb37de3e1-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:47:36,940] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-1/Sensor-3.dc044b826db843759f231569212a0f59-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:47:36,942] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-2/Sensor-5.71fbfa6c65294556a7465e8395cdd7cf-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:47:36,943] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-3/Sensor-4.f5f5175190594b18acb95a9fa6464226-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:47:36,943] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-4/Sensor-2.200b3e499da24fe09b37f4de60743196-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:47:36,944] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-2/Sensor-3.c2973f0e5e254c9a8a53953594283fb8-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:47:36,945] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-4/Sensor-3.89a87671d9214ce3a1a64db3c4c34ead-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:47:36,946] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-3/Sensor-5.be951ea113f9415c85a8eb3dee0d6ff8-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:47:36,948] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-4/Sensor-1.115343f075f143e1a2bbd16cc5a9fbce-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:47:36,948] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-3/Sensor-0.896bb4262f0c4634a401101b4ec601cf-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:47:40,223] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:47:40,223] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:47:40,223] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:47:40,223] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:47:40,224] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:47:40,224] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:47:40,226] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:47:40,228] INFO [KafkaServer id=5] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:47:40,227] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:47:40,230] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:47:40,230] INFO [KafkaServer id=5] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:47:40,230] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:47:40,230] INFO [KafkaServer id=4] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:47:40,231] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:47:40,231] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:47:40,226] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:47:40,234] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:47:40,234] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:47:40,248] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 10ms (kafka.server.KafkaServer)
[2022-05-15 23:47:40,251] INFO [KafkaServer id=5] Controlled shutdown request returned successfully after 12ms (kafka.server.KafkaServer)
[2022-05-15 23:47:40,251] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:47:40,252] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:47:40,252] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:47:40,253] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 13ms (kafka.server.KafkaServer)
[2022-05-15 23:47:40,253] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:47:40,254] INFO [KafkaServer id=4] Controlled shutdown request returned successfully after 15ms (kafka.server.KafkaServer)
[2022-05-15 23:47:40,256] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:47:40,256] INFO [KafkaServer id=3] Controlled shutdown request returned successfully after 14ms (kafka.server.KafkaServer)
[2022-05-15 23:47:40,256] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:47:40,256] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:47:40,258] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 15ms (kafka.server.KafkaServer)
[2022-05-15 23:47:40,258] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:47:40,259] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:47:40,259] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:47:40,260] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:47:40,259] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:47:40,259] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:47:40,260] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:47:40,260] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:47:40,260] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:47:40,260] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:47:40,262] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:47:40,262] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:47:40,262] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:47:40,263] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:47:40,263] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:47:40,264] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:47:40,267] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:47:40,278] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:47:40,281] INFO [data-plane Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:47:40,282] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:47:40,283] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:47:40,284] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:47:40,284] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:47:40,284] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:47:40,284] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:47:40,286] INFO [data-plane Kafka Request Handler on Broker 5], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:47:40,286] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:47:40,286] INFO [data-plane Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:47:40,287] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:47:40,287] INFO [data-plane Kafka Request Handler on Broker 4], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:47:40,289] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:47:40,292] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:47:40,291] INFO [data-plane Kafka Request Handler on Broker 5], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:47:40,292] INFO [ExpirationReaper-3-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,292] INFO [data-plane Kafka Request Handler on Broker 4], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:47:40,298] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,298] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,299] INFO [ExpirationReaper-5-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,300] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:47:40,301] INFO [ExpirationReaper-4-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,304] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,347] INFO [ExpirationReaper-5-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,347] INFO [ExpirationReaper-5-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,349] INFO [KafkaApi-5] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:47:40,350] INFO [ExpirationReaper-5-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,367] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,367] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,368] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:47:40,370] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,387] INFO [ExpirationReaper-3-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,387] INFO [ExpirationReaper-3-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,389] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:47:40,391] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,444] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,444] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,445] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:47:40,446] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,460] INFO [ExpirationReaper-5-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,460] INFO [ExpirationReaper-5-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,463] INFO [TransactionCoordinator id=5] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:47:40,465] INFO [Transaction State Manager 5]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:47:40,465] INFO [Transaction Marker Channel Manager 5]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:47:40,466] INFO [Transaction Marker Channel Manager 5]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:47:40,466] INFO [Transaction Marker Channel Manager 5]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:47:40,468] INFO [TransactionCoordinator id=5] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:47:40,470] INFO [GroupCoordinator 5]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:47:40,471] INFO [ExpirationReaper-5-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,480] INFO [ExpirationReaper-4-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,480] INFO [ExpirationReaper-4-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,481] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,481] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,481] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,481] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,482] INFO [KafkaApi-4] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:47:40,483] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:47:40,483] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:47:40,484] INFO [ExpirationReaper-4-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,484] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:47:40,485] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,485] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:47:40,485] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:47:40,485] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:47:40,486] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,486] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,487] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:47:40,488] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:47:40,488] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:47:40,489] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,490] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:47:40,490] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:47:40,490] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:47:40,490] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:47:40,493] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:47:40,493] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:47:40,494] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,504] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,504] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,505] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,572] INFO [ExpirationReaper-4-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,572] INFO [ExpirationReaper-4-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,576] INFO [TransactionCoordinator id=4] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:47:40,578] INFO [Transaction State Manager 4]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:47:40,578] INFO [Transaction Marker Channel Manager 4]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:47:40,579] INFO [Transaction Marker Channel Manager 4]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:47:40,579] INFO [Transaction Marker Channel Manager 4]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:47:40,581] INFO [TransactionCoordinator id=4] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:47:40,582] INFO [GroupCoordinator 4]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:47:40,583] INFO [ExpirationReaper-4-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,603] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,603] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,607] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:47:40,609] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:47:40,609] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:47:40,610] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:47:40,610] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:47:40,612] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:47:40,613] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:47:40,613] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,620] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,620] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,621] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,630] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,631] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,635] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:47:40,637] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:47:40,637] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:47:40,638] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:47:40,638] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:47:40,640] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:47:40,642] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:47:40,642] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,649] INFO [ExpirationReaper-5-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,649] INFO [ExpirationReaper-5-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,650] INFO [ExpirationReaper-5-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,682] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,682] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,683] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:47:40,684] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:47:40,685] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:47:40,685] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:47:40,685] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:47:40,686] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,687] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,687] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,687] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:40,690] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:40,690] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:40,691] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:40,691] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,706] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,706] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,707] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,713] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,713] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,714] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,719] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,719] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,720] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:47:40,722] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:47:40,723] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:47:40,723] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:47:40,723] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:47:40,724] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:40,725] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:40,726] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:40,726] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:40,726] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,729] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,729] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,730] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,747] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,747] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,747] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,755] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,755] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,756] INFO [ExpirationReaper-3-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,772] INFO [ExpirationReaper-4-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,772] INFO [ExpirationReaper-4-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,773] INFO [ExpirationReaper-4-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,781] INFO [ExpirationReaper-4-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,781] INFO [ExpirationReaper-4-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,782] INFO [GroupCoordinator 4]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:47:40,784] INFO [ReplicaManager broker=4] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:47:40,785] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:47:40,786] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:47:40,786] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:47:40,787] INFO [ReplicaFetcherManager on broker 4] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:40,788] INFO [ReplicaFetcherManager on broker 4] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:40,789] INFO [ReplicaAlterLogDirsManager on broker 4] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:40,790] INFO [ReplicaAlterLogDirsManager on broker 4] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:40,790] INFO [ExpirationReaper-4-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,804] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,805] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,806] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,816] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,816] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,816] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,818] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,818] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,819] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:47:40,822] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:47:40,822] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:47:40,823] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:47:40,824] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:47:40,825] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:40,826] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:40,827] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:40,828] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:40,828] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,849] INFO [ExpirationReaper-5-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,850] INFO [ExpirationReaper-5-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,851] INFO [GroupCoordinator 5]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:47:40,854] INFO [ReplicaManager broker=5] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:47:40,854] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:47:40,855] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:47:40,855] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:47:40,856] INFO [ReplicaFetcherManager on broker 5] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:40,859] INFO [ReplicaFetcherManager on broker 5] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:40,859] INFO [ReplicaAlterLogDirsManager on broker 5] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:40,860] INFO [ReplicaAlterLogDirsManager on broker 5] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:40,860] INFO [ExpirationReaper-5-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,866] INFO [ExpirationReaper-4-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,866] INFO [ExpirationReaper-4-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,866] INFO [ExpirationReaper-4-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,886] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,886] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,888] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:47:40,890] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:47:40,890] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:47:40,890] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:47:40,890] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:47:40,892] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:40,893] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:47:40,894] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:40,895] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:47:40,895] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,905] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,905] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,905] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,905] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,906] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,906] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,914] INFO [ExpirationReaper-5-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,914] INFO [ExpirationReaper-5-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,914] INFO [ExpirationReaper-5-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,920] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,920] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,920] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,934] INFO [ExpirationReaper-3-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,934] INFO [ExpirationReaper-3-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:40,945] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:47:40,945] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:40,946] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:40,946] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:40,948] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:47:40,948] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:40,949] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:40,949] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:40,950] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:47:40,951] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:47:40,975] INFO [ProducerStateManager partition=__consumer_offsets-38] Wrote producer snapshot at offset 112778 with 0 producer ids in 3 ms. (kafka.log.ProducerStateManager)
[2022-05-15 23:47:40,992] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:47:40,998] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:47:40,999] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:47:40,999] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:47:41,000] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:47:41,007] INFO [ExpirationReaper-4-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,007] INFO [ExpirationReaper-4-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,008] INFO [ExpirationReaper-4-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,012] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,012] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,017] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:47:41,018] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,018] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,018] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,020] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:47:41,020] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,021] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,021] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,022] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:47:41,023] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:47:41,025] INFO [ExpirationReaper-4-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,026] INFO [ExpirationReaper-4-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,027] INFO [ExpirationReaper-4-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,048] INFO [ProducerStateManager partition=__consumer_offsets-39] Wrote producer snapshot at offset 49540 with 0 producer ids in 4 ms. (kafka.log.ProducerStateManager)
[2022-05-15 23:47:41,054] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,054] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,055] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,055] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,055] INFO [Controller id=0, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,059] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,059] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,059] INFO [Controller id=0, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,059] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,059] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,060] WARN [Controller id=0, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,060] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,060] WARN [Controller id=0, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,060] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,059] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,061] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,061] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,061] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,062] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,062] INFO [Controller id=0, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,066] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:47:41,070] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,070] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,071] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,072] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,075] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,077] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,080] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,083] INFO [Controller id=0, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,085] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:47:41,085] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:47:41,085] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:47:41,087] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:47:41,087] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,087] INFO [ExpirationReaper-5-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,087] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,087] INFO [ExpirationReaper-5-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,087] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,088] INFO [ExpirationReaper-5-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,108] INFO EventThread shut down for session: 0x100000b00ad0099 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:47:41,108] INFO Session: 0x100000b00ad0099 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:47:41,111] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:47:41,112] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:41,116] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,116] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,120] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:47:41,121] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,121] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,121] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,123] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:47:41,124] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,124] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,124] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,125] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:47:41,125] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:47:41,153] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:47:41,191] INFO Session: 0x100000b00ad0096 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:47:41,191] INFO EventThread shut down for session: 0x100000b00ad0096 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:47:41,194] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:47:41,195] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:41,212] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,212] INFO [Controller id=2, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,212] INFO [Controller id=2, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,212] INFO [Controller id=2, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,215] WARN [Controller id=2, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,215] WARN [Controller id=2, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,215] WARN [Controller id=2, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,215] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,218] INFO [Controller id=2, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,218] INFO [Controller id=2, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,218] INFO [Controller id=2, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,218] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,221] INFO [ExpirationReaper-4-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,221] INFO [ExpirationReaper-4-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,227] INFO [ReplicaManager broker=4] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:47:41,228] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,228] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,228] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,230] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:47:41,231] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,231] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,231] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,232] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:47:41,233] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:47:41,250] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,250] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,250] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,261] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,261] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,267] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:47:41,268] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,268] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:47:41,268] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,268] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,271] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:47:41,272] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,272] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,272] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,274] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:47:41,275] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:47:41,279] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:47:41,280] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:47:41,280] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:47:41,282] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:47:41,287] INFO [ExpirationReaper-5-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,287] INFO [ExpirationReaper-5-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,287] INFO [ExpirationReaper-5-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,305] INFO [ExpirationReaper-5-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,305] INFO [ExpirationReaper-5-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:47:41,306] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:47:41,310] INFO [ReplicaManager broker=5] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:47:41,310] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,310] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,310] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,313] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:47:41,314] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,314] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,314] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:47:41,315] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:47:41,316] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:47:41,317] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:47:41,317] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:47:41,317] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:47:41,319] INFO [Controller id=2, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,319] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:47:41,319] INFO [Controller id=2, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,319] INFO [Controller id=2, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,319] INFO [Controller id=2, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,319] WARN [Controller id=2, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,319] WARN [Controller id=2, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,319] WARN [Controller id=2, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,319] WARN [Controller id=2, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,320] INFO [Controller id=2, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,320] INFO [Controller id=2, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,321] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,321] INFO [Controller id=2, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,339] INFO [ProducerStateManager partition=__consumer_offsets-40] Wrote producer snapshot at offset 49319 with 0 producer ids in 4 ms. (kafka.log.ProducerStateManager)
[2022-05-15 23:47:41,360] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:47:41,370] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:47:41,371] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:47:41,372] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:47:41,373] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:47:41,388] INFO Session: 0x100000b00ad009a closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:47:41,388] INFO EventThread shut down for session: 0x100000b00ad009a (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:47:41,390] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:47:41,391] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:41,396] INFO [Controller id=2, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,399] INFO [Controller id=2, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,402] INFO [Controller id=2, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,404] INFO [Controller id=2, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:47:41,408] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:47:41,408] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:47:41,408] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:47:41,409] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:47:41,413] WARN An exception was thrown while closing send thread for session 0x100000b00ad0098. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x100000b00ad0098, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 23:47:41,424] INFO Session: 0x100000b00ad0097 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:47:41,424] INFO EventThread shut down for session: 0x100000b00ad0097 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:47:41,426] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:47:41,427] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:41,480] INFO Session: 0x100000b00ad009b closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:47:41,480] INFO EventThread shut down for session: 0x100000b00ad009b (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:47:41,482] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:47:41,483] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:41,516] INFO Session: 0x100000b00ad0098 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:47:41,516] INFO EventThread shut down for session: 0x100000b00ad0098 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:47:41,518] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:47:41,519] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,003] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,003] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,004] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,004] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,004] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,004] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,012] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,012] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,013] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,013] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,013] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,014] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,024] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,024] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,024] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,026] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,026] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,026] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,074] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,074] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,074] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,099] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,099] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:42,099] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,004] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,004] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,005] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,007] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,007] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,009] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:47:43,013] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,013] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,014] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,024] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,024] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,025] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,026] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,026] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,026] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,026] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,027] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,029] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:47:43,036] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,036] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,037] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,038] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,038] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,041] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:47:43,046] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:47:43,047] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:47:43,047] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:47:43,048] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:47:43,051] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:47:43,053] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:47:43,054] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:47:43,070] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:47:43,071] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:47:43,071] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:47:43,072] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:47:43,074] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,074] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,074] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,075] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:47:43,076] INFO App info kafka.server for 4 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:47:43,077] INFO [KafkaServer id=4] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:47:43,078] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:47:43,079] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:47:43,079] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:47:43,079] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:47:43,081] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:47:43,082] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:47:43,083] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:47:43,099] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,099] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:43,100] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:44,025] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:44,025] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:44,025] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:44,074] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:44,074] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:44,075] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:44,100] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:44,100] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:44,100] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:45,025] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:45,025] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:45,027] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:47:45,058] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:47:45,059] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:47:45,059] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:47:45,059] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:47:45,062] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:47:45,063] INFO App info kafka.server for 3 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:47:45,064] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:47:45,075] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:45,075] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:45,077] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:47:45,100] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:45,100] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:47:45,103] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:47:45,106] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:47:45,107] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:47:45,108] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:47:45,108] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:47:45,111] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:47:45,112] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:47:45,113] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:47:45,130] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:47:45,131] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:47:45,131] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:47:45,132] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:47:45,134] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:47:45,135] INFO App info kafka.server for 5 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:47:45,136] INFO [KafkaServer id=5] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:48:10,073] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:48:10,083] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:48:10,084] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:48:10,084] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:48:10,084] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:48:10,086] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 23:48:10,086] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 23:48:10,086] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 23:48:10,086] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-15 23:48:10,089] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-15 23:48:10,104] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:48:10,105] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:48:10,105] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:48:10,105] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:48:10,105] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 23:48:10,105] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-15 23:48:10,120] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@6156496 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-15 23:48:10,124] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 23:48:10,136] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,137] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,137] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,137] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,137] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,137] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,137] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,137] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,137] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,137] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,139] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,139] INFO Server environment:host.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,139] INFO Server environment:java.version=11.0.15 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,139] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,139] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,139] INFO Server environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,140] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,140] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,140] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,140] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,140] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,140] INFO Server environment:os.version=5.13.0-40-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,140] INFO Server environment:user.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,140] INFO Server environment:user.home=/home/joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,140] INFO Server environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,140] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,140] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,140] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,140] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,140] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,140] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,141] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,141] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,141] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,141] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,143] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-15 23:48:10,146] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,146] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,147] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 23:48:10,147] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 23:48:10,148] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:48:10,149] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:48:10,149] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:48:10,149] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:48:10,149] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:48:10,149] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 23:48:10,153] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,153] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,153] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 23:48:10,160] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 23:48:10,162] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 23:48:10,163] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 23:48:10,168] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 23:48:10,169] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:459)
	at java.base/sun.nio.ch.Net.bind(Net.java:448)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:676)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:158)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:112)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:67)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:140)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:90)
[2022-05-15 23:48:10,172] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-15 23:48:10,175] ERROR Exiting JVM with code 1 (org.apache.zookeeper.util.ServiceUtils)
[2022-05-15 23:48:15,155] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:48:15,461] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:48:15,557] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:48:15,561] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:48:15,562] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:48:15,581] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:48:15,587] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:15,587] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:15,587] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:15,587] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:15,588] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:15,588] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:15,588] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:15,588] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:15,588] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:15,589] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:15,589] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:15,589] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:15,589] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:15,589] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:15,589] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:15,589] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:15,589] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:15,589] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:15,592] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:15,611] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:48:15,617] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:15,625] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:48:15,634] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:15,636] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:15,642] INFO Socket connection established, initiating session, client: /127.0.0.1:58146, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:15,652] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad009c, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:15,659] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:48:15,759] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:48:15,910] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:48:15,918] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:48:15,981] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:48:15,992] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:48:16,055] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:16,058] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:16,061] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:16,063] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:16,116] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:48:16,120] INFO Skipping recovery for all logs in /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:48:16,216] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:16,246] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-21, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 106ms (1/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:48:16,254] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:16,260] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-5.e8385236f1144253ba14f6f157ee3efb-delete, topicId=VVvCcK4FQJu1RWOwv5vuGQ, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (2/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:48:16,267] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:16,273] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-0.1ecd84b4a8c545f89c27d1c458a55cdd-delete, topicId=VVvCcK4FQJu1RWOwv5vuGQ, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (3/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:48:16,292] INFO Deleted producer state snapshot /tmp/kafka-logs/__consumer_offsets-39/00000000000000035579.snapshot (kafka.log.SnapshotFile)
[2022-05-15 23:48:16,294] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 49540 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:16,295] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 49540 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:16,296] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs/__consumer_offsets-39/00000000000000049540.snapshot,49540)' (kafka.log.ProducerStateManager)
[2022-05-15 23:48:16,303] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Producer state recovery took 8ms for snapshot load and 0ms for segment recovery from offset 49540 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:16,308] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-39, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=49540) with 1 segments in 34ms (4/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:48:16,315] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:16,320] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-15, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (5/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:48:16,326] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:16,330] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-1.250e6f2501c3409294198957ef33cf6e-delete, topicId=VVvCcK4FQJu1RWOwv5vuGQ, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (6/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:48:16,337] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:16,341] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-45, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (7/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:48:16,347] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:16,351] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-33, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (8/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:48:16,358] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:16,361] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-27, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (9/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:48:16,367] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:16,372] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-3, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (10/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:48:16,379] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:16,383] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-9, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (11/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 23:48:16,387] INFO Loaded 11 logs in 272ms. (kafka.log.LogManager)
[2022-05-15 23:48:16,389] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:48:16,391] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:48:16,698] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:16,836] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:48:16,840] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-15 23:48:16,865] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:48:16,871] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:16,886] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:16,888] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:16,890] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:16,891] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:16,903] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:48:16,953] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:48:16,971] INFO Stat of the created znode at /brokers/ids/0 is: 7563,7563,1652654896964,1652654896964,1,0,0,72057641293906076,192,0,7563
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:48:16,972] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://joao:9092, czxid (broker epoch): 7563 (kafka.zk.KafkaZkClient)
[2022-05-15 23:48:17,029] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:17,036] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:17,038] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:17,054] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:17,068] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:17,098] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:48:17,105] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:48:17,105] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:48:17,142] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:17,162] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:48:17,185] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:48:17,193] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:48:17,194] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:48:17,201] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:48:17,202] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:48:17,202] INFO Kafka startTimeMs: 1652654897194 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:48:17,204] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-15 23:48:17,276] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:17,276] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:17,276] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 49540 (kafka.cluster.Partition)
[2022-05-15 23:48:17,276] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:17,276] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:17,276] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:17,276] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:17,276] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:17,278] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:17,308] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:17,362] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-3, __consumer_offsets-15, __consumer_offsets-39, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:17,395] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 49 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:17,396] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 49 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:17,398] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 49 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:17,398] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 49 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:17,398] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 49 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:17,398] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 49 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:17,398] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 49 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:17,398] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 49 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:17,398] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 49 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:17,398] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 49 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:17,398] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 49 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:17,398] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 49 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:17,398] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 49 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:17,398] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 49 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:17,398] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 49 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:17,399] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 49 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:17,406] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 9 milliseconds for epoch 49, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:17,407] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 9 milliseconds for epoch 49, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:17,520] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 121 milliseconds for epoch 49, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:17,520] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 122 milliseconds for epoch 49, of which 122 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:17,521] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 123 milliseconds for epoch 49, of which 123 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:17,522] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 124 milliseconds for epoch 49, of which 123 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:17,522] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 124 milliseconds for epoch 49, of which 124 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:17,523] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 124 milliseconds for epoch 49, of which 123 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:20,138] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:48:20,430] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:48:20,512] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:48:20,515] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:48:20,515] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:48:20,531] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:48:20,537] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:20,537] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:20,538] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:20,538] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:20,538] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:20,538] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:20,538] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:20,538] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:20,538] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:20,538] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:20,538] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:20,538] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:20,538] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:20,538] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:20,538] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:20,538] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:20,538] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:20,538] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:20,541] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:20,546] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:48:20,551] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:20,574] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:48:20,582] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:20,584] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:20,590] INFO Socket connection established, initiating session, client: /127.0.0.1:58148, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:20,601] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad009d, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:20,607] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:48:20,703] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:48:20,861] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:48:20,870] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:48:20,939] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:48:20,949] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:48:21,018] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:21,020] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:21,022] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:21,025] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:21,074] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:48:21,080] INFO Skipping recovery for all logs in /tmp/kafka-logs-1 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:48:21,164] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:21,194] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-17, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 93ms (1/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:48:21,201] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:21,205] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-4.c9a9367007f44515b8e09e49b024de77-delete, topicId=VVvCcK4FQJu1RWOwv5vuGQ, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (2/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:48:21,211] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:21,216] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-35, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (3/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:48:21,221] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:21,224] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-3.dc044b826db843759f231569212a0f59-delete, topicId=VVvCcK4FQJu1RWOwv5vuGQ, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (4/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:48:21,230] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:21,233] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-41, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:48:21,239] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:21,243] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-29, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (6/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:48:21,249] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:21,252] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-11, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:48:21,257] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:21,260] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-23, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:48:21,265] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:21,269] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-2.744959a64dd14b27b1a6860e057daf4b-delete, topicId=VVvCcK4FQJu1RWOwv5vuGQ, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:48:21,274] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:21,278] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-47, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (10/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:48:21,283] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:21,286] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-5, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 23:48:21,292] INFO Loaded 11 logs in 217ms. (kafka.log.LogManager)
[2022-05-15 23:48:21,294] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:48:21,295] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:48:21,569] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:21,700] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:48:21,704] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-15 23:48:21,730] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:48:21,737] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:21,753] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:21,754] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:21,756] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:21,757] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:21,768] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:48:21,824] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:48:21,842] INFO Stat of the created znode at /brokers/ids/1 is: 7631,7631,1652654901833,1652654901833,1,0,0,72057641293906077,192,0,7631
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:48:21,843] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://joao:9093, czxid (broker epoch): 7631 (kafka.zk.KafkaZkClient)
[2022-05-15 23:48:21,911] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:21,916] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:21,917] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:21,932] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:21,942] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:21,966] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:48:21,972] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:48:21,972] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:48:21,999] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:22,018] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:48:22,039] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:48:22,045] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:48:22,045] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:48:22,052] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:48:22,053] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:48:22,053] INFO Kafka startTimeMs: 1652654902046 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:48:22,056] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-15 23:48:22,133] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:22,134] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:22,134] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:22,134] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:22,134] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:22,134] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:22,134] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:22,134] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:22,142] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:22,159] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-5, __consumer_offsets-29, __consumer_offsets-41, __consumer_offsets-23) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:22,186] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:22,193] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 76 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:22,195] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 76 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:22,196] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 76 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:22,196] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 76 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:22,196] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 76 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:22,196] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 76 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:22,196] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 76 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:22,196] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 76 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:22,196] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 76 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:22,196] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 76 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:22,196] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 76 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:22,196] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 76 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:22,196] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 76 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:22,197] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 76 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:22,197] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 76 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:22,197] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 76 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:22,203] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 7 milliseconds for epoch 76, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:22,204] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 8 milliseconds for epoch 76, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:22,204] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 8 milliseconds for epoch 76, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:22,204] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 8 milliseconds for epoch 76, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:22,205] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 9 milliseconds for epoch 76, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:22,205] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 9 milliseconds for epoch 76, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:22,205] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 8 milliseconds for epoch 76, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:22,205] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 8 milliseconds for epoch 76, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:25,145] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:48:25,470] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:48:25,583] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:48:25,588] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:48:25,590] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:48:25,609] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:48:25,615] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:25,615] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:25,615] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:25,615] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:25,615] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:25,615] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:25,616] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:25,616] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:25,616] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:25,616] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:25,616] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:25,616] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:25,616] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:25,616] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:25,616] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:25,616] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:25,616] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:25,616] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:25,619] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:25,625] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:48:25,632] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:25,651] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:48:25,660] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:25,663] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:25,670] INFO Socket connection established, initiating session, client: /127.0.0.1:58150, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:25,681] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad009e, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:25,686] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:48:25,783] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:48:25,932] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:48:25,940] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:48:26,009] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:48:26,020] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:48:26,083] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:26,085] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:26,088] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:26,091] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:26,135] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:48:26,138] INFO Skipping recovery for all logs in /tmp/kafka-logs-2 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:48:26,190] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:26,209] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-4.2a61f10179254669b540ce0eb37de3e1-delete, topicId=VVvCcK4FQJu1RWOwv5vuGQ, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 55ms (1/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:48:26,221] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:26,225] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-49, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (2/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:48:26,229] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:26,232] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-19, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (3/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:48:26,236] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:26,239] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-7, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (4/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:48:26,244] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:26,247] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-13, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:48:26,253] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:26,256] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-37, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:48:26,263] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:26,265] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-43, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (7/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:48:26,269] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:26,272] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-1, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:48:26,276] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:26,279] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-3.c2973f0e5e254c9a8a53953594283fb8-delete, topicId=VVvCcK4FQJu1RWOwv5vuGQ, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (9/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:48:26,282] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:26,285] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-5.71fbfa6c65294556a7465e8395cdd7cf-delete, topicId=VVvCcK4FQJu1RWOwv5vuGQ, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (10/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:48:26,289] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:26,291] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-31, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (11/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:48:26,295] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:26,296] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-25, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (12/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 23:48:26,300] INFO Loaded 12 logs in 164ms. (kafka.log.LogManager)
[2022-05-15 23:48:26,301] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:48:26,302] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:48:26,502] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:26,593] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:48:26,596] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-15 23:48:26,619] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:48:26,624] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:26,640] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:26,641] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:26,643] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:26,645] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:26,657] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:48:26,705] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:48:26,720] INFO Stat of the created znode at /brokers/ids/2 is: 7655,7655,1652654906713,1652654906713,1,0,0,72057641293906078,192,0,7655
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:48:26,721] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://joao:9094, czxid (broker epoch): 7655 (kafka.zk.KafkaZkClient)
[2022-05-15 23:48:26,784] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:26,788] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:26,790] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:26,802] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:26,813] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:26,824] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:48:26,828] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:48:26,828] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:48:26,861] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:26,875] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:48:26,894] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:48:26,898] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:48:26,899] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:48:26,904] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:48:26,905] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:48:26,905] INFO Kafka startTimeMs: 1652654906899 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:48:26,908] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-15 23:48:26,993] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:26,993] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:26,994] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:26,994] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:26,995] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:26,996] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:26,996] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:26,996] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:26,996] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:27,015] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:27,023] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-7, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:27,027] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:27,057] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:27,060] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:27,063] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:27,063] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:27,063] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:27,063] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:27,063] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:27,063] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:27,063] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:27,063] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:27,063] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:27,064] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:27,064] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:27,064] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:27,064] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:27,064] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:27,064] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 74 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:27,064] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 74 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:27,068] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 8 milliseconds for epoch 74, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:27,069] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 6 milliseconds for epoch 74, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:27,070] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 7 milliseconds for epoch 74, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:27,070] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 7 milliseconds for epoch 74, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:27,070] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 7 milliseconds for epoch 74, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:27,071] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 7 milliseconds for epoch 74, of which 6 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:27,071] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 7 milliseconds for epoch 74, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:27,071] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 7 milliseconds for epoch 74, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:27,072] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 7 milliseconds for epoch 74, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:29,984] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:48:30,233] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:48:30,306] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:48:30,309] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:48:30,310] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:48:30,325] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:48:30,330] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:30,330] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:30,330] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:30,330] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:30,330] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:30,330] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:30,331] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:30,331] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:30,331] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:30,331] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:30,331] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:30,331] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:30,331] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:30,331] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:30,331] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:30,331] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:30,331] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:30,331] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:30,342] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:30,346] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:48:30,351] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:30,355] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:48:30,361] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:30,362] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:30,365] INFO Socket connection established, initiating session, client: /127.0.0.1:58152, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:30,371] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad009f, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:30,375] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:48:30,445] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:48:30,564] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:48:30,571] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:48:30,614] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:48:30,621] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:48:30,664] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:30,666] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:30,668] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:30,669] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:30,703] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:48:30,706] INFO Skipping recovery for all logs in /tmp/kafka-logs-3 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:48:30,769] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:30,792] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-4.f5f5175190594b18acb95a9fa6464226-delete, topicId=VVvCcK4FQJu1RWOwv5vuGQ, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 74ms (1/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:48:30,805] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:30,810] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-14, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (2/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:48:30,823] INFO Deleted producer state snapshot /tmp/kafka-logs-3/__consumer_offsets-38/00000000000000098382.snapshot (kafka.log.SnapshotFile)
[2022-05-15 23:48:30,825] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Loading producer state till offset 112778 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:30,825] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Reloading from producer snapshot and rebuilding producer state from offset 112778 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:30,826] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-3/__consumer_offsets-38/00000000000000112778.snapshot,112778)' (kafka.log.ProducerStateManager)
[2022-05-15 23:48:30,832] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 112778 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:30,835] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-38, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=112778) with 1 segments in 25ms (3/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:48:30,841] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:30,846] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-8, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (4/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:48:30,850] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:30,853] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-2, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:48:30,857] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:30,860] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-26, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (6/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:48:30,864] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:30,868] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-20, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:48:30,872] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:30,875] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-32, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (8/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:48:30,881] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:30,884] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-44, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:48:30,888] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:30,891] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-0.896bb4262f0c4634a401101b4ec601cf-delete, topicId=VVvCcK4FQJu1RWOwv5vuGQ, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (10/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:48:30,895] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:30,899] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-5.be951ea113f9415c85a8eb3dee0d6ff8-delete, topicId=VVvCcK4FQJu1RWOwv5vuGQ, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 23:48:30,903] INFO Loaded 11 logs in 200ms. (kafka.log.LogManager)
[2022-05-15 23:48:30,903] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:48:30,904] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:48:31,114] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:31,215] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:48:31,218] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-05-15 23:48:31,241] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:48:31,247] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:31,263] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:31,265] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:31,267] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:31,268] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:31,279] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:48:31,332] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:48:31,350] INFO Stat of the created znode at /brokers/ids/3 is: 7680,7680,1652654911342,1652654911342,1,0,0,72057641293906079,192,0,7680
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:48:31,351] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://joao:9095, czxid (broker epoch): 7680 (kafka.zk.KafkaZkClient)
[2022-05-15 23:48:31,415] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:31,419] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:31,421] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:31,433] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:31,443] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:31,468] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:48:31,474] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:48:31,474] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:48:31,496] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:31,512] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:48:31,530] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:48:31,534] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:48:31,535] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:48:31,539] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:48:31,539] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:48:31,539] INFO Kafka startTimeMs: 1652654911535 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:48:31,541] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-05-15 23:48:31,626] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:31,633] INFO [Partition __consumer_offsets-2 broker=3] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:31,634] INFO [Partition __consumer_offsets-20 broker=3] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:31,634] INFO [Partition __consumer_offsets-38 broker=3] Log loaded for partition __consumer_offsets-38 with initial high watermark 112778 (kafka.cluster.Partition)
[2022-05-15 23:48:31,635] INFO [Partition __consumer_offsets-8 broker=3] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:31,635] INFO [Partition __consumer_offsets-26 broker=3] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:31,635] INFO [Partition __consumer_offsets-44 broker=3] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:31,636] INFO [Partition __consumer_offsets-14 broker=3] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:31,636] INFO [Partition __consumer_offsets-32 broker=3] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:31,654] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:31,664] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-26, __consumer_offsets-32, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:31,695] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 2 in epoch 77 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:31,697] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 77 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:31,699] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 20 in epoch 77 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:31,699] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 77 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:31,699] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 38 in epoch 77 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:31,699] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 77 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:31,699] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 8 in epoch 77 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:31,699] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 77 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:31,699] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 26 in epoch 77 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:31,699] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 77 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:31,699] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 44 in epoch 77 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:31,699] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 77 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:31,699] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 14 in epoch 77 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:31,699] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 77 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:31,699] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 32 in epoch 77 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:31,699] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 77 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:31,708] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-2 in 10 milliseconds for epoch 77, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:31,709] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-20 in 10 milliseconds for epoch 77, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:31,858] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-38 in 159 milliseconds for epoch 77, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:31,858] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-8 in 159 milliseconds for epoch 77, of which 159 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:31,859] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-26 in 160 milliseconds for epoch 77, of which 160 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:31,859] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-44 in 160 milliseconds for epoch 77, of which 160 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:31,859] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-14 in 160 milliseconds for epoch 77, of which 160 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:31,859] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-32 in 160 milliseconds for epoch 77, of which 160 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:35,170] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:48:35,507] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:48:35,616] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:48:35,620] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:48:35,620] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:48:35,638] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:48:35,643] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:35,643] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:35,643] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:35,643] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:35,643] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:35,643] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:35,644] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:35,644] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:35,644] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:35,644] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:35,644] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:35,644] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:35,644] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:35,644] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:35,644] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:35,644] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:35,644] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:35,644] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:35,647] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:35,653] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:48:35,660] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:35,680] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:48:35,690] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:35,692] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:35,698] INFO Socket connection established, initiating session, client: /127.0.0.1:58154, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:35,708] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad00a0, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:35,714] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:48:35,818] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:48:35,989] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:48:35,998] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:48:36,061] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:48:36,072] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:48:36,132] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:36,133] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:36,136] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:36,137] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:36,175] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:48:36,179] INFO Skipping recovery for all logs in /tmp/kafka-logs-4 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:48:36,241] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:36,262] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-24, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 71ms (1/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:48:36,268] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:36,272] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-12, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (2/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:48:36,276] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:36,282] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-30, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (3/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:48:36,288] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:36,291] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-36, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (4/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:48:36,296] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:36,299] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-42, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:48:36,304] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:36,306] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-3.89a87671d9214ce3a1a64db3c4c34ead-delete, topicId=VVvCcK4FQJu1RWOwv5vuGQ, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (6/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:48:36,311] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:36,315] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-0, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:48:36,319] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:36,323] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-18, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (8/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:48:36,328] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:36,331] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-6, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:48:36,335] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:36,338] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-1.115343f075f143e1a2bbd16cc5a9fbce-delete, topicId=VVvCcK4FQJu1RWOwv5vuGQ, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:48:36,343] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:36,344] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-48, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (11/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:48:36,349] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:36,351] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-2.200b3e499da24fe09b37f4de60743196-delete, topicId=VVvCcK4FQJu1RWOwv5vuGQ, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (12/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 23:48:36,354] INFO Loaded 12 logs in 179ms. (kafka.log.LogManager)
[2022-05-15 23:48:36,355] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:48:36,356] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:48:36,573] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:36,672] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:48:36,675] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.Acceptor)
[2022-05-15 23:48:36,701] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:48:36,710] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:36,728] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:36,729] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:36,730] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:36,732] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:36,743] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:48:36,797] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:48:36,815] INFO Stat of the created znode at /brokers/ids/4 is: 7704,7704,1652654916806,1652654916806,1,0,0,72057641293906080,192,0,7704
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:48:36,816] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://joao:9096, czxid (broker epoch): 7704 (kafka.zk.KafkaZkClient)
[2022-05-15 23:48:36,878] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:36,883] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:36,884] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:36,897] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:36,908] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:36,933] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:48:36,939] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:48:36,939] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:48:36,961] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:36,978] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:48:36,998] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:48:37,004] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:48:37,005] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:48:37,010] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:48:37,011] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:48:37,011] INFO Kafka startTimeMs: 1652654917005 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:48:37,013] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2022-05-15 23:48:37,084] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:37,113] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:37,116] INFO [Partition __consumer_offsets-18 broker=4] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:37,116] INFO [Partition __consumer_offsets-36 broker=4] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:37,116] INFO [Partition __consumer_offsets-6 broker=4] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:37,116] INFO [Partition __consumer_offsets-24 broker=4] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:37,117] INFO [Partition __consumer_offsets-42 broker=4] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:37,117] INFO [Partition __consumer_offsets-12 broker=4] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:37,117] INFO [Partition __consumer_offsets-30 broker=4] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:37,117] INFO [Partition __consumer_offsets-0 broker=4] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:37,117] INFO [Partition __consumer_offsets-48 broker=4] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:37,140] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-12, __consumer_offsets-42, __consumer_offsets-18) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:37,176] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 18 in epoch 81 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:37,178] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 81 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:37,180] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 36 in epoch 81 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:37,180] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 81 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:37,180] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 6 in epoch 81 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:37,180] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 81 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:37,180] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 24 in epoch 81 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:37,180] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 81 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:37,180] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 42 in epoch 81 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:37,180] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 81 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:37,180] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 12 in epoch 81 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:37,180] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 81 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:37,180] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 30 in epoch 81 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:37,180] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 81 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:37,180] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 0 in epoch 81 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:37,180] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 81 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:37,180] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 48 in epoch 81 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:37,180] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 81 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:37,187] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-18 in 8 milliseconds for epoch 81, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:37,188] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-36 in 8 milliseconds for epoch 81, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:37,188] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-6 in 8 milliseconds for epoch 81, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:37,188] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-24 in 8 milliseconds for epoch 81, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:37,188] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-42 in 8 milliseconds for epoch 81, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:37,188] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-12 in 8 milliseconds for epoch 81, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:37,188] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-30 in 8 milliseconds for epoch 81, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:37,188] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-0 in 8 milliseconds for epoch 81, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:37,189] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-48 in 9 milliseconds for epoch 81, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:40,171] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 23:48:40,510] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 23:48:40,618] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:48:40,622] INFO starting (kafka.server.KafkaServer)
[2022-05-15 23:48:40,623] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 23:48:40,642] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:48:40,648] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:40,648] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:40,648] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:40,648] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:40,649] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:40,649] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:40,649] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:40,649] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:40,649] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:40,649] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:40,649] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:40,649] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:40,649] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:40,649] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:40,650] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:40,650] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:40,650] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:40,650] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:40,652] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:48:40,658] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 23:48:40,664] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:40,683] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:48:40,688] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:40,689] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:40,694] INFO Socket connection established, initiating session, client: /127.0.0.1:58156, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:40,703] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad00a1, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:48:40,708] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:48:40,811] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:48:40,954] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 23:48:40,961] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 23:48:41,001] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:48:41,011] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 23:48:41,051] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:41,052] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:41,054] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:41,056] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:48:41,090] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:48:41,094] INFO Skipping recovery for all logs in /tmp/kafka-logs-5 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 23:48:41,157] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:41,175] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-46, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 69ms (1/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:48:41,180] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:41,183] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-2.ea4db75ebd8f483789bcba49129b3a18-delete, topicId=VVvCcK4FQJu1RWOwv5vuGQ, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (2/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:48:41,187] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:41,190] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-10, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (3/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:48:41,194] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:41,196] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-28, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (4/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:48:41,212] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Loading producer state till offset 56709 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:41,213] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 56709 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:41,214] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-22/00000000000000056709.snapshot,56709)' (kafka.log.ProducerStateManager)
[2022-05-15 23:48:41,219] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 56709 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:41,222] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-22, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=56709) with 1 segments in 26ms (5/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:48:41,227] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:41,230] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-16, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (6/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:48:41,234] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:41,237] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-1.d07a8b7d4c064362abd249df82ec60ec-delete, topicId=VVvCcK4FQJu1RWOwv5vuGQ, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (7/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:48:41,240] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:41,243] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-0.cc1cae6def4145b9b32e08af6b28d732-delete, topicId=VVvCcK4FQJu1RWOwv5vuGQ, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:48:41,250] INFO Deleted producer state snapshot /tmp/kafka-logs-5/__consumer_offsets-40/00000000000000035134.snapshot (kafka.log.SnapshotFile)
[2022-05-15 23:48:41,250] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Loading producer state till offset 49319 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:41,250] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 49319 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:41,250] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-40/00000000000000049319.snapshot,49319)' (kafka.log.ProducerStateManager)
[2022-05-15 23:48:41,251] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 49319 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:41,253] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-40, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=49319) with 1 segments in 9ms (9/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:48:41,256] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:41,260] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-34, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:48:41,265] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:41,267] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-4, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (11/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 23:48:41,270] INFO Loaded 11 logs in 180ms. (kafka.log.LogManager)
[2022-05-15 23:48:41,271] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 23:48:41,272] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 23:48:41,480] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:41,582] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 23:48:41,586] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.Acceptor)
[2022-05-15 23:48:41,609] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:48:41,615] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:41,630] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:41,631] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:41,632] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:41,634] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:41,644] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:48:41,700] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 23:48:41,718] INFO Stat of the created znode at /brokers/ids/5 is: 7729,7729,1652654921710,1652654921710,1,0,0,72057641293906081,192,0,7729
 (kafka.zk.KafkaZkClient)
[2022-05-15 23:48:41,719] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://joao:9097, czxid (broker epoch): 7729 (kafka.zk.KafkaZkClient)
[2022-05-15 23:48:41,778] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:41,785] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:41,786] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:41,801] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:41,813] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:41,837] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:48:41,843] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:48:41,843] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:48:41,864] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:48:41,880] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:48:41,899] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:48:41,904] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 23:48:41,905] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 23:48:41,909] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:48:41,909] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:48:41,909] INFO Kafka startTimeMs: 1652654921905 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:48:41,912] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2022-05-15 23:48:41,990] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:41,999] INFO [Partition __consumer_offsets-34 broker=5] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:41,999] INFO [Partition __consumer_offsets-4 broker=5] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:41,999] INFO [Partition __consumer_offsets-22 broker=5] Log loaded for partition __consumer_offsets-22 with initial high watermark 56709 (kafka.cluster.Partition)
[2022-05-15 23:48:42,000] INFO [Partition __consumer_offsets-40 broker=5] Log loaded for partition __consumer_offsets-40 with initial high watermark 49319 (kafka.cluster.Partition)
[2022-05-15 23:48:42,000] INFO [Partition __consumer_offsets-10 broker=5] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:42,000] INFO [Partition __consumer_offsets-28 broker=5] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:42,000] INFO [Partition __consumer_offsets-46 broker=5] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:42,000] INFO [Partition __consumer_offsets-16 broker=5] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:42,022] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:48:42,023] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:42,055] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 34 in epoch 85 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:42,056] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 85 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:42,058] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 4 in epoch 85 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:42,058] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 85 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:42,058] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 22 in epoch 85 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:42,058] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 85 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:42,058] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 40 in epoch 85 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:42,058] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 85 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:42,058] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 10 in epoch 85 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:42,058] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 85 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:42,058] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 28 in epoch 85 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:42,058] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 85 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:42,058] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 46 in epoch 85 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:42,058] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 85 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:42,058] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 16 in epoch 85 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:48:42,058] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 85 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:42,067] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-34 in 10 milliseconds for epoch 85, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:42,069] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-4 in 11 milliseconds for epoch 85, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:42,091] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-9fa5abef-fdc9-4c05-8f09-7f9780632837, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:48:42,100] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-ed3a6d0d-54c4-4b54-b4a4-a5d0ecba6f8e, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:48:42,100] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-1038faf2-d998-4707-9799-897de83d6136, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:48:42,100] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-b283a5ee-70be-4bf9-b41c-74e089f12e34, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:48:42,100] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-360d1581-f79b-41e6-82d3-fe3577615014, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:48:42,100] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-9e173d1e-b47a-4b16-9874-bf5d2688c730, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:48:42,100] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-81fafa38-80dc-43ea-ac6c-e398b06565dc, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:48:42,133] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-d15976bc-df63-4682-8583-fd67cbb1d9df, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:48:42,133] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-a0d7c5c7-e384-4339-b0be-414878362e3e, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:48:42,133] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-ee781f71-f1c3-46d7-bd93-d90a4fe359ff, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:48:42,134] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-78575c72-7be8-4563-b114-53b271a8ef70, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:48:42,134] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-0287b15c-1acd-4475-b9ce-b994aebeeff2, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:48:42,134] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-45d54f6e-f1d8-43f7-8ace-1db96ac0cfac, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:48:42,190] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-954ef0dc-d124-405b-9bb6-119086dd08c0, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:48:42,190] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-3f51cd43-28ab-4459-969e-211543e6cd72, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:48:42,191] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-4b8634e2-92f3-4603-97c5-35df7219bd84, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 4. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:48:42,191] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-5f6ccebb-0352-4648-b98e-7613d791d352, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:48:42,204] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-8863ee28-05fa-4d10-b813-b83668f9ecf8, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 23:48:42,212] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-22 in 154 milliseconds for epoch 85, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:42,250] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-40 in 192 milliseconds for epoch 85, of which 155 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:42,250] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-10 in 192 milliseconds for epoch 85, of which 192 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:42,251] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-28 in 193 milliseconds for epoch 85, of which 193 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:42,251] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-46 in 193 milliseconds for epoch 85, of which 193 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:42,252] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-16 in 194 milliseconds for epoch 85, of which 194 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:48:45,933] INFO Creating topic Sensor with configuration {min.insync.replicas=2} and initial partition assignment HashMap(0 -> ArrayBuffer(1, 0, 5), 1 -> ArrayBuffer(2, 5, 4), 2 -> ArrayBuffer(3, 4, 1), 3 -> ArrayBuffer(0, 1, 2), 4 -> ArrayBuffer(5, 2, 3), 5 -> ArrayBuffer(4, 3, 0)) (kafka.zk.AdminZkClient)
[2022-05-15 23:48:45,981] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:45,982] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-4) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:45,984] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:45,984] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:45,985] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:45,987] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:45,996] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:45,997] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:45,998] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:45,998] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:45,998] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:46,003] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-4/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:48:46,003] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:46,004] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-2/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:48:46,004] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-5/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:48:46,005] INFO Created log for partition Sensor-3 in /tmp/kafka-logs/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:48:46,006] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-1/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:48:46,006] INFO [Partition Sensor-5 broker=4] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 23:48:46,007] INFO [Partition Sensor-5 broker=4] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:46,007] INFO [Partition Sensor-4 broker=5] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 23:48:46,008] INFO [Partition Sensor-4 broker=5] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:46,007] INFO [Partition Sensor-1 broker=2] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 23:48:46,007] INFO [Partition Sensor-3 broker=0] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 23:48:46,008] INFO [Partition Sensor-1 broker=2] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:46,008] INFO [Partition Sensor-3 broker=0] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:46,008] INFO [Partition Sensor-0 broker=1] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 23:48:46,009] INFO [Partition Sensor-0 broker=1] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:46,010] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-3/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:48:46,011] INFO [Partition Sensor-2 broker=3] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 23:48:46,012] INFO [Partition Sensor-2 broker=3] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:46,020] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:46,020] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:46,021] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:46,022] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-5/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:48:46,022] INFO [Partition Sensor-0 broker=5] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 23:48:46,022] INFO [Partition Sensor-0 broker=5] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:46,022] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:46,022] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:46,023] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-4/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:48:46,023] INFO Created log for partition Sensor-5 in /tmp/kafka-logs/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:48:46,023] INFO [Partition Sensor-5 broker=0] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 23:48:46,023] INFO [Partition Sensor-2 broker=4] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 23:48:46,023] INFO [Partition Sensor-5 broker=0] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:46,023] INFO [Partition Sensor-2 broker=4] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:46,024] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-2/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:48:46,024] INFO [Partition Sensor-4 broker=2] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 23:48:46,024] INFO [Partition Sensor-4 broker=2] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:46,024] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-1/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:48:46,025] INFO [Partition Sensor-3 broker=1] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 23:48:46,025] INFO [Partition Sensor-3 broker=1] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:46,028] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:46,029] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-3/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:48:46,030] INFO [Partition Sensor-4 broker=3] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 23:48:46,030] INFO [Partition Sensor-4 broker=3] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:46,030] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:46,031] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:46,032] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-5/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:48:46,032] INFO [Partition Sensor-1 broker=5] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 23:48:46,032] INFO [Partition Sensor-1 broker=5] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:46,032] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:46,033] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:46,033] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:46,034] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:46,035] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-4/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:48:46,035] INFO [Partition Sensor-1 broker=4] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 23:48:46,035] INFO Created log for partition Sensor-0 in /tmp/kafka-logs/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:48:46,035] INFO [Partition Sensor-1 broker=4] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:46,035] INFO [Partition Sensor-0 broker=0] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 23:48:46,035] INFO [Partition Sensor-0 broker=0] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:46,035] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:46,035] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-2/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:48:46,036] INFO [Partition Sensor-3 broker=2] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 23:48:46,036] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(Sensor-5, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:46,036] INFO [Partition Sensor-3 broker=2] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:46,036] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(Sensor-4, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:46,038] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-1/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:48:46,038] INFO [Partition Sensor-2 broker=1] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 23:48:46,038] INFO [Partition Sensor-2 broker=1] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:46,038] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 23:48:46,039] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:46,040] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-3/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 23:48:46,040] INFO [Partition Sensor-5 broker=3] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 23:48:46,040] INFO [Partition Sensor-5 broker=3] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 23:48:46,041] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(Sensor-4, Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:46,056] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,060] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,060] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 4 for partitions Map(Sensor-5 -> InitialFetchState(Some(ODZrgYDFRf2j_psHedkYQQ),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:46,063] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,065] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,065] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,065] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,066] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 1 for partitions Map(Sensor-0 -> InitialFetchState(Some(ODZrgYDFRf2j_psHedkYQQ),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:46,066] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,067] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 2 for partitions Map(Sensor-1 -> InitialFetchState(Some(ODZrgYDFRf2j_psHedkYQQ),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:46,069] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:48:46,069] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:48:46,070] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 2 for partitions Map(Sensor-1 -> InitialFetchState(Some(ODZrgYDFRf2j_psHedkYQQ),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:46,070] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,073] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,073] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 4 for partitions Map(Sensor-5 -> InitialFetchState(Some(ODZrgYDFRf2j_psHedkYQQ),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:46,072] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 1 for partitions Map(Sensor-0 -> InitialFetchState(Some(ODZrgYDFRf2j_psHedkYQQ),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:46,073] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,076] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,077] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,077] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,077] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 3 for partitions Map(Sensor-2 -> InitialFetchState(Some(ODZrgYDFRf2j_psHedkYQQ),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:46,079] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,079] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,080] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:48:46,080] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions Map(Sensor-3 -> InitialFetchState(Some(ODZrgYDFRf2j_psHedkYQQ),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:46,077] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:48:46,077] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:48:46,083] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,084] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,084] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:48:46,085] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 5 for partitions Map(Sensor-4 -> InitialFetchState(Some(ODZrgYDFRf2j_psHedkYQQ),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:46,085] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,085] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,085] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 5 for partitions Map(Sensor-4 -> InitialFetchState(Some(ODZrgYDFRf2j_psHedkYQQ),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:46,086] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:48:46,084] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:48:46,085] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,088] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,088] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(Sensor-3 -> InitialFetchState(Some(ODZrgYDFRf2j_psHedkYQQ),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:46,092] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:48:46,094] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,097] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 3 for partitions Map(Sensor-2 -> InitialFetchState(Some(ODZrgYDFRf2j_psHedkYQQ),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:48:46,096] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:48:46,097] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,106] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,106] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:48:46,099] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 23:48:46,182] WARN [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-5. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,184] WARN [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-0. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,188] WARN [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-0. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,193] WARN [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:48:46,205] WARN [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:49:16,267] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=50727, lastModifiedTime=1652654768342, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:49:16,270] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=50727, lastModifiedTime=1652654768342, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:49:16,275] INFO Deleted log /tmp/kafka-logs/Sensor-5.e8385236f1144253ba14f6f157ee3efb-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:16,276] INFO Deleted offset index /tmp/kafka-logs/Sensor-5.e8385236f1144253ba14f6f157ee3efb-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:16,280] INFO Deleted time index /tmp/kafka-logs/Sensor-5.e8385236f1144253ba14f6f157ee3efb-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:16,286] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs/Sensor-5.e8385236f1144253ba14f6f157ee3efb-delete. (kafka.log.LogManager)
[2022-05-15 23:49:16,287] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=85920, lastModifiedTime=1652654797241, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:49:16,287] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=85920, lastModifiedTime=1652654797241, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:49:16,288] INFO Deleted log /tmp/kafka-logs/Sensor-0.1ecd84b4a8c545f89c27d1c458a55cdd-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:16,289] INFO Deleted offset index /tmp/kafka-logs/Sensor-0.1ecd84b4a8c545f89c27d1c458a55cdd-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:16,289] INFO Deleted time index /tmp/kafka-logs/Sensor-0.1ecd84b4a8c545f89c27d1c458a55cdd-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:16,290] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs/Sensor-0.1ecd84b4a8c545f89c27d1c458a55cdd-delete. (kafka.log.LogManager)
[2022-05-15 23:49:16,331] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=78701, lastModifiedTime=1652654791663, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:49:16,332] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=78701, lastModifiedTime=1652654791663, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:49:16,335] INFO Deleted log /tmp/kafka-logs/Sensor-1.250e6f2501c3409294198957ef33cf6e-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:16,335] INFO Deleted offset index /tmp/kafka-logs/Sensor-1.250e6f2501c3409294198957ef33cf6e-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:16,336] INFO Deleted time index /tmp/kafka-logs/Sensor-1.250e6f2501c3409294198957ef33cf6e-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:16,336] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs/Sensor-1.250e6f2501c3409294198957ef33cf6e-delete. (kafka.log.LogManager)
[2022-05-15 23:49:21,208] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=48405, lastModifiedTime=1652654785345, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:49:21,210] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=48405, lastModifiedTime=1652654785345, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:49:21,214] INFO Deleted log /tmp/kafka-logs-1/Sensor-4.c9a9367007f44515b8e09e49b024de77-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:21,215] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-4.c9a9367007f44515b8e09e49b024de77-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:21,219] INFO Deleted time index /tmp/kafka-logs-1/Sensor-4.c9a9367007f44515b8e09e49b024de77-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:21,227] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-1/Sensor-4.c9a9367007f44515b8e09e49b024de77-delete. (kafka.log.LogManager)
[2022-05-15 23:49:21,228] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=91626, lastModifiedTime=1652654796949, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:49:21,228] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=91626, lastModifiedTime=1652654796949, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:49:21,229] INFO Deleted log /tmp/kafka-logs-1/Sensor-3.dc044b826db843759f231569212a0f59-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:21,229] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-3.dc044b826db843759f231569212a0f59-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:21,230] INFO Deleted time index /tmp/kafka-logs-1/Sensor-3.dc044b826db843759f231569212a0f59-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:21,231] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-1/Sensor-3.dc044b826db843759f231569212a0f59-delete. (kafka.log.LogManager)
[2022-05-15 23:49:21,270] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=78243, lastModifiedTime=1652654795853, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:49:21,271] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=78243, lastModifiedTime=1652654795853, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:49:21,274] INFO Deleted log /tmp/kafka-logs-1/Sensor-2.744959a64dd14b27b1a6860e057daf4b-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:21,276] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-2.744959a64dd14b27b1a6860e057daf4b-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:21,276] INFO Deleted time index /tmp/kafka-logs-1/Sensor-2.744959a64dd14b27b1a6860e057daf4b-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:21,276] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-1/Sensor-2.744959a64dd14b27b1a6860e057daf4b-delete. (kafka.log.LogManager)
[2022-05-15 23:49:26,220] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=48405, lastModifiedTime=1652654785341, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:49:26,223] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=48405, lastModifiedTime=1652654785341, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:49:26,228] INFO Deleted log /tmp/kafka-logs-2/Sensor-4.2a61f10179254669b540ce0eb37de3e1-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:26,229] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-4.2a61f10179254669b540ce0eb37de3e1-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:26,236] INFO Deleted time index /tmp/kafka-logs-2/Sensor-4.2a61f10179254669b540ce0eb37de3e1-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:26,241] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-2/Sensor-4.2a61f10179254669b540ce0eb37de3e1-delete. (kafka.log.LogManager)
[2022-05-15 23:49:26,279] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=91626, lastModifiedTime=1652654796953, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:49:26,280] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=91626, lastModifiedTime=1652654796953, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:49:26,281] INFO Deleted log /tmp/kafka-logs-2/Sensor-3.c2973f0e5e254c9a8a53953594283fb8-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:26,282] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-3.c2973f0e5e254c9a8a53953594283fb8-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:26,282] INFO Deleted time index /tmp/kafka-logs-2/Sensor-3.c2973f0e5e254c9a8a53953594283fb8-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:26,283] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-2/Sensor-3.c2973f0e5e254c9a8a53953594283fb8-delete. (kafka.log.LogManager)
[2022-05-15 23:49:26,286] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=50727, lastModifiedTime=1652654768342, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:49:26,286] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=50727, lastModifiedTime=1652654768342, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:49:26,287] INFO Deleted log /tmp/kafka-logs-2/Sensor-5.71fbfa6c65294556a7465e8395cdd7cf-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:26,287] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-5.71fbfa6c65294556a7465e8395cdd7cf-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:26,287] INFO Deleted time index /tmp/kafka-logs-2/Sensor-5.71fbfa6c65294556a7465e8395cdd7cf-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:26,288] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-2/Sensor-5.71fbfa6c65294556a7465e8395cdd7cf-delete. (kafka.log.LogManager)
[2022-05-15 23:49:30,795] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=48405, lastModifiedTime=1652654785345, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:49:30,796] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=48405, lastModifiedTime=1652654785345, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:49:30,800] INFO Deleted log /tmp/kafka-logs-3/Sensor-4.f5f5175190594b18acb95a9fa6464226-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:30,802] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-4.f5f5175190594b18acb95a9fa6464226-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:30,807] INFO Deleted time index /tmp/kafka-logs-3/Sensor-4.f5f5175190594b18acb95a9fa6464226-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:30,813] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-3/Sensor-4.f5f5175190594b18acb95a9fa6464226-delete. (kafka.log.LogManager)
[2022-05-15 23:49:30,892] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=85920, lastModifiedTime=1652654797241, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:49:30,893] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=85920, lastModifiedTime=1652654797241, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:49:30,895] INFO Deleted log /tmp/kafka-logs-3/Sensor-0.896bb4262f0c4634a401101b4ec601cf-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:30,896] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-0.896bb4262f0c4634a401101b4ec601cf-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:30,896] INFO Deleted time index /tmp/kafka-logs-3/Sensor-0.896bb4262f0c4634a401101b4ec601cf-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:30,897] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-3/Sensor-0.896bb4262f0c4634a401101b4ec601cf-delete. (kafka.log.LogManager)
[2022-05-15 23:49:30,900] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=50727, lastModifiedTime=1652654768338, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:49:30,900] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=50727, lastModifiedTime=1652654768338, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:49:30,902] INFO Deleted log /tmp/kafka-logs-3/Sensor-5.be951ea113f9415c85a8eb3dee0d6ff8-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:30,902] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-5.be951ea113f9415c85a8eb3dee0d6ff8-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:30,903] INFO Deleted time index /tmp/kafka-logs-3/Sensor-5.be951ea113f9415c85a8eb3dee0d6ff8-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:30,904] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-3/Sensor-5.be951ea113f9415c85a8eb3dee0d6ff8-delete. (kafka.log.LogManager)
[2022-05-15 23:49:36,312] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=91626, lastModifiedTime=1652654796949, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:49:36,316] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=91626, lastModifiedTime=1652654796949, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:49:36,319] INFO Deleted log /tmp/kafka-logs-4/Sensor-3.89a87671d9214ce3a1a64db3c4c34ead-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:36,320] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-3.89a87671d9214ce3a1a64db3c4c34ead-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:36,323] INFO Deleted time index /tmp/kafka-logs-4/Sensor-3.89a87671d9214ce3a1a64db3c4c34ead-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:36,330] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-4/Sensor-3.89a87671d9214ce3a1a64db3c4c34ead-delete. (kafka.log.LogManager)
[2022-05-15 23:49:36,339] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=78701, lastModifiedTime=1652654791663, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:49:36,340] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=78701, lastModifiedTime=1652654791663, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:49:36,340] INFO Deleted log /tmp/kafka-logs-4/Sensor-1.115343f075f143e1a2bbd16cc5a9fbce-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:36,341] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-1.115343f075f143e1a2bbd16cc5a9fbce-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:36,341] INFO Deleted time index /tmp/kafka-logs-4/Sensor-1.115343f075f143e1a2bbd16cc5a9fbce-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:36,342] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-4/Sensor-1.115343f075f143e1a2bbd16cc5a9fbce-delete. (kafka.log.LogManager)
[2022-05-15 23:49:36,352] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=78243, lastModifiedTime=1652654795849, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:49:36,354] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=78243, lastModifiedTime=1652654795849, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:49:36,355] INFO Deleted log /tmp/kafka-logs-4/Sensor-2.200b3e499da24fe09b37f4de60743196-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:36,357] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-2.200b3e499da24fe09b37f4de60743196-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:36,358] INFO Deleted time index /tmp/kafka-logs-4/Sensor-2.200b3e499da24fe09b37f4de60743196-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:36,358] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-4/Sensor-2.200b3e499da24fe09b37f4de60743196-delete. (kafka.log.LogManager)
[2022-05-15 23:49:41,187] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=78243, lastModifiedTime=1652654795853, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:49:41,190] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=78243, lastModifiedTime=1652654795853, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:49:41,195] INFO Deleted log /tmp/kafka-logs-5/Sensor-2.ea4db75ebd8f483789bcba49129b3a18-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:41,196] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-2.ea4db75ebd8f483789bcba49129b3a18-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:41,204] INFO Deleted time index /tmp/kafka-logs-5/Sensor-2.ea4db75ebd8f483789bcba49129b3a18-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:41,224] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-5/Sensor-2.ea4db75ebd8f483789bcba49129b3a18-delete. (kafka.log.LogManager)
[2022-05-15 23:49:41,238] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=78701, lastModifiedTime=1652654791659, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:49:41,239] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=78701, lastModifiedTime=1652654791659, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:49:41,240] INFO Deleted log /tmp/kafka-logs-5/Sensor-1.d07a8b7d4c064362abd249df82ec60ec-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:41,242] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-1.d07a8b7d4c064362abd249df82ec60ec-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:41,242] INFO Deleted time index /tmp/kafka-logs-5/Sensor-1.d07a8b7d4c064362abd249df82ec60ec-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:41,242] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-5/Sensor-1.d07a8b7d4c064362abd249df82ec60ec-delete. (kafka.log.LogManager)
[2022-05-15 23:49:41,244] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=85920, lastModifiedTime=1652654797245, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 23:49:41,244] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=85920, lastModifiedTime=1652654797245, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 23:49:41,246] INFO Deleted log /tmp/kafka-logs-5/Sensor-0.cc1cae6def4145b9b32e08af6b28d732-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:41,246] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-0.cc1cae6def4145b9b32e08af6b28d732-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:41,247] INFO Deleted time index /tmp/kafka-logs-5/Sensor-0.cc1cae6def4145b9b32e08af6b28d732-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 23:49:41,247] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-5/Sensor-0.cc1cae6def4145b9b32e08af6b28d732-delete. (kafka.log.LogManager)
[2022-05-15 23:52:02,810] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:52:02,811] INFO [GroupCoordinator 4]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:52:02,812] INFO [GroupCoordinator 5]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:52:02,812] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:52:02,814] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:52:02,815] INFO [GroupMetadataManager brokerId=3] Group consumer-group transitioned to Dead in generation 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 23:52:02,821] INFO [GroupCoordinator 3]: Removed 6 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:52:02,845] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:02,845] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:02,845] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:02,845] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:02,847] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:02,847] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-5, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:02,847] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:02,847] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:02,847] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-5, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:02,847] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:02,847] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:02,848] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-2) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:02,852] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,853] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,854] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,854] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,855] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,855] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-5, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:02,855] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,856] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,856] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-5, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:02,857] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,857] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 640 due to node 2 being disconnected (elapsed time since creation: 127ms, elapsed time since send: 127ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,857] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 640 due to node 2 being disconnected (elapsed time since creation: 126ms, elapsed time since send: 126ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,857] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,856] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,858] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,859] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,859] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 685 due to node 0 being disconnected (elapsed time since creation: 417ms, elapsed time since send: 417ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,860] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 634 due to node 3 being disconnected (elapsed time since creation: 166ms, elapsed time since send: 166ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,861] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 576 due to node 4 being disconnected (elapsed time since creation: 405ms, elapsed time since send: 405ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,861] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 678 due to node 1 being disconnected (elapsed time since creation: 299ms, elapsed time since send: 299ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,858] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=959509096, epoch=638) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:52:02,862] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=2109883254, epoch=676) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:52:02,862] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,862] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,858] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=948700707, epoch=638) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:52:02,862] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,862] INFO [ReplicaFetcher replicaId=0, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,863] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,863] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,860] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=2035802798, epoch=685) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:52:02,865] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,865] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,861] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=936078803, epoch=634) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:52:02,862] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=96098156, epoch=576) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:52:02,866] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,866] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,866] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,868] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,871] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,870] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,872] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 634 due to node 3 being disconnected (elapsed time since creation: 161ms, elapsed time since send: 161ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,873] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,872] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=532097928, epoch=634) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:52:02,873] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,873] INFO [ReplicaFetcher replicaId=4, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,873] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,874] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 678 due to node 1 being disconnected (elapsed time since creation: 312ms, elapsed time since send: 312ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,874] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=1478495770, epoch=676) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:52:02,875] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,875] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,875] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,876] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,876] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,876] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:02,876] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,876] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 686 due to node 0 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,876] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:02,877] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 563 due to node 5 being disconnected (elapsed time since creation: 124ms, elapsed time since send: 124ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,877] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=251459385, epoch=563) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:52:02,877] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,877] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,876] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=535455902, epoch=686) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:52:02,877] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,877] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,880] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:02,880] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:02,880] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:02,881] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,879] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:02,881] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:02,881] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-2) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:02,879] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,884] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,884] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,884] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 577 due to node 4 being disconnected (elapsed time since creation: 421ms, elapsed time since send: 421ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,884] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 562 due to node 5 being disconnected (elapsed time since creation: 117ms, elapsed time since send: 117ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:02,885] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=90948257, epoch=562) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:52:02,885] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,885] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,884] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=2101978138, epoch=575) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 23:52:02,886] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,888] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:02,886] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 23:52:02,890] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:02,892] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs/Sensor-5.e90fcbe10a774d0f8f2542dc96ee6b6f-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:52:02,896] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs/Sensor-3.e05584282344422db10f0214bab0f7d4-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:52:02,897] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-4/Sensor-5.1a46d85223a947f6942218d98f4c483b-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:52:02,899] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-1/Sensor-2.d5fad001f933408a97ddfa7f40d7d8c1-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:52:02,900] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs/Sensor-0.9d7ea5960bc145f4bc558bdfd463db80-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:52:02,901] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-4/Sensor-2.d52a79cbd532464d8f12cdf14ad432bd-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:52:02,902] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-3/Sensor-4.45a65b6f7e5f4e039342f0e0abd8d134-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:52:02,903] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-1/Sensor-3.d71c3bca58444910b0a6f153438d053f-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:52:02,904] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-4/Sensor-1.8fce7e7252934f999a3a6368974eff7d-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:52:02,906] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-3/Sensor-5.4117e3cf0e9843fd826cbaef15000891-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:52:02,906] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-1/Sensor-0.a7bf3ec3283d43b9bf64371152de9f71-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:52:02,909] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-3/Sensor-2.32603f1a38424f39a65019e66f3f7b2d-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:52:02,910] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-5/Sensor-4.30c98438908040fd9e128b0fbcb31b40-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:52:02,910] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-2/Sensor-4.036e6b115beb462c80d386fc3d3dc806-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:52:02,913] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-5/Sensor-0.f25cf84cad43405795f519c1d818b83b-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:52:02,914] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-2/Sensor-3.b2be4508b6854214a1a640e68dcbf53f-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:52:02,916] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-5/Sensor-1.b3b70f9091014c3d871557159cad7213-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:52:02,918] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-2/Sensor-1.841342c9b51d4349871ddd3038c6df74-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 23:52:06,190] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:52:06,190] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:52:06,190] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:52:06,191] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:52:06,191] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:52:06,191] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 23:52:06,193] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:52:06,193] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:52:06,194] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:52:06,195] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:52:06,197] INFO [KafkaServer id=5] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:52:06,199] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:52:06,200] INFO [KafkaServer id=5] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:52:06,201] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:52:06,202] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:52:06,195] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:52:06,209] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2022-05-15 23:52:06,211] INFO [KafkaServer id=4] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 23:52:06,221] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 13ms (kafka.server.KafkaServer)
[2022-05-15 23:52:06,224] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 15ms (kafka.server.KafkaServer)
[2022-05-15 23:52:06,224] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:52:06,224] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:52:06,224] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:52:06,226] INFO [KafkaServer id=5] Controlled shutdown request returned successfully after 20ms (kafka.server.KafkaServer)
[2022-05-15 23:52:06,227] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:52:06,227] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:52:06,227] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:52:06,227] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:52:06,229] INFO [KafkaServer id=3] Controlled shutdown request returned successfully after 21ms (kafka.server.KafkaServer)
[2022-05-15 23:52:06,229] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:52:06,230] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:52:06,230] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:52:06,231] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:52:06,232] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 21ms (kafka.server.KafkaServer)
[2022-05-15 23:52:06,232] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:52:06,233] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:52:06,233] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:52:06,233] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:52:06,235] INFO [KafkaServer id=4] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:06,235] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:52:06,236] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:52:06,236] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:52:06,236] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:52:06,239] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:52:06,240] INFO [KafkaServer id=4] Cancelled in-flight CONTROLLED_SHUTDOWN request with correlation id 0 due to node 0 being disconnected (elapsed time since creation: 18ms, elapsed time since send: 18ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:06,241] WARN [KafkaServer id=4] Error during controlled shutdown, possibly because leader movement took longer than the configured controller.socket.timeout.ms and/or request.timeout.ms: Connection to 0 was disconnected before the response was read (kafka.server.KafkaServer)
[2022-05-15 23:52:06,248] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:52:06,249] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:52:06,249] INFO [data-plane Kafka Request Handler on Broker 5], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:52:06,251] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:52:06,251] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:52:06,251] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:52:06,252] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:52:06,253] INFO [data-plane Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:52:06,254] INFO [data-plane Kafka Request Handler on Broker 5], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:52:06,254] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:52:06,258] INFO [data-plane Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:52:06,258] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:52:06,259] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,259] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:52:06,260] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:52:06,260] INFO [ExpirationReaper-5-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,261] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:52:06,263] INFO [ExpirationReaper-3-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,265] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,266] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,279] INFO [ExpirationReaper-5-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,279] INFO [ExpirationReaper-5-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,281] INFO [KafkaApi-5] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:52:06,282] INFO [ExpirationReaper-5-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,286] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,286] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,288] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:52:06,289] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,324] INFO [ExpirationReaper-3-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,324] INFO [ExpirationReaper-3-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,325] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:52:06,327] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,380] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,380] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,381] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:52:06,383] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,387] INFO [ExpirationReaper-5-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,387] INFO [ExpirationReaper-5-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,399] INFO [TransactionCoordinator id=5] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:52:06,401] INFO [Transaction State Manager 5]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:52:06,401] INFO [Transaction Marker Channel Manager 5]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:52:06,401] INFO [Transaction Marker Channel Manager 5]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:52:06,401] INFO [Transaction Marker Channel Manager 5]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:52:06,403] INFO [TransactionCoordinator id=5] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:52:06,404] INFO [GroupCoordinator 5]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:52:06,404] INFO [ExpirationReaper-5-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,406] INFO [ExpirationReaper-5-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,406] INFO [ExpirationReaper-5-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,406] INFO [ExpirationReaper-5-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,420] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,420] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,423] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:52:06,424] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:52:06,425] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:52:06,425] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:52:06,425] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:52:06,428] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:52:06,429] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:52:06,430] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,431] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,431] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,431] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,431] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,432] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:52:06,434] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:52:06,434] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,435] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:52:06,435] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:52:06,436] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:52:06,436] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:52:06,438] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:52:06,438] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:52:06,439] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,485] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,485] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,487] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:52:06,490] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:52:06,490] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:52:06,492] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:52:06,493] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:52:06,495] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:52:06,496] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:52:06,496] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,540] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,540] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,545] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:52:06,547] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:52:06,547] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:52:06,547] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:52:06,548] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:52:06,551] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:52:06,551] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:52:06,552] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,606] INFO [ExpirationReaper-5-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,606] INFO [ExpirationReaper-5-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,608] INFO [GroupCoordinator 5]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:52:06,610] INFO [ReplicaManager broker=5] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:52:06,610] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:52:06,611] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:52:06,611] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:52:06,612] INFO [ReplicaFetcherManager on broker 5] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:06,614] INFO [ReplicaFetcherManager on broker 5] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:06,615] INFO [ReplicaAlterLogDirsManager on broker 5] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:06,616] INFO [ReplicaAlterLogDirsManager on broker 5] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:06,616] INFO [ExpirationReaper-5-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,627] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,627] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,628] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,631] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,631] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,632] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,633] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,633] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,634] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:52:06,636] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:52:06,636] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:52:06,637] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:52:06,637] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:52:06,638] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:06,639] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:06,639] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:06,640] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:06,640] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,676] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,676] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,677] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,705] INFO [ExpirationReaper-5-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,705] INFO [ExpirationReaper-5-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,705] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,705] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,706] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,706] INFO [ExpirationReaper-5-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,740] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,740] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,741] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,831] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,831] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,833] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:52:06,835] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:52:06,836] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:52:06,836] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:52:06,837] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:52:06,838] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:06,840] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:06,841] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:06,842] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:06,842] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,852] INFO [ExpirationReaper-5-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,852] INFO [ExpirationReaper-5-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,852] INFO [ExpirationReaper-5-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,862] INFO [ExpirationReaper-5-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,862] INFO [ExpirationReaper-5-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,863] INFO [ExpirationReaper-5-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,869] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,869] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,870] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,876] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,876] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,878] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:52:06,879] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:52:06,879] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:52:06,880] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:52:06,880] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,880] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,880] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:52:06,880] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:06,881] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,881] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:06,882] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:06,882] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:06,882] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,908] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,908] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,909] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,940] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,940] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,942] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:52:06,943] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:52:06,943] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:52:06,943] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:52:06,943] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:52:06,944] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:06,946] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,946] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,947] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:06,948] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:06,949] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:06,950] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:06,950] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,059] INFO [ExpirationReaper-5-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,059] INFO [ExpirationReaper-5-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,064] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,064] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,066] INFO [ReplicaManager broker=5] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:52:07,067] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,067] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,068] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,067] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,068] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,068] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,070] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:52:07,071] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:52:07,071] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,071] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,071] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,071] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,072] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,072] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,073] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:52:07,074] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:52:07,074] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:52:07,075] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,075] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,075] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,076] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:52:07,077] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:52:07,086] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,086] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,087] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,103] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:52:07,108] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:52:07,111] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:52:07,112] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:52:07,112] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:52:07,113] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:52:07,116] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:52:07,116] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:52:07,116] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:52:07,117] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:52:07,125] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,125] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,125] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,163] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,163] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,163] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,167] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,167] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,167] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,167] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,167] WARN [Controller id=0, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,167] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,169] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,169] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,169] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,195] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,195] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,196] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,218] INFO Session: 0x100000b00ad00a1 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:52:07,218] INFO EventThread shut down for session: 0x100000b00ad00a1 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:52:07,221] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:52:07,222] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:07,222] INFO Session: 0x100000b00ad009e closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:52:07,223] INFO EventThread shut down for session: 0x100000b00ad009e (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:52:07,225] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:52:07,226] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:07,270] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,271] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,271] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,271] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,271] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,271] WARN [Controller id=0, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,271] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,272] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,272] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,285] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,285] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,286] INFO [ExpirationReaper-3-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,325] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,325] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,326] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,341] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,341] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,346] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:52:07,346] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,347] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,347] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,349] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:52:07,350] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,350] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,350] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,351] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:52:07,352] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:52:07,373] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,373] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,373] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,373] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,373] WARN [Controller id=0, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,374] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,374] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,374] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,374] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,384] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:52:07,387] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,387] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,388] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,391] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,394] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,397] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,403] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:52:07,403] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:52:07,403] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:52:07,404] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:52:07,485] INFO [ExpirationReaper-3-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,486] INFO [ExpirationReaper-3-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,491] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:52:07,491] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,492] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,492] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,495] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:52:07,495] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,496] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,496] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,497] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:52:07,498] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:52:07,510] INFO Session: 0x100000b00ad009c closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:52:07,510] INFO EventThread shut down for session: 0x100000b00ad009c (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:52:07,512] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:52:07,512] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:07,524] INFO [ProducerStateManager partition=__consumer_offsets-38] Wrote producer snapshot at offset 139500 with 0 producer ids in 4 ms. (kafka.log.ProducerStateManager)
[2022-05-15 23:52:07,532] INFO [Controller id=1, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,532] INFO [Controller id=1, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,535] WARN [Controller id=1, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,535] WARN [Controller id=1, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,536] INFO [Controller id=1, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,536] INFO [Controller id=1, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,541] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:52:07,550] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:52:07,550] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:52:07,550] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:52:07,551] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:52:07,587] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,587] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:07,592] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:52:07,593] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,593] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,593] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,596] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:52:07,596] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,597] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,597] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:07,598] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:52:07,599] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:52:07,635] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:52:07,637] INFO [Controller id=1, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,637] INFO [Controller id=1, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,638] WARN [Controller id=1, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,638] WARN [Controller id=1, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,638] INFO [Controller id=1, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,638] INFO [Controller id=1, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,657] INFO Session: 0x100000b00ad009f closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:52:07,657] INFO EventThread shut down for session: 0x100000b00ad009f (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:52:07,660] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:52:07,660] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:07,708] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:07,708] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:07,708] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:07,720] INFO [Controller id=1, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,723] INFO [Controller id=1, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:07,729] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:52:07,730] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:52:07,730] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:52:07,731] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:52:07,837] INFO Session: 0x100000b00ad009d closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:52:07,837] INFO EventThread shut down for session: 0x100000b00ad009d (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:52:07,840] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:52:07,840] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,066] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,067] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,067] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,075] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,076] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,076] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,096] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,096] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,096] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,099] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,099] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,100] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,107] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,107] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,107] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,109] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,109] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,109] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,130] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,130] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,131] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,133] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,133] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,133] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,708] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,708] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,709] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,712] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,712] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:08,712] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:09,071] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:09,071] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:09,071] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:09,075] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:09,076] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:09,078] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:52:09,099] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:09,099] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:09,100] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:09,101] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:09,101] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:09,102] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:52:09,103] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:52:09,103] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:52:09,103] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:52:09,104] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:52:09,106] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:52:09,106] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:52:09,107] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:52:09,109] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:09,109] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:09,109] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:09,112] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:09,112] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:09,114] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:52:09,132] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:52:09,133] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:52:09,133] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:52:09,133] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:09,133] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:09,133] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:09,134] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:52:09,135] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:52:09,135] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:52:09,136] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:52:09,136] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:52:09,136] INFO App info kafka.server for 5 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:52:09,136] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:52:09,136] INFO [KafkaServer id=5] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:52:09,139] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:52:09,139] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:52:09,140] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:52:09,712] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:09,712] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:09,715] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:52:09,735] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:52:09,736] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:52:09,736] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:52:09,736] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:52:09,738] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:52:09,739] INFO App info kafka.server for 3 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:52:09,739] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:52:10,133] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:10,133] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:10,135] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:52:10,162] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:52:10,163] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:52:10,163] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:52:10,163] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:52:10,165] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:52:10,166] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:52:10,167] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-15 23:52:11,243] INFO [KafkaServer id=4] Retrying controlled shutdown (2 retries remaining) (kafka.server.KafkaServer)
[2022-05-15 23:52:11,243] INFO [KafkaServer id=4] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 23:52:11,260] INFO [KafkaServer id=4] Controlled shutdown request returned successfully after 15ms (kafka.server.KafkaServer)
[2022-05-15 23:52:11,263] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:52:11,264] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:52:11,264] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 23:52:11,265] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:52:11,275] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 23:52:11,277] INFO [data-plane Kafka Request Handler on Broker 4], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:52:11,282] INFO [data-plane Kafka Request Handler on Broker 4], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 23:52:11,288] INFO [ExpirationReaper-4-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:11,393] INFO [ExpirationReaper-4-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:11,393] INFO [ExpirationReaper-4-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:11,394] INFO [KafkaApi-4] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 23:52:11,396] INFO [ExpirationReaper-4-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:11,515] INFO [ExpirationReaper-4-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:11,515] INFO [ExpirationReaper-4-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:11,518] INFO [TransactionCoordinator id=4] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:52:11,521] INFO [Transaction State Manager 4]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 23:52:11,521] INFO [Transaction Marker Channel Manager 4]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:52:11,522] INFO [Transaction Marker Channel Manager 4]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:52:11,522] INFO [Transaction Marker Channel Manager 4]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 23:52:11,525] INFO [TransactionCoordinator id=4] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 23:52:11,526] INFO [GroupCoordinator 4]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:52:11,526] INFO [ExpirationReaper-4-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:11,709] INFO [ExpirationReaper-4-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:11,709] INFO [ExpirationReaper-4-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:11,710] INFO [ExpirationReaper-4-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:11,909] INFO [ExpirationReaper-4-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:11,909] INFO [ExpirationReaper-4-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:11,911] INFO [GroupCoordinator 4]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 23:52:11,912] INFO [ReplicaManager broker=4] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 23:52:11,913] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:52:11,913] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:52:11,913] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 23:52:11,915] INFO [ReplicaFetcherManager on broker 4] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:11,917] INFO [ReplicaFetcherManager on broker 4] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 23:52:11,918] INFO [ReplicaAlterLogDirsManager on broker 4] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:11,918] INFO [ReplicaAlterLogDirsManager on broker 4] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 23:52:11,918] INFO [ExpirationReaper-4-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:11,974] INFO [ExpirationReaper-4-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:11,974] INFO [ExpirationReaper-4-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:11,974] INFO [ExpirationReaper-4-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:12,146] INFO [ExpirationReaper-4-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:12,147] INFO [ExpirationReaper-4-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:12,147] INFO [ExpirationReaper-4-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:12,347] INFO [ExpirationReaper-4-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:12,347] INFO [ExpirationReaper-4-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:12,348] INFO [ExpirationReaper-4-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:12,352] INFO [ExpirationReaper-4-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:12,352] INFO [ExpirationReaper-4-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 23:52:12,362] INFO [ReplicaManager broker=4] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 23:52:12,362] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:12,363] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:12,363] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:12,366] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:52:12,366] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:12,367] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:12,367] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 23:52:12,368] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 23:52:12,369] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 23:52:12,404] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 23:52:12,415] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:52:12,415] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:52:12,415] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 23:52:12,416] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:52:12,420] WARN An exception was thrown while closing send thread for session 0x100000b00ad00a0. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x100000b00ad00a0, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 23:52:12,522] INFO Session: 0x100000b00ad00a0 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 23:52:12,522] INFO EventThread shut down for session: 0x100000b00ad00a0 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 23:52:12,524] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 23:52:12,525] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:13,178] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:13,178] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:13,179] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:14,178] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:14,179] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:14,179] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:14,188] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:14,188] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:14,189] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:15,179] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:15,179] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 23:52:15,181] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 23:52:15,213] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 23:52:15,215] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:52:15,215] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:52:15,215] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 23:52:15,217] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 23:52:15,219] INFO App info kafka.server for 4 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 23:52:15,220] INFO [KafkaServer id=4] shut down completed (kafka.server.KafkaServer)
