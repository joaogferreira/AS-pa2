[2022-05-15 18:06:24,274] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:06:24,281] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:06:24,282] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:06:24,282] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:06:24,282] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:06:24,285] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 18:06:24,285] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 18:06:24,285] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 18:06:24,285] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-15 18:06:24,288] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-15 18:06:24,302] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:06:24,303] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:06:24,303] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:06:24,303] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:06:24,303] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:06:24,303] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-15 18:06:24,316] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@3c153a1 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-15 18:06:24,320] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 18:06:24,330] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,330] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,330] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,330] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,331] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,331] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,331] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,331] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,331] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,331] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,332] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,332] INFO Server environment:host.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,332] INFO Server environment:java.version=11.0.15 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,332] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,332] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,332] INFO Server environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,333] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,333] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,333] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,333] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,333] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,333] INFO Server environment:os.version=5.13.0-40-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,333] INFO Server environment:user.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,333] INFO Server environment:user.home=/home/joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,333] INFO Server environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,333] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,333] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,333] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,333] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,333] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,333] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,333] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,333] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,334] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,334] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,335] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-15 18:06:24,336] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,336] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,337] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 18:06:24,338] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 18:06:24,338] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:06:24,339] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:06:24,339] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:06:24,339] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:06:24,339] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:06:24,339] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:06:24,341] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,341] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,341] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:06:24,348] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 18:06:24,349] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 18:06:24,350] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 18:06:24,353] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 18:06:24,354] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:459)
	at java.base/sun.nio.ch.Net.bind(Net.java:448)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:676)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:158)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:112)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:67)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:140)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:90)
[2022-05-15 18:06:24,357] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-15 18:06:24,359] ERROR Exiting JVM with code 1 (org.apache.zookeeper.util.ServiceUtils)
[2022-05-15 18:06:29,356] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:06:29,647] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:06:29,739] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:06:29,742] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:06:29,743] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:06:29,760] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:06:29,767] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:29,767] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:29,767] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:29,768] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:29,768] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:29,768] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:29,768] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:29,769] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:29,769] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:29,769] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:29,769] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:29,769] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:29,769] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:29,769] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:29,769] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:29,769] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:29,769] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:29,769] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:29,772] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:29,778] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:06:29,782] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:29,796] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:06:29,800] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:29,801] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:29,805] INFO Socket connection established, initiating session, client: /127.0.0.1:57924, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:29,811] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0036, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:29,815] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:06:29,895] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:06:30,049] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:06:30,055] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:06:30,108] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:06:30,115] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:06:30,170] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:30,171] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:30,173] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:30,175] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:30,215] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:06:30,220] INFO Skipping recovery for all logs in /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:06:30,303] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:30,330] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-21, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 97ms (1/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:06:30,351] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 17940 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:30,352] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 17940 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:30,353] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs/__consumer_offsets-39/00000000000000017940.snapshot,17940)' (kafka.log.ProducerStateManager)
[2022-05-15 18:06:30,360] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Producer state recovery took 8ms for snapshot load and 0ms for segment recovery from offset 17940 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:30,364] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-39, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=17940) with 1 segments in 33ms (2/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:06:30,370] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:30,376] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-15, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (3/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:06:30,382] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:30,389] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-45, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (4/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:06:30,395] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:30,400] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-33, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (5/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:06:30,407] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:30,410] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-27, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (6/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:06:30,415] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:30,419] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-3, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (7/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:06:30,424] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:30,427] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-9, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:06:30,432] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:30,437] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-0.f347012a743244e68bd164ee66f3de06-delete, topicId=p9wUrT5ySYuWIhJ6i536_w, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (9/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:06:30,440] INFO Loaded 9 logs in 225ms. (kafka.log.LogManager)
[2022-05-15 18:06:30,441] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:06:30,443] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:06:30,709] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:30,866] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:06:30,872] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-15 18:06:30,906] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:06:30,913] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:30,934] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:30,937] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:30,939] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:30,940] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:30,955] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:06:31,021] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:06:31,042] INFO Stat of the created znode at /brokers/ids/0 is: 2589,2589,1652634391033,1652634391033,1,0,0,72057641293905974,192,0,2589
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:06:31,044] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://joao:9092, czxid (broker epoch): 2589 (kafka.zk.KafkaZkClient)
[2022-05-15 18:06:31,116] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:31,123] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:31,125] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:31,143] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:31,160] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:31,192] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:06:31,198] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:06:31,198] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:06:31,234] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:31,258] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:06:31,283] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:06:31,292] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:06:31,293] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:06:31,300] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:06:31,300] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:06:31,301] INFO Kafka startTimeMs: 1652634391293 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:06:31,305] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-15 18:06:31,413] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:31,414] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:31,414] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 17940 (kafka.cluster.Partition)
[2022-05-15 18:06:31,414] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:31,414] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:31,414] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:31,414] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:31,414] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:31,418] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:31,422] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:31,497] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-3, __consumer_offsets-15, __consumer_offsets-39, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:06:31,536] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:31,537] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:31,539] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:31,539] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:31,539] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:31,539] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:31,539] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:31,539] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:31,539] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:31,539] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:31,539] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:31,539] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:31,539] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:31,539] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:31,539] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 16 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:31,539] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 16 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:31,547] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 9 milliseconds for epoch 16, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:31,548] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 9 milliseconds for epoch 16, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:31,622] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 83 milliseconds for epoch 16, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:31,623] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 84 milliseconds for epoch 16, of which 84 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:31,624] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 84 milliseconds for epoch 16, of which 84 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:31,624] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 85 milliseconds for epoch 16, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:31,625] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 86 milliseconds for epoch 16, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:31,625] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 85 milliseconds for epoch 16, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:34,324] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:06:34,606] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:06:34,696] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:06:34,700] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:06:34,701] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:06:34,717] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:06:34,722] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:34,722] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:34,722] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:34,722] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:34,722] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:34,722] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:34,722] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:34,722] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:34,722] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:34,722] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:34,722] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:34,723] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:34,723] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:34,723] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:34,723] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:34,723] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:34,723] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:34,723] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:34,725] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:34,737] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:06:34,741] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:34,746] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:06:34,751] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:34,753] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:34,757] INFO Socket connection established, initiating session, client: /127.0.0.1:57926, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:34,765] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0037, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:34,769] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:06:34,839] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:06:34,969] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:06:34,975] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:06:35,018] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:06:35,026] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:06:35,075] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:35,076] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:35,078] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:35,079] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:35,116] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:06:35,120] INFO Skipping recovery for all logs in /tmp/kafka-logs-1 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:06:35,190] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:35,214] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-17, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 81ms (1/8 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:06:35,219] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:35,222] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-35, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (2/8 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:06:35,226] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:35,229] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-41, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (3/8 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:06:35,239] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:35,246] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-29, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (4/8 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:06:35,254] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:35,258] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-11, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (5/8 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:06:35,263] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:35,269] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-23, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (6/8 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:06:35,274] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:35,278] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-47, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/8 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:06:35,283] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:35,286] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-5, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (8/8 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:06:35,288] INFO Loaded 8 logs in 172ms. (kafka.log.LogManager)
[2022-05-15 18:06:35,290] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:06:35,291] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:06:35,627] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:35,799] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:06:35,804] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-15 18:06:35,844] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:06:35,852] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:35,873] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:35,874] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:35,876] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:35,877] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:35,890] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:06:35,951] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:06:35,972] INFO Stat of the created znode at /brokers/ids/1 is: 2657,2657,1652634395962,1652634395962,1,0,0,72057641293905975,192,0,2657
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:06:35,974] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://joao:9093, czxid (broker epoch): 2657 (kafka.zk.KafkaZkClient)
[2022-05-15 18:06:36,059] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:36,068] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:36,069] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:36,092] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:36,108] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:36,137] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:06:36,144] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:06:36,144] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:06:36,176] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:36,205] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:06:36,231] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:06:36,238] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:06:36,238] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:06:36,245] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:06:36,245] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:06:36,245] INFO Kafka startTimeMs: 1652634396238 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:06:36,252] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-15 18:06:36,344] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:36,356] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:36,415] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:36,416] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:36,416] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:36,417] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:36,417] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:36,417] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:36,418] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:36,418] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:36,459] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-5, __consumer_offsets-29, __consumer_offsets-41, __consumer_offsets-23) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:06:36,507] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 25 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:36,509] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 25 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:36,510] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 25 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:36,511] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 25 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:36,511] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 25 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:36,511] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 25 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:36,511] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 25 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:36,511] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 25 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:36,511] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 25 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:36,511] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 25 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:36,511] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 25 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:36,511] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 25 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:36,511] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 25 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:36,511] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 25 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:36,511] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 25 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:36,511] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 25 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:36,525] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 14 milliseconds for epoch 25, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:36,526] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 15 milliseconds for epoch 25, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:36,526] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 15 milliseconds for epoch 25, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:36,526] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 15 milliseconds for epoch 25, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:36,527] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 16 milliseconds for epoch 25, of which 15 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:36,527] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 16 milliseconds for epoch 25, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:36,527] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 16 milliseconds for epoch 25, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:36,527] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 16 milliseconds for epoch 25, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:39,355] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:06:39,667] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:06:39,758] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:06:39,763] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:06:39,764] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:06:39,780] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:06:39,786] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:39,786] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:39,786] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:39,787] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:39,787] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:39,787] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:39,787] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:39,787] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:39,787] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:39,787] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:39,787] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:39,787] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:39,787] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:39,787] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:39,787] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:39,787] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:39,787] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:39,788] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:39,790] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:39,796] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:06:39,810] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:39,815] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:06:39,821] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:39,822] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:39,826] INFO Socket connection established, initiating session, client: /127.0.0.1:57928, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:39,833] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0038, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:39,838] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:06:39,918] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:06:40,106] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:06:40,112] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:06:40,174] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:06:40,187] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:06:40,246] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:40,248] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:40,250] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:40,251] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:40,304] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:06:40,311] INFO Skipping recovery for all logs in /tmp/kafka-logs-2 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:06:40,407] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:40,433] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-49, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 105ms (1/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:06:40,439] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:40,444] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-19, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (2/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:06:40,449] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:40,453] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-7, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (3/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:06:40,459] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:40,463] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-13, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (4/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:06:40,469] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:40,473] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-37, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (5/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:06:40,478] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:40,483] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-43, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (6/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:06:40,487] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:40,490] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-1, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:06:40,495] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:40,500] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-31, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (8/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:06:40,506] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:40,510] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-25, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (9/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:06:40,512] INFO Loaded 9 logs in 207ms. (kafka.log.LogManager)
[2022-05-15 18:06:40,512] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:06:40,514] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:06:40,757] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:40,888] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:06:40,891] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-15 18:06:40,917] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:06:40,924] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:40,940] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:40,941] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:40,942] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:40,944] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:40,954] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:06:41,012] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:06:41,031] INFO Stat of the created znode at /brokers/ids/2 is: 2681,2681,1652634401022,1652634401022,1,0,0,72057641293905976,192,0,2681
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:06:41,033] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://joao:9094, czxid (broker epoch): 2681 (kafka.zk.KafkaZkClient)
[2022-05-15 18:06:41,095] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:41,102] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:41,104] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:41,123] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:41,140] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:41,167] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:06:41,178] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:06:41,178] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:06:41,211] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:41,228] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:06:41,252] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:06:41,256] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:06:41,257] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:06:41,262] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:06:41,262] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:06:41,262] INFO Kafka startTimeMs: 1652634401257 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:06:41,266] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-15 18:06:41,368] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:41,393] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:41,393] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:41,394] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:41,395] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:41,396] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:41,396] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:41,397] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:41,398] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:41,398] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:41,428] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:41,432] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-7, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:06:41,469] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:41,470] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:41,471] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:41,472] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:41,472] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:41,472] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:41,472] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:41,472] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:41,472] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:41,472] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:41,472] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:41,472] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:41,472] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:41,472] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:41,472] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:41,472] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:41,472] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:41,472] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:41,480] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 10 milliseconds for epoch 24, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:41,481] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 9 milliseconds for epoch 24, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:41,482] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 10 milliseconds for epoch 24, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:41,482] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 10 milliseconds for epoch 24, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:41,483] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 10 milliseconds for epoch 24, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:41,483] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 11 milliseconds for epoch 24, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:41,484] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 12 milliseconds for epoch 24, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:41,484] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 12 milliseconds for epoch 24, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:41,485] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 13 milliseconds for epoch 24, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:44,317] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:06:44,579] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:06:44,661] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:06:44,664] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:06:44,664] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:06:44,677] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:06:44,681] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:44,682] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:44,682] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:44,682] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:44,682] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:44,682] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:44,682] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:44,682] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:44,682] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:44,682] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:44,683] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:44,683] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:44,683] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:44,683] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:44,683] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:44,683] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:44,683] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:44,683] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:44,694] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:44,699] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:06:44,703] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:44,707] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:06:44,713] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:44,714] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:44,718] INFO Socket connection established, initiating session, client: /127.0.0.1:57930, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:44,726] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0039, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:44,730] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:06:44,802] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:06:44,937] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:06:44,942] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:06:44,990] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:06:45,000] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:06:45,050] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:45,051] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:45,053] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:45,055] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:45,095] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:06:45,098] INFO Skipping recovery for all logs in /tmp/kafka-logs-3 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:06:45,179] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:45,201] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-14, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 91ms (1/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:06:45,217] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Loading producer state till offset 28503 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:45,218] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Reloading from producer snapshot and rebuilding producer state from offset 28503 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:45,219] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-3/__consumer_offsets-38/00000000000000028503.snapshot,28503)' (kafka.log.ProducerStateManager)
[2022-05-15 18:06:45,227] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Producer state recovery took 9ms for snapshot load and 0ms for segment recovery from offset 28503 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:45,230] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-38, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=28503) with 1 segments in 29ms (2/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:06:45,235] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:45,239] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-8, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (3/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:06:45,245] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:45,250] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-2, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (4/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:06:45,257] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:45,261] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-26, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (5/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:06:45,266] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:45,269] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-20, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:06:45,273] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:45,277] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-32, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:06:45,282] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:45,286] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-44, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:06:45,288] INFO Loaded 8 logs in 193ms. (kafka.log.LogManager)
[2022-05-15 18:06:45,289] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:06:45,291] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:06:45,569] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:45,743] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:06:45,749] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-05-15 18:06:45,787] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:06:45,796] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:45,822] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:45,823] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:45,825] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:45,827] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:45,840] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:06:45,918] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:06:45,937] INFO Stat of the created znode at /brokers/ids/3 is: 2706,2706,1652634405930,1652634405930,1,0,0,72057641293905977,192,0,2706
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:06:45,938] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://joao:9095, czxid (broker epoch): 2706 (kafka.zk.KafkaZkClient)
[2022-05-15 18:06:46,010] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:46,016] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:46,017] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:46,033] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:46,047] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:46,087] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:06:46,094] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:06:46,094] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:06:46,125] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:46,151] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:06:46,174] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:06:46,180] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:06:46,181] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:06:46,186] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:06:46,186] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:06:46,186] INFO Kafka startTimeMs: 1652634406181 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:06:46,189] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-05-15 18:06:46,289] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:46,300] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:46,315] INFO [Partition __consumer_offsets-2 broker=3] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:46,315] INFO [Partition __consumer_offsets-20 broker=3] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:46,316] INFO [Partition __consumer_offsets-38 broker=3] Log loaded for partition __consumer_offsets-38 with initial high watermark 28503 (kafka.cluster.Partition)
[2022-05-15 18:06:46,316] INFO [Partition __consumer_offsets-8 broker=3] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:46,316] INFO [Partition __consumer_offsets-26 broker=3] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:46,317] INFO [Partition __consumer_offsets-44 broker=3] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:46,317] INFO [Partition __consumer_offsets-14 broker=3] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:46,318] INFO [Partition __consumer_offsets-32 broker=3] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:46,354] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-26, __consumer_offsets-32, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:06:46,392] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 2 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:46,394] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:46,395] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 20 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:46,396] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:46,396] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 38 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:46,396] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:46,396] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 8 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:46,396] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:46,396] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 26 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:46,396] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:46,397] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 44 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:46,397] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:46,397] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 14 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:46,397] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:46,397] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 32 in epoch 24 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:46,397] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 24 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:46,406] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-2 in 11 milliseconds for epoch 24, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:46,407] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-20 in 11 milliseconds for epoch 24, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:46,498] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-38 in 102 milliseconds for epoch 24, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:46,499] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-8 in 103 milliseconds for epoch 24, of which 103 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:46,500] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-26 in 103 milliseconds for epoch 24, of which 102 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:46,501] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-44 in 104 milliseconds for epoch 24, of which 103 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:46,501] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-14 in 104 milliseconds for epoch 24, of which 104 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:46,502] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-32 in 105 milliseconds for epoch 24, of which 105 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:49,358] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:06:49,606] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:06:49,686] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:06:49,689] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:06:49,690] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:06:49,704] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:06:49,709] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:49,709] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:49,709] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:49,709] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:49,709] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:49,709] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:49,709] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:49,709] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:49,709] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:49,709] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:49,710] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:49,710] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:49,710] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:49,710] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:49,710] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:49,710] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:49,710] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:49,710] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:49,722] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:49,726] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:06:49,731] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:49,735] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:06:49,740] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:49,741] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:49,744] INFO Socket connection established, initiating session, client: /127.0.0.1:57932, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:49,752] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad003a, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:49,756] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:06:49,827] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:06:49,969] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:06:49,974] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:06:50,031] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:06:50,042] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:06:50,096] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:50,098] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:50,100] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:50,101] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:50,140] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:06:50,144] INFO Skipping recovery for all logs in /tmp/kafka-logs-4 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:06:50,222] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:50,251] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-24, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 93ms (1/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:06:50,257] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:50,261] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-12, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (2/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:06:50,266] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:50,271] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-30, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (3/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:06:50,276] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:50,281] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-36, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (4/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:06:50,286] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:50,289] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-42, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:06:50,296] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:50,300] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-0, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (6/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:06:50,306] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:50,309] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-0.783bcff9861845a599f7764eceb8c7d2-delete, topicId=p9wUrT5ySYuWIhJ6i536_w, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (7/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:06:50,315] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:50,320] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-18, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (8/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:06:50,325] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:50,328] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-6, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:06:50,333] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:50,336] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-48, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (10/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:06:50,339] INFO Loaded 10 logs in 199ms. (kafka.log.LogManager)
[2022-05-15 18:06:50,340] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:06:50,341] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:06:50,573] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:50,706] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:06:50,709] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.Acceptor)
[2022-05-15 18:06:50,733] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:06:50,738] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:50,754] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:50,755] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:50,757] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:50,758] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:50,769] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:06:50,824] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:06:50,842] INFO Stat of the created znode at /brokers/ids/4 is: 2730,2730,1652634410834,1652634410834,1,0,0,72057641293905978,192,0,2730
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:06:50,843] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://joao:9096, czxid (broker epoch): 2730 (kafka.zk.KafkaZkClient)
[2022-05-15 18:06:50,906] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:50,912] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:50,914] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:50,929] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:50,943] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:50,970] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:06:50,981] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:06:50,981] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:06:51,004] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:51,020] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:06:51,038] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:06:51,043] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:06:51,044] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:06:51,048] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:06:51,048] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:06:51,048] INFO Kafka startTimeMs: 1652634411044 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:06:51,051] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2022-05-15 18:06:51,143] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:51,153] INFO [Partition __consumer_offsets-18 broker=4] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:51,153] INFO [Partition __consumer_offsets-36 broker=4] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:51,153] INFO [Partition __consumer_offsets-6 broker=4] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:51,153] INFO [Partition __consumer_offsets-24 broker=4] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:51,153] INFO [Partition __consumer_offsets-42 broker=4] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:51,154] INFO [Partition __consumer_offsets-12 broker=4] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:51,154] INFO [Partition __consumer_offsets-30 broker=4] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:51,155] INFO [Partition __consumer_offsets-0 broker=4] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:51,155] INFO [Partition __consumer_offsets-48 broker=4] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:51,184] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:51,186] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-12, __consumer_offsets-42, __consumer_offsets-18) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:06:51,222] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 18 in epoch 28 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:51,225] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 28 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:51,226] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 36 in epoch 28 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:51,227] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 28 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:51,227] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 6 in epoch 28 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:51,227] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 28 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:51,227] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 24 in epoch 28 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:51,227] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 28 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:51,227] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 42 in epoch 28 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:51,227] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 28 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:51,227] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 12 in epoch 28 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:51,227] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 28 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:51,227] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 30 in epoch 28 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:51,227] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 28 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:51,227] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 0 in epoch 28 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:51,227] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 28 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:51,227] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 48 in epoch 28 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:51,227] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 28 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:51,235] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-18 in 9 milliseconds for epoch 28, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:51,236] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-36 in 9 milliseconds for epoch 28, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:51,237] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-6 in 10 milliseconds for epoch 28, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:51,237] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-24 in 10 milliseconds for epoch 28, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:51,237] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-42 in 10 milliseconds for epoch 28, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:51,238] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-12 in 11 milliseconds for epoch 28, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:51,238] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-30 in 11 milliseconds for epoch 28, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:51,239] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-0 in 12 milliseconds for epoch 28, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:51,239] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-48 in 12 milliseconds for epoch 28, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:54,275] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:06:54,524] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:06:54,601] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:06:54,604] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:06:54,605] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:06:54,620] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:06:54,626] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:54,626] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:54,626] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:54,626] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:54,626] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:54,626] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:54,627] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:54,627] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:54,627] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:54,627] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:54,627] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:54,627] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:54,627] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:54,627] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:54,627] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:54,627] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:54,627] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:54,627] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:54,629] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:06:54,641] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:06:54,645] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:54,650] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:06:54,654] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:54,654] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:54,658] INFO Socket connection established, initiating session, client: /127.0.0.1:57934, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:54,664] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad003b, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:06:54,668] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:06:54,740] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:06:54,878] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:06:54,882] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:06:54,945] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:06:54,957] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:06:55,008] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:55,009] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:55,012] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:55,013] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:06:55,053] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:06:55,057] INFO Skipping recovery for all logs in /tmp/kafka-logs-5 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:06:55,139] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:55,167] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-46, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 95ms (1/9 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:06:55,174] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:55,178] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-10, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (2/9 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:06:55,185] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:55,190] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-28, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (3/9 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:06:55,207] INFO Deleted producer state snapshot /tmp/kafka-logs-5/__consumer_offsets-22/00000000000000041030.snapshot (kafka.log.SnapshotFile)
[2022-05-15 18:06:55,209] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Loading producer state till offset 41063 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:55,209] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 41063 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:55,211] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-22/00000000000000041063.snapshot,41063)' (kafka.log.ProducerStateManager)
[2022-05-15 18:06:55,220] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Producer state recovery took 11ms for snapshot load and 0ms for segment recovery from offset 41063 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:55,226] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-22, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=41063) with 1 segments in 35ms (4/9 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:06:55,231] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:55,236] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-16, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (5/9 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:06:55,243] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:55,247] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-0.d0038cb97f28474fa784aa562da7ae1b-delete, topicId=p9wUrT5ySYuWIhJ6i536_w, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (6/9 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:06:55,259] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Loading producer state till offset 18252 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:55,259] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 18252 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:55,259] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-40/00000000000000018252.snapshot,18252)' (kafka.log.ProducerStateManager)
[2022-05-15 18:06:55,260] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 18252 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:55,263] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-40, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=18252) with 1 segments in 16ms (7/9 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:06:55,269] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:55,274] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-34, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (8/9 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:06:55,280] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:06:55,283] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-4, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/9 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:06:55,286] INFO Loaded 9 logs in 233ms. (kafka.log.LogManager)
[2022-05-15 18:06:55,287] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:06:55,289] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:06:55,537] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:55,688] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:06:55,693] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.Acceptor)
[2022-05-15 18:06:55,729] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:06:55,737] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:55,756] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:55,758] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:55,759] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:55,761] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:55,773] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:06:55,843] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:06:55,870] INFO Stat of the created znode at /brokers/ids/5 is: 2755,2755,1652634415860,1652634415860,1,0,0,72057641293905979,192,0,2755
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:06:55,872] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://joao:9097, czxid (broker epoch): 2755 (kafka.zk.KafkaZkClient)
[2022-05-15 18:06:55,964] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:55,971] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:55,973] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:55,994] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:56,018] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:56,033] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:06:56,039] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:06:56,039] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:06:56,065] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:06:56,089] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:06:56,109] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:06:56,115] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:06:56,116] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:06:56,124] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:06:56,124] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:06:56,124] INFO Kafka startTimeMs: 1652634416116 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:06:56,127] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2022-05-15 18:06:56,242] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:56,246] INFO [Partition __consumer_offsets-34 broker=5] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:56,247] INFO [Partition __consumer_offsets-4 broker=5] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:56,247] INFO [Partition __consumer_offsets-22 broker=5] Log loaded for partition __consumer_offsets-22 with initial high watermark 41063 (kafka.cluster.Partition)
[2022-05-15 18:06:56,247] INFO [Partition __consumer_offsets-40 broker=5] Log loaded for partition __consumer_offsets-40 with initial high watermark 18252 (kafka.cluster.Partition)
[2022-05-15 18:06:56,247] INFO [Partition __consumer_offsets-10 broker=5] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:56,248] INFO [Partition __consumer_offsets-28 broker=5] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:56,249] INFO [Partition __consumer_offsets-46 broker=5] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:56,250] INFO [Partition __consumer_offsets-16 broker=5] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:06:56,251] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:06:56,282] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:06:56,320] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 34 in epoch 28 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:56,322] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 28 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:56,324] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 4 in epoch 28 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:56,325] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 28 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:56,325] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 22 in epoch 28 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:56,325] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 28 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:56,325] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 40 in epoch 28 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:56,326] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 28 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:56,326] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 10 in epoch 28 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:56,326] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 28 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:56,326] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 28 in epoch 28 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:56,326] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 28 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:56,326] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 46 in epoch 28 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:56,326] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 28 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:56,326] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 16 in epoch 28 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:56,326] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 28 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:56,335] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-34 in 11 milliseconds for epoch 28, of which 5 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:56,335] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-4 in 10 milliseconds for epoch 28, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:56,367] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-9fa5abef-fdc9-4c05-8f09-7f9780632837, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:06:56,382] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-ed3a6d0d-54c4-4b54-b4a4-a5d0ecba6f8e, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:06:56,383] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-1038faf2-d998-4707-9799-897de83d6136, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:06:56,383] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-b283a5ee-70be-4bf9-b41c-74e089f12e34, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:06:56,383] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-360d1581-f79b-41e6-82d3-fe3577615014, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:06:56,383] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-9e173d1e-b47a-4b16-9874-bf5d2688c730, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:06:56,383] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-81fafa38-80dc-43ea-ac6c-e398b06565dc, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:06:56,417] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-d15976bc-df63-4682-8583-fd67cbb1d9df, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:06:56,418] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-a0d7c5c7-e384-4339-b0be-414878362e3e, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:06:56,418] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-ee781f71-f1c3-46d7-bd93-d90a4fe359ff, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:06:56,418] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-78575c72-7be8-4563-b114-53b271a8ef70, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:06:56,418] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-0287b15c-1acd-4475-b9ce-b994aebeeff2, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:06:56,419] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-45d54f6e-f1d8-43f7-8ace-1db96ac0cfac, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:06:56,502] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-954ef0dc-d124-405b-9bb6-119086dd08c0, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:06:56,503] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-3f51cd43-28ab-4459-969e-211543e6cd72, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:06:56,503] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-4b8634e2-92f3-4603-97c5-35df7219bd84, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 4. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:06:56,506] INFO [GroupCoordinator 5]: Loading group metadata for consumer with generation 4 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:06:56,513] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-22 in 188 milliseconds for epoch 28, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:56,545] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-40 in 219 milliseconds for epoch 28, of which 188 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:56,546] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-10 in 220 milliseconds for epoch 28, of which 219 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:56,547] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-28 in 220 milliseconds for epoch 28, of which 220 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:56,547] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-46 in 221 milliseconds for epoch 28, of which 221 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:06:56,548] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-16 in 222 milliseconds for epoch 28, of which 221 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:07:00,064] INFO Creating topic Sensor with configuration {min.insync.replicas=2} and initial partition assignment HashMap(0 -> ArrayBuffer(4, 3, 0), 1 -> ArrayBuffer(2, 0, 5), 2 -> ArrayBuffer(3, 5, 1)) (kafka.zk.AdminZkClient)
[2022-05-15 18:07:00,109] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:07:00,111] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:07:00,112] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:07:00,123] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:07:00,124] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:07:00,125] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:07:00,126] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:07:00,127] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:07:00,127] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:07:00,128] INFO Created log for partition Sensor-0 in /tmp/kafka-logs/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:07:00,129] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-2/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:07:00,129] INFO [Partition Sensor-0 broker=0] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 18:07:00,130] INFO [Partition Sensor-0 broker=0] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:07:00,131] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-4/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:07:00,133] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-3/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:07:00,133] INFO [Partition Sensor-0 broker=4] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 18:07:00,133] INFO [Partition Sensor-1 broker=2] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 18:07:00,134] INFO [Partition Sensor-0 broker=4] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:07:00,134] INFO [Partition Sensor-1 broker=2] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:07:00,134] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-1/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:07:00,135] INFO [Partition Sensor-2 broker=3] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 18:07:00,135] INFO [Partition Sensor-2 broker=3] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:07:00,135] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-5/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:07:00,136] INFO [Partition Sensor-2 broker=1] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 18:07:00,136] INFO [Partition Sensor-2 broker=1] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:07:00,137] INFO [Partition Sensor-2 broker=5] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 18:07:00,137] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:07:00,137] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:07:00,137] INFO [Partition Sensor-2 broker=5] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:07:00,139] INFO Created log for partition Sensor-1 in /tmp/kafka-logs/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:07:00,139] INFO [Partition Sensor-1 broker=0] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 18:07:00,139] INFO [Partition Sensor-1 broker=0] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:07:00,139] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:07:00,146] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:07:00,149] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-5/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:07:00,149] INFO [Partition Sensor-1 broker=5] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 18:07:00,150] INFO [Partition Sensor-1 broker=5] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:07:00,150] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:07:00,153] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:07:00,154] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-3/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:07:00,154] INFO [Partition Sensor-0 broker=3] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 18:07:00,155] INFO [Partition Sensor-0 broker=3] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:07:00,156] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:07:00,167] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:07:00,171] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 4 for partitions Map(Sensor-0 -> InitialFetchState(Some(dVRCsKtiRiy-k0VgICiGjQ),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:07:00,171] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:07:00,174] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:07:00,175] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:07:00,175] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions Map(Sensor-1 -> InitialFetchState(Some(dVRCsKtiRiy-k0VgICiGjQ),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:07:00,175] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:07:00,177] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 3 for partitions Map(Sensor-2 -> InitialFetchState(Some(dVRCsKtiRiy-k0VgICiGjQ),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:07:00,178] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:07:00,178] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:07:00,180] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:07:00,180] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:07:00,182] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:07:00,183] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:07:00,185] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 2 for partitions Map(Sensor-1 -> InitialFetchState(Some(dVRCsKtiRiy-k0VgICiGjQ),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:07:00,187] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 4 for partitions Map(Sensor-0 -> InitialFetchState(Some(dVRCsKtiRiy-k0VgICiGjQ),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:07:00,188] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:07:00,189] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:07:00,190] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 3 for partitions Map(Sensor-2 -> InitialFetchState(Some(dVRCsKtiRiy-k0VgICiGjQ),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:07:00,190] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:07:00,190] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:07:00,192] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:07:00,192] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:07:00,193] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:07:30,443] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=1052494, lastModifiedTime=1652633765061, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:07:30,446] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=1052494, lastModifiedTime=1652633765061, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:07:30,451] INFO Deleted log /tmp/kafka-logs/Sensor-0.f347012a743244e68bd164ee66f3de06-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:07:30,453] INFO Deleted offset index /tmp/kafka-logs/Sensor-0.f347012a743244e68bd164ee66f3de06-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:07:30,460] INFO Deleted time index /tmp/kafka-logs/Sensor-0.f347012a743244e68bd164ee66f3de06-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:07:30,471] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs/Sensor-0.f347012a743244e68bd164ee66f3de06-delete. (kafka.log.LogManager)
[2022-05-15 18:07:41,517] INFO [GroupCoordinator 5]: Member consumer-consumer-1-4b8634e2-92f3-4603-97c5-35df7219bd84 in group consumer has failed, removing it from the group (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:07:41,527] INFO [GroupCoordinator 5]: Preparing to rebalance group consumer in state PreparingRebalance with old generation 4 (__consumer_offsets-22) (reason: removing member consumer-consumer-1-4b8634e2-92f3-4603-97c5-35df7219bd84 on heartbeat expiration) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:07:41,532] INFO [GroupCoordinator 5]: Group consumer with generation 5 is now empty (__consumer_offsets-22) (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:07:50,316] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=1052494, lastModifiedTime=1652633765061, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:07:50,319] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=1052494, lastModifiedTime=1652633765061, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:07:50,324] INFO Deleted log /tmp/kafka-logs-4/Sensor-0.783bcff9861845a599f7764eceb8c7d2-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:07:50,325] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-0.783bcff9861845a599f7764eceb8c7d2-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:07:50,331] INFO Deleted time index /tmp/kafka-logs-4/Sensor-0.783bcff9861845a599f7764eceb8c7d2-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:07:50,338] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-4/Sensor-0.783bcff9861845a599f7764eceb8c7d2-delete. (kafka.log.LogManager)
[2022-05-15 18:07:55,254] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=1052494, lastModifiedTime=1652633765057, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:07:55,256] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=1052494, lastModifiedTime=1652633765057, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:07:55,262] INFO Deleted log /tmp/kafka-logs-5/Sensor-0.d0038cb97f28474fa784aa562da7ae1b-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:07:55,264] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-0.d0038cb97f28474fa784aa562da7ae1b-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:07:55,271] INFO Deleted time index /tmp/kafka-logs-5/Sensor-0.d0038cb97f28474fa784aa562da7ae1b-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:07:55,277] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-5/Sensor-0.d0038cb97f28474fa784aa562da7ae1b-delete. (kafka.log.LogManager)
[2022-05-15 18:16:36,613] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: Sensor-2, Sensor-1, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:36,616] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: Sensor-2, Sensor-1, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:36,616] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: Sensor-2, Sensor-1, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:36,616] INFO [GroupCoordinator 4]: Removed 0 offsets associated with deleted partitions: Sensor-2, Sensor-1, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:36,618] INFO [GroupMetadataManager brokerId=5] Group consumer transitioned to Dead in generation 5 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:36,618] INFO [GroupMetadataManager brokerId=3] Group consumer-group transitioned to Dead in generation 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:36,626] INFO [GroupCoordinator 3]: Removed 3 offsets associated with deleted partitions: Sensor-2, Sensor-1, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:36,626] INFO [GroupCoordinator 5]: Removed 0 offsets associated with deleted partitions: Sensor-2, Sensor-1, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:36,644] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:36,644] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:36,644] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:36,645] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:36,646] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:36,646] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:36,646] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-2, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:36,646] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:36,646] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:36,646] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-2, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:36,647] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:36,647] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-2, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:36,652] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:16:36,653] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:36,653] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:36,654] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:36,653] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:16:36,654] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:36,654] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:36,655] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:16:36,655] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:36,656] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:16:36,657] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1950 due to node 2 being disconnected (elapsed time since creation: 255ms, elapsed time since send: 255ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:36,657] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:36,657] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=2041478575, epoch=1950) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:16:36,658] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:16:36,658] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 2296 due to node 4 being disconnected (elapsed time since creation: 373ms, elapsed time since send: 373ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:36,658] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:36,659] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:16:36,660] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1959 due to node 3 being disconnected (elapsed time since creation: 170ms, elapsed time since send: 170ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:36,660] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1950 due to node 2 being disconnected (elapsed time since creation: 260ms, elapsed time since send: 260ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:36,659] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=94059607, epoch=2296) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:16:36,663] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:16:36,664] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:16:36,660] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=804863834, epoch=1959) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:16:36,665] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:16:36,665] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:16:36,661] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1570476856, epoch=1950) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:16:36,664] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:36,666] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 2298 due to node 4 being disconnected (elapsed time since creation: 5ms, elapsed time since send: 5ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:36,666] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=1124164997, epoch=2298) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:16:36,666] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:16:36,666] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:16:36,666] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:16:36,666] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:16:36,668] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:36,668] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:16:36,668] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:36,669] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-4/Sensor-0.b9b05feda85246369d4eee833f2e8efd-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:16:36,671] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-2, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:36,671] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:16:36,672] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:36,672] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1959 due to node 3 being disconnected (elapsed time since creation: 197ms, elapsed time since send: 197ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:36,671] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-2, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:36,672] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=911691853, epoch=1959) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:16:36,673] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:16:36,673] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:16:36,674] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:36,674] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:36,675] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:36,676] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-2, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:36,678] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs/Sensor-0.26078ada2b0e463cbfba4a8e70b5ab8b-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:16:36,678] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-2/Sensor-1.3585e503ed8c44ee95c18d3fe2b13596-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:16:36,681] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs/Sensor-1.518fc7036b4a4cac903c2d3cf2865ba1-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:16:36,686] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-1/Sensor-2.1fb4122dbdb045629c9015859498f59a-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:16:36,688] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-5/Sensor-2.ca323550a1b448bf82bd004f90669180-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:16:36,689] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-3/Sensor-2.4496ab99284d48e8a081417b8b6898e1-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:16:36,690] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-5/Sensor-1.dda0a108d9c24128a0571a8d02a8c405-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:16:36,692] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-3/Sensor-0.ed393a4d299447908f33cfef5cad963f-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:16:39,994] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:16:39,994] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:16:39,994] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:16:39,994] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:16:39,994] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:16:39,994] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:16:39,996] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:16:39,996] INFO [KafkaServer id=5] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:16:39,996] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:16:39,997] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:16:39,998] INFO [KafkaServer id=5] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:16:39,998] INFO [KafkaServer id=4] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:16:39,996] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:16:39,996] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:16:40,002] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:16:40,002] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:16:39,999] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:16:40,006] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:16:40,018] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 14ms (kafka.server.KafkaServer)
[2022-05-15 18:16:40,021] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:16:40,020] INFO [KafkaServer id=3] Controlled shutdown request returned successfully after 13ms (kafka.server.KafkaServer)
[2022-05-15 18:16:40,021] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:16:40,021] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:16:40,022] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:16:40,023] INFO [KafkaServer id=5] Controlled shutdown request returned successfully after 11ms (kafka.server.KafkaServer)
[2022-05-15 18:16:40,023] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:16:40,023] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:16:40,023] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:16:40,025] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:16:40,026] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:16:40,026] INFO [KafkaServer id=4] Controlled shutdown request returned successfully after 13ms (kafka.server.KafkaServer)
[2022-05-15 18:16:40,027] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:16:40,026] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 12ms (kafka.server.KafkaServer)
[2022-05-15 18:16:40,027] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:16:40,032] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 16ms (kafka.server.KafkaServer)
[2022-05-15 18:16:40,033] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:16:40,036] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:16:40,036] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:16:40,037] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:16:40,038] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:16:40,036] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:16:40,038] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:16:40,039] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:16:40,039] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:16:40,040] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:16:40,041] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:16:40,039] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:16:40,040] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:16:40,040] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:16:40,044] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:16:40,044] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:16:40,046] INFO [data-plane Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:16:40,047] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:16:40,048] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:16:40,050] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:16:40,049] INFO [data-plane Kafka Request Handler on Broker 5], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:16:40,050] INFO [data-plane Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:16:40,052] INFO [data-plane Kafka Request Handler on Broker 4], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:16:40,054] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,054] INFO [data-plane Kafka Request Handler on Broker 5], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:16:40,057] INFO [data-plane Kafka Request Handler on Broker 4], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:16:40,058] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:16:40,059] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:16:40,059] INFO [ExpirationReaper-3-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,059] INFO [ExpirationReaper-5-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,061] INFO [ExpirationReaper-4-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,062] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:16:40,062] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:16:40,063] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:16:40,066] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:16:40,066] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,069] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,072] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,072] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,073] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:16:40,073] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,104] INFO [ExpirationReaper-5-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,103] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,104] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,104] INFO [ExpirationReaper-5-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,104] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:16:40,105] INFO [KafkaApi-5] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:16:40,105] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,107] INFO [ExpirationReaper-5-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,152] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,152] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,154] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:16:40,156] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:16:40,156] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:16:40,157] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:16:40,157] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:16:40,159] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:16:40,161] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:40,161] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,162] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,162] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,162] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,178] INFO [ExpirationReaper-3-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,178] INFO [ExpirationReaper-3-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,179] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:16:40,181] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,195] INFO [ExpirationReaper-5-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,195] INFO [ExpirationReaper-5-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,200] INFO [TransactionCoordinator id=5] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:16:40,202] INFO [Transaction State Manager 5]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:16:40,202] INFO [Transaction Marker Channel Manager 5]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:16:40,202] INFO [Transaction Marker Channel Manager 5]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:16:40,203] INFO [Transaction Marker Channel Manager 5]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:16:40,204] INFO [TransactionCoordinator id=5] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:16:40,204] INFO [GroupCoordinator 5]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:40,205] INFO [ExpirationReaper-5-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,205] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,205] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,206] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:16:40,208] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:16:40,208] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:16:40,209] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:16:40,209] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:16:40,210] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:16:40,210] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:40,211] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,244] INFO [ExpirationReaper-4-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,244] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,244] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,244] INFO [ExpirationReaper-4-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,245] INFO [KafkaApi-4] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:16:40,245] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:16:40,246] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,246] INFO [ExpirationReaper-4-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,261] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,261] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,264] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:16:40,266] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:16:40,266] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:16:40,267] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:16:40,267] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:16:40,269] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:16:40,270] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:40,270] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,309] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,309] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,312] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:16:40,313] INFO [ExpirationReaper-5-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,313] INFO [ExpirationReaper-5-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,314] INFO [ExpirationReaper-5-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,314] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:16:40,314] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:16:40,315] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:16:40,315] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:16:40,317] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:16:40,318] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:40,319] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,326] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,326] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,326] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,345] INFO [ExpirationReaper-4-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,345] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,345] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,345] INFO [ExpirationReaper-4-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,346] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:40,346] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:16:40,347] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:16:40,347] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:16:40,347] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:16:40,347] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:40,349] INFO [TransactionCoordinator id=4] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:16:40,349] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:40,350] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:40,350] INFO [Transaction State Manager 4]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:16:40,350] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:40,350] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,350] INFO [Transaction Marker Channel Manager 4]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:16:40,351] INFO [Transaction Marker Channel Manager 4]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:16:40,351] INFO [Transaction Marker Channel Manager 4]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:16:40,352] INFO [TransactionCoordinator id=4] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:16:40,353] INFO [GroupCoordinator 4]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:40,353] INFO [ExpirationReaper-4-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,358] INFO [ExpirationReaper-4-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,358] INFO [ExpirationReaper-4-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,359] INFO [ExpirationReaper-4-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,369] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,369] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,370] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,380] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,380] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,381] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:40,382] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:16:40,382] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:16:40,382] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:16:40,382] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:16:40,384] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:40,385] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:40,386] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:40,387] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:40,387] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,428] INFO [ExpirationReaper-5-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,428] INFO [ExpirationReaper-5-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,430] INFO [GroupCoordinator 5]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:40,431] INFO [ReplicaManager broker=5] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:16:40,431] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:16:40,431] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:16:40,431] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:16:40,433] INFO [ReplicaFetcherManager on broker 5] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:40,434] INFO [ReplicaFetcherManager on broker 5] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:40,435] INFO [ReplicaAlterLogDirsManager on broker 5] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:40,436] INFO [ReplicaAlterLogDirsManager on broker 5] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:40,436] INFO [ExpirationReaper-5-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,449] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,449] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,449] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,461] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,461] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,462] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,504] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,504] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,505] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:40,507] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:16:40,507] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:16:40,507] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:16:40,507] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:16:40,509] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:40,510] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:40,511] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:40,511] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:40,512] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,530] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,530] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,531] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,558] INFO [ExpirationReaper-4-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,559] INFO [ExpirationReaper-4-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,559] INFO [GroupCoordinator 4]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:40,560] INFO [ReplicaManager broker=4] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:16:40,561] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:16:40,561] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:16:40,561] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:16:40,562] INFO [ReplicaFetcherManager on broker 4] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:40,564] INFO [ReplicaFetcherManager on broker 4] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:40,565] INFO [ReplicaAlterLogDirsManager on broker 4] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:40,565] INFO [ReplicaAlterLogDirsManager on broker 4] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:40,565] INFO [ExpirationReaper-4-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,569] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,569] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,569] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,569] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,569] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,569] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,589] INFO [ExpirationReaper-4-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,589] INFO [ExpirationReaper-4-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,589] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,589] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,590] INFO [ExpirationReaper-4-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,590] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,606] INFO [ExpirationReaper-5-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,607] INFO [ExpirationReaper-5-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,607] INFO [ExpirationReaper-5-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,644] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,644] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,645] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:40,646] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:16:40,647] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:16:40,647] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:16:40,647] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:16:40,648] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:40,656] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:40,657] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:40,657] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:16:40,657] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,715] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,715] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,716] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,769] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,770] INFO [ExpirationReaper-4-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,770] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,770] INFO [ExpirationReaper-4-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,770] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,770] INFO [ExpirationReaper-4-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,778] INFO [ExpirationReaper-5-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,778] INFO [ExpirationReaper-5-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,778] INFO [ExpirationReaper-5-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,789] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,789] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,790] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,821] INFO [ExpirationReaper-4-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,821] INFO [ExpirationReaper-4-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,822] INFO [ExpirationReaper-4-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,848] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,848] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,849] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,881] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,881] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,882] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,889] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,889] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,890] INFO [ExpirationReaper-3-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,909] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,909] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,910] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,970] INFO [ExpirationReaper-4-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,970] INFO [ExpirationReaper-4-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,970] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,970] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,970] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,970] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,975] INFO [ReplicaManager broker=4] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:16:40,976] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:16:40,976] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:16:40,976] INFO [ExpirationReaper-5-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,976] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,976] INFO [ExpirationReaper-5-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,977] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,977] INFO [ExpirationReaper-5-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,977] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,977] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,977] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,977] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,977] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,978] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,978] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,979] INFO [ExpirationReaper-5-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,979] INFO [ExpirationReaper-5-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:40,980] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:16:40,980] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:16:40,980] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:16:40,980] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,981] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,981] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,981] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,981] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,981] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,981] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,981] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,981] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,982] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:16:40,982] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:16:40,982] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:16:40,982] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:16:40,982] INFO [ReplicaManager broker=5] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:16:40,983] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:16:40,983] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:16:40,983] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,984] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,984] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,985] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:16:40,986] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,986] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,986] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:40,987] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:16:40,988] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:16:41,001] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:16:41,002] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:16:41,002] INFO [ProducerStateManager partition=__consumer_offsets-22] Wrote producer snapshot at offset 41065 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-05-15 18:16:41,006] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:16:41,006] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:16:41,006] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:16:41,006] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:16:41,006] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:16:41,013] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:16:41,014] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:16:41,014] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:16:41,014] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:16:41,014] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:16:41,015] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:16:41,015] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:16:41,015] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:16:41,016] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:16:41,019] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:16:41,019] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:16:41,019] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:16:41,020] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:16:41,081] INFO [ExpirationReaper-3-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:41,081] INFO [ExpirationReaper-3-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:41,085] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:16:41,086] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:41,087] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:41,087] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:41,089] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:16:41,090] INFO [Controller id=3, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:41,091] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:41,090] INFO [Controller id=3, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:41,091] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:41,092] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:41,092] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:16:41,093] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:16:41,094] WARN [Controller id=3, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:41,094] WARN [Controller id=3, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:41,095] INFO [Controller id=3, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:41,096] INFO [Controller id=3, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:41,105] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:41,105] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:41,109] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:16:41,109] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:41,110] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:41,110] INFO Session: 0x100000b00ad003a closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:41,110] INFO EventThread shut down for session: 0x100000b00ad003a (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:16:41,110] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:41,112] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:16:41,112] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:41,112] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:16:41,113] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:41,113] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:41,113] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:41,114] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:16:41,115] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:16:41,116] INFO [ProducerStateManager partition=__consumer_offsets-38] Wrote producer snapshot at offset 49254 with 0 producer ids in 3 ms. (kafka.log.ProducerStateManager)
[2022-05-15 18:16:41,118] INFO Session: 0x100000b00ad0038 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:41,119] INFO Session: 0x100000b00ad0036 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:41,120] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:16:41,120] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:41,118] INFO EventThread shut down for session: 0x100000b00ad0038 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:16:41,120] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:16:41,121] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:41,119] INFO EventThread shut down for session: 0x100000b00ad0036 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:16:41,123] INFO Session: 0x100000b00ad003b closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:41,124] INFO EventThread shut down for session: 0x100000b00ad003b (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:16:41,125] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:16:41,126] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:41,129] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:16:41,139] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:16:41,148] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:16:41,148] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:16:41,148] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:16:41,149] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:16:41,186] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:41,186] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:41,186] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:41,196] INFO [Controller id=3, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:41,196] INFO [Controller id=3, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:41,196] WARN [Controller id=3, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:41,196] WARN [Controller id=3, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:41,197] INFO [Controller id=3, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:41,197] INFO [Controller id=3, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:41,227] INFO [Controller id=3, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:41,229] INFO [Controller id=3, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:16:41,231] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:16:41,231] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:16:41,231] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:16:41,231] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:16:41,254] INFO Session: 0x100000b00ad0037 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:41,254] INFO EventThread shut down for session: 0x100000b00ad0037 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:16:41,256] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:16:41,257] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:41,261] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:41,261] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:41,262] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:41,265] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:41,265] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:41,266] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:41,334] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:41,334] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:41,334] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:41,335] INFO Session: 0x100000b00ad0039 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:41,335] INFO EventThread shut down for session: 0x100000b00ad0039 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:16:41,337] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:16:41,338] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,095] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,095] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,095] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,098] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,098] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,098] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,139] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,139] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,139] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,142] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,142] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,142] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,144] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,144] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,144] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,164] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,164] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,164] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,186] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,186] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,187] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,262] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,262] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,262] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,266] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,266] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,267] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:16:42,288] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:16:42,289] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:16:42,289] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:16:42,290] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:16:42,290] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:16:42,291] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:16:42,291] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:16:42,334] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,335] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:42,335] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:43,097] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:43,097] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:43,097] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:43,144] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:43,144] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:43,146] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:16:43,163] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:16:43,164] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:43,164] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:43,164] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:43,164] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:16:43,164] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:16:43,164] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:16:43,166] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:16:43,167] INFO App info kafka.server for 3 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:16:43,167] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:16:43,175] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:43,175] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:43,176] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:43,186] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:43,187] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:43,187] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:43,334] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:43,334] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:43,334] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:43,340] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:43,340] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:43,342] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:16:43,365] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:16:43,366] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:16:43,366] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:16:43,366] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:16:43,368] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:16:43,369] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:16:43,369] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:16:44,095] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:44,095] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:44,096] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:16:44,120] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:16:44,121] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:16:44,121] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:16:44,121] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:16:44,122] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:16:44,123] INFO App info kafka.server for 5 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:16:44,123] INFO [KafkaServer id=5] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:16:44,164] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:44,164] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:44,166] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:16:44,185] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:16:44,186] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:16:44,186] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:16:44,186] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:16:44,187] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:44,187] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:44,187] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:16:44,188] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:16:44,189] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:16:44,189] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:16:44,214] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:16:44,214] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:16:44,215] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:16:44,215] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:16:44,216] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:16:44,217] INFO App info kafka.server for 4 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:16:44,217] INFO [KafkaServer id=4] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:16:45,638] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:16:45,645] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:16:45,645] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:16:45,645] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:16:45,645] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:16:45,647] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 18:16:45,647] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 18:16:45,647] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 18:16:45,647] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-15 18:16:45,650] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-15 18:16:45,664] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:16:45,665] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:16:45,665] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:16:45,665] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:16:45,665] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:16:45,666] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-15 18:16:45,678] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@6156496 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-15 18:16:45,681] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 18:16:45,692] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,692] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,692] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,692] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,692] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,692] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,692] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,692] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,692] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,692] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,693] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,694] INFO Server environment:host.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,694] INFO Server environment:java.version=11.0.15 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,694] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,694] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,694] INFO Server environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,694] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,694] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,694] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,694] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,694] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,694] INFO Server environment:os.version=5.13.0-40-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,695] INFO Server environment:user.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,695] INFO Server environment:user.home=/home/joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,695] INFO Server environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,695] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,695] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,695] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,695] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,695] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,695] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,695] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,695] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,695] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,695] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,696] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-15 18:16:45,698] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,698] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,699] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 18:16:45,700] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 18:16:45,701] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:16:45,701] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:16:45,701] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:16:45,701] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:16:45,701] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:16:45,701] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:16:45,704] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,704] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,704] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:16:45,712] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 18:16:45,713] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 18:16:45,714] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 18:16:45,718] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 18:16:45,719] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:459)
	at java.base/sun.nio.ch.Net.bind(Net.java:448)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:676)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:158)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:112)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:67)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:140)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:90)
[2022-05-15 18:16:45,721] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-15 18:16:45,723] ERROR Exiting JVM with code 1 (org.apache.zookeeper.util.ServiceUtils)
[2022-05-15 18:16:50,692] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:16:50,973] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:16:51,058] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:16:51,062] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:16:51,063] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:16:51,079] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:16:51,084] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:51,085] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:51,085] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:51,085] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:51,085] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:51,085] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:51,085] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:51,085] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:51,085] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:51,085] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:51,086] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:51,086] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:51,086] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:51,086] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:51,086] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:51,086] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:51,086] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:51,086] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:51,099] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:51,105] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:16:51,111] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:16:51,115] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:16:51,122] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:16:51,123] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:16:51,128] INFO Socket connection established, initiating session, client: /127.0.0.1:57936, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:16:51,136] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad003c, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:16:51,141] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:16:51,213] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:16:51,358] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:16:51,364] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:16:51,410] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:16:51,419] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:16:51,469] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:51,470] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:51,472] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:51,474] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:51,515] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:16:51,521] INFO Skipping recovery for all logs in /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:16:51,609] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:16:51,641] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-21, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 103ms (1/10 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:16:51,664] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 17940 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:16:51,664] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 17940 (kafka.log.UnifiedLog$)
[2022-05-15 18:16:51,666] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs/__consumer_offsets-39/00000000000000017940.snapshot,17940)' (kafka.log.ProducerStateManager)
[2022-05-15 18:16:51,674] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Producer state recovery took 10ms for snapshot load and 0ms for segment recovery from offset 17940 (kafka.log.UnifiedLog$)
[2022-05-15 18:16:51,679] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-39, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=17940) with 1 segments in 37ms (2/10 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:16:51,684] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:16:51,691] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-15, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (3/10 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:16:51,698] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:16:51,703] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-45, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (4/10 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:16:51,708] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:16:51,714] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-1.518fc7036b4a4cac903c2d3cf2865ba1-delete, topicId=dVRCsKtiRiy-k0VgICiGjQ, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (5/10 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:16:51,719] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:16:51,724] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-33, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (6/10 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:16:51,729] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:16:51,733] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-27, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (7/10 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:16:51,738] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:16:51,744] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-3, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (8/10 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:16:51,750] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:16:51,755] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-9, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (9/10 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:16:51,761] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:16:51,765] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-0.26078ada2b0e463cbfba4a8e70b5ab8b-delete, topicId=dVRCsKtiRiy-k0VgICiGjQ, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (10/10 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:16:51,767] INFO Loaded 10 logs in 252ms. (kafka.log.LogManager)
[2022-05-15 18:16:51,768] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:16:51,769] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:16:52,051] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:52,208] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:16:52,213] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-15 18:16:52,246] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:16:52,254] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:52,274] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:52,275] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:52,277] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:52,278] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:52,292] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:16:52,350] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:16:52,371] INFO Stat of the created znode at /brokers/ids/0 is: 2852,2852,1652635012362,1652635012362,1,0,0,72057641293905980,192,0,2852
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:16:52,373] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://joao:9092, czxid (broker epoch): 2852 (kafka.zk.KafkaZkClient)
[2022-05-15 18:16:52,445] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:52,450] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:52,451] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:52,473] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:52,490] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:52,524] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:16:52,531] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:16:52,531] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:16:52,571] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:52,595] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:16:52,615] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:16:52,622] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:16:52,622] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:16:52,629] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:16:52,629] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:16:52,629] INFO Kafka startTimeMs: 1652635012623 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:16:52,632] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-15 18:16:52,728] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:16:52,729] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:16:52,729] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 17940 (kafka.cluster.Partition)
[2022-05-15 18:16:52,729] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:16:52,729] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:16:52,729] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:16:52,730] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:16:52,730] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:16:52,760] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:52,764] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:52,825] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-3, __consumer_offsets-15, __consumer_offsets-39, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:52,863] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:52,865] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:52,867] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:52,867] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:52,867] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:52,867] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:52,867] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:52,867] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:52,867] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:52,867] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:52,867] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:52,867] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:52,867] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:52,867] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:52,867] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:52,867] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:52,877] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 11 milliseconds for epoch 18, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:52,879] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 11 milliseconds for epoch 18, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:52,969] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 102 milliseconds for epoch 18, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:52,970] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 103 milliseconds for epoch 18, of which 102 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:52,971] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 104 milliseconds for epoch 18, of which 103 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:52,972] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 105 milliseconds for epoch 18, of which 104 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:52,972] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 105 milliseconds for epoch 18, of which 105 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:52,973] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 106 milliseconds for epoch 18, of which 106 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:55,666] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:16:55,941] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:16:56,024] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:16:56,028] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:16:56,029] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:16:56,044] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:16:56,048] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:56,048] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:56,048] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:56,048] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:56,048] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:56,048] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:56,049] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:56,049] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:56,049] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:56,049] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:56,049] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:56,049] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:56,049] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:56,049] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:56,049] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:56,049] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:56,049] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:56,049] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:56,053] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:16:56,058] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:16:56,063] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:16:56,080] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:16:56,086] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:16:56,087] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:16:56,092] INFO Socket connection established, initiating session, client: /127.0.0.1:57938, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:16:56,099] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad003d, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:16:56,103] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:16:56,171] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:16:56,303] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:16:56,310] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:16:56,354] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:16:56,363] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:16:56,410] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:56,412] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:56,414] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:56,415] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:16:56,458] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:16:56,464] INFO Skipping recovery for all logs in /tmp/kafka-logs-1 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:16:56,545] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:16:56,573] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-17, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 91ms (1/9 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:16:56,578] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:16:56,583] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-35, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (2/9 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:16:56,588] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:16:56,594] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-41, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (3/9 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:16:56,598] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:16:56,605] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-2.1fb4122dbdb045629c9015859498f59a-delete, topicId=dVRCsKtiRiy-k0VgICiGjQ, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (4/9 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:16:56,610] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:16:56,614] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-29, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (5/9 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:16:56,620] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:16:56,624] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-11, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (6/9 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:16:56,628] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:16:56,631] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-23, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/9 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:16:56,636] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:16:56,640] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-47, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (8/9 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:16:56,645] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:16:56,648] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-5, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/9 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:16:56,650] INFO Loaded 9 logs in 192ms. (kafka.log.LogManager)
[2022-05-15 18:16:56,651] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:16:56,652] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:16:56,924] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:57,028] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:16:57,033] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-15 18:16:57,060] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:16:57,066] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:57,085] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:57,086] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:57,088] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:57,089] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:57,101] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:16:57,168] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:16:57,192] INFO Stat of the created znode at /brokers/ids/1 is: 2920,2920,1652635017183,1652635017183,1,0,0,72057641293905981,192,0,2920
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:16:57,193] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://joao:9093, czxid (broker epoch): 2920 (kafka.zk.KafkaZkClient)
[2022-05-15 18:16:57,273] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:57,280] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:57,281] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:57,298] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:57,312] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:57,339] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:16:57,346] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:16:57,346] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:16:57,371] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:16:57,390] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:16:57,411] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:16:57,417] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:16:57,418] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:16:57,423] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:16:57,423] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:16:57,423] INFO Kafka startTimeMs: 1652635017418 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:16:57,425] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-15 18:16:57,537] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:57,539] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:16:57,540] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:16:57,540] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:16:57,540] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:16:57,540] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:16:57,541] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:16:57,541] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:16:57,541] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:16:57,569] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-5, __consumer_offsets-29, __consumer_offsets-41, __consumer_offsets-23) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:16:57,572] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:16:57,604] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 27 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:57,605] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 27 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:57,607] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 27 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:57,607] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 27 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:57,607] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 27 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:57,607] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 27 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:57,607] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 27 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:57,607] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 27 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:57,607] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 27 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:57,607] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 27 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:57,607] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 27 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:57,607] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 27 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:57,607] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 27 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:57,607] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 27 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:57,607] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 27 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:16:57,607] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 27 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:57,615] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 9 milliseconds for epoch 27, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:57,616] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 9 milliseconds for epoch 27, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:57,617] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 9 milliseconds for epoch 27, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:57,617] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 10 milliseconds for epoch 27, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:57,618] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 11 milliseconds for epoch 27, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:57,619] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 12 milliseconds for epoch 27, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:57,620] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 13 milliseconds for epoch 27, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:16:57,620] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 13 milliseconds for epoch 27, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:00,543] INFO Creating topic Sensor with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(0)) (kafka.zk.AdminZkClient)
[2022-05-15 18:17:00,558] INFO Creating topic Sensor with configuration {} and initial partition assignment HashMap(0 -> ArrayBuffer(1)) (kafka.zk.AdminZkClient)
[2022-05-15 18:17:00,620] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:17:00,652] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:00,661] INFO Created log for partition Sensor-0 in /tmp/kafka-logs/Sensor-0 with properties {} (kafka.log.LogManager)
[2022-05-15 18:17:00,664] INFO [Partition Sensor-0 broker=0] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 18:17:00,665] INFO [Partition Sensor-0 broker=0] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:01,522] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:17:01,847] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:17:01,943] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:17:01,948] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:17:01,949] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:17:01,963] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:17:01,970] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:01,970] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:01,970] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:01,970] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:01,970] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:01,970] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:01,970] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:01,970] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:01,970] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:01,970] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:01,970] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:01,970] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:01,970] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:01,970] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:01,970] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:01,971] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:01,971] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:01,971] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:01,982] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:01,988] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:17:01,994] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:17:02,002] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:17:02,007] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:17:02,008] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:17:02,013] INFO Socket connection established, initiating session, client: /127.0.0.1:57940, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:17:02,020] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad003e, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:17:02,024] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:17:02,098] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:17:02,239] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:17:02,245] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:17:02,297] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:17:02,307] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:17:02,360] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:17:02,361] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:17:02,363] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:17:02,365] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:17:02,409] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:17:02,414] INFO Skipping recovery for all logs in /tmp/kafka-logs-2 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:17:02,500] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:02,528] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-49, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 100ms (1/10 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:17:02,534] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:02,538] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-19, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (2/10 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:17:02,546] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:02,553] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-7, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (3/10 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:17:02,560] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:02,566] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-13, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (4/10 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:17:02,571] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:02,574] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-37, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/10 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:17:02,581] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:02,585] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-43, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (6/10 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:17:02,590] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:02,594] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-1.3585e503ed8c44ee95c18d3fe2b13596-delete, topicId=dVRCsKtiRiy-k0VgICiGjQ, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (7/10 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:17:02,599] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:02,603] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-1, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (8/10 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:17:02,608] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:02,612] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-31, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/10 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:17:02,617] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:02,621] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-25, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (10/10 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:17:02,624] INFO Loaded 10 logs in 215ms. (kafka.log.LogManager)
[2022-05-15 18:17:02,625] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:17:02,626] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:17:03,002] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:17:03,224] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:17:03,229] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-15 18:17:03,276] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:17:03,288] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:17:03,313] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:03,315] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:03,317] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:03,318] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:03,336] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:17:03,424] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:17:03,451] INFO Stat of the created znode at /brokers/ids/2 is: 2952,2952,1652635023440,1652635023440,1,0,0,72057641293905982,192,0,2952
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:17:03,453] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://joao:9094, czxid (broker epoch): 2952 (kafka.zk.KafkaZkClient)
[2022-05-15 18:17:03,553] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:03,563] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:03,564] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:03,590] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:03,606] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:03,634] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:17:03,646] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:17:03,646] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:17:03,676] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:03,705] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:17:03,730] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:17:03,737] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:17:03,737] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:17:03,743] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:17:03,743] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:17:03,743] INFO Kafka startTimeMs: 1652635023738 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:17:03,747] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-15 18:17:03,884] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:03,885] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:03,885] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:03,886] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:03,886] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:03,886] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:03,886] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:03,887] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:03,887] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:03,893] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:17:03,917] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-7, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:17:03,918] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:17:03,958] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 27 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:03,959] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 27 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:03,961] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 27 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:03,961] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 27 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:03,961] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 27 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:03,961] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 27 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:03,961] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 27 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:03,961] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 27 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:03,961] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 27 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:03,961] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 27 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:03,961] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 27 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:03,961] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 27 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:03,961] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 27 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:03,961] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 27 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:03,961] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 27 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:03,961] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 27 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:03,962] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 27 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:03,962] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 27 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:03,969] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 9 milliseconds for epoch 27, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:03,969] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 8 milliseconds for epoch 27, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:03,969] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 8 milliseconds for epoch 27, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:03,970] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 9 milliseconds for epoch 27, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:03,970] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 9 milliseconds for epoch 27, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:03,970] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 9 milliseconds for epoch 27, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:03,971] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 10 milliseconds for epoch 27, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:03,971] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 10 milliseconds for epoch 27, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:03,971] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 9 milliseconds for epoch 27, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:06,182] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:17:06,902] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:17:07,147] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:17:07,153] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:17:07,154] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:17:07,201] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:17:07,230] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:07,231] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:07,231] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:07,231] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:07,232] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:07,232] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:07,233] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:07,234] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:07,234] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:07,234] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:07,234] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:07,234] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:07,234] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:07,234] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:07,234] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:07,234] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:07,234] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:07,235] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:07,243] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:07,257] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:17:07,277] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:17:07,283] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:17:07,343] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:17:07,348] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:17:07,362] INFO Socket connection established, initiating session, client: /127.0.0.1:57942, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:17:07,391] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad003f, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:17:07,400] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:17:07,595] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:17:07,974] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:17:07,984] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:17:08,107] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:17:08,128] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:17:08,242] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:17:08,245] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:17:08,248] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:17:08,250] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:17:08,339] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:17:08,351] INFO Skipping recovery for all logs in /tmp/kafka-logs-3 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:17:08,542] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:08,599] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-14, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 211ms (1/10 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:17:08,608] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:08,616] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-2.4496ab99284d48e8a081417b8b6898e1-delete, topicId=dVRCsKtiRiy-k0VgICiGjQ, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 16ms (2/10 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:17:08,647] INFO Deleted producer state snapshot /tmp/kafka-logs-3/__consumer_offsets-38/00000000000000028503.snapshot (kafka.log.SnapshotFile)
[2022-05-15 18:17:08,651] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Loading producer state till offset 49254 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:08,652] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Reloading from producer snapshot and rebuilding producer state from offset 49254 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:08,657] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-3/__consumer_offsets-38/00000000000000049254.snapshot,49254)' (kafka.log.ProducerStateManager)
[2022-05-15 18:17:08,671] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Producer state recovery took 19ms for snapshot load and 0ms for segment recovery from offset 49254 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:08,679] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-38, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=49254) with 1 segments in 62ms (3/10 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:17:08,688] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:08,695] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-8, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (4/10 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:17:08,704] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:08,712] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-2, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (5/10 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:17:08,720] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:08,726] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-26, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (6/10 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:17:08,733] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:08,741] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-20, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 14ms (7/10 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:17:08,748] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:08,754] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-32, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (8/10 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:17:08,761] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:08,766] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-0.ed393a4d299447908f33cfef5cad963f-delete, topicId=dVRCsKtiRiy-k0VgICiGjQ, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (9/10 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:17:08,772] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:08,779] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-44, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (10/10 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:17:08,784] INFO Loaded 10 logs in 445ms. (kafka.log.LogManager)
[2022-05-15 18:17:08,786] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:17:08,789] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:17:09,244] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:17:09,553] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:17:09,561] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-05-15 18:17:09,614] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:17:09,629] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:17:09,667] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:09,670] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:09,673] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:09,678] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:09,706] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:17:09,854] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:17:09,897] INFO Stat of the created znode at /brokers/ids/3 is: 2977,2977,1652635029883,1652635029883,1,0,0,72057641293905983,192,0,2977
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:17:09,899] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://joao:9095, czxid (broker epoch): 2977 (kafka.zk.KafkaZkClient)
[2022-05-15 18:17:10,041] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:10,049] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:10,051] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:10,074] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:10,092] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:10,144] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:17:10,150] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:17:10,150] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:17:10,188] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:10,218] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:17:10,260] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:17:10,270] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:17:10,271] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:17:10,278] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:17:10,280] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:17:10,280] INFO Kafka startTimeMs: 1652635030271 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:17:10,283] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-05-15 18:17:10,440] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:17:10,462] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:17:10,517] INFO [Partition __consumer_offsets-2 broker=3] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:10,518] INFO [Partition __consumer_offsets-20 broker=3] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:10,519] INFO [Partition __consumer_offsets-38 broker=3] Log loaded for partition __consumer_offsets-38 with initial high watermark 49254 (kafka.cluster.Partition)
[2022-05-15 18:17:10,520] INFO [Partition __consumer_offsets-8 broker=3] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:10,520] INFO [Partition __consumer_offsets-26 broker=3] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:10,520] INFO [Partition __consumer_offsets-44 broker=3] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:10,521] INFO [Partition __consumer_offsets-14 broker=3] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:10,521] INFO [Partition __consumer_offsets-32 broker=3] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:10,576] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-26, __consumer_offsets-32, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:17:10,638] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 2 in epoch 26 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:10,641] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 26 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:10,647] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 20 in epoch 26 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:10,651] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 26 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:10,652] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 38 in epoch 26 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:10,652] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 26 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:10,653] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 8 in epoch 26 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:10,653] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 26 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:10,653] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 26 in epoch 26 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:10,653] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 26 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:10,653] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 44 in epoch 26 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:10,653] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 26 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:10,653] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 14 in epoch 26 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:10,653] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 26 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:10,653] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 32 in epoch 26 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:10,653] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 26 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:10,667] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-2 in 23 milliseconds for epoch 26, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:10,668] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-20 in 16 milliseconds for epoch 26, of which 16 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:10,964] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-38 in 312 milliseconds for epoch 26, of which 17 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:10,965] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-8 in 312 milliseconds for epoch 26, of which 311 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:10,966] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-26 in 313 milliseconds for epoch 26, of which 312 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:10,966] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-44 in 313 milliseconds for epoch 26, of which 313 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:10,966] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-14 in 313 milliseconds for epoch 26, of which 313 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:10,967] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-32 in 314 milliseconds for epoch 26, of which 314 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:11,425] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:17:11,982] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:17:12,177] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:17:12,185] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:17:12,187] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:17:12,226] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:17:12,235] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:12,235] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:12,235] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:12,235] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:12,235] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:12,235] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:12,236] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:12,236] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:12,236] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:12,236] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:12,236] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:12,236] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:12,236] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:12,236] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:12,237] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:12,237] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:12,237] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:12,237] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:12,240] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:12,252] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:17:12,276] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:17:12,284] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:17:12,290] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:17:12,290] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:17:12,298] INFO Socket connection established, initiating session, client: /127.0.0.1:57944, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:17:12,309] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0040, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:17:12,317] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:17:12,453] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:17:12,738] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:17:12,749] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:17:12,831] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:17:12,846] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:17:12,920] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:17:12,921] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:17:12,924] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:17:12,925] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:17:12,990] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:17:12,999] INFO Skipping recovery for all logs in /tmp/kafka-logs-4 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:17:13,134] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:13,176] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-24, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 156ms (1/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:17:13,192] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:13,196] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-12, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (2/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:17:13,202] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:13,208] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-30, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (3/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:17:13,218] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:13,224] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-36, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (4/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:17:13,232] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:13,238] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-0.b9b05feda85246369d4eee833f2e8efd-delete, topicId=dVRCsKtiRiy-k0VgICiGjQ, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (5/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:17:13,246] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:13,253] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-42, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 15ms (6/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:17:13,260] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:13,264] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-0, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (7/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:17:13,271] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:13,278] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-18, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (8/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:17:13,285] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:13,290] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-6, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (9/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:17:13,297] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:13,304] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-48, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 13ms (10/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:17:13,308] INFO Loaded 10 logs in 317ms. (kafka.log.LogManager)
[2022-05-15 18:17:13,309] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:17:13,312] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:17:13,742] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:17:13,965] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:17:13,972] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.Acceptor)
[2022-05-15 18:17:14,018] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:17:14,028] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:17:14,054] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:14,056] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:14,059] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:14,061] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:14,082] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:17:14,204] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:17:14,237] INFO Stat of the created znode at /brokers/ids/4 is: 3001,3001,1652635034221,1652635034221,1,0,0,72057641293905984,192,0,3001
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:17:14,240] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://joao:9096, czxid (broker epoch): 3001 (kafka.zk.KafkaZkClient)
[2022-05-15 18:17:14,331] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:14,340] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:14,342] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:14,365] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:14,385] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:14,428] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:17:14,433] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:17:14,434] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:17:14,473] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:14,506] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:17:14,539] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:17:14,549] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:17:14,550] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:17:14,556] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:17:14,556] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:17:14,556] INFO Kafka startTimeMs: 1652635034550 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:17:14,560] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2022-05-15 18:17:14,665] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:17:14,716] INFO [Partition __consumer_offsets-18 broker=4] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:14,716] INFO [Partition __consumer_offsets-36 broker=4] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:14,717] INFO [Partition __consumer_offsets-6 broker=4] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:14,717] INFO [Partition __consumer_offsets-24 broker=4] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:14,717] INFO [Partition __consumer_offsets-42 broker=4] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:14,717] INFO [Partition __consumer_offsets-12 broker=4] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:14,717] INFO [Partition __consumer_offsets-30 broker=4] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:14,718] INFO [Partition __consumer_offsets-0 broker=4] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:14,718] INFO [Partition __consumer_offsets-48 broker=4] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:14,734] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:17:14,756] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-12, __consumer_offsets-42, __consumer_offsets-18) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:17:14,804] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 18 in epoch 31 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:14,806] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 31 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:14,808] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 36 in epoch 31 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:14,808] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 31 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:14,808] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 6 in epoch 31 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:14,809] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 31 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:14,809] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 24 in epoch 31 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:14,809] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 31 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:14,809] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 42 in epoch 31 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:14,809] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 31 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:14,809] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 12 in epoch 31 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:14,809] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 31 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:14,809] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 30 in epoch 31 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:14,809] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 31 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:14,809] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 0 in epoch 31 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:14,809] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 31 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:14,809] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 48 in epoch 31 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:14,809] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 31 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:14,820] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-18 in 12 milliseconds for epoch 31, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:14,820] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-36 in 12 milliseconds for epoch 31, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:14,821] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-6 in 12 milliseconds for epoch 31, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:14,822] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-24 in 13 milliseconds for epoch 31, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:14,822] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-42 in 13 milliseconds for epoch 31, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:14,822] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-12 in 13 milliseconds for epoch 31, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:14,822] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-30 in 13 milliseconds for epoch 31, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:14,823] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-0 in 14 milliseconds for epoch 31, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:14,823] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-48 in 14 milliseconds for epoch 31, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:15,738] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:17:16,055] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:17:16,145] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:17:16,149] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:17:16,150] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:17:16,167] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:17:16,172] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:16,173] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:16,173] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:16,173] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:16,173] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:16,173] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:16,174] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:16,174] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:16,174] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:16,174] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:16,174] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:16,174] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:16,174] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:16,174] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:16,174] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:16,174] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:16,174] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:16,174] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:16,184] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:17:16,190] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:17:16,194] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:17:16,199] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:17:16,205] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:17:16,205] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:17:16,209] INFO Socket connection established, initiating session, client: /127.0.0.1:57946, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:17:16,216] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0041, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:17:16,219] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:17:16,290] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:17:16,426] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:17:16,431] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:17:16,482] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:17:16,490] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:17:16,544] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:17:16,546] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:17:16,548] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:17:16,550] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:17:16,597] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:17:16,601] INFO Skipping recovery for all logs in /tmp/kafka-logs-5 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:17:16,673] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:16,692] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-46, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 76ms (1/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:17:16,698] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:16,701] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-10, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (2/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:17:16,705] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:16,710] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-1.dda0a108d9c24128a0571a8d02a8c405-delete, topicId=dVRCsKtiRiy-k0VgICiGjQ, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (3/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:17:16,715] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:16,718] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-28, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:17:16,731] INFO Deleted producer state snapshot /tmp/kafka-logs-5/__consumer_offsets-22/00000000000000041063.snapshot (kafka.log.SnapshotFile)
[2022-05-15 18:17:16,733] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Loading producer state till offset 41065 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:16,734] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 41065 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:16,735] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-22/00000000000000041065.snapshot,41065)' (kafka.log.ProducerStateManager)
[2022-05-15 18:17:16,742] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Producer state recovery took 8ms for snapshot load and 0ms for segment recovery from offset 41065 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:16,746] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-22, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=41065) with 1 segments in 28ms (5/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:17:16,751] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:16,755] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-16, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (6/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:17:16,759] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:16,763] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-2.ca323550a1b448bf82bd004f90669180-delete, topicId=dVRCsKtiRiy-k0VgICiGjQ, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:17:16,771] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Loading producer state till offset 18252 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:16,771] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 18252 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:16,771] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-40/00000000000000018252.snapshot,18252)' (kafka.log.ProducerStateManager)
[2022-05-15 18:17:16,772] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 18252 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:16,777] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-40, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=18252) with 1 segments in 14ms (8/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:17:16,782] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:16,785] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-34, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:17:16,790] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:17:16,793] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-4, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (10/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:17:16,795] INFO Loaded 10 logs in 198ms. (kafka.log.LogManager)
[2022-05-15 18:17:16,796] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:17:16,797] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:17:17,075] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:17:17,207] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:17:17,212] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.Acceptor)
[2022-05-15 18:17:17,240] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:17:17,246] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:17:17,268] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:17,269] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:17,271] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:17,272] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:17,283] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:17:17,346] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:17:17,366] INFO Stat of the created znode at /brokers/ids/5 is: 3026,3026,1652635037356,1652635037356,1,0,0,72057641293905985,192,0,3026
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:17:17,367] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://joao:9097, czxid (broker epoch): 3026 (kafka.zk.KafkaZkClient)
[2022-05-15 18:17:17,440] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:17,445] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:17,446] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:17,465] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:17,478] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:17,504] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:17:17,509] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:17:17,509] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:17:17,533] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:17:17,551] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:17:17,575] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:17:17,579] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:17:17,580] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:17:17,584] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:17:17,584] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:17:17,584] INFO Kafka startTimeMs: 1652635037580 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:17:17,587] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2022-05-15 18:17:17,651] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:17:17,688] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:17:17,693] INFO [Partition __consumer_offsets-34 broker=5] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:17,694] INFO [Partition __consumer_offsets-4 broker=5] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:17,694] INFO [Partition __consumer_offsets-22 broker=5] Log loaded for partition __consumer_offsets-22 with initial high watermark 41065 (kafka.cluster.Partition)
[2022-05-15 18:17:17,695] INFO [Partition __consumer_offsets-40 broker=5] Log loaded for partition __consumer_offsets-40 with initial high watermark 18252 (kafka.cluster.Partition)
[2022-05-15 18:17:17,696] INFO [Partition __consumer_offsets-10 broker=5] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:17,696] INFO [Partition __consumer_offsets-28 broker=5] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:17,696] INFO [Partition __consumer_offsets-46 broker=5] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:17,697] INFO [Partition __consumer_offsets-16 broker=5] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:17:17,722] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:17:17,760] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 34 in epoch 31 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:17,762] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 31 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:17,764] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 4 in epoch 31 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:17,765] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 31 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:17,765] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 22 in epoch 31 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:17,765] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 31 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:17,765] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 40 in epoch 31 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:17,765] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 31 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:17,765] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 10 in epoch 31 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:17,765] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 31 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:17,765] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 28 in epoch 31 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:17,765] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 31 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:17,765] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 46 in epoch 31 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:17,765] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 31 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:17,765] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 16 in epoch 31 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:17:17,765] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 31 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:17,775] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-34 in 11 milliseconds for epoch 31, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:17,776] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-4 in 11 milliseconds for epoch 31, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:17,808] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-9fa5abef-fdc9-4c05-8f09-7f9780632837, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:17:17,821] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-ed3a6d0d-54c4-4b54-b4a4-a5d0ecba6f8e, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:17:17,821] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-1038faf2-d998-4707-9799-897de83d6136, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:17:17,821] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-b283a5ee-70be-4bf9-b41c-74e089f12e34, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:17:17,821] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-360d1581-f79b-41e6-82d3-fe3577615014, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:17:17,821] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-9e173d1e-b47a-4b16-9874-bf5d2688c730, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:17:17,821] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-81fafa38-80dc-43ea-ac6c-e398b06565dc, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:17:17,857] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-d15976bc-df63-4682-8583-fd67cbb1d9df, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:17:17,857] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-a0d7c5c7-e384-4339-b0be-414878362e3e, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:17:17,857] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-ee781f71-f1c3-46d7-bd93-d90a4fe359ff, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:17:17,857] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-78575c72-7be8-4563-b114-53b271a8ef70, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:17:17,858] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-0287b15c-1acd-4475-b9ce-b994aebeeff2, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:17:17,858] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-45d54f6e-f1d8-43f7-8ace-1db96ac0cfac, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:17:17,924] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-954ef0dc-d124-405b-9bb6-119086dd08c0, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:17:17,925] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-3f51cd43-28ab-4459-969e-211543e6cd72, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:17:17,926] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-4b8634e2-92f3-4603-97c5-35df7219bd84, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 4. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:17:17,927] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-22 in 162 milliseconds for epoch 31, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:17,956] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-40 in 191 milliseconds for epoch 31, of which 162 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:17,957] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-10 in 191 milliseconds for epoch 31, of which 191 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:17,957] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-28 in 192 milliseconds for epoch 31, of which 192 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:17,957] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-46 in 192 milliseconds for epoch 31, of which 192 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:17,958] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-16 in 193 milliseconds for epoch 31, of which 192 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:17:51,719] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=218257, lastModifiedTime=1652634646492, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:17:51,721] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=218257, lastModifiedTime=1652634646492, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:17:51,725] INFO Deleted log /tmp/kafka-logs/Sensor-1.518fc7036b4a4cac903c2d3cf2865ba1-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:17:51,725] INFO Deleted offset index /tmp/kafka-logs/Sensor-1.518fc7036b4a4cac903c2d3cf2865ba1-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:17:51,728] INFO Deleted time index /tmp/kafka-logs/Sensor-1.518fc7036b4a4cac903c2d3cf2865ba1-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:17:51,734] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs/Sensor-1.518fc7036b4a4cac903c2d3cf2865ba1-delete. (kafka.log.LogManager)
[2022-05-15 18:17:51,766] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=307857, lastModifiedTime=1652634669004, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:17:51,767] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=307857, lastModifiedTime=1652634669004, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:17:51,769] INFO Deleted log /tmp/kafka-logs/Sensor-0.26078ada2b0e463cbfba4a8e70b5ab8b-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:17:51,769] INFO Deleted offset index /tmp/kafka-logs/Sensor-0.26078ada2b0e463cbfba4a8e70b5ab8b-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:17:51,769] INFO Deleted time index /tmp/kafka-logs/Sensor-0.26078ada2b0e463cbfba4a8e70b5ab8b-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:17:51,770] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs/Sensor-0.26078ada2b0e463cbfba4a8e70b5ab8b-delete. (kafka.log.LogManager)
[2022-05-15 18:17:56,609] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=220595, lastModifiedTime=1652634647612, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:17:56,611] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=220595, lastModifiedTime=1652634647612, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:17:56,615] INFO Deleted log /tmp/kafka-logs-1/Sensor-2.1fb4122dbdb045629c9015859498f59a-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:17:56,616] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-2.1fb4122dbdb045629c9015859498f59a-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:17:56,619] INFO Deleted time index /tmp/kafka-logs-1/Sensor-2.1fb4122dbdb045629c9015859498f59a-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:17:56,622] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-1/Sensor-2.1fb4122dbdb045629c9015859498f59a-delete. (kafka.log.LogManager)
[2022-05-15 18:18:02,599] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=218257, lastModifiedTime=1652634646492, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:18:02,601] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=218257, lastModifiedTime=1652634646492, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:18:02,605] INFO Deleted log /tmp/kafka-logs-2/Sensor-1.3585e503ed8c44ee95c18d3fe2b13596-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:18:02,606] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-1.3585e503ed8c44ee95c18d3fe2b13596-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:18:02,608] INFO Deleted time index /tmp/kafka-logs-2/Sensor-1.3585e503ed8c44ee95c18d3fe2b13596-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:18:02,611] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-2/Sensor-1.3585e503ed8c44ee95c18d3fe2b13596-delete. (kafka.log.LogManager)
[2022-05-15 18:18:07,074] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:07,076] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:07,076] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:07,077] INFO [GroupCoordinator 4]: Removed 0 offsets associated with deleted partitions: Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:07,077] INFO [GroupCoordinator 3]: Removed 0 offsets associated with deleted partitions: Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:07,079] INFO [GroupCoordinator 5]: Removed 0 offsets associated with deleted partitions: Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:07,088] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:07,088] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:18:07,095] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:07,095] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:18:07,103] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs/Sensor-0.3e0e09ffd86a4d3eafb0faa3652f418e-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:18:08,620] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=220595, lastModifiedTime=1652634647608, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:18:08,622] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=220595, lastModifiedTime=1652634647608, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:18:08,626] INFO Deleted log /tmp/kafka-logs-3/Sensor-2.4496ab99284d48e8a081417b8b6898e1-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:18:08,626] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-2.4496ab99284d48e8a081417b8b6898e1-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:18:08,629] INFO Deleted time index /tmp/kafka-logs-3/Sensor-2.4496ab99284d48e8a081417b8b6898e1-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:18:08,633] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-3/Sensor-2.4496ab99284d48e8a081417b8b6898e1-delete. (kafka.log.LogManager)
[2022-05-15 18:18:08,766] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=307857, lastModifiedTime=1652634669004, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:18:08,767] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=307857, lastModifiedTime=1652634669004, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:18:08,768] INFO Deleted log /tmp/kafka-logs-3/Sensor-0.ed393a4d299447908f33cfef5cad963f-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:18:08,768] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-0.ed393a4d299447908f33cfef5cad963f-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:18:08,768] INFO Deleted time index /tmp/kafka-logs-3/Sensor-0.ed393a4d299447908f33cfef5cad963f-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:18:08,769] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-3/Sensor-0.ed393a4d299447908f33cfef5cad963f-delete. (kafka.log.LogManager)
[2022-05-15 18:18:10,446] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:18:10,446] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:18:10,446] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:18:10,446] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:18:10,446] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:18:10,447] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:18:10,449] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:18:10,449] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:18:10,450] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:18:10,450] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:18:10,449] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:18:10,449] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:18:10,452] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:18:10,452] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:18:10,452] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:18:10,449] INFO [KafkaServer id=5] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:18:10,456] INFO [KafkaServer id=5] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:18:10,457] INFO [KafkaServer id=4] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:18:10,476] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 18ms (kafka.server.KafkaServer)
[2022-05-15 18:18:10,478] INFO [KafkaServer id=5] Controlled shutdown request returned successfully after 8ms (kafka.server.KafkaServer)
[2022-05-15 18:18:10,480] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:10,480] INFO [KafkaServer id=3] Controlled shutdown request returned successfully after 8ms (kafka.server.KafkaServer)
[2022-05-15 18:18:10,481] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 8ms (kafka.server.KafkaServer)
[2022-05-15 18:18:10,481] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:10,481] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:10,482] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 7ms (kafka.server.KafkaServer)
[2022-05-15 18:18:10,482] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:18:10,483] INFO [KafkaServer id=4] Controlled shutdown request returned successfully after 5ms (kafka.server.KafkaServer)
[2022-05-15 18:18:10,484] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:10,485] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:10,485] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:10,486] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:18:10,486] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:10,487] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:10,487] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:10,488] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:18:10,488] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:10,489] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:10,489] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:10,490] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:10,491] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:10,491] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:18:10,491] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:10,491] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:10,491] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:18:10,492] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:10,492] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:10,493] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:18:10,494] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:18:10,493] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:18:10,495] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:18:10,501] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:18:10,502] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:18:10,503] INFO [data-plane Kafka Request Handler on Broker 5], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:18:10,503] INFO [data-plane Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:18:10,505] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,506] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:18:10,508] INFO [data-plane Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:18:10,508] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:18:10,508] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:18:10,509] INFO [data-plane Kafka Request Handler on Broker 5], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:18:10,510] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:18:10,512] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:18:10,512] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:18:10,513] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:18:10,514] INFO [data-plane Kafka Request Handler on Broker 4], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:18:10,517] INFO [ExpirationReaper-5-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,517] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,517] INFO [ExpirationReaper-3-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,517] INFO [data-plane Kafka Request Handler on Broker 4], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:18:10,519] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,520] INFO [ExpirationReaper-4-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,535] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,535] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,536] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:18:10,537] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,575] INFO [ExpirationReaper-5-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,575] INFO [ExpirationReaper-5-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,576] INFO [KafkaApi-5] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:18:10,578] INFO [ExpirationReaper-5-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,613] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,613] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,617] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:10,619] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:18:10,619] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:10,620] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:10,620] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:10,621] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:10,622] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:10,623] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,637] INFO [ExpirationReaper-3-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,637] INFO [ExpirationReaper-3-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,638] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:18:10,639] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,639] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,639] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,639] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,640] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,640] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:18:10,640] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,641] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,644] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,644] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,646] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:18:10,647] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,684] INFO [ExpirationReaper-5-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,684] INFO [ExpirationReaper-5-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,687] INFO [TransactionCoordinator id=5] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:10,688] INFO [Transaction State Manager 5]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:18:10,688] INFO [Transaction Marker Channel Manager 5]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:10,690] INFO [Transaction Marker Channel Manager 5]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:10,690] INFO [Transaction Marker Channel Manager 5]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:10,691] INFO [TransactionCoordinator id=5] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:10,692] INFO [GroupCoordinator 5]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:10,693] INFO [ExpirationReaper-5-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,696] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,696] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,697] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:10,698] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:18:10,698] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:10,699] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:10,699] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:10,700] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:10,700] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:10,701] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,712] INFO [ExpirationReaper-4-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,712] INFO [ExpirationReaper-4-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,713] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,713] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,713] INFO [KafkaApi-4] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:18:10,714] INFO [ExpirationReaper-4-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,716] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:10,717] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:18:10,717] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:10,718] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:10,717] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:10,720] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:10,721] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:10,721] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,737] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,737] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,742] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:10,744] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:18:10,744] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:10,744] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:10,744] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:10,745] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:10,746] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:10,746] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,749] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,749] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,749] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,774] INFO [ExpirationReaper-4-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,774] INFO [ExpirationReaper-4-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,777] INFO [TransactionCoordinator id=4] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:10,779] INFO [Transaction State Manager 4]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:18:10,779] INFO [Transaction Marker Channel Manager 4]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:10,780] INFO [Transaction Marker Channel Manager 4]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:10,780] INFO [Transaction Marker Channel Manager 4]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:10,781] INFO [TransactionCoordinator id=4] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:10,781] INFO [GroupCoordinator 4]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:10,782] INFO [ExpirationReaper-4-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,788] INFO [ExpirationReaper-4-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,787] INFO [ExpirationReaper-4-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,789] INFO [ExpirationReaper-4-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,834] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,834] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,836] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:10,837] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:18:10,838] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:10,839] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:10,839] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:10,840] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:10,841] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:10,841] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:18:10,841] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:18:10,841] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,887] INFO [ExpirationReaper-5-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,887] INFO [ExpirationReaper-5-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,888] INFO [ExpirationReaper-5-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,889] INFO [ExpirationReaper-5-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,889] INFO [ExpirationReaper-5-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,890] INFO [GroupCoordinator 5]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:10,891] INFO [ReplicaManager broker=5] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:18:10,892] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:10,893] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:10,893] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:10,894] INFO [ReplicaFetcherManager on broker 5] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:10,895] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,896] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,897] INFO [ReplicaFetcherManager on broker 5] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:10,897] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,897] INFO [ReplicaAlterLogDirsManager on broker 5] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:18:10,898] INFO [ReplicaAlterLogDirsManager on broker 5] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:18:10,898] INFO [ExpirationReaper-5-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,905] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,905] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,906] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:10,907] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:18:10,907] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:10,908] INFO [ExpirationReaper-5-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,908] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:10,908] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:10,908] INFO [ExpirationReaper-5-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,909] INFO [ExpirationReaper-5-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,909] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:10,910] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:10,910] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:18:10,910] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:18:10,910] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,913] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,913] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,914] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,914] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,914] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,914] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,948] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,948] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,949] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:10,950] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:18:10,950] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:10,951] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:10,951] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:10,953] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:10,954] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:10,955] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:18:10,955] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:18:10,955] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,972] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,972] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,972] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,984] INFO [ExpirationReaper-4-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,984] INFO [ExpirationReaper-4-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:10,986] INFO [GroupCoordinator 4]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:10,986] INFO [ReplicaManager broker=4] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:18:10,987] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:10,987] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:10,987] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:10,988] INFO [ReplicaFetcherManager on broker 4] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:10,989] INFO [ReplicaFetcherManager on broker 4] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:10,990] INFO [ReplicaAlterLogDirsManager on broker 4] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:18:10,990] INFO [ReplicaAlterLogDirsManager on broker 4] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:18:10,990] INFO [ExpirationReaper-4-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,101] INFO [ExpirationReaper-4-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,101] INFO [ExpirationReaper-4-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,102] INFO [ExpirationReaper-4-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,108] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,108] INFO [ExpirationReaper-5-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,108] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,108] INFO [ExpirationReaper-5-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,109] INFO [ExpirationReaper-5-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,110] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:11,111] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:18:11,112] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:11,112] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:11,112] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:11,113] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:11,113] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,113] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,114] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,114] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:11,114] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:18:11,115] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:18:11,115] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,122] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,122] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,123] INFO [ExpirationReaper-3-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,129] INFO [ExpirationReaper-3-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,129] INFO [ExpirationReaper-3-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,133] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:18:11,134] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,134] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,134] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,136] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:18:11,137] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,137] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,137] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,138] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:18:11,139] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:18:11,144] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,144] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,145] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,149] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,149] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,150] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,161] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,161] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,162] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,162] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:18:11,167] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:11,167] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:11,167] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:11,168] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:11,171] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,171] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,172] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,177] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,177] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,177] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,199] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,199] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,199] INFO [Controller id=0, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,199] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,199] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,202] INFO [Controller id=0, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,202] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,202] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,202] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,202] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,202] WARN [Controller id=0, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,202] WARN [Controller id=0, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,202] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,202] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,202] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,202] INFO [Controller id=0, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,203] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,203] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,203] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,203] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,272] INFO EventThread shut down for session: 0x100000b00ad003f (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:11,272] INFO Session: 0x100000b00ad003f closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:11,274] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:11,275] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,296] INFO [ExpirationReaper-4-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,296] INFO [ExpirationReaper-4-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,297] INFO [ExpirationReaper-4-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,303] INFO [Controller id=0, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,303] WARN [Controller id=0, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,303] INFO [Controller id=0, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,303] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,303] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,304] WARN [Controller id=0, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,303] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,304] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,304] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,304] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,304] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,304] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,304] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,305] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,305] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,306] INFO [ExpirationReaper-4-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,306] INFO [ExpirationReaper-4-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,306] INFO [ExpirationReaper-4-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,309] INFO [ExpirationReaper-5-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,309] INFO [ExpirationReaper-5-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,309] INFO [ExpirationReaper-5-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,313] INFO [ExpirationReaper-5-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,313] INFO [ExpirationReaper-5-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,317] INFO [ReplicaManager broker=5] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:18:11,317] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,318] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,318] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,320] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:18:11,320] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,321] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,321] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,321] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:18:11,322] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:18:11,340] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,340] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,341] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,347] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,347] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,348] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,348] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,348] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,350] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:18:11,352] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:18:11,353] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,353] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,353] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,356] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:18:11,356] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:11,357] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:11,357] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,357] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:11,357] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,357] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,358] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:11,358] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:18:11,358] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:18:11,365] INFO [Controller id=0, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,374] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,374] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,379] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:18:11,380] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,381] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,381] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,383] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:18:11,383] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,383] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:18:11,384] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,384] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,385] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:18:11,386] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:18:11,390] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:11,390] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:11,390] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:11,397] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:11,401] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,405] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,405] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,405] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,405] WARN [Controller id=0, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,405] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,405] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,405] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,406] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,406] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,409] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:18:11,416] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:11,417] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:11,417] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:11,418] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:11,420] WARN An exception was thrown while closing send thread for session 0x100000b00ad003e. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x100000b00ad003e, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 18:18:11,426] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,462] INFO EventThread shut down for session: 0x100000b00ad0041 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:11,462] INFO Session: 0x100000b00ad0041 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:11,463] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:11,464] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,500] INFO Session: 0x100000b00ad003d closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:11,500] INFO EventThread shut down for session: 0x100000b00ad003d (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:11,502] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:11,503] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,506] INFO [ExpirationReaper-4-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,506] INFO [ExpirationReaper-4-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,506] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,506] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,507] WARN [Controller id=0, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,507] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,507] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,507] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,510] INFO [ReplicaManager broker=4] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:18:11,511] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,511] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,511] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,513] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:18:11,514] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,515] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,515] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,515] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:18:11,516] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:18:11,524] INFO Session: 0x100000b00ad003e closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:11,524] INFO EventThread shut down for session: 0x100000b00ad003e (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:11,526] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:11,526] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,537] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,537] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,538] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,543] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:18:11,547] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:11,547] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:11,547] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:11,548] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:11,548] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,548] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:11,552] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:18:11,552] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,552] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,552] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,553] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,553] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,553] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,553] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,551] WARN An exception was thrown while closing send thread for session 0x100000b00ad0040. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x100000b00ad0040, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 18:18:11,554] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,554] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,554] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,555] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:18:11,555] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,556] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,556] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:11,556] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:18:11,557] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:18:11,558] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,558] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,558] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,560] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,560] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,561] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:18:11,582] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:18:11,582] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:18:11,583] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:18:11,583] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:18:11,583] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:18:11,586] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:18:11,587] INFO App info kafka.server for 5 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:11,588] INFO [KafkaServer id=5] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:18:11,589] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:18:11,591] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:11,591] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:11,591] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:11,592] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:11,655] INFO EventThread shut down for session: 0x100000b00ad0040 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:11,655] INFO Session: 0x100000b00ad0040 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:11,657] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:11,658] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,696] INFO Session: 0x100000b00ad003c closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:11,696] INFO EventThread shut down for session: 0x100000b00ad003c (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:11,697] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:11,698] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,930] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,930] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,930] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,931] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,931] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,931] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,933] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,933] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,933] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,935] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,935] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:11,936] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:18:11,949] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:18:11,950] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:18:11,950] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:18:11,950] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:18:11,951] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:18:11,952] INFO App info kafka.server for 4 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:11,952] INFO [KafkaServer id=4] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:18:12,253] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:12,253] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:12,253] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:12,258] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:12,258] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:12,259] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:12,373] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:12,373] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:12,374] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:12,426] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:12,426] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:12,426] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:12,481] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:12,481] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:12,481] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:12,483] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:12,483] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:12,483] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:12,488] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:12,488] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:12,488] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:13,258] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:13,258] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:13,259] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:13,261] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:13,261] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:13,264] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:18:13,279] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:18:13,280] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:18:13,280] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:18:13,280] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:18:13,281] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:18:13,282] INFO App info kafka.server for 3 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:13,282] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:18:13,373] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:13,373] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:13,374] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:13,425] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:13,425] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:13,425] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:13,427] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:13,427] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:13,427] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:13,488] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:13,488] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:13,489] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:18:13,509] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:18:13,510] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:18:13,510] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:18:13,510] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:18:13,511] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:18:13,511] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:13,511] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:18:14,374] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:14,374] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:14,375] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:14,395] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:14,395] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:14,397] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:18:14,414] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:18:14,414] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:18:14,414] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:18:14,414] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:18:14,417] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:18:14,417] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:14,418] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:18:14,427] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:14,427] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:14,429] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:18:14,451] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:18:14,451] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:18:14,451] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:18:14,451] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:18:14,453] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:18:14,454] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:14,454] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:18:17,506] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:18:17,512] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:18:17,512] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:18:17,513] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:18:17,513] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:18:17,514] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 18:18:17,514] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 18:18:17,514] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 18:18:17,514] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-15 18:18:17,518] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-15 18:18:17,531] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:18:17,532] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:18:17,532] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:18:17,532] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:18:17,532] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:18:17,532] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-15 18:18:17,544] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@6156496 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-15 18:18:17,547] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 18:18:17,556] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,556] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,556] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,556] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,556] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,556] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,556] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,556] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,556] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,556] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,558] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,558] INFO Server environment:host.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,558] INFO Server environment:java.version=11.0.15 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,558] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,558] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,558] INFO Server environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,558] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,558] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,558] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,558] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,558] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,558] INFO Server environment:os.version=5.13.0-40-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,558] INFO Server environment:user.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,558] INFO Server environment:user.home=/home/joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,558] INFO Server environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,558] INFO Server environment:os.memory.free=489MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,558] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,558] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,558] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,559] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,559] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,559] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,559] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,559] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,559] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,560] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-15 18:18:17,562] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,562] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,564] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 18:18:17,564] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 18:18:17,565] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:18:17,565] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:18:17,565] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:18:17,565] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:18:17,566] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:18:17,566] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:18:17,569] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,569] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,569] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:18:17,576] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 18:18:17,576] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 18:18:17,578] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 18:18:17,582] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 18:18:17,582] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:459)
	at java.base/sun.nio.ch.Net.bind(Net.java:448)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:676)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:158)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:112)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:67)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:140)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:90)
[2022-05-15 18:18:17,585] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-15 18:18:17,587] ERROR Exiting JVM with code 1 (org.apache.zookeeper.util.ServiceUtils)
[2022-05-15 18:18:22,498] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:18:22,747] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:18:22,825] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:18:22,828] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:18:22,829] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:18:22,844] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:22,849] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:22,849] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:22,849] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:22,849] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:22,850] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:22,850] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:22,850] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:22,850] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:22,850] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:22,851] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:22,851] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:22,851] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:22,851] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:22,851] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:22,851] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:22,851] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:22,851] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:22,851] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:22,853] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:22,857] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:18:22,864] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:22,877] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:22,881] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:22,883] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:22,886] INFO Socket connection established, initiating session, client: /127.0.0.1:57948, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:22,893] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0042, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:22,898] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:22,972] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:23,103] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:18:23,108] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:18:23,158] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:18:23,169] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:18:23,216] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:23,217] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:23,219] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:23,220] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:23,254] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:18:23,259] INFO Skipping recovery for all logs in /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:18:23,339] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:23,364] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-21, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 91ms (1/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:18:23,383] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 17940 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:23,384] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 17940 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:23,385] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs/__consumer_offsets-39/00000000000000017940.snapshot,17940)' (kafka.log.ProducerStateManager)
[2022-05-15 18:18:23,390] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Producer state recovery took 6ms for snapshot load and 0ms for segment recovery from offset 17940 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:23,395] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-39, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=17940) with 1 segments in 29ms (2/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:18:23,400] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:23,404] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-15, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (3/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:18:23,410] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:23,415] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-45, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (4/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:18:23,420] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:23,423] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-0.3e0e09ffd86a4d3eafb0faa3652f418e-delete, topicId=69OX0DluT7qesZIqR0c0bQ, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:18:23,428] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:23,431] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-33, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:18:23,435] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:23,439] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-27, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:18:23,444] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:23,449] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-3, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (8/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:18:23,455] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:23,458] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-9, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/9 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:18:23,460] INFO Loaded 9 logs in 207ms. (kafka.log.LogManager)
[2022-05-15 18:18:23,461] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:18:23,463] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:18:23,698] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:23,808] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:18:23,811] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-15 18:18:23,838] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:18:23,843] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:23,859] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:23,860] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:23,862] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:23,864] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:23,875] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:23,920] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:18:23,937] INFO Stat of the created znode at /brokers/ids/0 is: 3106,3106,1652635103929,1652635103929,1,0,0,72057641293905986,192,0,3106
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:18:23,939] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://joao:9092, czxid (broker epoch): 3106 (kafka.zk.KafkaZkClient)
[2022-05-15 18:18:23,998] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:24,003] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:24,004] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:24,018] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:24,034] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:24,064] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:24,068] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:24,068] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:24,095] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:24,117] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:24,138] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:18:24,144] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:18:24,144] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:18:24,150] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:24,150] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:24,150] INFO Kafka startTimeMs: 1652635104145 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:24,154] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-15 18:18:24,207] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:24,247] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:24,250] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-3, __consumer_offsets-15, __consumer_offsets-39, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:24,258] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:24,269] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:24,272] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 17940 (kafka.cluster.Partition)
[2022-05-15 18:18:24,274] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:24,277] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:24,279] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:24,282] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:24,284] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:24,294] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:24,297] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:24,299] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:24,299] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:24,300] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:24,300] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:24,300] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:24,300] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:24,300] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:24,300] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:24,300] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:24,300] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:24,300] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:24,300] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:24,300] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 18 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:24,300] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 18 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:24,313] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 13 milliseconds for epoch 18, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:24,313] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 14 milliseconds for epoch 18, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:24,392] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 92 milliseconds for epoch 18, of which 14 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:24,393] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 93 milliseconds for epoch 18, of which 93 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:24,393] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 93 milliseconds for epoch 18, of which 93 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:24,394] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 94 milliseconds for epoch 18, of which 94 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:24,395] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 95 milliseconds for epoch 18, of which 94 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:24,395] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 95 milliseconds for epoch 18, of which 95 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:27,545] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:18:27,804] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:18:27,884] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:18:27,887] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:18:27,888] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:18:27,901] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:27,905] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:27,905] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:27,905] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:27,905] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:27,906] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:27,906] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:27,906] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:27,906] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:27,906] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:27,906] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:27,906] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:27,906] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:27,906] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:27,906] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:27,906] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:27,906] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:27,906] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:27,906] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:27,908] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:27,913] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:18:27,918] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:27,933] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:27,938] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:27,939] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:27,942] INFO Socket connection established, initiating session, client: /127.0.0.1:57950, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:27,951] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0043, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:27,955] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:28,031] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:28,160] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:18:28,166] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:18:28,221] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:18:28,232] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:18:28,282] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:28,283] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:28,285] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:28,286] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:28,325] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:18:28,329] INFO Skipping recovery for all logs in /tmp/kafka-logs-1 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:18:28,404] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:28,427] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-17, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 84ms (1/8 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:18:28,434] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:28,437] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-35, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (2/8 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:18:28,442] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:28,447] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-41, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (3/8 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:18:28,453] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:28,456] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-29, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (4/8 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:18:28,460] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:28,463] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-11, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (5/8 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:18:28,469] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:28,472] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-23, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/8 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:18:28,476] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:28,481] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-47, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (7/8 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:18:28,486] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:28,490] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-5, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (8/8 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:18:28,494] INFO Loaded 8 logs in 168ms. (kafka.log.LogManager)
[2022-05-15 18:18:28,495] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:18:28,497] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:18:28,744] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:28,885] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:18:28,889] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-15 18:18:28,917] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:18:28,924] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:28,941] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:28,942] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:28,943] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:28,945] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:28,957] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:29,017] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:18:29,041] INFO Stat of the created znode at /brokers/ids/1 is: 3166,3166,1652635109032,1652635109032,1,0,0,72057641293905987,192,0,3166
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:18:29,043] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://joao:9093, czxid (broker epoch): 3166 (kafka.zk.KafkaZkClient)
[2022-05-15 18:18:29,118] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:29,124] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:29,125] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:29,140] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:29,157] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:29,181] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:29,190] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:29,191] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:29,215] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:29,230] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:29,248] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:18:29,255] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:18:29,255] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:18:29,260] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:29,260] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:29,260] INFO Kafka startTimeMs: 1652635109255 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:29,264] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-15 18:18:29,329] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:29,359] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:29,370] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:29,370] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:29,371] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:29,371] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:29,371] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:29,371] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:29,371] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:29,372] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:29,397] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-5, __consumer_offsets-29, __consumer_offsets-41, __consumer_offsets-23) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:29,430] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 30 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:29,432] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 30 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:29,434] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 30 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:29,434] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 30 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:29,434] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 30 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:29,435] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 30 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:29,435] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 30 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:29,435] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 30 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:29,435] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 30 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:29,435] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 30 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:29,435] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 30 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:29,435] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 30 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:29,435] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 30 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:29,435] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 30 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:29,435] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 30 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:29,435] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 30 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:29,441] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 9 milliseconds for epoch 30, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:29,442] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 8 milliseconds for epoch 30, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:29,443] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 8 milliseconds for epoch 30, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:29,443] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 8 milliseconds for epoch 30, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:29,443] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 8 milliseconds for epoch 30, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:29,443] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 8 milliseconds for epoch 30, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:29,444] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 9 milliseconds for epoch 30, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:29,445] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 10 milliseconds for epoch 30, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:32,540] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:18:32,832] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:18:32,915] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:18:32,920] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:18:32,921] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:18:32,936] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:32,940] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:32,940] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:32,940] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:32,940] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:32,940] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:32,940] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:32,941] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:32,941] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:32,941] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:32,942] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:32,942] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:32,942] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:32,942] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:32,942] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:32,942] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:32,942] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:32,942] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:32,942] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:32,945] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:32,951] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:18:32,956] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:32,969] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:32,975] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:32,976] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:32,981] INFO Socket connection established, initiating session, client: /127.0.0.1:57952, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:32,988] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0044, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:32,994] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:33,066] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:33,211] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:18:33,216] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:18:33,267] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:18:33,278] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:18:33,327] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:33,329] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:33,331] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:33,333] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:33,374] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:18:33,379] INFO Skipping recovery for all logs in /tmp/kafka-logs-2 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:18:33,458] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:33,484] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-49, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 90ms (1/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:18:33,490] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:33,495] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-19, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (2/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:18:33,501] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:33,506] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-7, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (3/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:18:33,512] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:33,516] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-13, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (4/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:18:33,522] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:33,526] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-37, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (5/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:18:33,532] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:33,536] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-43, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (6/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:18:33,541] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:33,545] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-1, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:18:33,550] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:33,554] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-31, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (8/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:18:33,560] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:33,563] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-25, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/9 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:18:33,566] INFO Loaded 9 logs in 191ms. (kafka.log.LogManager)
[2022-05-15 18:18:33,567] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:18:33,568] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:18:33,834] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:33,991] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:18:33,994] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-15 18:18:34,030] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:18:34,037] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:34,055] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:34,056] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:34,058] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:34,060] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:34,073] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:34,139] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:18:34,161] INFO Stat of the created znode at /brokers/ids/2 is: 3190,3190,1652635114152,1652635114152,1,0,0,72057641293905988,192,0,3190
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:18:34,162] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://joao:9094, czxid (broker epoch): 3190 (kafka.zk.KafkaZkClient)
[2022-05-15 18:18:34,234] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:34,241] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:34,242] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:34,259] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:34,273] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:34,298] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:34,308] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:34,308] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:34,336] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:34,355] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:34,377] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:18:34,383] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:18:34,384] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:18:34,389] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:34,389] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:34,390] INFO Kafka startTimeMs: 1652635114384 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:34,392] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-15 18:18:34,507] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:34,508] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:34,508] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:34,509] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:34,509] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:34,510] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:34,510] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:34,511] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:34,511] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:34,541] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-7, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:34,544] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:34,546] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:34,584] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 30 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:34,586] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 30 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:34,587] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 30 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:34,588] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 30 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:34,588] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 30 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:34,588] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 30 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:34,588] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 30 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:34,588] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 30 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:34,588] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 30 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:34,588] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 30 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:34,589] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 30 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:34,589] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 30 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:34,589] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 30 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:34,589] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 30 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:34,589] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 30 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:34,589] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 30 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:34,589] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 30 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:34,589] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 30 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:34,598] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 11 milliseconds for epoch 30, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:34,599] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 11 milliseconds for epoch 30, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:34,600] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 12 milliseconds for epoch 30, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:34,600] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 12 milliseconds for epoch 30, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:34,601] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 12 milliseconds for epoch 30, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:34,601] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 12 milliseconds for epoch 30, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:34,602] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 13 milliseconds for epoch 30, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:34,602] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 13 milliseconds for epoch 30, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:34,603] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 14 milliseconds for epoch 30, of which 13 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:37,540] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:18:37,801] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:18:37,881] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:18:37,884] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:18:37,885] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:18:37,898] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:37,902] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:37,902] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:37,902] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:37,902] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:37,902] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:37,902] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:37,902] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:37,902] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:37,902] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:37,902] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:37,903] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:37,903] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:37,903] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:37,903] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:37,903] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:37,903] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:37,903] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:37,903] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:37,917] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:37,922] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:18:37,927] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:37,931] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:37,937] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:37,938] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:37,942] INFO Socket connection established, initiating session, client: /127.0.0.1:57954, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:37,949] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0045, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:37,955] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:38,023] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:38,154] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:18:38,158] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:18:38,206] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:18:38,215] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:18:38,263] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:38,264] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:38,266] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:38,268] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:38,304] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:18:38,309] INFO Skipping recovery for all logs in /tmp/kafka-logs-3 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:18:38,381] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:38,408] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-14, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 87ms (1/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:18:38,425] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Loading producer state till offset 49254 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:38,426] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Reloading from producer snapshot and rebuilding producer state from offset 49254 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:38,427] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-3/__consumer_offsets-38/00000000000000049254.snapshot,49254)' (kafka.log.ProducerStateManager)
[2022-05-15 18:18:38,435] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Producer state recovery took 9ms for snapshot load and 0ms for segment recovery from offset 49254 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:38,441] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-38, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=49254) with 1 segments in 33ms (2/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:18:38,446] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:38,451] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-8, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (3/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:18:38,456] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:38,461] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-2, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (4/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:18:38,466] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:38,469] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-26, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:18:38,474] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:38,477] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-20, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:18:38,481] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:38,484] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-32, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (7/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:18:38,488] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:38,491] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-44, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/8 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:18:38,493] INFO Loaded 8 logs in 189ms. (kafka.log.LogManager)
[2022-05-15 18:18:38,494] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:18:38,495] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:18:38,746] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:38,878] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:18:38,882] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-05-15 18:18:38,912] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:18:38,919] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:38,936] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:38,937] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:38,939] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:38,941] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:38,954] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:39,021] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:18:39,045] INFO Stat of the created znode at /brokers/ids/3 is: 3215,3215,1652635119036,1652635119036,1,0,0,72057641293905989,192,0,3215
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:18:39,046] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://joao:9095, czxid (broker epoch): 3215 (kafka.zk.KafkaZkClient)
[2022-05-15 18:18:39,113] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:39,118] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:39,120] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:39,133] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:39,155] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:39,172] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:39,177] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:39,177] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:39,202] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:39,221] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:39,243] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:18:39,247] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:18:39,248] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:18:39,253] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:39,253] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:39,253] INFO Kafka startTimeMs: 1652635119248 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:39,257] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-05-15 18:18:39,325] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:39,357] INFO [Partition __consumer_offsets-2 broker=3] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:39,357] INFO [Partition __consumer_offsets-20 broker=3] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:39,358] INFO [Partition __consumer_offsets-38 broker=3] Log loaded for partition __consumer_offsets-38 with initial high watermark 49254 (kafka.cluster.Partition)
[2022-05-15 18:18:39,358] INFO [Partition __consumer_offsets-8 broker=3] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:39,358] INFO [Partition __consumer_offsets-26 broker=3] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:39,358] INFO [Partition __consumer_offsets-44 broker=3] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:39,358] INFO [Partition __consumer_offsets-14 broker=3] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:39,358] INFO [Partition __consumer_offsets-32 broker=3] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:39,359] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:39,385] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-26, __consumer_offsets-32, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:39,421] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 2 in epoch 29 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:39,423] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 29 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:39,424] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 20 in epoch 29 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:39,425] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 29 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:39,425] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 38 in epoch 29 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:39,425] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 29 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:39,425] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 8 in epoch 29 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:39,425] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 29 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:39,425] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 26 in epoch 29 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:39,425] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 29 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:39,425] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 44 in epoch 29 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:39,425] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 29 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:39,425] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 14 in epoch 29 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:39,426] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 29 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:39,426] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 32 in epoch 29 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:39,426] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 29 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:39,433] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-2 in 9 milliseconds for epoch 29, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:39,434] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-20 in 9 milliseconds for epoch 29, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:39,565] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-38 in 140 milliseconds for epoch 29, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:39,566] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-8 in 141 milliseconds for epoch 29, of which 141 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:39,566] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-26 in 141 milliseconds for epoch 29, of which 141 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:39,566] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-44 in 141 milliseconds for epoch 29, of which 141 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:39,566] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-14 in 140 milliseconds for epoch 29, of which 140 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:39,567] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-32 in 141 milliseconds for epoch 29, of which 141 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:42,546] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:18:42,810] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:18:42,893] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:18:42,897] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:18:42,898] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:18:42,915] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:42,920] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:42,921] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:42,921] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:42,921] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:42,921] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:42,921] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:42,921] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:42,921] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:42,921] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:42,921] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:42,922] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:42,922] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:42,922] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:42,922] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:42,922] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:42,922] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:42,922] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:42,922] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:42,924] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:42,929] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:18:42,933] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:42,947] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:42,951] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:42,952] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:42,956] INFO Socket connection established, initiating session, client: /127.0.0.1:57956, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:42,961] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0046, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:42,967] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:43,039] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:43,166] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:18:43,171] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:18:43,220] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:18:43,227] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:18:43,274] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:43,275] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:43,277] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:43,278] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:43,315] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:18:43,319] INFO Skipping recovery for all logs in /tmp/kafka-logs-4 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:18:43,393] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:43,418] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-24, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 85ms (1/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:18:43,423] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:43,426] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-12, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (2/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:18:43,431] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:43,434] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-30, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (3/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:18:43,439] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:43,442] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-36, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:18:43,444] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:43,446] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-0.b9b05feda85246369d4eee833f2e8efd-delete, topicId=dVRCsKtiRiy-k0VgICiGjQ, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 4ms (5/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:18:43,451] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:43,453] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-42, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (6/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:18:43,457] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:43,461] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-0, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:18:43,466] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:43,470] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-18, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (8/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:18:43,476] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:43,479] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-6, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:18:43,483] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:43,486] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-48, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/10 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:18:43,488] INFO Loaded 10 logs in 173ms. (kafka.log.LogManager)
[2022-05-15 18:18:43,489] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:18:43,490] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:18:43,745] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:43,873] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:18:43,877] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.Acceptor)
[2022-05-15 18:18:43,904] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:18:43,910] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:43,925] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:43,927] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:43,928] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:43,929] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:43,943] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:44,008] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:18:44,027] INFO Stat of the created znode at /brokers/ids/4 is: 3239,3239,1652635124019,1652635124019,1,0,0,72057641293905990,192,0,3239
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:18:44,028] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://joao:9096, czxid (broker epoch): 3239 (kafka.zk.KafkaZkClient)
[2022-05-15 18:18:44,093] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:44,099] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:44,101] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:44,115] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:44,126] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:44,150] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:44,157] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:44,157] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:44,185] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:44,204] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:44,223] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:18:44,228] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:18:44,229] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:18:44,235] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:44,235] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:44,235] INFO Kafka startTimeMs: 1652635124229 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:44,238] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2022-05-15 18:18:44,315] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:44,347] INFO [Partition __consumer_offsets-18 broker=4] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:44,348] INFO [Partition __consumer_offsets-36 broker=4] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:44,348] INFO [Partition __consumer_offsets-6 broker=4] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:44,348] INFO [Partition __consumer_offsets-24 broker=4] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:44,348] INFO [Partition __consumer_offsets-42 broker=4] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:44,349] INFO [Partition __consumer_offsets-12 broker=4] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:44,349] INFO [Partition __consumer_offsets-30 broker=4] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:44,349] INFO [Partition __consumer_offsets-0 broker=4] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:44,350] INFO [Partition __consumer_offsets-48 broker=4] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:44,354] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:44,375] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-12, __consumer_offsets-42, __consumer_offsets-18) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:44,409] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 18 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:44,411] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:44,412] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 36 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:44,412] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:44,412] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 6 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:44,413] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:44,413] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 24 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:44,413] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:44,413] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 42 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:44,413] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:44,413] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 12 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:44,413] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:44,413] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 30 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:44,413] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:44,413] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 0 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:44,413] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:44,413] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 48 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:44,413] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:44,419] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-18 in 7 milliseconds for epoch 34, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:44,420] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-36 in 8 milliseconds for epoch 34, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:44,420] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-6 in 7 milliseconds for epoch 34, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:44,420] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-24 in 7 milliseconds for epoch 34, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:44,421] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-42 in 8 milliseconds for epoch 34, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:44,421] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-12 in 8 milliseconds for epoch 34, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:44,422] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-30 in 9 milliseconds for epoch 34, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:44,422] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-0 in 9 milliseconds for epoch 34, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:44,422] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-48 in 9 milliseconds for epoch 34, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:47,498] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:18:47,759] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:18:47,841] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:18:47,843] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:18:47,844] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:18:47,856] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:47,860] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:47,860] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:47,860] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:47,860] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:47,860] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:47,860] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:47,861] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:47,861] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:47,861] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:47,861] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:47,861] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:47,861] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:47,861] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:47,861] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:47,861] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:47,861] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:47,861] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:47,861] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:47,864] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:18:47,869] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:18:47,873] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:47,885] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:47,891] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:47,891] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:47,895] INFO Socket connection established, initiating session, client: /127.0.0.1:57958, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:47,902] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0047, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:18:47,906] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:18:47,975] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:18:48,103] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:18:48,107] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:18:48,155] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:18:48,164] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:18:48,210] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:48,211] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:48,213] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:48,214] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:18:48,252] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:18:48,256] INFO Skipping recovery for all logs in /tmp/kafka-logs-5 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:18:48,325] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:48,352] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-46, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 81ms (1/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:18:48,357] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:48,359] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-10, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (2/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:18:48,361] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:48,367] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-1.dda0a108d9c24128a0571a8d02a8c405-delete, topicId=dVRCsKtiRiy-k0VgICiGjQ, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (3/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:18:48,372] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:48,374] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-28, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (4/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:18:48,392] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Loading producer state till offset 41065 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:48,392] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 41065 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:48,394] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-22/00000000000000041065.snapshot,41065)' (kafka.log.ProducerStateManager)
[2022-05-15 18:18:48,402] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Producer state recovery took 10ms for snapshot load and 0ms for segment recovery from offset 41065 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:48,404] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-22, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=41065) with 1 segments in 30ms (5/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:18:48,408] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:48,411] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-16, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (6/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:18:48,412] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:48,415] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-2.ca323550a1b448bf82bd004f90669180-delete, topicId=dVRCsKtiRiy-k0VgICiGjQ, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 3ms (7/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:18:48,422] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Loading producer state till offset 18252 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:48,422] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 18252 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:48,423] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-40/00000000000000018252.snapshot,18252)' (kafka.log.ProducerStateManager)
[2022-05-15 18:18:48,423] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Producer state recovery took 1ms for snapshot load and 0ms for segment recovery from offset 18252 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:48,425] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-40, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=18252) with 1 segments in 10ms (8/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:18:48,429] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:48,433] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-34, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (9/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:18:48,437] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:48,440] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-4, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/10 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:18:48,442] INFO Loaded 10 logs in 190ms. (kafka.log.LogManager)
[2022-05-15 18:18:48,443] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:18:48,444] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:18:48,694] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:48,807] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:18:48,810] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.Acceptor)
[2022-05-15 18:18:48,837] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:18:48,842] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:48,860] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:48,861] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:48,862] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:48,864] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:48,877] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:18:48,931] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:18:48,950] INFO Stat of the created znode at /brokers/ids/5 is: 3264,3264,1652635128941,1652635128941,1,0,0,72057641293905991,192,0,3264
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:18:48,950] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://joao:9097, czxid (broker epoch): 3264 (kafka.zk.KafkaZkClient)
[2022-05-15 18:18:49,028] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:49,036] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:49,038] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:49,056] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:49,073] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:49,099] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:49,103] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:18:49,103] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:18:49,127] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:18:49,149] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:18:49,171] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:18:49,177] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:18:49,177] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:18:49,183] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:49,184] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:49,184] INFO Kafka startTimeMs: 1652635129177 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:18:49,186] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2022-05-15 18:18:49,247] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:49,299] INFO [Partition __consumer_offsets-34 broker=5] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:49,300] INFO [Partition __consumer_offsets-4 broker=5] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:49,300] INFO [Partition __consumer_offsets-22 broker=5] Log loaded for partition __consumer_offsets-22 with initial high watermark 41065 (kafka.cluster.Partition)
[2022-05-15 18:18:49,301] INFO [Partition __consumer_offsets-40 broker=5] Log loaded for partition __consumer_offsets-40 with initial high watermark 18252 (kafka.cluster.Partition)
[2022-05-15 18:18:49,302] INFO [Partition __consumer_offsets-10 broker=5] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:49,302] INFO [Partition __consumer_offsets-28 broker=5] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:49,302] INFO [Partition __consumer_offsets-46 broker=5] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:49,302] INFO [Partition __consumer_offsets-16 broker=5] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:49,304] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:18:49,329] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:49,368] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 34 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:49,371] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:49,373] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 4 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:49,373] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:49,373] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 22 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:49,373] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:49,373] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 40 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:49,373] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:49,374] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 10 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:49,374] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:49,374] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 28 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:49,374] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:49,374] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 46 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:49,374] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:49,374] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 16 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:18:49,374] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:49,379] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-34 in 7 milliseconds for epoch 34, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:49,380] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-4 in 7 milliseconds for epoch 34, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:49,405] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-9fa5abef-fdc9-4c05-8f09-7f9780632837, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:18:49,414] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-ed3a6d0d-54c4-4b54-b4a4-a5d0ecba6f8e, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:18:49,415] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-1038faf2-d998-4707-9799-897de83d6136, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:18:49,415] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-b283a5ee-70be-4bf9-b41c-74e089f12e34, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:18:49,415] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-360d1581-f79b-41e6-82d3-fe3577615014, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:18:49,415] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-9e173d1e-b47a-4b16-9874-bf5d2688c730, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:18:49,415] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-81fafa38-80dc-43ea-ac6c-e398b06565dc, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:18:49,446] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-d15976bc-df63-4682-8583-fd67cbb1d9df, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:18:49,446] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-a0d7c5c7-e384-4339-b0be-414878362e3e, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:18:49,446] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-ee781f71-f1c3-46d7-bd93-d90a4fe359ff, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:18:49,446] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-78575c72-7be8-4563-b114-53b271a8ef70, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:18:49,446] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-0287b15c-1acd-4475-b9ce-b994aebeeff2, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:18:49,447] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-45d54f6e-f1d8-43f7-8ace-1db96ac0cfac, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:18:49,510] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-954ef0dc-d124-405b-9bb6-119086dd08c0, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:18:49,511] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-3f51cd43-28ab-4459-969e-211543e6cd72, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:18:49,511] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-4b8634e2-92f3-4603-97c5-35df7219bd84, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 4. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:18:49,512] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-22 in 139 milliseconds for epoch 34, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:49,541] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-40 in 168 milliseconds for epoch 34, of which 140 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:49,542] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-10 in 168 milliseconds for epoch 34, of which 168 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:49,543] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-28 in 169 milliseconds for epoch 34, of which 168 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:49,543] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-46 in 169 milliseconds for epoch 34, of which 169 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:49,544] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-16 in 170 milliseconds for epoch 34, of which 170 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:18:53,133] INFO Creating topic Sensor with configuration {min.insync.replicas=2} and initial partition assignment HashMap(0 -> ArrayBuffer(4, 3, 0), 1 -> ArrayBuffer(2, 0, 5), 2 -> ArrayBuffer(3, 5, 1), 3 -> ArrayBuffer(0, 1, 4), 4 -> ArrayBuffer(5, 4, 2), 5 -> ArrayBuffer(1, 2, 3)) (kafka.zk.AdminZkClient)
[2022-05-15 18:18:53,181] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,185] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,185] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,186] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-4) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,187] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,187] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,194] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:53,198] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:53,200] INFO Created log for partition Sensor-3 in /tmp/kafka-logs/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:18:53,200] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:53,200] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:53,201] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:53,201] INFO [Partition Sensor-3 broker=0] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 18:18:53,201] INFO [Partition Sensor-3 broker=0] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:53,202] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:53,206] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-5/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:18:53,206] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-3/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:18:53,206] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-4/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:18:53,207] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-2/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:18:53,207] INFO [Partition Sensor-4 broker=5] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 18:18:53,207] INFO [Partition Sensor-4 broker=5] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:53,207] INFO [Partition Sensor-2 broker=3] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 18:18:53,208] INFO [Partition Sensor-2 broker=3] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:53,208] INFO [Partition Sensor-0 broker=4] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 18:18:53,208] INFO [Partition Sensor-0 broker=4] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:53,209] INFO [Partition Sensor-1 broker=2] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 18:18:53,209] INFO [Partition Sensor-1 broker=2] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:53,212] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-1/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:18:53,214] INFO [Partition Sensor-5 broker=1] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 18:18:53,214] INFO [Partition Sensor-5 broker=1] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:53,220] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:53,221] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:53,221] INFO Created log for partition Sensor-0 in /tmp/kafka-logs/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:18:53,221] INFO [Partition Sensor-0 broker=0] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 18:18:53,222] INFO [Partition Sensor-0 broker=0] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:53,222] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:53,222] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-5/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:18:53,222] INFO [Partition Sensor-2 broker=5] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 18:18:53,223] INFO [Partition Sensor-2 broker=5] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:53,226] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-4/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:18:53,226] INFO [Partition Sensor-4 broker=4] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 18:18:53,226] INFO [Partition Sensor-4 broker=4] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:53,227] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:53,229] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:53,229] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-2/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:18:53,230] INFO [Partition Sensor-4 broker=2] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 18:18:53,230] INFO [Partition Sensor-4 broker=2] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:53,230] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:53,230] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:53,231] INFO Created log for partition Sensor-1 in /tmp/kafka-logs/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:18:53,231] INFO [Partition Sensor-1 broker=0] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 18:18:53,231] INFO [Partition Sensor-1 broker=0] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:53,232] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-5/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:18:53,232] INFO [Partition Sensor-1 broker=5] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 18:18:53,232] INFO [Partition Sensor-1 broker=5] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:53,229] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:53,232] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,233] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,233] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-1/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:18:53,233] INFO [Partition Sensor-3 broker=1] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 18:18:53,234] INFO [Partition Sensor-3 broker=1] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:53,235] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-3/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:18:53,235] INFO [Partition Sensor-5 broker=3] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 18:18:53,235] INFO [Partition Sensor-5 broker=3] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:53,238] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:53,240] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-4/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:18:53,240] INFO [Partition Sensor-3 broker=4] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 18:18:53,240] INFO [Partition Sensor-3 broker=4] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:53,241] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(Sensor-4, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,241] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:53,242] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:53,243] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-2/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:18:53,243] INFO [Partition Sensor-5 broker=2] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 18:18:53,244] INFO [Partition Sensor-5 broker=2] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:53,244] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(Sensor-4, Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,245] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-1/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:18:53,246] INFO [Partition Sensor-2 broker=1] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 18:18:53,246] INFO [Partition Sensor-2 broker=1] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:53,246] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,249] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:18:53,251] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-3/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:18:53,251] INFO [Partition Sensor-0 broker=3] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 18:18:53,251] INFO [Partition Sensor-0 broker=3] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:18:53,252] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(Sensor-5, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,264] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,268] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 2 for partitions Map(Sensor-1 -> InitialFetchState(Some(BTTwpy-LQsG5rcGyE4FslQ),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,273] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,274] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 3 for partitions Map(Sensor-2 -> InitialFetchState(Some(BTTwpy-LQsG5rcGyE4FslQ),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,275] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,275] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,275] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,278] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:18:53,278] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:18:53,282] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,282] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,283] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,284] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 4 for partitions Map(Sensor-0 -> InitialFetchState(Some(BTTwpy-LQsG5rcGyE4FslQ),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,287] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,288] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:18:53,290] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,289] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 0 for partitions Map(Sensor-3 -> InitialFetchState(Some(BTTwpy-LQsG5rcGyE4FslQ),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,292] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,292] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(Sensor-5 -> InitialFetchState(Some(BTTwpy-LQsG5rcGyE4FslQ),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,293] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 0 for partitions Map(Sensor-3 -> InitialFetchState(Some(BTTwpy-LQsG5rcGyE4FslQ),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,294] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,295] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:18:53,298] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,298] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:18:53,300] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 5 for partitions Map(Sensor-4 -> InitialFetchState(Some(BTTwpy-LQsG5rcGyE4FslQ),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,300] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 5 for partitions Map(Sensor-4 -> InitialFetchState(Some(BTTwpy-LQsG5rcGyE4FslQ),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,301] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,301] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,302] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,302] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,302] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:18:53,303] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:18:53,303] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,303] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,304] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,304] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 3 for partitions Map(Sensor-2 -> InitialFetchState(Some(BTTwpy-LQsG5rcGyE4FslQ),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,304] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions Map(Sensor-1 -> InitialFetchState(Some(BTTwpy-LQsG5rcGyE4FslQ),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,304] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,304] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:18:53,304] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:18:53,303] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:18:53,308] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,312] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:18:53,312] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 4 for partitions Map(Sensor-0 -> InitialFetchState(Some(BTTwpy-LQsG5rcGyE4FslQ),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,322] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,324] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,324] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 1 for partitions Map(Sensor-5 -> InitialFetchState(Some(BTTwpy-LQsG5rcGyE4FslQ),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:18:53,325] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:18:53,405] WARN [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,405] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-1. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:18:53,427] WARN [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-2. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:19:23,431] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=115704, lastModifiedTime=1652635035321, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:19:23,435] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=115704, lastModifiedTime=1652635035321, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:19:23,448] INFO Deleted log /tmp/kafka-logs/Sensor-0.3e0e09ffd86a4d3eafb0faa3652f418e-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:19:23,449] INFO Deleted offset index /tmp/kafka-logs/Sensor-0.3e0e09ffd86a4d3eafb0faa3652f418e-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:19:23,458] INFO Deleted time index /tmp/kafka-logs/Sensor-0.3e0e09ffd86a4d3eafb0faa3652f418e-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:19:23,475] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs/Sensor-0.3e0e09ffd86a4d3eafb0faa3652f418e-delete. (kafka.log.LogManager)
[2022-05-15 18:19:43,454] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=307857, lastModifiedTime=1652634669004, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:19:43,457] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=307857, lastModifiedTime=1652634669004, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:19:43,462] INFO Deleted log /tmp/kafka-logs-4/Sensor-0.b9b05feda85246369d4eee833f2e8efd-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:19:43,464] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-0.b9b05feda85246369d4eee833f2e8efd-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:19:43,470] INFO Deleted time index /tmp/kafka-logs-4/Sensor-0.b9b05feda85246369d4eee833f2e8efd-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:19:43,477] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-4/Sensor-0.b9b05feda85246369d4eee833f2e8efd-delete. (kafka.log.LogManager)
[2022-05-15 18:19:48,403] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=218257, lastModifiedTime=1652634646492, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:19:48,406] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=218257, lastModifiedTime=1652634646492, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:19:48,410] INFO Deleted log /tmp/kafka-logs-5/Sensor-1.dda0a108d9c24128a0571a8d02a8c405-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:19:48,411] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-1.dda0a108d9c24128a0571a8d02a8c405-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:19:48,417] INFO Deleted time index /tmp/kafka-logs-5/Sensor-1.dda0a108d9c24128a0571a8d02a8c405-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:19:48,424] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-5/Sensor-1.dda0a108d9c24128a0571a8d02a8c405-delete. (kafka.log.LogManager)
[2022-05-15 18:19:48,425] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=220595, lastModifiedTime=1652634647612, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:19:48,425] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=220595, lastModifiedTime=1652634647612, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:19:48,426] INFO Deleted log /tmp/kafka-logs-5/Sensor-2.ca323550a1b448bf82bd004f90669180-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:19:48,426] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-2.ca323550a1b448bf82bd004f90669180-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:19:48,426] INFO Deleted time index /tmp/kafka-logs-5/Sensor-2.ca323550a1b448bf82bd004f90669180-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:19:48,427] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-5/Sensor-2.ca323550a1b448bf82bd004f90669180-delete. (kafka.log.LogManager)
[2022-05-15 18:21:30,459] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:21:30,461] INFO [GroupCoordinator 5]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:21:30,461] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:21:30,461] INFO [GroupCoordinator 4]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:21:30,463] INFO [GroupCoordinator 3]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:21:30,463] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:21:30,493] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-3, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:30,493] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-3, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:30,495] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:30,495] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:30,496] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:30,496] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:30,496] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:30,496] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:30,496] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:30,497] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:30,497] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:30,497] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:30,500] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,502] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:30,503] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,504] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:30,505] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1636 due to node 2 being disconnected (elapsed time since creation: 347ms, elapsed time since send: 347ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:30,505] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,505] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1877501774, epoch=1634) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:21:30,506] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,507] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,507] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,507] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,507] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,508] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,508] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,508] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:30,508] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1636 due to node 2 being disconnected (elapsed time since creation: 353ms, elapsed time since send: 353ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:30,508] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:30,509] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:30,511] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 922 due to node 1 being disconnected (elapsed time since creation: 96ms, elapsed time since send: 96ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:30,511] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 922 due to node 1 being disconnected (elapsed time since creation: 107ms, elapsed time since send: 107ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:30,512] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1709 due to node 0 being disconnected (elapsed time since creation: 206ms, elapsed time since send: 206ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:30,509] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=1038400473, epoch=1634) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:21:30,513] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,514] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,514] INFO [ReplicaFetcher replicaId=5, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,514] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:30,515] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1602 due to node 4 being disconnected (elapsed time since creation: 98ms, elapsed time since send: 98ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:30,515] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=616631436, epoch=1602) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:21:30,516] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,516] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,512] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=2112921169, epoch=922) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:21:30,512] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=563496284, epoch=922) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:21:30,517] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,517] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,517] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,517] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,518] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,513] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=980441184, epoch=1709) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:21:30,521] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,517] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:30,523] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-3, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:30,524] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,524] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,525] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-3, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:30,525] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,525] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:30,525] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1709 due to node 0 being disconnected (elapsed time since creation: 221ms, elapsed time since send: 221ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:30,526] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1602 due to node 4 being disconnected (elapsed time since creation: 113ms, elapsed time since send: 113ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:30,526] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,525] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:30,526] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,526] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,527] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 875 due to node 5 being disconnected (elapsed time since creation: 388ms, elapsed time since send: 388ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:30,526] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=353706606, epoch=1602) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:21:30,528] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,527] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=527367710, epoch=875) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:21:30,529] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,529] INFO [ReplicaFetcher replicaId=2, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,530] INFO [ReplicaFetcher replicaId=3, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,530] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:30,530] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:30,532] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:30,532] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,533] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:30,532] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:30,533] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 875 due to node 5 being disconnected (elapsed time since creation: 415ms, elapsed time since send: 415ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:30,533] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=773110224, epoch=875) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:21:30,535] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,537] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:30,526] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=1942091473, epoch=1709) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:21:30,539] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,538] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:30,541] INFO [ReplicaFetcher replicaId=1, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,543] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:21:30,550] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:30,552] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:30,553] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-5, Sensor-2, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:30,553] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-3, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:30,557] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-2/Sensor-4.17f3327be9ea4a5caf3bb1758b725a22-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:21:30,558] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs/Sensor-3.210a68451f2644058440fc92da220896-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:21:30,561] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-2/Sensor-5.eac2e363178441dea0ae6162ca2bb3f8-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:21:30,561] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-3/Sensor-5.130076b655c34f0288130f1b47429aca-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:21:30,562] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs/Sensor-0.73524822ca3d43ddabff0d54203141f4-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:21:30,565] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs/Sensor-1.3e0a0f4a13f64799a0ccad0c0103088d-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:21:30,565] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-2/Sensor-1.cdef75df5ec945eab2e4d6c998ed0796-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:21:30,567] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-3/Sensor-2.409f5bbbbdb749ad8a30073c9f5759c8-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:21:30,570] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-5/Sensor-4.1e1a3e360006431689844519fd509c1c-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:21:30,570] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-3/Sensor-0.462c8c7345df46839a4728cf20418b72-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:21:30,574] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-5/Sensor-2.78d7ce1a4ead4caab50090a53bd3381e-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:21:30,576] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-4/Sensor-4.86794a459947483ab50518399f9b06df-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:21:30,577] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-5/Sensor-1.f91c206489554e4483a9a4cf94207fe5-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:21:30,578] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-1/Sensor-5.f1c1587f169f40a8942f75f7cbc1987f-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:21:30,580] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-4/Sensor-3.a0ac44419410478f9481243d407f6c79-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:21:30,582] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-1/Sensor-2.5c0af66327dc4d33870ba3059a691e94-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:21:30,583] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-4/Sensor-0.0720a3ccadd94b3e96e1107eb8cc4472-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:21:30,584] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-1/Sensor-3.ac4dbea2c89a4f07aff9a776b6979ae6-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:21:33,826] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:21:33,826] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:21:33,826] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:21:33,826] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:21:33,826] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:21:33,826] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:21:33,828] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:21:33,829] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:21:33,829] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:21:33,829] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:21:33,829] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:21:33,830] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:21:33,831] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:21:33,831] INFO [KafkaServer id=4] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:21:33,829] INFO [KafkaServer id=5] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:21:33,832] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:21:33,832] INFO [KafkaServer id=5] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:21:33,835] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:21:33,844] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 9ms (kafka.server.KafkaServer)
[2022-05-15 18:21:33,844] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 9ms (kafka.server.KafkaServer)
[2022-05-15 18:21:33,846] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:21:33,846] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 10ms (kafka.server.KafkaServer)
[2022-05-15 18:21:33,846] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:21:33,847] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:21:33,846] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:21:33,846] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:21:33,847] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:21:33,848] INFO [KafkaServer id=4] Controlled shutdown request returned successfully after 11ms (kafka.server.KafkaServer)
[2022-05-15 18:21:33,848] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:21:33,848] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:21:33,849] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:21:33,850] INFO [KafkaServer id=5] Controlled shutdown request returned successfully after 11ms (kafka.server.KafkaServer)
[2022-05-15 18:21:33,850] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:21:33,850] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:21:33,851] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:21:33,851] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:21:33,851] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:21:33,852] INFO [KafkaServer id=3] Controlled shutdown request returned successfully after 11ms (kafka.server.KafkaServer)
[2022-05-15 18:21:33,852] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:21:33,853] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:21:33,854] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:21:33,855] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:21:33,855] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:21:33,855] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:21:33,856] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:21:33,856] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:21:33,856] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:21:33,860] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:21:33,861] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:21:33,861] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:21:33,863] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:21:33,863] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:21:33,865] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:21:33,867] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:21:33,867] INFO [data-plane Kafka Request Handler on Broker 4], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:21:33,867] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:21:33,870] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:21:33,870] INFO [data-plane Kafka Request Handler on Broker 4], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:21:33,870] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:21:33,871] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:21:33,871] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:33,871] INFO [data-plane Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:21:33,872] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:21:33,873] INFO [data-plane Kafka Request Handler on Broker 5], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:21:33,873] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:33,874] INFO [ExpirationReaper-4-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:33,874] INFO [data-plane Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:21:33,876] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:21:33,876] INFO [data-plane Kafka Request Handler on Broker 5], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:21:33,877] INFO [ExpirationReaper-3-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:33,879] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:33,879] INFO [ExpirationReaper-5-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:33,903] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:33,903] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:33,904] INFO [ExpirationReaper-5-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:33,904] INFO [ExpirationReaper-5-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:33,904] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:21:33,905] INFO [KafkaApi-5] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:21:33,905] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:33,906] INFO [ExpirationReaper-5-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:33,996] INFO [ExpirationReaper-3-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:33,996] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:33,996] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:33,996] INFO [ExpirationReaper-3-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:33,997] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:21:33,997] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:21:33,998] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:33,999] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,015] INFO [ExpirationReaper-5-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,015] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,015] INFO [ExpirationReaper-5-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,015] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,017] INFO [TransactionCoordinator id=5] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:21:34,017] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:21:34,019] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:21:34,019] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:21:34,019] INFO [Transaction State Manager 5]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:21:34,019] INFO [Transaction Marker Channel Manager 5]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:21:34,019] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:21:34,019] INFO [Transaction Marker Channel Manager 5]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:21:34,020] INFO [Transaction Marker Channel Manager 5]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:21:34,019] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:21:34,021] INFO [TransactionCoordinator id=5] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:21:34,021] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:21:34,022] INFO [GroupCoordinator 5]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:21:34,022] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:21:34,023] INFO [ExpirationReaper-5-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,023] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,025] INFO [ExpirationReaper-4-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,025] INFO [ExpirationReaper-4-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,026] INFO [KafkaApi-4] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:21:34,027] INFO [ExpirationReaper-4-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,042] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,043] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,043] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,072] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,072] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,073] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:21:34,074] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,079] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,079] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,082] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:21:34,084] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:21:34,084] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:21:34,084] INFO [ExpirationReaper-4-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,084] INFO [ExpirationReaper-4-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,084] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:21:34,084] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:21:34,086] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:21:34,087] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:21:34,087] INFO [TransactionCoordinator id=4] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:21:34,088] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,088] INFO [Transaction State Manager 4]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:21:34,088] INFO [Transaction Marker Channel Manager 4]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:21:34,089] INFO [Transaction Marker Channel Manager 4]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:21:34,089] INFO [Transaction Marker Channel Manager 4]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:21:34,090] INFO [TransactionCoordinator id=4] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:21:34,091] INFO [GroupCoordinator 4]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:21:34,091] INFO [ExpirationReaper-4-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,096] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,096] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,096] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,158] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,158] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,162] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:21:34,163] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:21:34,163] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:21:34,164] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:21:34,164] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:21:34,166] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:21:34,167] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:21:34,167] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,215] INFO [ExpirationReaper-5-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,215] INFO [ExpirationReaper-5-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,216] INFO [ExpirationReaper-5-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,235] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,235] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,236] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:21:34,236] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:21:34,237] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:21:34,237] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:21:34,237] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:21:34,238] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:34,239] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:34,239] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:34,240] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:34,240] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,248] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,248] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,248] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,254] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,254] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,257] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:21:34,258] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:21:34,258] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:21:34,258] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:21:34,258] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:21:34,260] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:21:34,260] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:21:34,261] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,289] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,289] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,289] INFO [ExpirationReaper-4-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,289] INFO [ExpirationReaper-4-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,290] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:21:34,290] INFO [ExpirationReaper-4-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,291] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:21:34,291] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:21:34,292] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:21:34,292] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:21:34,293] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:34,294] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:34,294] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:34,295] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:34,295] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,297] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,297] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,298] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,301] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,301] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,302] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,304] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,304] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,304] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,321] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,321] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,322] INFO [ExpirationReaper-3-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,332] INFO [ExpirationReaper-3-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,332] INFO [ExpirationReaper-3-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,338] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:21:34,339] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,339] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,339] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,342] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:21:34,343] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,343] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,343] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,344] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:21:34,345] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:21:34,357] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,357] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,357] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,358] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,358] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,359] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:21:34,360] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:21:34,361] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:21:34,361] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:21:34,361] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:21:34,361] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:34,363] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:34,363] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:34,363] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:34,363] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,368] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:21:34,372] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,372] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,372] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,373] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:21:34,373] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:21:34,373] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:21:34,374] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:21:34,401] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,401] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,401] INFO [Controller id=0, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,401] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,401] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,404] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,404] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,404] INFO [Controller id=0, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,404] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,404] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,404] WARN [Controller id=0, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,404] WARN [Controller id=0, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,404] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,404] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,404] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,405] INFO [Controller id=0, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,405] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,406] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,406] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,406] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,414] INFO [ExpirationReaper-5-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,415] INFO [ExpirationReaper-5-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,415] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,415] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,416] INFO [GroupCoordinator 5]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:21:34,417] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:21:34,417] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:21:34,417] INFO [ReplicaManager broker=5] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:21:34,417] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:21:34,418] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:21:34,418] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:21:34,418] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:21:34,418] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:21:34,418] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:21:34,419] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:34,419] INFO [ReplicaFetcherManager on broker 5] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:34,421] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:34,421] INFO [ReplicaFetcherManager on broker 5] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:34,421] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:34,422] INFO [ReplicaAlterLogDirsManager on broker 5] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:34,422] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:34,422] INFO [ReplicaAlterLogDirsManager on broker 5] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:34,422] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,422] INFO [ExpirationReaper-5-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,429] INFO [ExpirationReaper-5-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,429] INFO [ExpirationReaper-5-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,429] INFO [ExpirationReaper-5-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,432] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,432] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,433] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,434] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,434] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,438] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:21:34,438] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,439] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,439] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,441] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:21:34,441] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,441] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,441] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,442] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:21:34,443] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:21:34,447] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,447] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,448] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,465] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:21:34,468] INFO [ExpirationReaper-4-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,468] INFO [ExpirationReaper-4-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,469] INFO [GroupCoordinator 4]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:21:34,470] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:21:34,470] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:21:34,470] INFO [ReplicaManager broker=4] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:21:34,470] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:21:34,470] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:21:34,470] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:21:34,470] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:21:34,471] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:21:34,471] INFO [ReplicaFetcherManager on broker 4] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:34,472] INFO [ReplicaFetcherManager on broker 4] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:21:34,473] INFO [ReplicaAlterLogDirsManager on broker 4] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:34,474] INFO [ReplicaAlterLogDirsManager on broker 4] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:21:34,474] INFO [ExpirationReaper-4-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,478] INFO Session: 0x100000b00ad0045 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:21:34,478] INFO EventThread shut down for session: 0x100000b00ad0045 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:21:34,478] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,479] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:21:34,480] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:34,506] INFO [Controller id=0, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,506] WARN [Controller id=0, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,506] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,506] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,507] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,507] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,507] WARN [Controller id=0, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,507] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,507] INFO [Controller id=0, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,507] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,507] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,507] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,521] INFO [ExpirationReaper-5-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,521] INFO [ExpirationReaper-5-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,522] INFO [ExpirationReaper-5-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,522] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,522] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,522] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,555] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,555] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,556] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,574] INFO Session: 0x100000b00ad0044 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:21:34,574] INFO EventThread shut down for session: 0x100000b00ad0044 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:21:34,577] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:21:34,577] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:34,608] INFO [Controller id=0, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,608] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,608] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,608] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,608] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,608] WARN [Controller id=0, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,609] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,608] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,608] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,609] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,609] INFO [Controller id=0, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,609] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,609] WARN [Controller id=0, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,609] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,610] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,616] INFO [ExpirationReaper-5-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,616] INFO [ExpirationReaper-5-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,616] INFO [ExpirationReaper-5-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,635] INFO [ExpirationReaper-5-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,635] INFO [ExpirationReaper-5-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,639] INFO [ReplicaManager broker=5] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:21:34,640] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,640] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,640] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,642] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:21:34,643] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,643] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,643] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,644] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:21:34,644] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:21:34,648] INFO [ExpirationReaper-4-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,648] INFO [ExpirationReaper-4-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,648] INFO [ExpirationReaper-4-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,662] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:21:34,666] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:21:34,666] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:21:34,666] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:21:34,667] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:21:34,673] INFO [Controller id=0, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,701] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,702] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,702] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,710] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,710] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,710] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,710] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,710] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,711] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,711] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,711] WARN [Controller id=0, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,711] INFO [ExpirationReaper-4-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,711] INFO [ExpirationReaper-4-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,711] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,712] INFO [ExpirationReaper-4-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,755] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,755] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,760] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:21:34,761] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,761] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,761] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,764] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:21:34,764] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,765] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,765] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,765] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:21:34,766] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:21:34,771] INFO EventThread shut down for session: 0x100000b00ad0047 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:21:34,771] INFO Session: 0x100000b00ad0047 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:21:34,773] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:21:34,773] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:34,794] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:21:34,799] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:21:34,799] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:21:34,799] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:21:34,800] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:21:34,806] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,811] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,811] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,811] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,812] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,812] WARN [Controller id=0, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,813] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,836] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,836] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,837] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,848] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,848] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,852] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:21:34,853] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,853] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,853] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,855] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:21:34,856] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,856] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,856] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:34,857] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:21:34,858] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:21:34,876] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:21:34,879] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,881] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,882] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:21:34,882] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:21:34,882] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:21:34,883] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:21:34,896] INFO [ExpirationReaper-4-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,896] INFO [ExpirationReaper-4-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,897] INFO [ExpirationReaper-4-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:34,904] INFO Session: 0x100000b00ad0043 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:21:34,904] INFO EventThread shut down for session: 0x100000b00ad0043 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:21:34,905] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:21:34,906] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:34,956] INFO [Controller id=4, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,958] WARN [Controller id=4, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,959] INFO [Controller id=4, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:34,987] INFO Session: 0x100000b00ad0042 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:21:34,987] INFO EventThread shut down for session: 0x100000b00ad0042 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:21:34,988] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:21:34,989] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,060] INFO [Controller id=4, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:35,061] WARN [Controller id=4, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:35,061] INFO [Controller id=4, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:35,089] INFO [ExpirationReaper-4-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:35,089] INFO [ExpirationReaper-4-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:21:35,093] INFO [ReplicaManager broker=4] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:21:35,094] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:35,095] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:35,095] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:35,096] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:21:35,097] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:35,097] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:35,097] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:21:35,097] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:21:35,098] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:21:35,116] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:21:35,125] INFO [Controller id=4, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:21:35,127] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:21:35,127] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:21:35,127] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:21:35,128] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:21:35,232] INFO Session: 0x100000b00ad0046 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:21:35,232] INFO EventThread shut down for session: 0x100000b00ad0046 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:21:35,234] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:21:35,235] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,240] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,240] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,240] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,245] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,245] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,245] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,266] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,266] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,266] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,293] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,294] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,294] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,302] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,302] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,302] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,304] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,304] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,304] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,304] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,304] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,304] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,312] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,312] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,312] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,318] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,318] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,319] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,362] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,362] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,362] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,370] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,370] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,370] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,376] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,376] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:35,376] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,240] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,240] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,240] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,242] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,242] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,243] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:21:36,255] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,255] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,255] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,259] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:21:36,260] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:21:36,260] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:21:36,260] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:21:36,261] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:21:36,261] INFO App info kafka.server for 5 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:21:36,262] INFO [KafkaServer id=5] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:21:36,303] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,303] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,304] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,304] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,304] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,305] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:21:36,312] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,312] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,313] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,320] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,320] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,320] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,323] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,323] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,324] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:21:36,324] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:21:36,324] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:21:36,324] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:21:36,325] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:21:36,325] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:21:36,326] INFO App info kafka.server for 3 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:21:36,326] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:21:36,343] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:21:36,344] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:21:36,344] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:21:36,344] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:21:36,346] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:21:36,346] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:21:36,347] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:21:36,362] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,362] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:36,363] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:21:36,381] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:21:36,381] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:21:36,381] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:21:36,382] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:21:36,383] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:21:36,384] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:21:36,384] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:21:37,253] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:37,253] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:37,253] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:37,256] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:37,256] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:37,258] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:21:37,277] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:21:37,278] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:21:37,278] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:21:37,278] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:21:37,279] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:21:37,279] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:21:37,280] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:21:37,303] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:37,304] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:21:37,305] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:21:37,323] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:21:37,324] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:21:37,324] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:21:37,324] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:21:37,325] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:21:37,325] INFO App info kafka.server for 4 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:21:37,326] INFO [KafkaServer id=4] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:24:36,966] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:24:36,974] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:24:36,974] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:24:36,974] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:24:36,974] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:24:36,976] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 18:24:36,976] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 18:24:36,976] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 18:24:36,976] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-15 18:24:36,980] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-15 18:24:36,994] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:24:36,995] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:24:36,995] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:24:36,995] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:24:36,995] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:24:36,995] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-15 18:24:37,008] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@6156496 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-15 18:24:37,012] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 18:24:37,021] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,021] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,021] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,021] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,021] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,021] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,021] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,021] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,021] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,021] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,023] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,023] INFO Server environment:host.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,023] INFO Server environment:java.version=11.0.15 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,023] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,023] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,023] INFO Server environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,023] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,023] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,024] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,024] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,024] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,024] INFO Server environment:os.version=5.13.0-40-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,024] INFO Server environment:user.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,024] INFO Server environment:user.home=/home/joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,024] INFO Server environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,024] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,024] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,024] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,024] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,024] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,024] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,025] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,025] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,025] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,025] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,026] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-15 18:24:37,027] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,027] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,028] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 18:24:37,029] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 18:24:37,030] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:24:37,030] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:24:37,030] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:24:37,030] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:24:37,030] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:24:37,030] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:24:37,033] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,033] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,033] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:24:37,039] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 18:24:37,040] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 18:24:37,042] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 18:24:37,046] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 18:24:37,047] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:459)
	at java.base/sun.nio.ch.Net.bind(Net.java:448)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:676)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:158)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:112)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:67)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:140)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:90)
[2022-05-15 18:24:37,050] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-15 18:24:37,052] ERROR Exiting JVM with code 1 (org.apache.zookeeper.util.ServiceUtils)
[2022-05-15 18:24:41,991] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:24:42,236] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:24:42,318] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:24:42,323] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:24:42,324] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:24:42,338] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:24:42,343] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:42,343] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:42,343] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:42,343] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:42,344] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:42,344] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:42,344] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:42,344] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:42,345] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:42,345] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:42,345] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:42,345] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:42,345] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:42,345] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:42,345] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:42,346] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:42,346] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:42,346] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:42,359] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:42,363] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:24:42,368] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:24:42,372] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:24:42,378] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:24:42,379] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:24:42,383] INFO Socket connection established, initiating session, client: /127.0.0.1:57960, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:24:42,390] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0048, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:24:42,394] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:24:42,472] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:24:42,592] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:24:42,598] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:24:42,641] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:24:42,651] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:24:42,697] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:24:42,698] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:24:42,700] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:24:42,702] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:24:42,738] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:24:42,742] INFO Skipping recovery for all logs in /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:24:42,811] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:42,835] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-21, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 80ms (1/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:24:42,842] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:42,846] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-0.73524822ca3d43ddabff0d54203141f4-delete, topicId=BTTwpy-LQsG5rcGyE4FslQ, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (2/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:24:42,851] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:42,854] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-3.210a68451f2644058440fc92da220896-delete, topicId=BTTwpy-LQsG5rcGyE4FslQ, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (3/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:24:42,872] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 17940 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:42,872] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 17940 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:42,874] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs/__consumer_offsets-39/00000000000000017940.snapshot,17940)' (kafka.log.ProducerStateManager)
[2022-05-15 18:24:42,880] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Producer state recovery took 7ms for snapshot load and 1ms for segment recovery from offset 17940 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:42,884] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-39, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=17940) with 1 segments in 30ms (4/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:24:42,889] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:42,892] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-15, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:24:42,897] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:42,901] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-45, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:24:42,905] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:42,908] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-33, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:24:42,912] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:42,915] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-27, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (8/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:24:42,920] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:42,922] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-1.3e0a0f4a13f64799a0ccad0c0103088d-delete, topicId=BTTwpy-LQsG5rcGyE4FslQ, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (9/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:24:42,927] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:42,930] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-3, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (10/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:24:42,935] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:42,937] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-9, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:24:42,940] INFO Loaded 11 logs in 202ms. (kafka.log.LogManager)
[2022-05-15 18:24:42,941] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:24:42,942] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:24:43,186] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:24:43,308] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:24:43,312] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-15 18:24:43,338] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:24:43,345] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:24:43,361] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:43,362] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:43,364] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:43,366] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:43,378] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:24:43,427] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:24:43,444] INFO Stat of the created znode at /brokers/ids/0 is: 3421,3421,1652635483437,1652635483437,1,0,0,72057641293905992,192,0,3421
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:24:43,445] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://joao:9092, czxid (broker epoch): 3421 (kafka.zk.KafkaZkClient)
[2022-05-15 18:24:43,500] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:43,505] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:43,506] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:43,523] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:43,551] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:43,569] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:24:43,575] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:24:43,576] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:24:43,606] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:43,623] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:24:43,644] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:24:43,652] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:24:43,652] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:24:43,662] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:24:43,662] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:24:43,663] INFO Kafka startTimeMs: 1652635483653 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:24:43,667] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-15 18:24:43,697] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:24:43,741] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:43,741] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:43,741] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 17940 (kafka.cluster.Partition)
[2022-05-15 18:24:43,741] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:43,741] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:43,741] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:43,741] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:43,741] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:43,749] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:24:43,813] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-3, __consumer_offsets-15, __consumer_offsets-39, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:24:43,842] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:43,843] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:43,845] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:43,845] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:43,845] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:43,845] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:43,845] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:43,845] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:43,845] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:43,845] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:43,845] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:43,845] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:43,845] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:43,845] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:43,845] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 20 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:43,845] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 20 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:43,854] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 10 milliseconds for epoch 20, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:43,855] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 10 milliseconds for epoch 20, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:43,930] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 85 milliseconds for epoch 20, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:43,930] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 85 milliseconds for epoch 20, of which 85 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:43,931] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 86 milliseconds for epoch 20, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:43,932] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 87 milliseconds for epoch 20, of which 86 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:43,932] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 87 milliseconds for epoch 20, of which 87 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:43,933] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 88 milliseconds for epoch 20, of which 88 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:47,045] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:24:47,308] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:24:47,386] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:24:47,389] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:24:47,390] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:24:47,403] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:24:47,407] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:47,407] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:47,407] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:47,407] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:47,407] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:47,407] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:47,407] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:47,408] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:47,408] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:47,408] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:47,408] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:47,408] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:47,408] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:47,408] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:47,408] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:47,408] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:47,408] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:47,408] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:47,410] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:47,414] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:24:47,419] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:24:47,431] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:24:47,438] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:24:47,439] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:24:47,442] INFO Socket connection established, initiating session, client: /127.0.0.1:57962, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:24:47,450] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0049, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:24:47,454] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:24:47,522] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:24:47,658] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:24:47,662] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:24:47,710] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:24:47,719] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:24:47,766] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:24:47,767] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:24:47,769] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:24:47,771] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:24:47,810] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:24:47,815] INFO Skipping recovery for all logs in /tmp/kafka-logs-1 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:24:47,887] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:47,907] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-17, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 78ms (1/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:24:47,912] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:47,915] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-35, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (2/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:24:47,920] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:47,922] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-5.f1c1587f169f40a8942f75f7cbc1987f-delete, topicId=BTTwpy-LQsG5rcGyE4FslQ, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (3/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:24:47,928] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:47,932] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-41, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (4/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:24:47,937] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:47,940] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-29, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:24:47,945] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:47,948] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-11, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:24:47,952] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:47,955] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-2.5c0af66327dc4d33870ba3059a691e94-delete, topicId=BTTwpy-LQsG5rcGyE4FslQ, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (7/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:24:47,960] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:47,962] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-23, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:24:47,967] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:47,969] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-47, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (9/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:24:47,974] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:47,977] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-3.ac4dbea2c89a4f07aff9a776b6979ae6-delete, topicId=BTTwpy-LQsG5rcGyE4FslQ, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (10/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:24:47,981] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:47,985] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-5, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (11/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:24:47,988] INFO Loaded 11 logs in 177ms. (kafka.log.LogManager)
[2022-05-15 18:24:47,989] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:24:47,990] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:24:48,242] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:24:48,376] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:24:48,381] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-15 18:24:48,411] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:24:48,418] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:24:48,438] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:48,439] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:48,440] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:48,442] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:48,454] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:24:48,516] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:24:48,537] INFO Stat of the created znode at /brokers/ids/1 is: 3489,3489,1652635488528,1652635488528,1,0,0,72057641293905993,192,0,3489
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:24:48,538] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://joao:9093, czxid (broker epoch): 3489 (kafka.zk.KafkaZkClient)
[2022-05-15 18:24:48,603] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:48,610] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:48,611] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:48,625] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:48,639] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:48,667] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:24:48,671] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:24:48,672] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:24:48,697] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:48,714] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:24:48,740] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:24:48,746] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:24:48,747] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:24:48,752] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:24:48,752] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:24:48,752] INFO Kafka startTimeMs: 1652635488747 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:24:48,754] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-15 18:24:48,822] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:24:48,852] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:24:48,864] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:48,864] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:48,864] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:48,865] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:48,865] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:48,866] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:48,866] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:48,866] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:48,890] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-5, __consumer_offsets-29, __consumer_offsets-41, __consumer_offsets-23) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:24:48,925] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:48,927] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:48,928] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:48,928] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:48,929] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:48,929] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:48,929] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:48,929] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:48,930] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:48,930] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:48,930] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:48,930] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:48,930] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:48,931] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:48,931] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:48,931] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:48,937] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 9 milliseconds for epoch 34, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:48,938] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 9 milliseconds for epoch 34, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:48,938] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 9 milliseconds for epoch 34, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:48,938] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 9 milliseconds for epoch 34, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:48,939] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 9 milliseconds for epoch 34, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:48,939] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 9 milliseconds for epoch 34, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:48,939] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 8 milliseconds for epoch 34, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:48,939] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 8 milliseconds for epoch 34, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:52,017] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:24:52,268] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:24:52,343] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:24:52,346] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:24:52,347] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:24:52,362] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:24:52,366] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:52,366] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:52,366] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:52,366] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:52,366] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:52,366] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:52,367] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:52,367] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:52,367] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:52,367] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:52,367] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:52,367] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:52,367] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:52,367] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:52,367] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:52,367] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:52,367] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:52,367] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:52,369] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:52,372] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:24:52,376] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:24:52,387] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:24:52,393] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:24:52,394] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:24:52,398] INFO Socket connection established, initiating session, client: /127.0.0.1:57964, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:24:52,405] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad004a, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:24:52,410] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:24:52,472] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:24:52,614] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:24:52,619] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:24:52,657] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:24:52,665] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:24:52,718] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:24:52,720] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:24:52,721] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:24:52,723] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:24:52,771] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:24:52,776] INFO Skipping recovery for all logs in /tmp/kafka-logs-2 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:24:52,853] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:52,877] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-49, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 85ms (1/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:24:52,884] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:52,890] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-19, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (2/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:24:52,895] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:52,901] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-5.eac2e363178441dea0ae6162ca2bb3f8-delete, topicId=BTTwpy-LQsG5rcGyE4FslQ, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (3/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:24:52,906] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:52,912] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-7, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (4/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:24:52,917] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:52,921] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-13, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (5/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:24:52,926] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:52,930] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-37, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:24:52,934] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:52,937] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-43, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:24:52,941] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:52,944] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-1, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:24:52,949] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:52,951] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-1.cdef75df5ec945eab2e4d6c998ed0796-delete, topicId=BTTwpy-LQsG5rcGyE4FslQ, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (9/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:24:52,955] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:52,959] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-4.17f3327be9ea4a5caf3bb1758b725a22-delete, topicId=BTTwpy-LQsG5rcGyE4FslQ, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:24:52,963] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:52,967] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-31, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (11/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:24:52,972] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:52,976] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-25, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (12/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:24:52,978] INFO Loaded 12 logs in 207ms. (kafka.log.LogManager)
[2022-05-15 18:24:52,979] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:24:52,980] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:24:53,261] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:24:53,415] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:24:53,420] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-15 18:24:53,452] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:24:53,459] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:24:53,480] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:53,482] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:53,483] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:53,485] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:53,500] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:24:53,572] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:24:53,598] INFO Stat of the created znode at /brokers/ids/2 is: 3513,3513,1652635493590,1652635493590,1,0,0,72057641293905994,192,0,3513
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:24:53,600] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://joao:9094, czxid (broker epoch): 3513 (kafka.zk.KafkaZkClient)
[2022-05-15 18:24:53,681] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:53,689] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:53,690] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:53,709] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:53,724] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:53,754] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:24:53,759] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:24:53,760] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:24:53,789] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:53,810] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:24:53,833] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:24:53,838] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:24:53,838] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:24:53,845] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:24:53,845] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:24:53,845] INFO Kafka startTimeMs: 1652635493838 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:24:53,847] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-15 18:24:53,965] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:24:53,979] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:24:53,980] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:53,980] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:53,981] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:53,981] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:53,982] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:53,982] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:53,982] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:53,982] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:53,982] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:54,016] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-7, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:24:54,051] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:54,053] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:54,055] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:54,055] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:54,056] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:54,056] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:54,056] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:54,056] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:54,056] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:54,056] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:54,056] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:54,056] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:54,056] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:54,056] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:54,056] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:54,056] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:54,056] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 34 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:54,056] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 34 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:54,064] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 9 milliseconds for epoch 34, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:54,065] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 10 milliseconds for epoch 34, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:54,066] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 10 milliseconds for epoch 34, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:54,066] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 10 milliseconds for epoch 34, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:54,066] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 10 milliseconds for epoch 34, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:54,066] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 10 milliseconds for epoch 34, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:54,066] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 10 milliseconds for epoch 34, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:54,067] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 10 milliseconds for epoch 34, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:54,067] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 11 milliseconds for epoch 34, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:57,082] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:24:57,359] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:24:57,451] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:24:57,457] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:24:57,457] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:24:57,474] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:24:57,479] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:57,479] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:57,479] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:57,479] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:57,479] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:57,479] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:57,480] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:57,480] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:57,480] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:57,480] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:57,480] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:57,480] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:57,481] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:57,481] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:57,481] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:57,481] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:57,481] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:57,481] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:57,483] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:24:57,488] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:24:57,494] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:24:57,505] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:24:57,512] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:24:57,513] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:24:57,517] INFO Socket connection established, initiating session, client: /127.0.0.1:57966, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:24:57,526] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad004b, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:24:57,530] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:24:57,600] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:24:57,751] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:24:57,757] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:24:57,806] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:24:57,816] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:24:57,869] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:24:57,870] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:24:57,873] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:24:57,875] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:24:57,917] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:24:57,922] INFO Skipping recovery for all logs in /tmp/kafka-logs-3 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:24:57,999] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:58,024] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-14, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 88ms (1/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:24:58,044] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Loading producer state till offset 49254 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:58,044] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Reloading from producer snapshot and rebuilding producer state from offset 49254 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:58,046] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-3/__consumer_offsets-38/00000000000000049254.snapshot,49254)' (kafka.log.ProducerStateManager)
[2022-05-15 18:24:58,052] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 49254 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:58,058] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-38, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=49254) with 1 segments in 33ms (2/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:24:58,063] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:58,068] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-5.130076b655c34f0288130f1b47429aca-delete, topicId=BTTwpy-LQsG5rcGyE4FslQ, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (3/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:24:58,073] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:58,078] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-8, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (4/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:24:58,084] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:58,087] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-2, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (5/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:24:58,093] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:58,097] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-2.409f5bbbbdb749ad8a30073c9f5759c8-delete, topicId=BTTwpy-LQsG5rcGyE4FslQ, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (6/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:24:58,102] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:58,106] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-26, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:24:58,112] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:58,115] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-20, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (8/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:24:58,120] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:58,124] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-0.462c8c7345df46839a4728cf20418b72-delete, topicId=BTTwpy-LQsG5rcGyE4FslQ, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (9/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:24:58,129] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:58,131] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-32, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:24:58,136] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:24:58,138] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-44, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (11/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:24:58,141] INFO Loaded 11 logs in 224ms. (kafka.log.LogManager)
[2022-05-15 18:24:58,142] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:24:58,143] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:24:58,419] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:24:58,556] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:24:58,561] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-05-15 18:24:58,592] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:24:58,599] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:24:58,615] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:58,617] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:58,618] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:58,619] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:58,634] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:24:58,703] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:24:58,726] INFO Stat of the created znode at /brokers/ids/3 is: 3538,3538,1652635498716,1652635498716,1,0,0,72057641293905995,192,0,3538
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:24:58,727] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://joao:9095, czxid (broker epoch): 3538 (kafka.zk.KafkaZkClient)
[2022-05-15 18:24:58,800] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:58,806] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:58,807] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:58,822] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:58,846] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:58,863] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:24:58,867] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:24:58,867] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:24:58,895] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:24:58,914] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:24:58,934] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:24:58,941] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:24:58,942] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:24:58,947] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:24:58,947] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:24:58,947] INFO Kafka startTimeMs: 1652635498942 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:24:58,950] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-05-15 18:24:59,033] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:24:59,060] INFO [Partition __consumer_offsets-2 broker=3] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:59,061] INFO [Partition __consumer_offsets-20 broker=3] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:59,062] INFO [Partition __consumer_offsets-38 broker=3] Log loaded for partition __consumer_offsets-38 with initial high watermark 49254 (kafka.cluster.Partition)
[2022-05-15 18:24:59,062] INFO [Partition __consumer_offsets-8 broker=3] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:59,063] INFO [Partition __consumer_offsets-26 broker=3] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:59,063] INFO [Partition __consumer_offsets-44 broker=3] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:59,063] INFO [Partition __consumer_offsets-14 broker=3] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:59,063] INFO [Partition __consumer_offsets-32 broker=3] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:24:59,092] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-26, __consumer_offsets-32, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:24:59,104] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:24:59,125] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 2 in epoch 33 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:59,126] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 33 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:59,129] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 20 in epoch 33 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:59,129] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 33 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:59,129] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 38 in epoch 33 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:59,129] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 33 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:59,129] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 8 in epoch 33 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:59,129] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 33 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:59,129] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 26 in epoch 33 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:59,129] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 33 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:59,129] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 44 in epoch 33 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:59,129] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 33 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:59,129] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 14 in epoch 33 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:59,129] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 33 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:59,130] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 32 in epoch 33 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:24:59,130] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 33 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:59,136] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-2 in 9 milliseconds for epoch 33, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:59,138] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-20 in 9 milliseconds for epoch 33, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:59,274] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-38 in 145 milliseconds for epoch 33, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:59,275] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-8 in 146 milliseconds for epoch 33, of which 145 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:59,275] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-26 in 146 milliseconds for epoch 33, of which 146 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:59,275] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-44 in 146 milliseconds for epoch 33, of which 146 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:59,276] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-14 in 147 milliseconds for epoch 33, of which 147 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:24:59,277] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-32 in 146 milliseconds for epoch 33, of which 146 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:02,068] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:25:02,334] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:25:02,418] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:25:02,422] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:25:02,423] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:25:02,437] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:25:02,442] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:02,442] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:02,442] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:02,442] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:02,442] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:02,442] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:02,442] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:02,443] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:02,443] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:02,443] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:02,443] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:02,443] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:02,443] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:02,443] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:02,443] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:02,443] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:02,443] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:02,443] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:02,453] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:02,458] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:25:02,463] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:25:02,467] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:25:02,471] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:25:02,473] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:25:02,477] INFO Socket connection established, initiating session, client: /127.0.0.1:57968, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:25:02,483] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad004c, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:25:02,488] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:25:02,556] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:25:02,687] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:25:02,692] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:25:02,742] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:25:02,751] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:25:02,803] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:25:02,804] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:25:02,806] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:25:02,808] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:25:02,843] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:25:02,846] INFO Skipping recovery for all logs in /tmp/kafka-logs-4 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:25:02,919] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:02,943] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-24, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 82ms (1/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:25:02,948] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:02,952] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-12, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (2/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:25:02,957] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:02,960] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-30, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (3/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:25:02,965] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:02,969] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-36, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (4/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:25:02,973] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:02,976] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-0.0720a3ccadd94b3e96e1107eb8cc4472-delete, topicId=BTTwpy-LQsG5rcGyE4FslQ, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:25:02,981] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:02,985] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-3.a0ac44419410478f9481243d407f6c79-delete, topicId=BTTwpy-LQsG5rcGyE4FslQ, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (6/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:25:02,990] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:02,995] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-42, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (7/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:25:03,000] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:03,003] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-0, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (8/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:25:03,008] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:03,010] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-4.86794a459947483ab50518399f9b06df-delete, topicId=BTTwpy-LQsG5rcGyE4FslQ, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (9/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:25:03,015] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:03,019] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-18, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (10/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:25:03,024] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:03,027] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-6, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (11/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:25:03,033] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:03,035] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-48, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (12/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:25:03,038] INFO Loaded 12 logs in 195ms. (kafka.log.LogManager)
[2022-05-15 18:25:03,039] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:25:03,040] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:25:03,273] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:25:03,411] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:25:03,415] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.Acceptor)
[2022-05-15 18:25:03,443] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:25:03,451] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:25:03,467] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:25:03,469] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:25:03,470] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:25:03,471] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:25:03,484] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:25:03,546] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:25:03,570] INFO Stat of the created znode at /brokers/ids/4 is: 3562,3562,1652635503562,1652635503562,1,0,0,72057641293905996,192,0,3562
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:25:03,571] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://joao:9096, czxid (broker epoch): 3562 (kafka.zk.KafkaZkClient)
[2022-05-15 18:25:03,643] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:25:03,648] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:25:03,649] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:25:03,666] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:25:03,682] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:25:03,710] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:25:03,716] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:25:03,716] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:25:03,742] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:25:03,761] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:25:03,780] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:25:03,790] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:25:03,791] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:25:03,796] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:25:03,796] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:25:03,797] INFO Kafka startTimeMs: 1652635503791 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:25:03,799] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2022-05-15 18:25:03,886] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:25:03,913] INFO [Partition __consumer_offsets-18 broker=4] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:03,914] INFO [Partition __consumer_offsets-36 broker=4] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:03,914] INFO [Partition __consumer_offsets-6 broker=4] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:03,915] INFO [Partition __consumer_offsets-24 broker=4] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:03,915] INFO [Partition __consumer_offsets-42 broker=4] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:03,916] INFO [Partition __consumer_offsets-12 broker=4] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:03,917] INFO [Partition __consumer_offsets-30 broker=4] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:03,917] INFO [Partition __consumer_offsets-0 broker=4] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:03,917] INFO [Partition __consumer_offsets-48 broker=4] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:03,945] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-12, __consumer_offsets-42, __consumer_offsets-18) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:03,956] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:25:03,985] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 18 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:25:03,987] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:03,989] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 36 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:25:03,989] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:03,989] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 6 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:25:03,989] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:03,989] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 24 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:25:03,989] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:03,989] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 42 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:25:03,989] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:03,989] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 12 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:25:03,989] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:03,990] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 30 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:25:03,990] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:03,990] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 0 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:25:03,990] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:03,990] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 48 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:25:03,990] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:03,997] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-18 in 9 milliseconds for epoch 36, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:03,998] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-36 in 9 milliseconds for epoch 36, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:03,998] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-6 in 9 milliseconds for epoch 36, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:03,998] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-24 in 9 milliseconds for epoch 36, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:03,999] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-42 in 10 milliseconds for epoch 36, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:03,999] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-12 in 9 milliseconds for epoch 36, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:03,999] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-30 in 9 milliseconds for epoch 36, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:03,999] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-0 in 9 milliseconds for epoch 36, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:03,999] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-48 in 9 milliseconds for epoch 36, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:07,071] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:25:07,325] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:25:07,406] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:25:07,410] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:25:07,410] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:25:07,426] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:25:07,430] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:07,430] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:07,430] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:07,430] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:07,430] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:07,430] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:07,431] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:07,431] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:07,431] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:07,431] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:07,431] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:07,431] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:07,431] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:07,431] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:07,431] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:07,431] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:07,431] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:07,431] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:07,433] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:25:07,437] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:25:07,444] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:25:07,460] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:25:07,465] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:25:07,466] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:25:07,471] INFO Socket connection established, initiating session, client: /127.0.0.1:57972, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:25:07,479] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad004d, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:25:07,484] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:25:07,558] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:25:07,687] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:25:07,692] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:25:07,744] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:25:07,757] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:25:07,803] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:25:07,804] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:25:07,806] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:25:07,807] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:25:07,853] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:25:07,857] INFO Skipping recovery for all logs in /tmp/kafka-logs-5 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:25:07,930] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:07,953] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-46, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 82ms (1/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:25:07,958] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:07,962] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-2.78d7ce1a4ead4caab50090a53bd3381e-delete, topicId=BTTwpy-LQsG5rcGyE4FslQ, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (2/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:25:07,967] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:07,970] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-10, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (3/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:25:07,974] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:07,977] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-1.f91c206489554e4483a9a4cf94207fe5-delete, topicId=BTTwpy-LQsG5rcGyE4FslQ, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (4/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:25:07,982] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:07,985] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-28, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:25:07,990] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:07,993] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-4.1e1a3e360006431689844519fd509c1c-delete, topicId=BTTwpy-LQsG5rcGyE4FslQ, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:25:08,008] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Loading producer state till offset 41065 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:08,009] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 41065 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:08,010] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-22/00000000000000041065.snapshot,41065)' (kafka.log.ProducerStateManager)
[2022-05-15 18:25:08,019] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Producer state recovery took 10ms for snapshot load and 0ms for segment recovery from offset 41065 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:08,022] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-22, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=41065) with 1 segments in 28ms (7/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:25:08,026] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:08,029] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-16, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (8/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:25:08,036] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Loading producer state till offset 18252 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:08,036] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 18252 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:08,037] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-40/00000000000000018252.snapshot,18252)' (kafka.log.ProducerStateManager)
[2022-05-15 18:25:08,037] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 18252 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:08,041] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-40, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=18252) with 1 segments in 12ms (9/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:25:08,045] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:08,049] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-34, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (10/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:25:08,055] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:08,057] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-4, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (11/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:25:08,060] INFO Loaded 11 logs in 206ms. (kafka.log.LogManager)
[2022-05-15 18:25:08,060] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:25:08,061] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:25:08,300] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:25:08,420] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:25:08,423] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.Acceptor)
[2022-05-15 18:25:08,451] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:25:08,458] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:25:08,474] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:25:08,475] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:25:08,477] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:25:08,478] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:25:08,491] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:25:08,554] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:25:08,572] INFO Stat of the created znode at /brokers/ids/5 is: 3587,3587,1652635508564,1652635508564,1,0,0,72057641293905997,192,0,3587
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:25:08,573] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://joao:9097, czxid (broker epoch): 3587 (kafka.zk.KafkaZkClient)
[2022-05-15 18:25:08,640] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:25:08,646] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:25:08,647] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:25:08,662] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:25:08,689] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:25:08,708] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:25:08,714] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:25:08,714] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:25:08,745] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:25:08,766] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:25:08,788] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:25:08,793] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:25:08,793] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:25:08,798] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:25:08,798] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:25:08,798] INFO Kafka startTimeMs: 1652635508794 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:25:08,802] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2022-05-15 18:25:08,863] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:25:08,910] INFO [Partition __consumer_offsets-34 broker=5] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:08,910] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:25:08,910] INFO [Partition __consumer_offsets-4 broker=5] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:08,910] INFO [Partition __consumer_offsets-22 broker=5] Log loaded for partition __consumer_offsets-22 with initial high watermark 41065 (kafka.cluster.Partition)
[2022-05-15 18:25:08,910] INFO [Partition __consumer_offsets-40 broker=5] Log loaded for partition __consumer_offsets-40 with initial high watermark 18252 (kafka.cluster.Partition)
[2022-05-15 18:25:08,910] INFO [Partition __consumer_offsets-10 broker=5] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:08,911] INFO [Partition __consumer_offsets-28 broker=5] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:08,911] INFO [Partition __consumer_offsets-46 broker=5] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:08,911] INFO [Partition __consumer_offsets-16 broker=5] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:08,939] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:08,970] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 34 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:25:08,972] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:08,974] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 4 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:25:08,974] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:08,974] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 22 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:25:08,974] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:08,974] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 40 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:25:08,974] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:08,974] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 10 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:25:08,974] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:08,974] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 28 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:25:08,974] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:08,974] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 46 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:25:08,974] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:08,974] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 16 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:25:08,974] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:08,985] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-34 in 11 milliseconds for epoch 38, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:08,986] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-4 in 12 milliseconds for epoch 38, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:09,009] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-9fa5abef-fdc9-4c05-8f09-7f9780632837, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:25:09,023] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-ed3a6d0d-54c4-4b54-b4a4-a5d0ecba6f8e, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:25:09,023] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-1038faf2-d998-4707-9799-897de83d6136, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:25:09,023] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-b283a5ee-70be-4bf9-b41c-74e089f12e34, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:25:09,024] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-360d1581-f79b-41e6-82d3-fe3577615014, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:25:09,024] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-9e173d1e-b47a-4b16-9874-bf5d2688c730, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:25:09,024] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-81fafa38-80dc-43ea-ac6c-e398b06565dc, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:25:09,055] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-d15976bc-df63-4682-8583-fd67cbb1d9df, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:25:09,055] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-a0d7c5c7-e384-4339-b0be-414878362e3e, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:25:09,056] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-ee781f71-f1c3-46d7-bd93-d90a4fe359ff, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:25:09,056] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-78575c72-7be8-4563-b114-53b271a8ef70, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:25:09,056] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-0287b15c-1acd-4475-b9ce-b994aebeeff2, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:25:09,056] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-45d54f6e-f1d8-43f7-8ace-1db96ac0cfac, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:25:09,118] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-954ef0dc-d124-405b-9bb6-119086dd08c0, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:25:09,119] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-3f51cd43-28ab-4459-969e-211543e6cd72, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:25:09,120] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-4b8634e2-92f3-4603-97c5-35df7219bd84, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 4. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:25:09,121] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-22 in 147 milliseconds for epoch 38, of which 12 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:09,140] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-40 in 166 milliseconds for epoch 38, of which 147 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:09,141] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-10 in 167 milliseconds for epoch 38, of which 166 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:09,141] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-28 in 167 milliseconds for epoch 38, of which 167 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:09,142] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-46 in 168 milliseconds for epoch 38, of which 168 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:09,143] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-16 in 169 milliseconds for epoch 38, of which 168 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:25:12,718] INFO Creating topic Sensor with configuration {min.insync.replicas=2} and initial partition assignment HashMap(0 -> ArrayBuffer(3, 1, 2), 1 -> ArrayBuffer(0, 2, 3), 2 -> ArrayBuffer(5, 3, 0), 3 -> ArrayBuffer(4, 0, 5), 4 -> ArrayBuffer(1, 5, 4), 5 -> ArrayBuffer(2, 4, 1)) (kafka.zk.AdminZkClient)
[2022-05-15 18:25:12,760] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-4) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,761] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,761] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,762] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,762] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,762] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,773] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:12,774] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:12,775] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:12,775] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:12,776] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:12,778] INFO Created log for partition Sensor-1 in /tmp/kafka-logs/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:25:12,780] INFO [Partition Sensor-1 broker=0] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 18:25:12,781] INFO [Partition Sensor-1 broker=0] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:12,781] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-4/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:25:12,777] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:12,782] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-2/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:25:12,784] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-3/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:25:12,785] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-1/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:25:12,785] INFO [Partition Sensor-5 broker=2] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 18:25:12,786] INFO [Partition Sensor-5 broker=2] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:12,786] INFO [Partition Sensor-3 broker=4] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 18:25:12,786] INFO [Partition Sensor-3 broker=4] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:12,787] INFO [Partition Sensor-0 broker=3] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 18:25:12,787] INFO [Partition Sensor-0 broker=3] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:12,787] INFO [Partition Sensor-4 broker=1] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 18:25:12,788] INFO [Partition Sensor-4 broker=1] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:12,790] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-5/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:25:12,793] INFO [Partition Sensor-2 broker=5] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 18:25:12,794] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:12,794] INFO [Partition Sensor-2 broker=5] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:12,795] INFO Created log for partition Sensor-3 in /tmp/kafka-logs/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:25:12,795] INFO [Partition Sensor-3 broker=0] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 18:25:12,795] INFO [Partition Sensor-3 broker=0] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:12,799] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:12,799] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:12,800] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-2/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:25:12,800] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-4/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:25:12,800] INFO [Partition Sensor-0 broker=2] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 18:25:12,800] INFO [Partition Sensor-4 broker=4] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 18:25:12,801] INFO [Partition Sensor-0 broker=2] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:12,801] INFO [Partition Sensor-4 broker=4] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:12,801] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:12,803] INFO Created log for partition Sensor-2 in /tmp/kafka-logs/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:25:12,803] INFO [Partition Sensor-2 broker=0] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 18:25:12,803] INFO [Partition Sensor-2 broker=0] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:12,803] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:12,803] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,804] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:12,806] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-1/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:25:12,807] INFO [Partition Sensor-5 broker=1] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 18:25:12,807] INFO [Partition Sensor-5 broker=1] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:12,808] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:12,808] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:12,809] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-3/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:25:12,810] INFO [Partition Sensor-2 broker=3] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 18:25:12,810] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-2/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:25:12,810] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:12,810] INFO [Partition Sensor-2 broker=3] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:12,810] INFO [Partition Sensor-1 broker=2] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 18:25:12,810] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-4/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:25:12,810] INFO [Partition Sensor-1 broker=2] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:12,810] INFO [Partition Sensor-5 broker=4] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 18:25:12,810] INFO [Partition Sensor-5 broker=4] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:12,810] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,810] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(Sensor-4, Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,812] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-5/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:25:12,813] INFO [Partition Sensor-4 broker=5] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 18:25:12,814] INFO [Partition Sensor-4 broker=5] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:12,819] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:12,820] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:12,821] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-1/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:25:12,821] INFO [Partition Sensor-0 broker=1] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 18:25:12,822] INFO [Partition Sensor-0 broker=1] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:12,822] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-3/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:25:12,822] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(Sensor-5, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,822] INFO [Partition Sensor-1 broker=3] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 18:25:12,822] INFO [Partition Sensor-1 broker=3] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:12,822] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,823] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:25:12,825] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-5/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:25:12,825] INFO [Partition Sensor-3 broker=5] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 18:25:12,825] INFO [Partition Sensor-3 broker=5] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:25:12,825] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(Sensor-4, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,828] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,831] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 4 for partitions Map(Sensor-3 -> InitialFetchState(Some(MFB1IcMITPONtX0EWrt34w),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,834] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,834] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,835] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 5 for partitions Map(Sensor-2 -> InitialFetchState(Some(MFB1IcMITPONtX0EWrt34w),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,835] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,838] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,838] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,838] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:25:12,838] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:25:12,841] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 0 for partitions Map(Sensor-1 -> InitialFetchState(Some(MFB1IcMITPONtX0EWrt34w),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,842] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 2 for partitions Map(Sensor-5 -> InitialFetchState(Some(MFB1IcMITPONtX0EWrt34w),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,844] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,844] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,847] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,847] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,848] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 3 for partitions Map(Sensor-0 -> InitialFetchState(Some(MFB1IcMITPONtX0EWrt34w),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,848] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 1 for partitions Map(Sensor-4 -> InitialFetchState(Some(MFB1IcMITPONtX0EWrt34w),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,848] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,848] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,848] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:25:12,848] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:25:12,849] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:25:12,849] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:25:12,855] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,859] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,862] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 4 for partitions Map(Sensor-3 -> InitialFetchState(Some(MFB1IcMITPONtX0EWrt34w),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,859] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,866] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 2 for partitions Map(Sensor-5 -> InitialFetchState(Some(MFB1IcMITPONtX0EWrt34w),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,869] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,871] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,871] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,872] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,872] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 3 for partitions Map(Sensor-0 -> InitialFetchState(Some(MFB1IcMITPONtX0EWrt34w),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,873] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 0 for partitions Map(Sensor-1 -> InitialFetchState(Some(MFB1IcMITPONtX0EWrt34w),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,875] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:25:12,874] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:25:12,875] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:25:12,883] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 1 for partitions Map(Sensor-4 -> InitialFetchState(Some(MFB1IcMITPONtX0EWrt34w),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,883] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,885] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,886] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,889] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:25:12,892] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 5 for partitions Map(Sensor-2 -> InitialFetchState(Some(MFB1IcMITPONtX0EWrt34w),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:25:12,895] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,885] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:25:12,914] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,915] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:25:12,976] WARN [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-3. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,980] WARN [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-2. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,989] WARN [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-4. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,996] WARN [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-0. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:12,996] WARN [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-0. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:25:42,849] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=134116, lastModifiedTime=1652635189158, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:25:42,850] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=134116, lastModifiedTime=1652635189158, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:25:42,853] INFO Deleted log /tmp/kafka-logs/Sensor-0.73524822ca3d43ddabff0d54203141f4-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:42,853] INFO Deleted offset index /tmp/kafka-logs/Sensor-0.73524822ca3d43ddabff0d54203141f4-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:42,855] INFO Deleted time index /tmp/kafka-logs/Sensor-0.73524822ca3d43ddabff0d54203141f4-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:42,861] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs/Sensor-0.73524822ca3d43ddabff0d54203141f4-delete. (kafka.log.LogManager)
[2022-05-15 18:25:42,862] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=144656, lastModifiedTime=1652635190542, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:25:42,862] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=144656, lastModifiedTime=1652635190542, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:25:42,863] INFO Deleted log /tmp/kafka-logs/Sensor-3.210a68451f2644058440fc92da220896-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:42,863] INFO Deleted offset index /tmp/kafka-logs/Sensor-3.210a68451f2644058440fc92da220896-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:42,863] INFO Deleted time index /tmp/kafka-logs/Sensor-3.210a68451f2644058440fc92da220896-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:42,864] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs/Sensor-3.210a68451f2644058440fc92da220896-delete. (kafka.log.LogManager)
[2022-05-15 18:25:42,923] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=137762, lastModifiedTime=1652635189886, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:25:42,923] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=137762, lastModifiedTime=1652635189886, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:25:42,925] INFO Deleted log /tmp/kafka-logs/Sensor-1.3e0a0f4a13f64799a0ccad0c0103088d-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:42,925] INFO Deleted offset index /tmp/kafka-logs/Sensor-1.3e0a0f4a13f64799a0ccad0c0103088d-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:42,925] INFO Deleted time index /tmp/kafka-logs/Sensor-1.3e0a0f4a13f64799a0ccad0c0103088d-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:42,926] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs/Sensor-1.3e0a0f4a13f64799a0ccad0c0103088d-delete. (kafka.log.LogManager)
[2022-05-15 18:25:47,926] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=66568, lastModifiedTime=1652635171053, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:25:47,928] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=66568, lastModifiedTime=1652635171053, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:25:47,930] INFO Deleted log /tmp/kafka-logs-1/Sensor-5.f1c1587f169f40a8942f75f7cbc1987f-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:47,931] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-5.f1c1587f169f40a8942f75f7cbc1987f-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:47,933] INFO Deleted time index /tmp/kafka-logs-1/Sensor-5.f1c1587f169f40a8942f75f7cbc1987f-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:47,935] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-1/Sensor-5.f1c1587f169f40a8942f75f7cbc1987f-delete. (kafka.log.LogManager)
[2022-05-15 18:25:47,956] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=132683, lastModifiedTime=1652635188738, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:25:47,957] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=132683, lastModifiedTime=1652635188738, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:25:47,958] INFO Deleted log /tmp/kafka-logs-1/Sensor-2.5c0af66327dc4d33870ba3059a691e94-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:47,958] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-2.5c0af66327dc4d33870ba3059a691e94-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:47,959] INFO Deleted time index /tmp/kafka-logs-1/Sensor-2.5c0af66327dc4d33870ba3059a691e94-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:47,959] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-1/Sensor-2.5c0af66327dc4d33870ba3059a691e94-delete. (kafka.log.LogManager)
[2022-05-15 18:25:47,979] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=144656, lastModifiedTime=1652635190542, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:25:47,979] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=144656, lastModifiedTime=1652635190542, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:25:47,980] INFO Deleted log /tmp/kafka-logs-1/Sensor-3.ac4dbea2c89a4f07aff9a776b6979ae6-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:47,981] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-3.ac4dbea2c89a4f07aff9a776b6979ae6-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:47,981] INFO Deleted time index /tmp/kafka-logs-1/Sensor-3.ac4dbea2c89a4f07aff9a776b6979ae6-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:47,981] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-1/Sensor-3.ac4dbea2c89a4f07aff9a776b6979ae6-delete. (kafka.log.LogManager)
[2022-05-15 18:25:52,906] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=66568, lastModifiedTime=1652635171057, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:25:52,909] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=66568, lastModifiedTime=1652635171057, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:25:52,911] INFO Deleted log /tmp/kafka-logs-2/Sensor-5.eac2e363178441dea0ae6162ca2bb3f8-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:52,912] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-5.eac2e363178441dea0ae6162ca2bb3f8-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:52,914] INFO Deleted time index /tmp/kafka-logs-2/Sensor-5.eac2e363178441dea0ae6162ca2bb3f8-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:52,917] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-2/Sensor-5.eac2e363178441dea0ae6162ca2bb3f8-delete. (kafka.log.LogManager)
[2022-05-15 18:25:52,952] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=137762, lastModifiedTime=1652635189886, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:25:52,953] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=137762, lastModifiedTime=1652635189886, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:25:52,954] INFO Deleted log /tmp/kafka-logs-2/Sensor-1.cdef75df5ec945eab2e4d6c998ed0796-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:52,954] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-1.cdef75df5ec945eab2e4d6c998ed0796-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:52,955] INFO Deleted time index /tmp/kafka-logs-2/Sensor-1.cdef75df5ec945eab2e4d6c998ed0796-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:52,956] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-2/Sensor-1.cdef75df5ec945eab2e4d6c998ed0796-delete. (kafka.log.LogManager)
[2022-05-15 18:25:52,960] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=62006, lastModifiedTime=1652635169777, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:25:52,961] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=62006, lastModifiedTime=1652635169777, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:25:52,962] INFO Deleted log /tmp/kafka-logs-2/Sensor-4.17f3327be9ea4a5caf3bb1758b725a22-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:52,962] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-4.17f3327be9ea4a5caf3bb1758b725a22-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:52,963] INFO Deleted time index /tmp/kafka-logs-2/Sensor-4.17f3327be9ea4a5caf3bb1758b725a22-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:52,963] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-2/Sensor-4.17f3327be9ea4a5caf3bb1758b725a22-delete. (kafka.log.LogManager)
[2022-05-15 18:25:58,072] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=66568, lastModifiedTime=1652635171057, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:25:58,074] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=66568, lastModifiedTime=1652635171057, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:25:58,078] INFO Deleted log /tmp/kafka-logs-3/Sensor-5.130076b655c34f0288130f1b47429aca-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:58,078] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-5.130076b655c34f0288130f1b47429aca-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:58,080] INFO Deleted time index /tmp/kafka-logs-3/Sensor-5.130076b655c34f0288130f1b47429aca-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:58,084] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-3/Sensor-5.130076b655c34f0288130f1b47429aca-delete. (kafka.log.LogManager)
[2022-05-15 18:25:58,097] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=132683, lastModifiedTime=1652635188734, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:25:58,098] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=132683, lastModifiedTime=1652635188734, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:25:58,099] INFO Deleted log /tmp/kafka-logs-3/Sensor-2.409f5bbbbdb749ad8a30073c9f5759c8-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:58,100] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-2.409f5bbbbdb749ad8a30073c9f5759c8-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:58,101] INFO Deleted time index /tmp/kafka-logs-3/Sensor-2.409f5bbbbdb749ad8a30073c9f5759c8-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:58,101] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-3/Sensor-2.409f5bbbbdb749ad8a30073c9f5759c8-delete. (kafka.log.LogManager)
[2022-05-15 18:25:58,124] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=134116, lastModifiedTime=1652635189158, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:25:58,125] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=134116, lastModifiedTime=1652635189158, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:25:58,126] INFO Deleted log /tmp/kafka-logs-3/Sensor-0.462c8c7345df46839a4728cf20418b72-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:58,126] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-0.462c8c7345df46839a4728cf20418b72-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:58,126] INFO Deleted time index /tmp/kafka-logs-3/Sensor-0.462c8c7345df46839a4728cf20418b72-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:25:58,127] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-3/Sensor-0.462c8c7345df46839a4728cf20418b72-delete. (kafka.log.LogManager)
[2022-05-15 18:26:02,981] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=134116, lastModifiedTime=1652635189154, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:26:02,983] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=134116, lastModifiedTime=1652635189154, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:26:02,986] INFO Deleted log /tmp/kafka-logs-4/Sensor-0.0720a3ccadd94b3e96e1107eb8cc4472-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:26:02,986] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-0.0720a3ccadd94b3e96e1107eb8cc4472-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:26:02,990] INFO Deleted time index /tmp/kafka-logs-4/Sensor-0.0720a3ccadd94b3e96e1107eb8cc4472-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:26:02,993] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-4/Sensor-0.0720a3ccadd94b3e96e1107eb8cc4472-delete. (kafka.log.LogManager)
[2022-05-15 18:26:02,994] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=144656, lastModifiedTime=1652635190542, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:26:02,994] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=144656, lastModifiedTime=1652635190542, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:26:02,995] INFO Deleted log /tmp/kafka-logs-4/Sensor-3.a0ac44419410478f9481243d407f6c79-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:26:02,995] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-3.a0ac44419410478f9481243d407f6c79-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:26:02,995] INFO Deleted time index /tmp/kafka-logs-4/Sensor-3.a0ac44419410478f9481243d407f6c79-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:26:02,995] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-4/Sensor-3.a0ac44419410478f9481243d407f6c79-delete. (kafka.log.LogManager)
[2022-05-15 18:26:03,012] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=62006, lastModifiedTime=1652635169777, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:26:03,013] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=62006, lastModifiedTime=1652635169777, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:26:03,014] INFO Deleted log /tmp/kafka-logs-4/Sensor-4.86794a459947483ab50518399f9b06df-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:26:03,016] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-4.86794a459947483ab50518399f9b06df-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:26:03,016] INFO Deleted time index /tmp/kafka-logs-4/Sensor-4.86794a459947483ab50518399f9b06df-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:26:03,017] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-4/Sensor-4.86794a459947483ab50518399f9b06df-delete. (kafka.log.LogManager)
[2022-05-15 18:26:07,967] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=132683, lastModifiedTime=1652635188738, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:26:07,969] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=132683, lastModifiedTime=1652635188738, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:26:07,971] INFO Deleted log /tmp/kafka-logs-5/Sensor-2.78d7ce1a4ead4caab50090a53bd3381e-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:26:07,972] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-2.78d7ce1a4ead4caab50090a53bd3381e-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:26:07,974] INFO Deleted time index /tmp/kafka-logs-5/Sensor-2.78d7ce1a4ead4caab50090a53bd3381e-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:26:07,979] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-5/Sensor-2.78d7ce1a4ead4caab50090a53bd3381e-delete. (kafka.log.LogManager)
[2022-05-15 18:26:07,980] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=137762, lastModifiedTime=1652635189886, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:26:07,980] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=137762, lastModifiedTime=1652635189886, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:26:07,981] INFO Deleted log /tmp/kafka-logs-5/Sensor-1.f91c206489554e4483a9a4cf94207fe5-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:26:07,981] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-1.f91c206489554e4483a9a4cf94207fe5-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:26:07,981] INFO Deleted time index /tmp/kafka-logs-5/Sensor-1.f91c206489554e4483a9a4cf94207fe5-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:26:07,982] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-5/Sensor-1.f91c206489554e4483a9a4cf94207fe5-delete. (kafka.log.LogManager)
[2022-05-15 18:26:07,994] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=62006, lastModifiedTime=1652635169773, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:26:07,995] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=62006, lastModifiedTime=1652635169773, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:26:07,996] INFO Deleted log /tmp/kafka-logs-5/Sensor-4.1e1a3e360006431689844519fd509c1c-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:26:07,997] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-4.1e1a3e360006431689844519fd509c1c-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:26:07,997] INFO Deleted time index /tmp/kafka-logs-5/Sensor-4.1e1a3e360006431689844519fd509c1c-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:26:07,998] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-5/Sensor-4.1e1a3e360006431689844519fd509c1c-delete. (kafka.log.LogManager)
[2022-05-15 18:30:57,992] INFO [GroupMetadataManager brokerId=0] Group group2 transitioned to Dead in generation 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:30:57,992] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:30:57,993] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:30:57,993] INFO [GroupCoordinator 4]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:30:57,996] INFO [GroupMetadataManager brokerId=5] Group group1 transitioned to Dead in generation 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:30:57,996] INFO [GroupMetadataManager brokerId=3] Group group3 transitioned to Dead in generation 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:30:57,996] INFO [GroupCoordinator 0]: Removed 6 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:30:58,002] INFO [GroupCoordinator 3]: Removed 6 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:30:58,002] INFO [GroupCoordinator 5]: Removed 6 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:30:58,005] WARN [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_OR_PARTITION from the leader for partition Sensor-5. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,005] WARN [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_OR_PARTITION from the leader for partition Sensor-5. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,024] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:30:58,024] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:30:58,025] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:30:58,025] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:30:58,024] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:30:58,025] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:30:58,025] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:30:58,026] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:30:58,026] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:30:58,026] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:30:58,026] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:30:58,026] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:30:58,031] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,031] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,032] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,033] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:30:58,033] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,033] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:30:58,034] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,034] INFO [ReplicaFetcher replicaId=1, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,035] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,035] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,035] INFO [ReplicaFetcher replicaId=4, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,035] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,036] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:30:58,036] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:30:58,036] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1056 due to node 3 being disconnected (elapsed time since creation: 142ms, elapsed time since send: 142ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:30:58,036] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1071 due to node 4 being disconnected (elapsed time since creation: 148ms, elapsed time since send: 148ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:30:58,037] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=130838774, epoch=1069) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:30:58,038] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,038] INFO [ReplicaFetcher replicaId=0, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,038] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 874 due to node 1 being disconnected (elapsed time since creation: 378ms, elapsed time since send: 378ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:30:58,038] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1005 due to node 0 being disconnected (elapsed time since creation: 298ms, elapsed time since send: 298ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:30:58,040] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,040] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,041] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:30:58,040] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:30:58,037] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1863390917, epoch=1054) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:30:58,042] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,042] INFO [ReplicaFetcher replicaId=2, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,039] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=1262286396, epoch=874) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:30:58,039] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=1753225528, epoch=1005) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:30:58,044] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,044] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 875 due to node 1 being disconnected (elapsed time since creation: 387ms, elapsed time since send: 387ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:30:58,043] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1056 due to node 3 being disconnected (elapsed time since creation: 152ms, elapsed time since send: 152ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:30:58,044] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,044] INFO [ReplicaFetcher replicaId=5, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,044] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,044] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:30:58,045] INFO [ReplicaFetcher replicaId=3, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,045] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1005 due to node 5 being disconnected (elapsed time since creation: 319ms, elapsed time since send: 319ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:30:58,045] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=1067903975, epoch=1003) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:30:58,046] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,046] INFO [ReplicaFetcher replicaId=0, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,047] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,047] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:30:58,044] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=76641466, epoch=1054) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:30:58,044] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=345779984, epoch=873) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:30:58,048] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,048] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1005 due to node 0 being disconnected (elapsed time since creation: 310ms, elapsed time since send: 310ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:30:58,048] INFO [ReplicaFetcher replicaId=1, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,048] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,048] INFO [ReplicaFetcher replicaId=4, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,048] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=227551520, epoch=1005) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:30:58,049] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,049] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,049] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,049] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:30:58,049] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:30:58,050] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1071 due to node 4 being disconnected (elapsed time since creation: 157ms, elapsed time since send: 157ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:30:58,050] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1006 due to node 5 being disconnected (elapsed time since creation: 324ms, elapsed time since send: 324ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:30:58,050] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:30:58,050] INFO [ReplicaFetcher replicaId=2, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,050] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=1159267289, epoch=1006) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:30:58,051] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:30:58,051] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,051] INFO [ReplicaFetcher replicaId=3, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,051] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:30:58,051] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:30:58,050] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=1473378318, epoch=1071) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:30:58,052] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,052] INFO [ReplicaFetcher replicaId=5, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:30:58,053] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:30:58,053] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:30:58,053] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:30:58,053] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:30:58,053] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:30:58,054] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:30:58,056] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:30:58,055] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:30:58,067] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-2/Sensor-5.5a196a2bd4b245c1be41f480b33c8ba7-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:30:58,069] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs/Sensor-2.01dd320e0ebd4d20a04eb73da7c80ac4-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:30:58,070] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-1/Sensor-4.4479f2c030844a5aa14211563cecfd5b-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:30:58,071] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-2/Sensor-0.c4518740d1aa4dc78469b2defde2fe0b-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:30:58,072] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-4/Sensor-4.581a01e9e9e8483baa62ca9705cb52d5-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:30:58,074] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs/Sensor-3.ffb5dcaaab7a492fa153776acb87fc91-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:30:58,074] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-2/Sensor-1.f6d39bd0eb4f43f6a0c2447f5677ec85-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:30:58,075] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-3/Sensor-2.6cde347c54fc4b018b3006510e13d1e4-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:30:58,075] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-1/Sensor-5.c92d8dc6bdc743778a88985cb555afa2-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:30:58,077] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-4/Sensor-5.55e2e7cb7a65404da3a2440f977c622d-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:30:58,078] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-1/Sensor-0.78a885ba31764e8a8d8164e2108a98aa-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:30:58,080] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-3/Sensor-0.434b88b4914b4f1c989e3cccb7661f7a-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:30:58,080] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs/Sensor-1.90aeadc965834f82bde787d0712295af-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:30:58,081] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-4/Sensor-3.d9dbb331425840eb87e57f7252b3292d-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:30:58,081] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-5/Sensor-4.a862048540fb42729791ec7261669c7e-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:30:58,083] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-3/Sensor-1.b672de8a8b844dda988724e226cd6942-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:30:58,086] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-5/Sensor-2.6bb94050f00147e980250ed613fe0785-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:30:58,089] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-5/Sensor-3.1b3279a48d8d4b309803f2680348f2d3-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:31:01,366] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:31:01,366] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:31:01,366] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:31:01,366] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:31:01,366] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:31:01,366] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:31:01,368] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:31:01,368] INFO [KafkaServer id=5] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:31:01,368] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:31:01,369] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:31:01,369] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:31:01,369] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:31:01,370] INFO [KafkaServer id=5] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:31:01,370] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:31:01,370] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:31:01,371] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:31:01,372] INFO [KafkaServer id=4] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:31:01,373] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:31:01,396] INFO [KafkaServer id=5] Controlled shutdown request returned successfully after 20ms (kafka.server.KafkaServer)
[2022-05-15 18:31:01,398] INFO [KafkaServer id=4] Controlled shutdown request returned successfully after 18ms (kafka.server.KafkaServer)
[2022-05-15 18:31:01,400] INFO [KafkaServer id=3] Controlled shutdown request returned successfully after 21ms (kafka.server.KafkaServer)
[2022-05-15 18:31:01,400] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:31:01,400] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:31:01,400] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:31:01,400] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:31:01,400] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:31:01,401] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:31:01,401] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 19ms (kafka.server.KafkaServer)
[2022-05-15 18:31:01,402] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:31:01,402] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 26ms (kafka.server.KafkaServer)
[2022-05-15 18:31:01,402] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:31:01,402] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 15ms (kafka.server.KafkaServer)
[2022-05-15 18:31:01,403] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:31:01,403] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:31:01,403] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:31:01,404] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:31:01,404] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:31:01,405] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:31:01,405] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:31:01,405] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:31:01,405] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:31:01,406] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:31:01,406] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:31:01,405] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:31:01,407] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:31:01,407] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:31:01,405] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:31:01,408] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:31:01,416] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:31:01,418] INFO [data-plane Kafka Request Handler on Broker 5], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:31:01,420] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:31:01,422] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:31:01,422] INFO [data-plane Kafka Request Handler on Broker 4], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:31:01,424] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:31:01,424] INFO [data-plane Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:31:01,425] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:31:01,425] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:31:01,425] INFO [data-plane Kafka Request Handler on Broker 5], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:31:01,426] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:31:01,429] INFO [data-plane Kafka Request Handler on Broker 4], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:31:01,431] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:31:01,431] INFO [ExpirationReaper-5-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,433] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:31:01,434] INFO [ExpirationReaper-4-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,434] INFO [data-plane Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:31:01,436] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:31:01,437] INFO [ExpirationReaper-5-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,437] INFO [ExpirationReaper-5-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,438] INFO [ExpirationReaper-3-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,439] INFO [KafkaApi-5] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:31:01,439] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:31:01,440] INFO [ExpirationReaper-5-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,440] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,442] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:31:01,442] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,445] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,494] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,494] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,495] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:31:01,496] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,518] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,518] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,519] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:31:01,520] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,520] INFO [ExpirationReaper-5-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,520] INFO [ExpirationReaper-5-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,522] INFO [TransactionCoordinator id=5] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:31:01,523] INFO [Transaction State Manager 5]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:31:01,523] INFO [Transaction Marker Channel Manager 5]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:31:01,523] INFO [Transaction Marker Channel Manager 5]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:31:01,523] INFO [Transaction Marker Channel Manager 5]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:31:01,524] INFO [TransactionCoordinator id=5] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:31:01,525] INFO [GroupCoordinator 5]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:31:01,526] INFO [ExpirationReaper-5-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,568] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,568] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,570] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:31:01,571] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:31:01,571] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:31:01,571] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:31:01,571] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:31:01,573] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:31:01,573] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:31:01,573] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,578] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,578] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,579] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,587] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,587] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,589] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:31:01,590] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:31:01,590] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:31:01,591] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:31:01,591] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:31:01,592] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:31:01,593] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:31:01,593] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,594] INFO [ExpirationReaper-3-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,594] INFO [ExpirationReaper-3-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,595] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:31:01,597] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,600] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,600] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,601] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:31:01,602] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,619] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,619] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,619] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,628] INFO [ExpirationReaper-4-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,628] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,628] INFO [ExpirationReaper-4-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,628] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,629] INFO [KafkaApi-4] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:31:01,629] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:31:01,630] INFO [ExpirationReaper-4-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,630] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:31:01,631] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:31:01,631] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:31:01,631] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:31:01,632] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:31:01,633] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:31:01,634] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:31:01,634] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:31:01,634] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,686] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,686] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,688] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:31:01,689] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:31:01,689] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:31:01,689] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:31:01,689] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:31:01,690] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:31:01,691] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:31:01,691] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,715] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,715] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,717] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:31:01,719] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:31:01,719] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:31:01,719] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:31:01,719] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:31:01,719] INFO [ExpirationReaper-5-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,719] INFO [ExpirationReaper-5-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,720] INFO [ExpirationReaper-5-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,720] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:31:01,721] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:31:01,721] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,725] INFO [ExpirationReaper-4-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,725] INFO [ExpirationReaper-4-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,727] INFO [TransactionCoordinator id=4] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:31:01,729] INFO [Transaction State Manager 4]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:31:01,729] INFO [Transaction Marker Channel Manager 4]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:31:01,729] INFO [Transaction Marker Channel Manager 4]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:31:01,729] INFO [Transaction Marker Channel Manager 4]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:31:01,730] INFO [TransactionCoordinator id=4] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:31:01,731] INFO [GroupCoordinator 4]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:31:01,731] INFO [ExpirationReaper-4-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,769] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,769] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,769] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:31:01,770] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:31:01,770] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:31:01,771] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:31:01,771] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:31:01,771] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:31:01,772] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:31:01,773] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:31:01,773] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:31:01,773] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,804] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,804] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,805] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,827] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,827] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,827] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,862] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,862] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,863] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,881] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,882] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,881] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,882] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,882] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,882] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,889] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,889] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,890] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:31:01,891] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:31:01,891] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:31:01,891] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:31:01,891] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:31:01,892] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:31:01,894] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:31:01,895] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:31:01,895] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:31:01,895] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,897] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,897] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,898] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:31:01,899] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:31:01,899] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:31:01,900] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:31:01,900] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:31:01,900] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:31:01,902] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:31:01,902] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:31:01,903] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:31:01,903] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,919] INFO [ExpirationReaper-5-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,920] INFO [ExpirationReaper-5-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,920] INFO [ExpirationReaper-4-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,920] INFO [ExpirationReaper-4-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,920] INFO [ExpirationReaper-4-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,920] INFO [GroupCoordinator 5]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:31:01,921] INFO [ReplicaManager broker=5] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:31:01,921] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:31:01,922] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:31:01,922] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:31:01,922] INFO [ReplicaFetcherManager on broker 5] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:31:01,924] INFO [ReplicaFetcherManager on broker 5] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:31:01,924] INFO [ReplicaAlterLogDirsManager on broker 5] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:31:01,924] INFO [ReplicaAlterLogDirsManager on broker 5] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:31:01,924] INFO [ExpirationReaper-5-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,947] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,947] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,947] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,969] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,969] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,969] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,977] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,977] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,978] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,981] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,981] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,987] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,987] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,987] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:01,990] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:31:01,990] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:01,990] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:01,990] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:01,992] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:31:01,993] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:01,993] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:01,994] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:01,995] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:31:01,996] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:31:02,015] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:31:02,020] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:31:02,021] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:31:02,021] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:31:02,021] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:31:02,026] INFO [ExpirationReaper-5-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,026] INFO [ExpirationReaper-5-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,027] INFO [ExpirationReaper-5-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,050] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,050] INFO [Controller id=0, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,050] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,050] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,050] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,053] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,053] INFO [Controller id=0, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,053] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,053] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,053] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,053] WARN [Controller id=0, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,053] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,053] WARN [Controller id=0, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,053] WARN [Controller id=0, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,054] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,055] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,055] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,055] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,055] INFO [Controller id=0, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,055] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,062] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,062] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,063] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,090] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,090] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,091] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,115] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,116] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,116] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,120] INFO [ExpirationReaper-4-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,120] INFO [ExpirationReaper-4-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,121] INFO [GroupCoordinator 4]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:31:02,122] INFO [ReplicaManager broker=4] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:31:02,122] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:31:02,123] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:31:02,123] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:31:02,124] INFO [ReplicaFetcherManager on broker 4] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:31:02,125] INFO Session: 0x100000b00ad004a closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:31:02,125] INFO EventThread shut down for session: 0x100000b00ad004a (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:31:02,125] INFO [ReplicaFetcherManager on broker 4] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:31:02,126] INFO [ReplicaAlterLogDirsManager on broker 4] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:31:02,127] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:31:02,127] INFO [ReplicaAlterLogDirsManager on broker 4] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:31:02,127] INFO [ExpirationReaper-4-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,128] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,156] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,156] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,156] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,156] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,156] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,156] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,156] INFO [Controller id=0, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,156] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,157] WARN [Controller id=0, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,156] WARN [Controller id=0, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,157] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,157] WARN [Controller id=0, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,157] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,157] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,158] INFO [Controller id=0, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,169] INFO [ExpirationReaper-5-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,169] INFO [ExpirationReaper-5-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,169] INFO [ExpirationReaper-5-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,186] INFO [ExpirationReaper-5-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,186] INFO [ExpirationReaper-5-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,186] INFO [ExpirationReaper-5-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,187] INFO [ExpirationReaper-4-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,187] INFO [ExpirationReaper-4-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,187] INFO [ExpirationReaper-4-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,257] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,258] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,258] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,258] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,258] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,258] INFO [Controller id=0, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,258] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,259] INFO [Controller id=0, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,259] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,259] WARN [Controller id=0, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,259] WARN [Controller id=0, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,259] WARN [Controller id=0, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,259] INFO [Controller id=0, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,259] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,259] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,261] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,261] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,266] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:31:02,266] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,266] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,266] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,268] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:31:02,268] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,269] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,269] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,269] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:31:02,270] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:31:02,282] INFO [ProducerStateManager partition=__consumer_offsets-39] Wrote producer snapshot at offset 27680 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-05-15 18:31:02,290] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,290] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,290] INFO [ExpirationReaper-3-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,294] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:31:02,297] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,299] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,300] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,301] INFO [Controller id=0, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,302] INFO [Controller id=0, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,304] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:31:02,304] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:31:02,304] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:31:02,304] INFO [ExpirationReaper-3-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,304] INFO [ExpirationReaper-3-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,304] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:31:02,307] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:31:02,307] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,308] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,308] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,310] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:31:02,311] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,312] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,312] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,312] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:31:02,313] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:31:02,316] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,316] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,316] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,339] INFO [ProducerStateManager partition=__consumer_offsets-38] Wrote producer snapshot at offset 58924 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-05-15 18:31:02,341] INFO [ExpirationReaper-4-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,341] INFO [ExpirationReaper-4-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,342] INFO [ExpirationReaper-4-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,343] INFO [ExpirationReaper-4-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,343] INFO [ExpirationReaper-4-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,344] INFO [ExpirationReaper-4-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,348] INFO [ExpirationReaper-5-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,348] INFO [ExpirationReaper-5-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,350] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:31:02,351] INFO [ReplicaManager broker=5] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:31:02,352] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,352] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,352] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,352] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,352] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,353] INFO [ExpirationReaper-4-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,355] INFO [ExpirationReaper-4-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:31:02,356] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:31:02,356] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,357] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,357] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,357] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:31:02,358] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:31:02,358] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:31:02,358] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,359] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,359] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,359] INFO [ReplicaManager broker=4] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:31:02,360] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,360] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,360] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,361] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:31:02,361] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:31:02,361] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:31:02,361] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:31:02,362] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,362] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,362] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,363] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:31:02,363] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:31:02,363] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:31:02,364] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,365] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,365] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:31:02,365] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:31:02,365] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:31:02,366] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:31:02,367] WARN An exception was thrown while closing send thread for session 0x100000b00ad004b. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x100000b00ad004b, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 18:31:02,381] INFO [ProducerStateManager partition=__consumer_offsets-40] Wrote producer snapshot at offset 27700 with 0 producer ids in 5 ms. (kafka.log.ProducerStateManager)
[2022-05-15 18:31:02,396] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:31:02,399] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:31:02,407] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:31:02,407] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:31:02,407] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:31:02,407] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:31:02,408] INFO Session: 0x100000b00ad0048 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:31:02,408] INFO EventThread shut down for session: 0x100000b00ad0048 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:31:02,408] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:31:02,411] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:31:02,411] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:31:02,411] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:31:02,411] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:31:02,412] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,413] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:31:02,448] INFO [Controller id=4, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,448] INFO [Controller id=4, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,448] INFO [Controller id=4, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,448] INFO [Controller id=4, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,451] WARN [Controller id=4, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,451] WARN [Controller id=4, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,451] WARN [Controller id=4, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,451] WARN [Controller id=4, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,452] INFO [Controller id=4, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,453] INFO [Controller id=4, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,453] INFO [Controller id=4, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,453] INFO [Controller id=4, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,469] INFO Session: 0x100000b00ad004b closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:31:02,469] INFO EventThread shut down for session: 0x100000b00ad004b (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:31:02,471] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:31:02,472] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,515] INFO EventThread shut down for session: 0x100000b00ad0049 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:31:02,515] INFO Session: 0x100000b00ad0049 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:31:02,517] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:31:02,517] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,519] INFO Session: 0x100000b00ad004d closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:31:02,519] INFO EventThread shut down for session: 0x100000b00ad004d (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:31:02,521] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:31:02,522] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,553] INFO [Controller id=4, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,553] WARN [Controller id=4, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,553] INFO [Controller id=4, targetBrokerId=4] Node 4 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,553] INFO [Controller id=4, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,554] WARN [Controller id=4, targetBrokerId=4] Connection to node 4 (joao/127.0.1.1:9096) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,554] WARN [Controller id=4, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,554] INFO [Controller id=4, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,554] INFO [Controller id=4, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,554] WARN [Controller id=4, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,554] INFO [Controller id=4, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,554] INFO [Controller id=4, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,555] INFO [Controller id=4, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,586] INFO [Controller id=4, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,588] INFO [Controller id=4, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,589] INFO [Controller id=4, targetBrokerId=4] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,590] INFO [Controller id=4, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:31:02,592] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:31:02,592] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:31:02,592] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:31:02,593] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:31:02,596] WARN An exception was thrown while closing send thread for session 0x100000b00ad004c. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x100000b00ad004c, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 18:31:02,698] INFO Session: 0x100000b00ad004c closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:31:02,698] INFO EventThread shut down for session: 0x100000b00ad004c (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:31:02,699] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:31:02,700] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,755] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,755] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,755] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,761] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,761] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,761] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,776] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,776] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,776] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,781] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,781] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,781] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,833] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,833] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,833] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,857] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,858] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,858] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,860] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,860] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,860] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,861] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,861] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,861] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,929] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,929] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:02,929] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:03,759] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:03,759] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:03,759] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:03,781] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:03,781] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:03,781] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:03,827] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:03,827] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:03,828] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:03,832] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:03,832] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:03,833] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:03,855] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:03,855] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:03,855] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:03,856] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:03,856] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:03,857] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:03,860] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:03,860] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:03,862] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:31:03,885] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:31:03,885] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:31:03,886] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:31:03,886] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:31:03,887] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:31:03,888] INFO App info kafka.server for 4 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:31:03,888] INFO [KafkaServer id=4] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:31:03,928] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:03,928] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:03,928] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:04,755] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:04,755] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:04,757] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:31:04,776] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:04,776] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:04,777] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:31:04,778] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:31:04,778] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:31:04,778] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:31:04,778] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:31:04,780] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:31:04,781] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:31:04,782] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:31:04,796] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:31:04,797] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:31:04,797] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:31:04,797] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:31:04,798] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:31:04,798] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:31:04,799] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:31:04,833] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:04,833] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:04,834] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:31:04,854] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:31:04,854] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:31:04,855] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:31:04,855] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:31:04,855] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:04,855] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:04,855] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:04,856] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:31:04,857] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:31:04,857] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:31:04,859] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:04,859] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:04,860] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:31:04,878] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:31:04,879] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:31:04,879] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:31:04,879] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:31:04,881] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:31:04,881] INFO App info kafka.server for 5 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:31:04,881] INFO [KafkaServer id=5] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:31:04,928] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:04,928] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:04,928] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:05,928] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:05,928] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:31:05,929] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:31:05,948] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:31:05,949] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:31:05,949] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:31:05,949] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:31:05,950] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:31:05,951] INFO App info kafka.server for 3 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:31:05,951] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:32:33,523] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:32:33,529] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:32:33,529] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:32:33,529] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:32:33,530] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:32:33,531] INFO autopurge.snapRetainCount set to 3 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 18:32:33,531] INFO autopurge.purgeInterval set to 0 (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 18:32:33,531] INFO Purge task is not scheduled. (org.apache.zookeeper.server.DatadirCleanupManager)
[2022-05-15 18:32:33,531] WARN Either no config or no quorum defined in config, running in standalone mode (org.apache.zookeeper.server.quorum.QuorumPeerMain)
[2022-05-15 18:32:33,534] INFO Log4j 1.2 jmx support found and enabled. (org.apache.zookeeper.jmx.ManagedUtil)
[2022-05-15 18:32:33,547] INFO Reading configuration from: ./../../kafka_2.13-3.1.0/config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:32:33,548] INFO clientPortAddress is 0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:32:33,548] INFO secureClientPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:32:33,548] INFO observerMasterPort is not set (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:32:33,548] INFO metricsProvider.className is org.apache.zookeeper.metrics.impl.DefaultMetricsProvider (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2022-05-15 18:32:33,548] INFO Starting server (org.apache.zookeeper.server.ZooKeeperServerMain)
[2022-05-15 18:32:33,560] INFO ServerMetrics initialized with provider org.apache.zookeeper.metrics.impl.DefaultMetricsProvider@6156496 (org.apache.zookeeper.server.ServerMetrics)
[2022-05-15 18:32:33,563] INFO zookeeper.snapshot.trust.empty : false (org.apache.zookeeper.server.persistence.FileTxnSnapLog)
[2022-05-15 18:32:33,572] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,572] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,572] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,572] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,572] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,572] INFO   / /__  | (_) | | (_) | |   <  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,572] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,572] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,572] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,572] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,573] INFO Server environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,573] INFO Server environment:host.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,573] INFO Server environment:java.version=11.0.15 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,574] INFO Server environment:java.vendor=Private Build (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,574] INFO Server environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,574] INFO Server environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,574] INFO Server environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,574] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,574] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,574] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,574] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,574] INFO Server environment:os.version=5.13.0-40-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,574] INFO Server environment:user.name=joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,574] INFO Server environment:user.home=/home/joao (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,574] INFO Server environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,574] INFO Server environment:os.memory.free=490MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,574] INFO Server environment:os.memory.max=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,574] INFO Server environment:os.memory.total=512MB (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,574] INFO zookeeper.enableEagerACLCheck = false (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,575] INFO zookeeper.digest.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,575] INFO zookeeper.closeSessionTxn.enabled = true (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,575] INFO zookeeper.flushDelay=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,575] INFO zookeeper.maxWriteQueuePollTime=0 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,575] INFO zookeeper.maxBatchSize=1000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,575] INFO zookeeper.intBufferStartingSizeBytes = 1024 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,576] INFO Weighed connection throttling is disabled (org.apache.zookeeper.server.BlueThrottle)
[2022-05-15 18:32:33,578] INFO minSessionTimeout set to 6000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,578] INFO maxSessionTimeout set to 60000 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,579] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 18:32:33,579] INFO Response cache size is initialized with value 400. (org.apache.zookeeper.server.ResponseCache)
[2022-05-15 18:32:33,580] INFO zookeeper.pathStats.slotCapacity = 60 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:32:33,580] INFO zookeeper.pathStats.slotDuration = 15 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:32:33,580] INFO zookeeper.pathStats.maxDepth = 6 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:32:33,580] INFO zookeeper.pathStats.initialDelay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:32:33,581] INFO zookeeper.pathStats.delay = 5 (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:32:33,581] INFO zookeeper.pathStats.enabled = false (org.apache.zookeeper.server.util.RequestPathMetricsCollector)
[2022-05-15 18:32:33,583] INFO The max bytes for all large requests are set to 104857600 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,583] INFO The large request threshold is set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,583] INFO Created server with tickTime 3000 minSessionTimeout 6000 maxSessionTimeout 60000 clientPortListenBacklog -1 datadir /tmp/zookeeper/version-2 snapdir /tmp/zookeeper/version-2 (org.apache.zookeeper.server.ZooKeeperServer)
[2022-05-15 18:32:33,591] INFO Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 18:32:33,592] WARN maxCnxns is not configured, using default value 0. (org.apache.zookeeper.server.ServerCnxnFactory)
[2022-05-15 18:32:33,593] INFO Configuring NIO connection handler with 10s sessionless connection timeout, 2 selector thread(s), 32 worker threads, and 64 kB direct buffers. (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 18:32:33,597] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)
[2022-05-15 18:32:33,597] ERROR Unexpected exception, exiting abnormally (org.apache.zookeeper.server.ZooKeeperServerMain)
java.net.BindException: Address already in use
	at java.base/sun.nio.ch.Net.bind0(Native Method)
	at java.base/sun.nio.ch.Net.bind(Net.java:459)
	at java.base/sun.nio.ch.Net.bind(Net.java:448)
	at java.base/sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:227)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:80)
	at java.base/sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:73)
	at org.apache.zookeeper.server.NIOServerCnxnFactory.configure(NIOServerCnxnFactory.java:676)
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:158)
	at org.apache.zookeeper.server.ZooKeeperServerMain.initializeAndRun(ZooKeeperServerMain.java:112)
	at org.apache.zookeeper.server.ZooKeeperServerMain.main(ZooKeeperServerMain.java:67)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.initializeAndRun(QuorumPeerMain.java:140)
	at org.apache.zookeeper.server.quorum.QuorumPeerMain.main(QuorumPeerMain.java:90)
[2022-05-15 18:32:33,599] INFO ZooKeeper audit is disabled. (org.apache.zookeeper.audit.ZKAuditProvider)
[2022-05-15 18:32:33,601] ERROR Exiting JVM with code 1 (org.apache.zookeeper.util.ServiceUtils)
[2022-05-15 18:32:38,576] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:32:38,810] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:32:38,886] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:32:38,890] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:32:38,891] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:32:38,905] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:32:38,909] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:38,909] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:38,909] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:38,909] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:38,909] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:38,909] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:38,910] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:38,910] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:38,910] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:38,910] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:38,910] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:38,910] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:38,910] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:38,910] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:38,910] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:38,910] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:38,910] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:38,910] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:38,913] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:38,918] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:32:38,923] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:38,937] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:32:38,942] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:38,943] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:38,948] INFO Socket connection established, initiating session, client: /127.0.0.1:57974, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:38,954] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad004e, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:38,959] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:32:39,032] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:32:39,166] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:32:39,172] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:32:39,222] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:32:39,232] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 0
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:32:39,279] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:32:39,281] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:32:39,283] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:32:39,285] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:32:39,323] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:32:39,327] INFO Skipping recovery for all logs in /tmp/kafka-logs since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:32:39,401] INFO [LogLoader partition=__consumer_offsets-21, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:39,432] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-21, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=21, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 93ms (1/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:32:39,438] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:39,445] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-1.90aeadc965834f82bde787d0712295af-delete, topicId=MFB1IcMITPONtX0EWrt34w, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (2/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:32:39,463] INFO Deleted producer state snapshot /tmp/kafka-logs/__consumer_offsets-39/00000000000000017940.snapshot (kafka.log.SnapshotFile)
[2022-05-15 18:32:39,465] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Loading producer state till offset 27680 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:39,465] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Reloading from producer snapshot and rebuilding producer state from offset 27680 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:39,468] INFO [ProducerStateManager partition=__consumer_offsets-39] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs/__consumer_offsets-39/00000000000000027680.snapshot,27680)' (kafka.log.ProducerStateManager)
[2022-05-15 18:32:39,476] INFO [LogLoader partition=__consumer_offsets-39, dir=/tmp/kafka-logs] Producer state recovery took 11ms for snapshot load and 0ms for segment recovery from offset 27680 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:39,482] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-39, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=39, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=27680) with 1 segments in 36ms (3/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:32:39,487] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:39,493] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-2.01dd320e0ebd4d20a04eb73da7c80ac4-delete, topicId=MFB1IcMITPONtX0EWrt34w, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (4/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:32:39,498] INFO [LogLoader partition=__consumer_offsets-15, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:39,502] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-15, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=15, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (5/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:32:39,510] INFO [LogLoader partition=__consumer_offsets-45, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:39,515] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-45, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=45, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 12ms (6/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:32:39,520] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:39,526] INFO Completed load of Log(dir=/tmp/kafka-logs/Sensor-3.ffb5dcaaab7a492fa153776acb87fc91-delete, topicId=MFB1IcMITPONtX0EWrt34w, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (7/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:32:39,532] INFO [LogLoader partition=__consumer_offsets-33, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:39,538] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-33, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=33, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (8/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:32:39,546] INFO [LogLoader partition=__consumer_offsets-27, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:39,550] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-27, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=27, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (9/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:32:39,556] INFO [LogLoader partition=__consumer_offsets-3, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:39,561] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-3, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (10/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:32:39,566] INFO [LogLoader partition=__consumer_offsets-9, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:39,571] INFO Completed load of Log(dir=/tmp/kafka-logs/__consumer_offsets-9, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=9, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (11/11 loaded in /tmp/kafka-logs) (kafka.log.LogManager)
[2022-05-15 18:32:39,574] INFO Loaded 11 logs in 251ms. (kafka.log.LogManager)
[2022-05-15 18:32:39,575] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:32:39,576] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:32:39,829] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:32:39,969] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:32:39,973] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
[2022-05-15 18:32:39,996] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:32:40,002] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:32:40,019] INFO [ExpirationReaper-0-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:40,020] INFO [ExpirationReaper-0-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:40,022] INFO [ExpirationReaper-0-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:40,023] INFO [ExpirationReaper-0-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:40,036] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:32:40,087] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:32:40,105] INFO Stat of the created znode at /brokers/ids/0 is: 3699,3699,1652635960098,1652635960098,1,0,0,72057641293905998,192,0,3699
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:32:40,106] INFO Registered broker 0 at path /brokers/ids/0 with addresses: PLAINTEXT://joao:9092, czxid (broker epoch): 3699 (kafka.zk.KafkaZkClient)
[2022-05-15 18:32:40,167] INFO [ExpirationReaper-0-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:40,174] INFO [ExpirationReaper-0-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:40,176] INFO [ExpirationReaper-0-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:40,197] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:40,226] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:40,246] INFO [TransactionCoordinator id=0] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:32:40,251] INFO [Transaction Marker Channel Manager 0]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:32:40,251] INFO [TransactionCoordinator id=0] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:32:40,290] INFO [ExpirationReaper-0-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:40,317] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:32:40,341] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:32:40,347] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:32:40,348] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:32:40,356] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:32:40,357] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:32:40,357] INFO Kafka startTimeMs: 1652635960348 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:32:40,360] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2022-05-15 18:32:40,413] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:32:40,440] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:32:40,453] INFO [Partition __consumer_offsets-3 broker=0] Log loaded for partition __consumer_offsets-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:40,453] INFO [Partition __consumer_offsets-21 broker=0] Log loaded for partition __consumer_offsets-21 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:40,453] INFO [Partition __consumer_offsets-39 broker=0] Log loaded for partition __consumer_offsets-39 with initial high watermark 27680 (kafka.cluster.Partition)
[2022-05-15 18:32:40,453] INFO [Partition __consumer_offsets-9 broker=0] Log loaded for partition __consumer_offsets-9 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:40,453] INFO [Partition __consumer_offsets-27 broker=0] Log loaded for partition __consumer_offsets-27 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:40,453] INFO [Partition __consumer_offsets-45 broker=0] Log loaded for partition __consumer_offsets-45 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:40,454] INFO [Partition __consumer_offsets-15 broker=0] Log loaded for partition __consumer_offsets-15 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:40,454] INFO [Partition __consumer_offsets-33 broker=0] Log loaded for partition __consumer_offsets-33 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:40,542] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(__consumer_offsets-21, __consumer_offsets-33, __consumer_offsets-3, __consumer_offsets-15, __consumer_offsets-39, __consumer_offsets-45, __consumer_offsets-27, __consumer_offsets-9) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:32:40,582] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 3 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:40,583] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:40,585] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 21 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:40,585] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-21 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:40,585] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 39 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:40,585] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-39 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:40,585] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 9 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:40,585] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-9 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:40,585] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 27 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:40,585] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-27 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:40,585] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 45 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:40,585] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-45 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:40,585] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 15 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:40,585] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-15 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:40,585] INFO [GroupCoordinator 0]: Elected as the group coordinator for partition 33 in epoch 22 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:40,586] INFO [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-33 for epoch 22 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:40,592] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 7 milliseconds for epoch 22, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:40,593] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-21 in 7 milliseconds for epoch 22, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:40,689] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-39 in 104 milliseconds for epoch 22, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:40,690] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-9 in 104 milliseconds for epoch 22, of which 104 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:40,690] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-27 in 105 milliseconds for epoch 22, of which 105 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:40,691] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-45 in 106 milliseconds for epoch 22, of which 105 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:40,691] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-15 in 106 milliseconds for epoch 22, of which 106 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:40,692] INFO [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-33 in 106 milliseconds for epoch 22, of which 105 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:43,553] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:32:43,822] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:32:43,902] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:32:43,906] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:32:43,906] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:32:43,920] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:32:43,927] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:43,927] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:43,927] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:43,927] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:43,927] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:43,927] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:43,927] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:43,928] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:43,928] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:43,928] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:43,928] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:43,928] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:43,928] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:43,928] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:43,928] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:43,928] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:43,929] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:43,929] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:43,930] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:43,936] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:32:43,941] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:43,953] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:32:43,960] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:43,963] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:43,967] INFO Socket connection established, initiating session, client: /127.0.0.1:57978, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:43,974] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad004f, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:43,978] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:32:44,043] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:32:44,175] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:32:44,179] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:32:44,229] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:32:44,238] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9093
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-1
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:32:44,287] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:32:44,289] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:32:44,291] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:32:44,293] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:32:44,328] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:32:44,333] INFO Skipping recovery for all logs in /tmp/kafka-logs-1 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:32:44,404] INFO [LogLoader partition=__consumer_offsets-17, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:44,426] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-17, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=17, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 81ms (1/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:32:44,432] INFO [LogLoader partition=__consumer_offsets-35, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:44,437] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-35, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=35, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (2/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:32:44,442] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:44,447] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-5.c92d8dc6bdc743778a88985cb555afa2-delete, topicId=MFB1IcMITPONtX0EWrt34w, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (3/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:32:44,452] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:44,456] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-0.78a885ba31764e8a8d8164e2108a98aa-delete, topicId=MFB1IcMITPONtX0EWrt34w, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (4/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:32:44,462] INFO [LogLoader partition=__consumer_offsets-41, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:44,465] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-41, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=41, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (5/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:32:44,470] INFO [LogLoader partition=__consumer_offsets-29, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:44,474] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-29, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=29, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (6/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:32:44,478] INFO [LogLoader partition=__consumer_offsets-11, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:44,482] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-11, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=11, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (7/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:32:44,485] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:44,489] INFO Completed load of Log(dir=/tmp/kafka-logs-1/Sensor-4.4479f2c030844a5aa14211563cecfd5b-delete, topicId=MFB1IcMITPONtX0EWrt34w, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:32:44,495] INFO [LogLoader partition=__consumer_offsets-23, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:44,498] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-23, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=23, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (9/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:32:44,503] INFO [LogLoader partition=__consumer_offsets-47, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:44,506] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-47, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=47, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (10/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:32:44,511] INFO [LogLoader partition=__consumer_offsets-5, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:44,514] INFO Completed load of Log(dir=/tmp/kafka-logs-1/__consumer_offsets-5, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (11/11 loaded in /tmp/kafka-logs-1) (kafka.log.LogManager)
[2022-05-15 18:32:44,518] INFO Loaded 11 logs in 190ms. (kafka.log.LogManager)
[2022-05-15 18:32:44,518] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:32:44,519] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:32:44,748] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:32:44,855] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:32:44,859] INFO Awaiting socket connections on 0.0.0.0:9093. (kafka.network.Acceptor)
[2022-05-15 18:32:44,883] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:32:44,891] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:32:44,906] INFO [ExpirationReaper-1-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:44,907] INFO [ExpirationReaper-1-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:44,908] INFO [ExpirationReaper-1-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:44,910] INFO [ExpirationReaper-1-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:44,929] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:32:44,981] INFO Creating /brokers/ids/1 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:32:44,998] INFO Stat of the created znode at /brokers/ids/1 is: 3767,3767,1652635964991,1652635964991,1,0,0,72057641293905999,192,0,3767
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:32:45,000] INFO Registered broker 1 at path /brokers/ids/1 with addresses: PLAINTEXT://joao:9093, czxid (broker epoch): 3767 (kafka.zk.KafkaZkClient)
[2022-05-15 18:32:45,062] INFO [ExpirationReaper-1-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:45,069] INFO [ExpirationReaper-1-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:45,070] INFO [ExpirationReaper-1-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:45,085] INFO [GroupCoordinator 1]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:45,096] INFO [GroupCoordinator 1]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:45,118] INFO [TransactionCoordinator id=1] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:32:45,124] INFO [Transaction Marker Channel Manager 1]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:32:45,124] INFO [TransactionCoordinator id=1] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:32:45,145] INFO [ExpirationReaper-1-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:45,163] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:32:45,184] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:32:45,189] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:32:45,190] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:32:45,194] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:32:45,195] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:32:45,195] INFO Kafka startTimeMs: 1652635965190 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:32:45,196] INFO [KafkaServer id=1] started (kafka.server.KafkaServer)
[2022-05-15 18:32:45,258] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:32:45,291] INFO [Partition __consumer_offsets-35 broker=1] Log loaded for partition __consumer_offsets-35 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:45,292] INFO [Partition __consumer_offsets-5 broker=1] Log loaded for partition __consumer_offsets-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:45,292] INFO [Partition __consumer_offsets-23 broker=1] Log loaded for partition __consumer_offsets-23 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:45,292] INFO [Partition __consumer_offsets-41 broker=1] Log loaded for partition __consumer_offsets-41 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:45,293] INFO [Partition __consumer_offsets-11 broker=1] Log loaded for partition __consumer_offsets-11 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:45,293] INFO [Partition __consumer_offsets-29 broker=1] Log loaded for partition __consumer_offsets-29 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:45,294] INFO [Partition __consumer_offsets-47 broker=1] Log loaded for partition __consumer_offsets-47 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:45,294] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:32:45,294] INFO [Partition __consumer_offsets-17 broker=1] Log loaded for partition __consumer_offsets-17 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:45,317] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(__consumer_offsets-35, __consumer_offsets-47, __consumer_offsets-17, __consumer_offsets-11, __consumer_offsets-5, __consumer_offsets-29, __consumer_offsets-41, __consumer_offsets-23) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:32:45,350] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 35 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:45,351] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-35 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:45,353] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 5 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:45,353] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-5 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:45,353] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 23 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:45,353] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-23 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:45,353] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 41 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:45,353] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-41 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:45,353] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 11 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:45,354] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-11 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:45,354] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 29 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:45,354] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-29 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:45,354] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 47 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:45,354] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-47 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:45,354] INFO [GroupCoordinator 1]: Elected as the group coordinator for partition 17 in epoch 36 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:45,354] INFO [GroupMetadataManager brokerId=1] Scheduling loading of offsets and group metadata from __consumer_offsets-17 for epoch 36 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:45,360] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-35 in 8 milliseconds for epoch 36, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:45,361] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-5 in 8 milliseconds for epoch 36, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:45,362] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-23 in 9 milliseconds for epoch 36, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:45,362] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-41 in 9 milliseconds for epoch 36, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:45,362] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-11 in 8 milliseconds for epoch 36, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:45,363] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-29 in 9 milliseconds for epoch 36, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:45,363] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-47 in 9 milliseconds for epoch 36, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:45,363] INFO [GroupMetadataManager brokerId=1] Finished loading offsets and group metadata from __consumer_offsets-17 in 8 milliseconds for epoch 36, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:48,594] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:32:48,853] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:32:48,926] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:32:48,930] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:32:48,930] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:32:48,943] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:32:48,946] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:48,946] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:48,946] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:48,946] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:48,946] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:48,947] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:48,947] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:48,947] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:48,947] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:48,947] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:48,947] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:48,947] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:48,947] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:48,947] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:48,947] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:48,947] INFO Client environment:os.memory.free=972MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:48,947] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:48,947] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:48,949] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:48,963] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:32:48,967] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:48,971] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:32:48,976] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:48,977] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:48,980] INFO Socket connection established, initiating session, client: /127.0.0.1:57980, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:48,988] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0050, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:48,992] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:32:49,062] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:32:49,184] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:32:49,189] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:32:49,236] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:32:49,245] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 2
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9094
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-2
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 2
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:32:49,293] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:32:49,294] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:32:49,296] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:32:49,297] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:32:49,338] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:32:49,342] INFO Skipping recovery for all logs in /tmp/kafka-logs-2 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:32:49,405] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:49,427] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-1.f6d39bd0eb4f43f6a0c2447f5677ec85-delete, topicId=MFB1IcMITPONtX0EWrt34w, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 71ms (1/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:32:49,441] INFO [LogLoader partition=__consumer_offsets-49, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:49,445] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-49, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=49, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (2/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:32:49,450] INFO [LogLoader partition=__consumer_offsets-19, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:49,454] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-19, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=19, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (3/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:32:49,458] INFO [LogLoader partition=__consumer_offsets-7, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:49,463] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-7, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=7, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (4/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:32:49,467] INFO [LogLoader partition=__consumer_offsets-13, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:49,470] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-13, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=13, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:32:49,475] INFO [LogLoader partition=__consumer_offsets-37, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:49,478] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-37, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=37, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:32:49,484] INFO [LogLoader partition=__consumer_offsets-43, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:49,487] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-43, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=43, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (7/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:32:49,491] INFO [LogLoader partition=__consumer_offsets-1, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:49,494] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-1, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (8/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:32:49,498] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:49,501] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-5.5a196a2bd4b245c1be41f480b33c8ba7-delete, topicId=MFB1IcMITPONtX0EWrt34w, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (9/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:32:49,505] INFO [LogLoader partition=__consumer_offsets-31, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:49,507] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-31, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=31, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (10/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:32:49,511] INFO [LogLoader partition=__consumer_offsets-25, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:49,513] INFO Completed load of Log(dir=/tmp/kafka-logs-2/__consumer_offsets-25, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=25, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 5ms (11/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:32:49,518] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:49,520] INFO Completed load of Log(dir=/tmp/kafka-logs-2/Sensor-0.c4518740d1aa4dc78469b2defde2fe0b-delete, topicId=MFB1IcMITPONtX0EWrt34w, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (12/12 loaded in /tmp/kafka-logs-2) (kafka.log.LogManager)
[2022-05-15 18:32:49,524] INFO Loaded 12 logs in 185ms. (kafka.log.LogManager)
[2022-05-15 18:32:49,525] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:32:49,526] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:32:49,755] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:32:49,864] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:32:49,870] INFO Awaiting socket connections on 0.0.0.0:9094. (kafka.network.Acceptor)
[2022-05-15 18:32:49,897] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:32:49,904] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:32:49,921] INFO [ExpirationReaper-2-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:49,922] INFO [ExpirationReaper-2-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:49,924] INFO [ExpirationReaper-2-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:49,926] INFO [ExpirationReaper-2-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:49,939] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:32:49,994] INFO Creating /brokers/ids/2 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:32:50,012] INFO Stat of the created znode at /brokers/ids/2 is: 3791,3791,1652635970005,1652635970005,1,0,0,72057641293906000,192,0,3791
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:32:50,013] INFO Registered broker 2 at path /brokers/ids/2 with addresses: PLAINTEXT://joao:9094, czxid (broker epoch): 3791 (kafka.zk.KafkaZkClient)
[2022-05-15 18:32:50,077] INFO [ExpirationReaper-2-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:50,083] INFO [ExpirationReaper-2-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:50,085] INFO [ExpirationReaper-2-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:50,101] INFO [GroupCoordinator 2]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:50,116] INFO [GroupCoordinator 2]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:50,141] INFO [TransactionCoordinator id=2] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:32:50,147] INFO [Transaction Marker Channel Manager 2]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:32:50,147] INFO [TransactionCoordinator id=2] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:32:50,172] INFO [ExpirationReaper-2-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:50,191] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:32:50,212] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:32:50,217] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:32:50,218] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:32:50,223] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:32:50,223] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:32:50,224] INFO Kafka startTimeMs: 1652635970218 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:32:50,225] INFO [KafkaServer id=2] started (kafka.server.KafkaServer)
[2022-05-15 18:32:50,309] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:32:50,316] INFO [Partition __consumer_offsets-19 broker=2] Log loaded for partition __consumer_offsets-19 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:50,317] INFO [Partition __consumer_offsets-37 broker=2] Log loaded for partition __consumer_offsets-37 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:50,317] INFO [Partition __consumer_offsets-7 broker=2] Log loaded for partition __consumer_offsets-7 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:50,317] INFO [Partition __consumer_offsets-25 broker=2] Log loaded for partition __consumer_offsets-25 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:50,317] INFO [Partition __consumer_offsets-43 broker=2] Log loaded for partition __consumer_offsets-43 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:50,317] INFO [Partition __consumer_offsets-13 broker=2] Log loaded for partition __consumer_offsets-13 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:50,317] INFO [Partition __consumer_offsets-31 broker=2] Log loaded for partition __consumer_offsets-31 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:50,317] INFO [Partition __consumer_offsets-1 broker=2] Log loaded for partition __consumer_offsets-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:50,318] INFO [Partition __consumer_offsets-49 broker=2] Log loaded for partition __consumer_offsets-49 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:50,343] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(__consumer_offsets-7, __consumer_offsets-25, __consumer_offsets-49, __consumer_offsets-31, __consumer_offsets-37, __consumer_offsets-19, __consumer_offsets-13, __consumer_offsets-43, __consumer_offsets-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:32:50,368] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:32:50,381] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 19 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:50,383] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-19 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:50,385] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 37 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:50,385] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-37 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:50,385] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 7 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:50,385] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-7 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:50,386] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 25 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:50,386] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-25 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:50,386] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 43 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:50,386] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-43 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:50,386] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 13 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:50,386] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-13 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:50,386] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 31 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:50,386] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-31 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:50,386] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 1 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:50,386] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-1 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:50,387] INFO [GroupCoordinator 2]: Elected as the group coordinator for partition 49 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:50,387] INFO [GroupMetadataManager brokerId=2] Scheduling loading of offsets and group metadata from __consumer_offsets-49 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:50,394] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-19 in 9 milliseconds for epoch 38, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:50,395] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-37 in 10 milliseconds for epoch 38, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:50,395] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-7 in 10 milliseconds for epoch 38, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:50,395] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-25 in 9 milliseconds for epoch 38, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:50,396] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-43 in 10 milliseconds for epoch 38, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:50,396] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-13 in 10 milliseconds for epoch 38, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:50,397] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-31 in 11 milliseconds for epoch 38, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:50,397] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-1 in 11 milliseconds for epoch 38, of which 11 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:50,397] INFO [GroupMetadataManager brokerId=2] Finished loading offsets and group metadata from __consumer_offsets-49 in 10 milliseconds for epoch 38, of which 10 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:53,538] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:32:53,784] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:32:53,857] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:32:53,860] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:32:53,860] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:32:53,873] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:32:53,878] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:53,878] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:53,878] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:53,878] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:53,878] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:53,878] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:53,878] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:53,878] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:53,878] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:53,878] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:53,878] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:53,878] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:53,878] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:53,878] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:53,878] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:53,878] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:53,878] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:53,878] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:53,880] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:53,884] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:32:53,889] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:53,901] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:32:53,907] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:53,909] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:53,912] INFO Socket connection established, initiating session, client: /127.0.0.1:57982, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:53,919] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0051, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:53,924] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:32:54,002] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:32:54,135] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:32:54,139] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:32:54,181] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:32:54,189] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 3
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9095
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-3
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 3
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:32:54,233] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:32:54,235] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:32:54,238] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:32:54,240] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:32:54,279] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:32:54,282] INFO Skipping recovery for all logs in /tmp/kafka-logs-3 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:32:54,354] INFO [LogLoader partition=__consumer_offsets-14, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:54,379] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-14, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=14, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 81ms (1/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:32:54,394] INFO Deleted producer state snapshot /tmp/kafka-logs-3/__consumer_offsets-38/00000000000000049254.snapshot (kafka.log.SnapshotFile)
[2022-05-15 18:32:54,397] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Loading producer state till offset 58924 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:54,397] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Reloading from producer snapshot and rebuilding producer state from offset 58924 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:54,400] INFO [ProducerStateManager partition=__consumer_offsets-38] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-3/__consumer_offsets-38/00000000000000058924.snapshot,58924)' (kafka.log.ProducerStateManager)
[2022-05-15 18:32:54,407] INFO [LogLoader partition=__consumer_offsets-38, dir=/tmp/kafka-logs-3] Producer state recovery took 10ms for snapshot load and 0ms for segment recovery from offset 58924 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:54,411] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-38, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=38, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=58924) with 1 segments in 32ms (2/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:32:54,417] INFO [LogLoader partition=__consumer_offsets-8, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:54,420] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-8, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=8, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (3/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:32:54,426] INFO [LogLoader partition=__consumer_offsets-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:54,430] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-2, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (4/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:32:54,435] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:54,438] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-0.434b88b4914b4f1c989e3cccb7661f7a-delete, topicId=MFB1IcMITPONtX0EWrt34w, topic=Sensor, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:32:54,443] INFO [LogLoader partition=__consumer_offsets-26, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:54,447] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-26, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=26, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:32:54,451] INFO [LogLoader partition=__consumer_offsets-20, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:54,455] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-20, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=20, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (7/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:32:54,460] INFO [LogLoader partition=__consumer_offsets-32, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:54,464] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-32, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=32, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (8/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:32:54,470] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:54,473] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-2.6cde347c54fc4b018b3006510e13d1e4-delete, topicId=MFB1IcMITPONtX0EWrt34w, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (9/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:32:54,478] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:54,481] INFO Completed load of Log(dir=/tmp/kafka-logs-3/Sensor-1.b672de8a8b844dda988724e226cd6942-delete, topicId=MFB1IcMITPONtX0EWrt34w, topic=Sensor, partition=1, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (10/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:32:54,487] INFO [LogLoader partition=__consumer_offsets-44, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:54,490] INFO Completed load of Log(dir=/tmp/kafka-logs-3/__consumer_offsets-44, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=44, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (11/11 loaded in /tmp/kafka-logs-3) (kafka.log.LogManager)
[2022-05-15 18:32:54,493] INFO Loaded 11 logs in 214ms. (kafka.log.LogManager)
[2022-05-15 18:32:54,494] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:32:54,495] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:32:54,746] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:32:54,883] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:32:54,888] INFO Awaiting socket connections on 0.0.0.0:9095. (kafka.network.Acceptor)
[2022-05-15 18:32:54,921] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:32:54,928] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:32:54,945] INFO [ExpirationReaper-3-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:54,946] INFO [ExpirationReaper-3-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:54,948] INFO [ExpirationReaper-3-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:54,950] INFO [ExpirationReaper-3-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:54,961] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:32:55,021] INFO Creating /brokers/ids/3 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:32:55,043] INFO Stat of the created znode at /brokers/ids/3 is: 3816,3816,1652635975034,1652635975034,1,0,0,72057641293906001,192,0,3816
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:32:55,045] INFO Registered broker 3 at path /brokers/ids/3 with addresses: PLAINTEXT://joao:9095, czxid (broker epoch): 3816 (kafka.zk.KafkaZkClient)
[2022-05-15 18:32:55,118] INFO [ExpirationReaper-3-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:55,124] INFO [ExpirationReaper-3-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:55,125] INFO [ExpirationReaper-3-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:55,142] INFO [GroupCoordinator 3]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:55,156] INFO [GroupCoordinator 3]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:55,186] INFO [TransactionCoordinator id=3] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:32:55,190] INFO [Transaction Marker Channel Manager 3]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:32:55,190] INFO [TransactionCoordinator id=3] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:32:55,218] INFO [ExpirationReaper-3-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:55,237] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:32:55,260] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:32:55,265] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:32:55,265] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:32:55,271] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:32:55,272] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:32:55,272] INFO Kafka startTimeMs: 1652635975265 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:32:55,274] INFO [KafkaServer id=3] started (kafka.server.KafkaServer)
[2022-05-15 18:32:55,333] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:32:55,357] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:32:55,376] INFO [Partition __consumer_offsets-2 broker=3] Log loaded for partition __consumer_offsets-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:55,376] INFO [Partition __consumer_offsets-20 broker=3] Log loaded for partition __consumer_offsets-20 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:55,377] INFO [Partition __consumer_offsets-38 broker=3] Log loaded for partition __consumer_offsets-38 with initial high watermark 58924 (kafka.cluster.Partition)
[2022-05-15 18:32:55,377] INFO [Partition __consumer_offsets-8 broker=3] Log loaded for partition __consumer_offsets-8 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:55,378] INFO [Partition __consumer_offsets-26 broker=3] Log loaded for partition __consumer_offsets-26 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:55,378] INFO [Partition __consumer_offsets-44 broker=3] Log loaded for partition __consumer_offsets-44 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:55,378] INFO [Partition __consumer_offsets-14 broker=3] Log loaded for partition __consumer_offsets-14 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:55,378] INFO [Partition __consumer_offsets-32 broker=3] Log loaded for partition __consumer_offsets-32 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:32:55,401] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(__consumer_offsets-8, __consumer_offsets-38, __consumer_offsets-26, __consumer_offsets-32, __consumer_offsets-2, __consumer_offsets-14, __consumer_offsets-20, __consumer_offsets-44) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:32:55,433] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 2 in epoch 35 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:55,435] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-2 for epoch 35 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:55,437] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 20 in epoch 35 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:55,438] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-20 for epoch 35 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:55,438] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 38 in epoch 35 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:55,438] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-38 for epoch 35 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:55,438] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 8 in epoch 35 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:55,438] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-8 for epoch 35 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:55,438] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 26 in epoch 35 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:55,438] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-26 for epoch 35 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:55,438] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 44 in epoch 35 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:55,439] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-44 for epoch 35 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:55,439] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 14 in epoch 35 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:55,439] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-14 for epoch 35 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:55,439] INFO [GroupCoordinator 3]: Elected as the group coordinator for partition 32 in epoch 35 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:32:55,439] INFO [GroupMetadataManager brokerId=3] Scheduling loading of offsets and group metadata from __consumer_offsets-32 for epoch 35 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:55,446] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-2 in 9 milliseconds for epoch 35, of which 4 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:55,447] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-20 in 9 milliseconds for epoch 35, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:55,572] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-38 in 133 milliseconds for epoch 35, of which 9 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:55,572] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-8 in 134 milliseconds for epoch 35, of which 134 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:55,573] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-26 in 135 milliseconds for epoch 35, of which 134 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:55,573] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-44 in 134 milliseconds for epoch 35, of which 134 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:55,574] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-14 in 135 milliseconds for epoch 35, of which 135 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:55,574] INFO [GroupMetadataManager brokerId=3] Finished loading offsets and group metadata from __consumer_offsets-32 in 135 milliseconds for epoch 35, of which 135 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:32:58,575] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:32:58,855] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:32:58,939] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:32:58,942] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:32:58,943] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:32:58,959] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:32:58,963] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:58,963] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:58,963] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:58,964] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:58,964] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:58,964] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:58,964] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:58,964] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:58,964] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:58,964] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:58,965] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:58,965] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:58,965] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:58,965] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:58,965] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:58,965] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:58,965] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:58,965] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:58,967] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:32:58,971] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:32:58,975] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:58,989] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:32:58,993] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:58,994] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:58,998] INFO Socket connection established, initiating session, client: /127.0.0.1:57984, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:59,004] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0052, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:32:59,009] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:32:59,082] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:32:59,208] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:32:59,214] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:32:59,264] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:32:59,273] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 4
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9096
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-4
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 4
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:32:59,315] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:32:59,316] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:32:59,319] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:32:59,321] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:32:59,360] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:32:59,365] INFO Skipping recovery for all logs in /tmp/kafka-logs-4 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:32:59,435] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:59,463] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-4.581a01e9e9e8483baa62ca9705cb52d5-delete, topicId=MFB1IcMITPONtX0EWrt34w, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 84ms (1/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:32:59,477] INFO [LogLoader partition=__consumer_offsets-24, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:59,482] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-24, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=24, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 19ms (2/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:32:59,487] INFO [LogLoader partition=__consumer_offsets-12, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:59,491] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-12, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=12, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (3/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:32:59,497] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:59,502] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-5.55e2e7cb7a65404da3a2440f977c622d-delete, topicId=MFB1IcMITPONtX0EWrt34w, topic=Sensor, partition=5, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 11ms (4/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:32:59,507] INFO [LogLoader partition=__consumer_offsets-30, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:59,510] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-30, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=30, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (5/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:32:59,515] INFO [LogLoader partition=__consumer_offsets-36, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:59,519] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-36, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=36, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (6/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:32:59,524] INFO [LogLoader partition=__consumer_offsets-42, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:59,528] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-42, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=42, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (7/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:32:59,533] INFO [LogLoader partition=__consumer_offsets-0, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:59,537] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-0, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=0, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (8/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:32:59,541] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:59,544] INFO Completed load of Log(dir=/tmp/kafka-logs-4/Sensor-3.d9dbb331425840eb87e57f7252b3292d-delete, topicId=MFB1IcMITPONtX0EWrt34w, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (9/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:32:59,549] INFO [LogLoader partition=__consumer_offsets-18, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:59,554] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-18, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=18, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (10/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:32:59,560] INFO [LogLoader partition=__consumer_offsets-6, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:59,563] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-6, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=6, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (11/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:32:59,569] INFO [LogLoader partition=__consumer_offsets-48, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:32:59,573] INFO Completed load of Log(dir=/tmp/kafka-logs-4/__consumer_offsets-48, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=48, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (12/12 loaded in /tmp/kafka-logs-4) (kafka.log.LogManager)
[2022-05-15 18:32:59,575] INFO Loaded 12 logs in 215ms. (kafka.log.LogManager)
[2022-05-15 18:32:59,576] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:32:59,577] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:32:59,818] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:32:59,927] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:32:59,931] INFO Awaiting socket connections on 0.0.0.0:9096. (kafka.network.Acceptor)
[2022-05-15 18:32:59,958] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:32:59,964] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:32:59,980] INFO [ExpirationReaper-4-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:59,981] INFO [ExpirationReaper-4-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:59,983] INFO [ExpirationReaper-4-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:59,985] INFO [ExpirationReaper-4-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:32:59,996] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:33:00,054] INFO Creating /brokers/ids/4 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:33:00,070] INFO Stat of the created znode at /brokers/ids/4 is: 3840,3840,1652635980063,1652635980063,1,0,0,72057641293906002,192,0,3840
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:33:00,072] INFO Registered broker 4 at path /brokers/ids/4 with addresses: PLAINTEXT://joao:9096, czxid (broker epoch): 3840 (kafka.zk.KafkaZkClient)
[2022-05-15 18:33:00,136] INFO [ExpirationReaper-4-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:33:00,141] INFO [ExpirationReaper-4-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:33:00,142] INFO [ExpirationReaper-4-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:33:00,158] INFO [GroupCoordinator 4]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:33:00,170] INFO [GroupCoordinator 4]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:33:00,191] INFO [TransactionCoordinator id=4] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:33:00,199] INFO [Transaction Marker Channel Manager 4]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:33:00,199] INFO [TransactionCoordinator id=4] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:33:00,226] INFO [ExpirationReaper-4-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:33:00,249] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:33:00,272] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:33:00,278] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:33:00,279] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:33:00,286] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:33:00,287] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:33:00,287] INFO Kafka startTimeMs: 1652635980280 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:33:00,291] INFO [KafkaServer id=4] started (kafka.server.KafkaServer)
[2022-05-15 18:33:00,370] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:33:00,409] INFO [Partition __consumer_offsets-18 broker=4] Log loaded for partition __consumer_offsets-18 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:00,409] INFO [Partition __consumer_offsets-36 broker=4] Log loaded for partition __consumer_offsets-36 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:00,409] INFO [Partition __consumer_offsets-6 broker=4] Log loaded for partition __consumer_offsets-6 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:00,410] INFO [Partition __consumer_offsets-24 broker=4] Log loaded for partition __consumer_offsets-24 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:00,410] INFO [Partition __consumer_offsets-42 broker=4] Log loaded for partition __consumer_offsets-42 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:00,411] INFO [Partition __consumer_offsets-12 broker=4] Log loaded for partition __consumer_offsets-12 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:00,411] INFO [Partition __consumer_offsets-30 broker=4] Log loaded for partition __consumer_offsets-30 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:00,411] INFO [Partition __consumer_offsets-0 broker=4] Log loaded for partition __consumer_offsets-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:00,412] INFO [Partition __consumer_offsets-48 broker=4] Log loaded for partition __consumer_offsets-48 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:00,431] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:33:00,441] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(__consumer_offsets-30, __consumer_offsets-36, __consumer_offsets-24, __consumer_offsets-48, __consumer_offsets-6, __consumer_offsets-0, __consumer_offsets-12, __consumer_offsets-42, __consumer_offsets-18) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:00,487] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 18 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:33:00,488] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-18 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:00,490] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 36 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:33:00,491] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-36 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:00,491] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 6 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:33:00,491] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-6 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:00,491] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 24 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:33:00,491] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-24 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:00,491] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 42 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:33:00,491] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-42 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:00,491] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 12 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:33:00,491] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-12 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:00,491] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 30 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:33:00,491] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-30 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:00,491] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 0 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:33:00,491] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-0 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:00,491] INFO [GroupCoordinator 4]: Elected as the group coordinator for partition 48 in epoch 38 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:33:00,491] INFO [GroupMetadataManager brokerId=4] Scheduling loading of offsets and group metadata from __consumer_offsets-48 for epoch 38 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:00,497] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-18 in 7 milliseconds for epoch 38, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:00,498] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-36 in 7 milliseconds for epoch 38, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:00,498] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-6 in 7 milliseconds for epoch 38, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:00,498] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-24 in 7 milliseconds for epoch 38, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:00,499] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-42 in 8 milliseconds for epoch 38, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:00,499] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-12 in 8 milliseconds for epoch 38, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:00,499] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-30 in 8 milliseconds for epoch 38, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:00,499] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-0 in 8 milliseconds for epoch 38, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:00,499] INFO [GroupMetadataManager brokerId=4] Finished loading offsets and group metadata from __consumer_offsets-48 in 8 milliseconds for epoch 38, of which 8 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:03,564] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2022-05-15 18:33:03,812] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2022-05-15 18:33:03,891] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:33:03,894] INFO starting (kafka.server.KafkaServer)
[2022-05-15 18:33:03,895] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2022-05-15 18:33:03,909] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:33:03,914] INFO Client environment:zookeeper.version=3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:33:03,914] INFO Client environment:host.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:33:03,914] INFO Client environment:java.version=11.0.15 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:33:03,914] INFO Client environment:java.vendor=Private Build (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:33:03,914] INFO Client environment:java.home=/usr/lib/jvm/java-11-openjdk-amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:33:03,915] INFO Client environment:java.class.path=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/activation-1.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/aopalliance-repackaged-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/argparse4j-0.7.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/audience-annotations-0.5.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-cli-1.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/commons-lang3-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-basic-auth-extension-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-file-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-json-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-mirror-client-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-runtime-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/connect-transforms-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-api-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-locator-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/hk2-utils-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-core-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-databind-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-dataformat-csv-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-datatype-jdk8-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-base-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-jaxrs-json-provider-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-jaxb-annotations-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jackson-module-scala_2.13-2.12.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.activation-api-1.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.annotation-api-1.3.5.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.inject-2.6.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.validation-api-2.0.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.ws.rs-api-2.1.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jakarta.xml.bind-api-2.3.2.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javassist-3.27.0-GA.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.servlet-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jaxb-api-2.3.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-client-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-common-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-container-servlet-core-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-hk2-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jersey-server-2.34.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-client-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-continuation-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-http-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-io-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-security-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-server-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlet-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-servlets-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jetty-util-ajax-9.4.43.v20210629.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jline-3.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jopt-simple-5.0.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/jose4j-0.7.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-clients-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-log4j-appender-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-metadata-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-raft-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-server-common-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-shell-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-storage-api-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-examples-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-scala_2.13-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-streams-test-utils-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/kafka-tools-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/log4j-1.2.17.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/lz4-java-1.8.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/maven-artifact-3.8.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-2.2.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/metrics-core-4.1.12.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-buffer-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-codec-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-handler-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-resolver-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-epoll-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/netty-transport-native-unix-common-4.1.68.Final.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/osgi-resource-locator-1.0.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/paranamer-2.8.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/plexus-utils-3.2.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/reflections-0.9.12.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/rocksdbjni-6.22.1.1.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-collection-compat_2.13-2.4.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-java8-compat_2.13-1.0.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-library-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-logging_2.13-3.9.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/scala-reflect-2.13.6.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-api-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/slf4j-log4j12-1.7.30.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/snappy-java-1.1.8.4.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/trogdor-3.1.0.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zookeeper-jute-3.6.3.jar:/home/joao/Documents/AS/pa2/PA2_G17/src/scripts/../../kafka_2.13-3.1.0/bin/../libs/zstd-jni-1.5.0-4.jar (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:33:03,915] INFO Client environment:java.library.path=/usr/java/packages/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:33:03,915] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:33:03,915] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:33:03,915] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:33:03,915] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:33:03,915] INFO Client environment:os.version=5.13.0-40-generic (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:33:03,915] INFO Client environment:user.name=joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:33:03,915] INFO Client environment:user.home=/home/joao (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:33:03,915] INFO Client environment:user.dir=/home/joao/Documents/AS/pa2/PA2_G17/src/scripts (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:33:03,915] INFO Client environment:os.memory.free=973MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:33:03,916] INFO Client environment:os.memory.max=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:33:03,916] INFO Client environment:os.memory.total=1024MB (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:33:03,918] INFO Initiating client connection, connectString=localhost:2181 sessionTimeout=18000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@6a57ae10 (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:33:03,922] INFO jute.maxbuffer value is 4194304 Bytes (org.apache.zookeeper.ClientCnxnSocket)
[2022-05-15 18:33:03,927] INFO zookeeper.request.timeout value is 0. feature enabled=false (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:33:03,942] INFO [ZooKeeperClient Kafka server] Waiting until connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:33:03,946] INFO Opening socket connection to server localhost/127.0.0.1:2181. (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:33:03,947] INFO SASL config status: Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:33:03,950] INFO Socket connection established, initiating session, client: /127.0.0.1:57986, server: localhost/127.0.0.1:2181 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:33:03,956] INFO Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x100000b00ad0053, negotiated timeout = 18000 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:33:03,961] INFO [ZooKeeperClient Kafka server] Connected. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:33:04,032] INFO [feature-zk-node-event-process-thread]: Starting (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:33:04,158] INFO Updated cache from existing <empty> to latest FinalizedFeaturesAndEpoch(features=Features{}, epoch=0). (kafka.server.FinalizedFeatureCache)
[2022-05-15 18:33:04,164] INFO Cluster ID = Sn3YL4gJRkquVvVQQD9xjw (kafka.server.KafkaServer)
[2022-05-15 18:33:04,207] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:33:04,217] INFO KafkaConfig values: 
	advertised.listeners = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.heartbeat.interval.ms = 2000
	broker.id = 5
	broker.id.generation.enable = true
	broker.rack = null
	broker.session.timeout.ms = 9000
	client.quota.callback.class = null
	compression.type = producer
	connection.failed.authentication.delay.ms = 100
	connections.max.idle.ms = 600000
	connections.max.reauth.ms = 0
	control.plane.listener.name = null
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.listener.names = null
	controller.quorum.append.linger.ms = 25
	controller.quorum.election.backoff.max.ms = 1000
	controller.quorum.election.timeout.ms = 1000
	controller.quorum.fetch.timeout.ms = 2000
	controller.quorum.request.timeout.ms = 2000
	controller.quorum.retry.backoff.ms = 20
	controller.quorum.voters = []
	controller.quota.window.num = 11
	controller.quota.window.size.seconds = 1
	controller.socket.timeout.ms = 30000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delegation.token.secret.key = null
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.max.bytes = 57671680
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 1800000
	group.max.size = 2147483647
	group.min.session.timeout.ms = 6000
	initial.broker.registration.timeout.ms = 60000
	inter.broker.listener.name = null
	inter.broker.protocol.version = 3.1-IV0
	kafka.metrics.polling.interval.secs = 10
	kafka.metrics.reporters = []
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://:9097
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.max.compaction.lag.ms = 9223372036854775807
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /tmp/kafka-logs-5
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 3.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connection.creation.rate = 2147483647
	max.connections = 2147483647
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1048588
	metadata.log.dir = null
	metadata.log.max.record.bytes.between.snapshots = 20971520
	metadata.log.segment.bytes = 1073741824
	metadata.log.segment.min.bytes = 8388608
	metadata.log.segment.ms = 604800000
	metadata.max.retention.bytes = -1
	metadata.max.retention.ms = 604800000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	node.id = 5
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	principal.builder.class = class org.apache.kafka.common.security.authenticator.DefaultKafkaPrincipalBuilder
	process.roles = []
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.window.num = 11
	quota.window.size.seconds = 1
	remote.log.index.file.cache.total.size.bytes = 1073741824
	remote.log.manager.task.interval.ms = 30000
	remote.log.manager.task.retry.backoff.max.ms = 30000
	remote.log.manager.task.retry.backoff.ms = 500
	remote.log.manager.task.retry.jitter = 0.2
	remote.log.manager.thread.pool.size = 10
	remote.log.metadata.manager.class.name = null
	remote.log.metadata.manager.class.path = null
	remote.log.metadata.manager.impl.prefix = null
	remote.log.metadata.manager.listener.name = null
	remote.log.reader.max.pending.tasks = 100
	remote.log.reader.threads = 10
	remote.log.storage.manager.class.name = null
	remote.log.storage.manager.class.path = null
	remote.log.storage.manager.impl.prefix = null
	remote.log.storage.system.enable = false
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 30000
	replica.selector.class = null
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism.controller.protocol = GSSAPI
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	security.providers = null
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.principal.mapping.rules = DEFAULT
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 10000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 1
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 1
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.clientCnxnSocket = null
	zookeeper.connect = localhost:2181
	zookeeper.connection.timeout.ms = 18000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 18000
	zookeeper.set.acl = false
	zookeeper.ssl.cipher.suites = null
	zookeeper.ssl.client.enable = false
	zookeeper.ssl.crl.enable = false
	zookeeper.ssl.enabled.protocols = null
	zookeeper.ssl.endpoint.identification.algorithm = HTTPS
	zookeeper.ssl.keystore.location = null
	zookeeper.ssl.keystore.password = null
	zookeeper.ssl.keystore.type = null
	zookeeper.ssl.ocsp.enable = false
	zookeeper.ssl.protocol = TLSv1.2
	zookeeper.ssl.truststore.location = null
	zookeeper.ssl.truststore.password = null
	zookeeper.ssl.truststore.type = null
	zookeeper.sync.time.ms = 2000
 (kafka.server.KafkaConfig)
[2022-05-15 18:33:04,265] INFO [ThrottledChannelReaper-Fetch]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:33:04,266] INFO [ThrottledChannelReaper-Produce]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:33:04,268] INFO [ThrottledChannelReaper-Request]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:33:04,270] INFO [ThrottledChannelReaper-ControllerMutation]: Starting (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:33:04,308] INFO Loading logs from log dirs ArraySeq(/tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:33:04,313] INFO Skipping recovery for all logs in /tmp/kafka-logs-5 since clean shutdown file was found (kafka.log.LogManager)
[2022-05-15 18:33:04,373] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:04,397] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-3.1b3279a48d8d4b309803f2680348f2d3-delete, topicId=MFB1IcMITPONtX0EWrt34w, topic=Sensor, partition=3, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 71ms (1/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:33:04,411] INFO [LogLoader partition=__consumer_offsets-46, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:04,415] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-46, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=46, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 17ms (2/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:33:04,420] INFO [LogLoader partition=__consumer_offsets-10, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:04,425] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-10, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=10, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (3/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:33:04,431] INFO [LogLoader partition=__consumer_offsets-28, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:04,435] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-28, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=28, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 10ms (4/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:33:04,439] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:04,443] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-2.6bb94050f00147e980250ed613fe0785-delete, topicId=MFB1IcMITPONtX0EWrt34w, topic=Sensor, partition=2, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 8ms (5/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:33:04,460] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Loading producer state till offset 41065 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:04,460] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 41065 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:04,462] INFO [ProducerStateManager partition=__consumer_offsets-22] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-22/00000000000000041065.snapshot,41065)' (kafka.log.ProducerStateManager)
[2022-05-15 18:33:04,467] INFO [LogLoader partition=__consumer_offsets-22, dir=/tmp/kafka-logs-5] Producer state recovery took 7ms for snapshot load and 0ms for segment recovery from offset 41065 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:04,470] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-22, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=22, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=41065) with 1 segments in 27ms (6/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:33:04,475] INFO [LogLoader partition=__consumer_offsets-16, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:04,480] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-16, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=16, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 9ms (7/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:33:04,484] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:04,487] INFO Completed load of Log(dir=/tmp/kafka-logs-5/Sensor-4.a862048540fb42729791ec7261669c7e-delete, topicId=MFB1IcMITPONtX0EWrt34w, topic=Sensor, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (8/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:33:04,493] INFO Deleted producer state snapshot /tmp/kafka-logs-5/__consumer_offsets-40/00000000000000018252.snapshot (kafka.log.SnapshotFile)
[2022-05-15 18:33:04,493] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Loading producer state till offset 27700 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:04,494] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Reloading from producer snapshot and rebuilding producer state from offset 27700 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:04,494] INFO [ProducerStateManager partition=__consumer_offsets-40] Loading producer state from snapshot file 'SnapshotFile(/tmp/kafka-logs-5/__consumer_offsets-40/00000000000000027700.snapshot,27700)' (kafka.log.ProducerStateManager)
[2022-05-15 18:33:04,494] INFO [LogLoader partition=__consumer_offsets-40, dir=/tmp/kafka-logs-5] Producer state recovery took 0ms for snapshot load and 0ms for segment recovery from offset 27700 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:04,497] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-40, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=40, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=27700) with 1 segments in 10ms (9/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:33:04,501] INFO [LogLoader partition=__consumer_offsets-34, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:04,505] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-34, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=34, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 7ms (10/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:33:04,509] INFO [LogLoader partition=__consumer_offsets-4, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:04,511] INFO Completed load of Log(dir=/tmp/kafka-logs-5/__consumer_offsets-4, topicId=i92dBKjZSHC6C_09rDCkbQ, topic=__consumer_offsets, partition=4, highWatermark=0, lastStableOffset=0, logStartOffset=0, logEndOffset=0) with 1 segments in 6ms (11/11 loaded in /tmp/kafka-logs-5) (kafka.log.LogManager)
[2022-05-15 18:33:04,515] INFO Loaded 11 logs in 207ms. (kafka.log.LogManager)
[2022-05-15 18:33:04,516] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
[2022-05-15 18:33:04,517] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
[2022-05-15 18:33:04,761] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:33:04,878] INFO Updated connection-accept-rate max connection creation rate to 2147483647 (kafka.network.ConnectionQuotas)
[2022-05-15 18:33:04,881] INFO Awaiting socket connections on 0.0.0.0:9097. (kafka.network.Acceptor)
[2022-05-15 18:33:04,910] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Created data-plane acceptor and processors for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:33:04,916] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Starting (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:33:04,933] INFO [ExpirationReaper-5-Produce]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:33:04,935] INFO [ExpirationReaper-5-Fetch]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:33:04,936] INFO [ExpirationReaper-5-DeleteRecords]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:33:04,937] INFO [ExpirationReaper-5-ElectLeader]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:33:04,952] INFO [LogDirFailureHandler]: Starting (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:33:05,009] INFO Creating /brokers/ids/5 (is it secure? false) (kafka.zk.KafkaZkClient)
[2022-05-15 18:33:05,027] INFO Stat of the created znode at /brokers/ids/5 is: 3865,3865,1652635985020,1652635985020,1,0,0,72057641293906003,192,0,3865
 (kafka.zk.KafkaZkClient)
[2022-05-15 18:33:05,028] INFO Registered broker 5 at path /brokers/ids/5 with addresses: PLAINTEXT://joao:9097, czxid (broker epoch): 3865 (kafka.zk.KafkaZkClient)
[2022-05-15 18:33:05,090] INFO [ExpirationReaper-5-topic]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:33:05,097] INFO [ExpirationReaper-5-Heartbeat]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:33:05,098] INFO [ExpirationReaper-5-Rebalance]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:33:05,112] INFO [GroupCoordinator 5]: Starting up. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:33:05,122] INFO [GroupCoordinator 5]: Startup complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:33:05,146] INFO [TransactionCoordinator id=5] Starting up. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:33:05,151] INFO [Transaction Marker Channel Manager 5]: Starting (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:33:05,151] INFO [TransactionCoordinator id=5] Startup complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:33:05,174] INFO [ExpirationReaper-5-AlterAcls]: Starting (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:33:05,191] INFO [/config/changes-event-process-thread]: Starting (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:33:05,207] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Starting socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:33:05,215] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started data-plane acceptor and processor(s) for endpoint : ListenerName(PLAINTEXT) (kafka.network.SocketServer)
[2022-05-15 18:33:05,215] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Started socket server acceptors and processors (kafka.network.SocketServer)
[2022-05-15 18:33:05,221] INFO Kafka version: 3.1.0 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:33:05,222] INFO Kafka commitId: 37edeed0777bacb3 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:33:05,222] INFO Kafka startTimeMs: 1652635985216 (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:33:05,225] INFO [KafkaServer id=5] started (kafka.server.KafkaServer)
[2022-05-15 18:33:05,273] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:33:05,319] INFO [Partition __consumer_offsets-34 broker=5] Log loaded for partition __consumer_offsets-34 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:05,320] INFO [Partition __consumer_offsets-4 broker=5] Log loaded for partition __consumer_offsets-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:05,320] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Recorded new controller, from now on will use broker joao:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:33:05,320] INFO [Partition __consumer_offsets-22 broker=5] Log loaded for partition __consumer_offsets-22 with initial high watermark 41065 (kafka.cluster.Partition)
[2022-05-15 18:33:05,320] INFO [Partition __consumer_offsets-40 broker=5] Log loaded for partition __consumer_offsets-40 with initial high watermark 27700 (kafka.cluster.Partition)
[2022-05-15 18:33:05,320] INFO [Partition __consumer_offsets-10 broker=5] Log loaded for partition __consumer_offsets-10 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:05,321] INFO [Partition __consumer_offsets-28 broker=5] Log loaded for partition __consumer_offsets-28 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:05,321] INFO [Partition __consumer_offsets-46 broker=5] Log loaded for partition __consumer_offsets-46 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:05,322] INFO [Partition __consumer_offsets-16 broker=5] Log loaded for partition __consumer_offsets-16 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:05,348] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(__consumer_offsets-22, __consumer_offsets-4, __consumer_offsets-46, __consumer_offsets-34, __consumer_offsets-16, __consumer_offsets-28, __consumer_offsets-10, __consumer_offsets-40) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:05,383] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 34 in epoch 40 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:33:05,386] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-34 for epoch 40 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:05,387] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 4 in epoch 40 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:33:05,387] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-4 for epoch 40 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:05,387] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 22 in epoch 40 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:33:05,387] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-22 for epoch 40 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:05,387] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 40 in epoch 40 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:33:05,388] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-40 for epoch 40 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:05,388] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 10 in epoch 40 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:33:05,388] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-10 for epoch 40 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:05,388] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 28 in epoch 40 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:33:05,388] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-28 for epoch 40 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:05,388] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 46 in epoch 40 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:33:05,388] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-46 for epoch 40 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:05,388] INFO [GroupCoordinator 5]: Elected as the group coordinator for partition 16 in epoch 40 (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:33:05,388] INFO [GroupMetadataManager brokerId=5] Scheduling loading of offsets and group metadata from __consumer_offsets-16 for epoch 40 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:05,393] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-34 in 6 milliseconds for epoch 40, of which 3 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:05,394] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-4 in 7 milliseconds for epoch 40, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:05,415] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-9fa5abef-fdc9-4c05-8f09-7f9780632837, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:33:05,426] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-ed3a6d0d-54c4-4b54-b4a4-a5d0ecba6f8e, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:33:05,426] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-1038faf2-d998-4707-9799-897de83d6136, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:33:05,426] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-b283a5ee-70be-4bf9-b41c-74e089f12e34, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:33:05,426] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-360d1581-f79b-41e6-82d3-fe3577615014, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:33:05,426] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-9e173d1e-b47a-4b16-9874-bf5d2688c730, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:33:05,426] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-81fafa38-80dc-43ea-ac6c-e398b06565dc, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:33:05,455] INFO Loaded member MemberMetadata(memberId=consumer-consumer-4-d15976bc-df63-4682-8583-fd67cbb1d9df, groupInstanceId=None, clientId=consumer-consumer-4, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:33:05,455] INFO Loaded member MemberMetadata(memberId=consumer-consumer-3-a0d7c5c7-e384-4339-b0be-414878362e3e, groupInstanceId=None, clientId=consumer-consumer-3, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:33:05,455] INFO Loaded member MemberMetadata(memberId=consumer-consumer-2-ee781f71-f1c3-46d7-bd93-d90a4fe359ff, groupInstanceId=None, clientId=consumer-consumer-2, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:33:05,455] INFO Loaded member MemberMetadata(memberId=consumer-consumer-5-78575c72-7be8-4563-b114-53b271a8ef70, groupInstanceId=None, clientId=consumer-consumer-5, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:33:05,455] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-0287b15c-1acd-4475-b9ce-b994aebeeff2, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:33:05,455] INFO Loaded member MemberMetadata(memberId=consumer-consumer-6-45d54f6e-f1d8-43f7-8ace-1db96ac0cfac, groupInstanceId=None, clientId=consumer-consumer-6, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:33:05,517] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-954ef0dc-d124-405b-9bb6-119086dd08c0, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 1. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:33:05,518] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-3f51cd43-28ab-4459-969e-211543e6cd72, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 3. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:33:05,518] INFO Loaded member MemberMetadata(memberId=consumer-consumer-1-4b8634e2-92f3-4603-97c5-35df7219bd84, groupInstanceId=None, clientId=consumer-consumer-1, clientHost=/127.0.0.1, sessionTimeoutMs=45000, rebalanceTimeoutMs=300000, supportedProtocols=List(range)) in group consumer with generation 4. (kafka.coordinator.group.GroupMetadata$)
[2022-05-15 18:33:05,519] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-22 in 132 milliseconds for epoch 40, of which 7 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:05,550] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-40 in 161 milliseconds for epoch 40, of which 131 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:05,550] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-10 in 162 milliseconds for epoch 40, of which 162 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:05,551] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-28 in 163 milliseconds for epoch 40, of which 162 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:05,551] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-46 in 163 milliseconds for epoch 40, of which 163 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:05,551] INFO [GroupMetadataManager brokerId=5] Finished loading offsets and group metadata from __consumer_offsets-16 in 163 milliseconds for epoch 40, of which 163 milliseconds was spent in the scheduler. (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:33:09,390] INFO Creating topic Sensor with configuration {min.insync.replicas=2} and initial partition assignment HashMap(0 -> ArrayBuffer(3, 0, 5), 1 -> ArrayBuffer(0, 5, 4), 2 -> ArrayBuffer(5, 4, 1), 3 -> ArrayBuffer(4, 1, 2), 4 -> ArrayBuffer(1, 2, 3), 5 -> ArrayBuffer(2, 3, 0)) (kafka.zk.AdminZkClient)
[2022-05-15 18:33:09,442] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,443] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-4) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,443] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,445] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-2) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,447] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,445] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,462] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:09,464] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:09,464] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:09,465] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:09,465] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:09,466] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:09,469] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-5/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:33:09,470] INFO Created log for partition Sensor-1 in /tmp/kafka-logs/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:33:09,470] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-3/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:33:09,471] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-1/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:33:09,473] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-2/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:33:09,473] INFO [Partition Sensor-0 broker=3] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 18:33:09,473] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-4/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:33:09,474] INFO [Partition Sensor-0 broker=3] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:09,473] INFO [Partition Sensor-4 broker=1] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 18:33:09,474] INFO [Partition Sensor-4 broker=1] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:09,474] INFO [Partition Sensor-1 broker=0] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 18:33:09,475] INFO [Partition Sensor-5 broker=2] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 18:33:09,475] INFO [Partition Sensor-1 broker=0] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:09,475] INFO [Partition Sensor-5 broker=2] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:09,471] INFO [Partition Sensor-2 broker=5] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 18:33:09,476] INFO [Partition Sensor-2 broker=5] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:09,476] INFO [Partition Sensor-3 broker=4] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 18:33:09,477] INFO [Partition Sensor-3 broker=4] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:09,487] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:09,489] INFO Created log for partition Sensor-5 in /tmp/kafka-logs/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:33:09,489] INFO [Partition Sensor-5 broker=0] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 18:33:09,489] INFO [Partition Sensor-5 broker=0] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:09,491] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:09,491] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:09,492] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:09,492] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-2/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:33:09,492] INFO [LogLoader partition=Sensor-4, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:09,493] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:09,493] INFO [Partition Sensor-4 broker=2] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 18:33:09,493] INFO [Partition Sensor-4 broker=2] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:09,494] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-1/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:33:09,494] INFO [LogLoader partition=Sensor-0, dir=/tmp/kafka-logs] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:09,494] INFO [Partition Sensor-3 broker=1] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 18:33:09,495] INFO [Partition Sensor-3 broker=1] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:09,495] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-4/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:33:09,495] INFO [Partition Sensor-2 broker=4] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 18:33:09,495] INFO [Partition Sensor-2 broker=4] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:09,496] INFO Created log for partition Sensor-0 in /tmp/kafka-logs-5/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:33:09,496] INFO [Partition Sensor-0 broker=5] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 18:33:09,496] INFO [Partition Sensor-0 broker=5] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:09,496] INFO Created log for partition Sensor-0 in /tmp/kafka-logs/Sensor-0 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:33:09,497] INFO [Partition Sensor-0 broker=0] No checkpointed highwatermark is found for partition Sensor-0 (kafka.cluster.Partition)
[2022-05-15 18:33:09,497] INFO [Partition Sensor-0 broker=0] Log loaded for partition Sensor-0 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:09,497] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions HashSet(Sensor-5, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,496] INFO Created log for partition Sensor-4 in /tmp/kafka-logs-3/Sensor-4 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:33:09,500] INFO [Partition Sensor-4 broker=3] No checkpointed highwatermark is found for partition Sensor-4 (kafka.cluster.Partition)
[2022-05-15 18:33:09,500] INFO [Partition Sensor-4 broker=3] Log loaded for partition Sensor-4 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:09,503] INFO [LogLoader partition=Sensor-3, dir=/tmp/kafka-logs-2] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:09,504] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-4] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:09,504] INFO [LogLoader partition=Sensor-1, dir=/tmp/kafka-logs-5] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:09,506] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-4/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:33:09,507] INFO Created log for partition Sensor-1 in /tmp/kafka-logs-5/Sensor-1 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:33:09,507] INFO [Partition Sensor-1 broker=4] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 18:33:09,507] INFO [Partition Sensor-1 broker=5] No checkpointed highwatermark is found for partition Sensor-1 (kafka.cluster.Partition)
[2022-05-15 18:33:09,507] INFO [Partition Sensor-1 broker=4] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:09,507] INFO [Partition Sensor-1 broker=5] Log loaded for partition Sensor-1 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:09,507] INFO [LogLoader partition=Sensor-2, dir=/tmp/kafka-logs-1] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:09,507] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions HashSet(Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,507] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions HashSet(Sensor-2, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,508] INFO Created log for partition Sensor-3 in /tmp/kafka-logs-2/Sensor-3 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:33:09,508] INFO [Partition Sensor-3 broker=2] No checkpointed highwatermark is found for partition Sensor-3 (kafka.cluster.Partition)
[2022-05-15 18:33:09,508] INFO [Partition Sensor-3 broker=2] Log loaded for partition Sensor-3 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:09,509] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions HashSet(Sensor-4, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,509] INFO Created log for partition Sensor-2 in /tmp/kafka-logs-1/Sensor-2 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:33:09,509] INFO [Partition Sensor-2 broker=1] No checkpointed highwatermark is found for partition Sensor-2 (kafka.cluster.Partition)
[2022-05-15 18:33:09,509] INFO [Partition Sensor-2 broker=1] Log loaded for partition Sensor-2 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:09,511] INFO [LogLoader partition=Sensor-5, dir=/tmp/kafka-logs-3] Loading producer state till offset 0 with message format version 2 (kafka.log.UnifiedLog$)
[2022-05-15 18:33:09,512] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions HashSet(Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,514] INFO Created log for partition Sensor-5 in /tmp/kafka-logs-3/Sensor-5 with properties {min.insync.replicas=2} (kafka.log.LogManager)
[2022-05-15 18:33:09,515] INFO [Partition Sensor-5 broker=3] No checkpointed highwatermark is found for partition Sensor-5 (kafka.cluster.Partition)
[2022-05-15 18:33:09,515] INFO [Partition Sensor-5 broker=3] Log loaded for partition Sensor-5 with initial high watermark 0 (kafka.cluster.Partition)
[2022-05-15 18:33:09,516] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions HashSet(Sensor-4, Sensor-5) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,522] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,525] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 2 for partitions Map(Sensor-5 -> InitialFetchState(Some(br_4hhZ6RHOKcZ7BGpwieg),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,528] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,529] INFO [ReplicaFetcherManager on broker 0] Added fetcher to broker 3 for partitions Map(Sensor-0 -> InitialFetchState(Some(br_4hhZ6RHOKcZ7BGpwieg),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,529] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,530] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,531] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:33:09,531] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:33:09,537] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,540] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,545] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 0 for partitions Map(Sensor-1 -> InitialFetchState(Some(br_4hhZ6RHOKcZ7BGpwieg),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,547] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 4 for partitions Map(Sensor-3 -> InitialFetchState(Some(br_4hhZ6RHOKcZ7BGpwieg),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,547] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,548] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,548] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,549] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,551] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,554] INFO [ReplicaFetcherManager on broker 5] Added fetcher to broker 3 for partitions Map(Sensor-0 -> InitialFetchState(Some(br_4hhZ6RHOKcZ7BGpwieg),BrokerEndPoint(id=3, host=joao:9095),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,554] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 4 for partitions Map(Sensor-3 -> InitialFetchState(Some(br_4hhZ6RHOKcZ7BGpwieg),BrokerEndPoint(id=4, host=joao:9096),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,556] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:33:09,557] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Truncating partition Sensor-3 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,556] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,557] INFO [ReplicaFetcherManager on broker 2] Added fetcher to broker 1 for partitions Map(Sensor-4 -> InitialFetchState(Some(br_4hhZ6RHOKcZ7BGpwieg),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,557] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,557] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:33:09,558] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 0 for partitions Map(Sensor-1 -> InitialFetchState(Some(br_4hhZ6RHOKcZ7BGpwieg),BrokerEndPoint(id=0, host=joao:9092),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,558] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs-2] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:33:09,559] INFO [ReplicaFetcherManager on broker 1] Added fetcher to broker 5 for partitions Map(Sensor-2 -> InitialFetchState(Some(br_4hhZ6RHOKcZ7BGpwieg),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,560] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Truncating partition Sensor-1 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,560] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,561] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,561] INFO [UnifiedLog partition=Sensor-3, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:33:09,553] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,563] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Truncating partition Sensor-0 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,565] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 2 for partitions Map(Sensor-5 -> InitialFetchState(Some(br_4hhZ6RHOKcZ7BGpwieg),BrokerEndPoint(id=2, host=joao:9094),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,563] INFO [UnifiedLog partition=Sensor-0, dir=/tmp/kafka-logs-5] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:33:09,562] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs-1] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:33:09,569] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Truncating partition Sensor-5 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,568] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,573] INFO [ReplicaFetcherManager on broker 4] Added fetcher to broker 5 for partitions Map(Sensor-2 -> InitialFetchState(Some(br_4hhZ6RHOKcZ7BGpwieg),BrokerEndPoint(id=5, host=joao:9097),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,573] INFO [UnifiedLog partition=Sensor-5, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:33:09,573] INFO [ReplicaFetcherManager on broker 3] Added fetcher to broker 1 for partitions Map(Sensor-4 -> InitialFetchState(Some(br_4hhZ6RHOKcZ7BGpwieg),BrokerEndPoint(id=1, host=joao:9093),0,0)) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:33:09,573] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Truncating partition Sensor-2 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,575] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Starting (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,576] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Truncating partition Sensor-4 with TruncationState(offset=0, completed=true) due to local high watermark 0 (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,576] INFO [UnifiedLog partition=Sensor-2, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:33:09,576] INFO [UnifiedLog partition=Sensor-4, dir=/tmp/kafka-logs-3] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:33:09,584] INFO [UnifiedLog partition=Sensor-1, dir=/tmp/kafka-logs-4] Truncating to 0 has no effect as the largest offset in the log is -1 (kafka.log.UnifiedLog)
[2022-05-15 18:33:09,664] WARN [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-5. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,681] WARN [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-0. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:09,720] WARN [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Received UNKNOWN_TOPIC_ID from the leader for partition Sensor-3. This error may be returned transiently when the partition is being created or deleted, but it is not expected to persist. (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:33:39,449] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=67556, lastModifiedTime=1652635826649, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:33:39,451] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=67556, lastModifiedTime=1652635826649, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:33:39,455] INFO Deleted log /tmp/kafka-logs/Sensor-1.90aeadc965834f82bde787d0712295af-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:39,455] INFO Deleted offset index /tmp/kafka-logs/Sensor-1.90aeadc965834f82bde787d0712295af-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:39,457] INFO Deleted time index /tmp/kafka-logs/Sensor-1.90aeadc965834f82bde787d0712295af-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:39,459] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs/Sensor-1.90aeadc965834f82bde787d0712295af-delete. (kafka.log.LogManager)
[2022-05-15 18:33:39,494] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=67517, lastModifiedTime=1652635822113, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:33:39,495] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=67517, lastModifiedTime=1652635822113, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:33:39,496] INFO Deleted log /tmp/kafka-logs/Sensor-2.01dd320e0ebd4d20a04eb73da7c80ac4-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:39,496] INFO Deleted offset index /tmp/kafka-logs/Sensor-2.01dd320e0ebd4d20a04eb73da7c80ac4-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:39,497] INFO Deleted time index /tmp/kafka-logs/Sensor-2.01dd320e0ebd4d20a04eb73da7c80ac4-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:39,498] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs/Sensor-2.01dd320e0ebd4d20a04eb73da7c80ac4-delete. (kafka.log.LogManager)
[2022-05-15 18:33:39,527] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=79359, lastModifiedTime=1652635829809, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:33:39,527] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs] Deleting segment files LogSegment(baseOffset=0, size=79359, lastModifiedTime=1652635829809, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:33:39,528] INFO Deleted log /tmp/kafka-logs/Sensor-3.ffb5dcaaab7a492fa153776acb87fc91-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:39,528] INFO Deleted offset index /tmp/kafka-logs/Sensor-3.ffb5dcaaab7a492fa153776acb87fc91-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:39,529] INFO Deleted time index /tmp/kafka-logs/Sensor-3.ffb5dcaaab7a492fa153776acb87fc91-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:39,529] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs/Sensor-3.ffb5dcaaab7a492fa153776acb87fc91-delete. (kafka.log.LogManager)
[2022-05-15 18:33:44,451] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=44838, lastModifiedTime=1652635819365, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:33:44,453] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=44838, lastModifiedTime=1652635819365, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:33:44,456] INFO Deleted log /tmp/kafka-logs-1/Sensor-5.c92d8dc6bdc743778a88985cb555afa2-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:44,456] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-5.c92d8dc6bdc743778a88985cb555afa2-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:44,460] INFO Deleted time index /tmp/kafka-logs-1/Sensor-5.c92d8dc6bdc743778a88985cb555afa2-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:44,465] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-1/Sensor-5.c92d8dc6bdc743778a88985cb555afa2-delete. (kafka.log.LogManager)
[2022-05-15 18:33:44,466] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=76236, lastModifiedTime=1652635829809, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:33:44,466] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=76236, lastModifiedTime=1652635829809, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:33:44,466] INFO Deleted log /tmp/kafka-logs-1/Sensor-0.78a885ba31764e8a8d8164e2108a98aa-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:44,467] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-0.78a885ba31764e8a8d8164e2108a98aa-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:44,467] INFO Deleted time index /tmp/kafka-logs-1/Sensor-0.78a885ba31764e8a8d8164e2108a98aa-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:44,467] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-1/Sensor-0.78a885ba31764e8a8d8164e2108a98aa-delete. (kafka.log.LogManager)
[2022-05-15 18:33:44,490] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-1] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=39828, lastModifiedTime=1652635825049, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:33:44,491] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-1] Deleting segment files LogSegment(baseOffset=0, size=39828, lastModifiedTime=1652635825049, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:33:44,492] INFO Deleted log /tmp/kafka-logs-1/Sensor-4.4479f2c030844a5aa14211563cecfd5b-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:44,492] INFO Deleted offset index /tmp/kafka-logs-1/Sensor-4.4479f2c030844a5aa14211563cecfd5b-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:44,493] INFO Deleted time index /tmp/kafka-logs-1/Sensor-4.4479f2c030844a5aa14211563cecfd5b-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:44,494] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-1/Sensor-4.4479f2c030844a5aa14211563cecfd5b-delete. (kafka.log.LogManager)
[2022-05-15 18:33:49,430] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=67556, lastModifiedTime=1652635826649, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:33:49,432] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=67556, lastModifiedTime=1652635826649, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:33:49,436] INFO Deleted log /tmp/kafka-logs-2/Sensor-1.f6d39bd0eb4f43f6a0c2447f5677ec85-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:49,437] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-1.f6d39bd0eb4f43f6a0c2447f5677ec85-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:49,439] INFO Deleted time index /tmp/kafka-logs-2/Sensor-1.f6d39bd0eb4f43f6a0c2447f5677ec85-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:49,443] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-2/Sensor-1.f6d39bd0eb4f43f6a0c2447f5677ec85-delete. (kafka.log.LogManager)
[2022-05-15 18:33:49,502] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=44838, lastModifiedTime=1652635819361, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:33:49,502] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=44838, lastModifiedTime=1652635819361, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:33:49,503] INFO Deleted log /tmp/kafka-logs-2/Sensor-5.5a196a2bd4b245c1be41f480b33c8ba7-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:49,504] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-5.5a196a2bd4b245c1be41f480b33c8ba7-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:49,504] INFO Deleted time index /tmp/kafka-logs-2/Sensor-5.5a196a2bd4b245c1be41f480b33c8ba7-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:49,505] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-2/Sensor-5.5a196a2bd4b245c1be41f480b33c8ba7-delete. (kafka.log.LogManager)
[2022-05-15 18:33:49,521] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-2] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=76236, lastModifiedTime=1652635829809, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:33:49,522] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-2] Deleting segment files LogSegment(baseOffset=0, size=76236, lastModifiedTime=1652635829809, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:33:49,522] INFO Deleted log /tmp/kafka-logs-2/Sensor-0.c4518740d1aa4dc78469b2defde2fe0b-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:49,522] INFO Deleted offset index /tmp/kafka-logs-2/Sensor-0.c4518740d1aa4dc78469b2defde2fe0b-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:49,523] INFO Deleted time index /tmp/kafka-logs-2/Sensor-0.c4518740d1aa4dc78469b2defde2fe0b-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:49,523] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-2/Sensor-0.c4518740d1aa4dc78469b2defde2fe0b-delete. (kafka.log.LogManager)
[2022-05-15 18:33:54,443] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=76236, lastModifiedTime=1652635829809, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:33:54,446] INFO [LocalLog partition=Sensor-0, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=76236, lastModifiedTime=1652635829809, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:33:54,450] INFO Deleted log /tmp/kafka-logs-3/Sensor-0.434b88b4914b4f1c989e3cccb7661f7a-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:54,450] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-0.434b88b4914b4f1c989e3cccb7661f7a-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:54,453] INFO Deleted time index /tmp/kafka-logs-3/Sensor-0.434b88b4914b4f1c989e3cccb7661f7a-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:54,457] INFO Deleted log for partition Sensor-0 in /tmp/kafka-logs-3/Sensor-0.434b88b4914b4f1c989e3cccb7661f7a-delete. (kafka.log.LogManager)
[2022-05-15 18:33:54,473] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=67517, lastModifiedTime=1652635822109, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:33:54,474] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=67517, lastModifiedTime=1652635822109, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:33:54,475] INFO Deleted log /tmp/kafka-logs-3/Sensor-2.6cde347c54fc4b018b3006510e13d1e4-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:54,475] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-2.6cde347c54fc4b018b3006510e13d1e4-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:54,475] INFO Deleted time index /tmp/kafka-logs-3/Sensor-2.6cde347c54fc4b018b3006510e13d1e4-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:54,476] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-3/Sensor-2.6cde347c54fc4b018b3006510e13d1e4-delete. (kafka.log.LogManager)
[2022-05-15 18:33:54,482] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-3] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=67556, lastModifiedTime=1652635826649, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:33:54,482] INFO [LocalLog partition=Sensor-1, dir=/tmp/kafka-logs-3] Deleting segment files LogSegment(baseOffset=0, size=67556, lastModifiedTime=1652635826649, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:33:54,483] INFO Deleted log /tmp/kafka-logs-3/Sensor-1.b672de8a8b844dda988724e226cd6942-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:54,484] INFO Deleted offset index /tmp/kafka-logs-3/Sensor-1.b672de8a8b844dda988724e226cd6942-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:54,484] INFO Deleted time index /tmp/kafka-logs-3/Sensor-1.b672de8a8b844dda988724e226cd6942-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:54,485] INFO Deleted log for partition Sensor-1 in /tmp/kafka-logs-3/Sensor-1.b672de8a8b844dda988724e226cd6942-delete. (kafka.log.LogManager)
[2022-05-15 18:33:59,467] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=39828, lastModifiedTime=1652635825053, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:33:59,468] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=39828, lastModifiedTime=1652635825053, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:33:59,471] INFO Deleted log /tmp/kafka-logs-4/Sensor-4.581a01e9e9e8483baa62ca9705cb52d5-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:59,472] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-4.581a01e9e9e8483baa62ca9705cb52d5-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:59,475] INFO Deleted time index /tmp/kafka-logs-4/Sensor-4.581a01e9e9e8483baa62ca9705cb52d5-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:59,479] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-4/Sensor-4.581a01e9e9e8483baa62ca9705cb52d5-delete. (kafka.log.LogManager)
[2022-05-15 18:33:59,503] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=44838, lastModifiedTime=1652635819365, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:33:59,503] INFO [LocalLog partition=Sensor-5, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=44838, lastModifiedTime=1652635819365, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:33:59,504] INFO Deleted log /tmp/kafka-logs-4/Sensor-5.55e2e7cb7a65404da3a2440f977c622d-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:59,505] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-5.55e2e7cb7a65404da3a2440f977c622d-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:59,505] INFO Deleted time index /tmp/kafka-logs-4/Sensor-5.55e2e7cb7a65404da3a2440f977c622d-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:59,505] INFO Deleted log for partition Sensor-5 in /tmp/kafka-logs-4/Sensor-5.55e2e7cb7a65404da3a2440f977c622d-delete. (kafka.log.LogManager)
[2022-05-15 18:33:59,545] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-4] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=79359, lastModifiedTime=1652635829809, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:33:59,546] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-4] Deleting segment files LogSegment(baseOffset=0, size=79359, lastModifiedTime=1652635829809, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:33:59,547] INFO Deleted log /tmp/kafka-logs-4/Sensor-3.d9dbb331425840eb87e57f7252b3292d-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:59,549] INFO Deleted offset index /tmp/kafka-logs-4/Sensor-3.d9dbb331425840eb87e57f7252b3292d-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:59,549] INFO Deleted time index /tmp/kafka-logs-4/Sensor-3.d9dbb331425840eb87e57f7252b3292d-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:33:59,550] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-4/Sensor-3.d9dbb331425840eb87e57f7252b3292d-delete. (kafka.log.LogManager)
[2022-05-15 18:34:04,400] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=79359, lastModifiedTime=1652635829813, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:34:04,402] INFO [LocalLog partition=Sensor-3, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=79359, lastModifiedTime=1652635829813, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:34:04,406] INFO Deleted log /tmp/kafka-logs-5/Sensor-3.1b3279a48d8d4b309803f2680348f2d3-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:34:04,406] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-3.1b3279a48d8d4b309803f2680348f2d3-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:34:04,409] INFO Deleted time index /tmp/kafka-logs-5/Sensor-3.1b3279a48d8d4b309803f2680348f2d3-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:34:04,413] INFO Deleted log for partition Sensor-3 in /tmp/kafka-logs-5/Sensor-3.1b3279a48d8d4b309803f2680348f2d3-delete. (kafka.log.LogManager)
[2022-05-15 18:34:04,444] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=67517, lastModifiedTime=1652635822109, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:34:04,444] INFO [LocalLog partition=Sensor-2, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=67517, lastModifiedTime=1652635822109, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:34:04,445] INFO Deleted log /tmp/kafka-logs-5/Sensor-2.6bb94050f00147e980250ed613fe0785-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:34:04,446] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-2.6bb94050f00147e980250ed613fe0785-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:34:04,446] INFO Deleted time index /tmp/kafka-logs-5/Sensor-2.6bb94050f00147e980250ed613fe0785-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:34:04,446] INFO Deleted log for partition Sensor-2 in /tmp/kafka-logs-5/Sensor-2.6bb94050f00147e980250ed613fe0785-delete. (kafka.log.LogManager)
[2022-05-15 18:34:04,487] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-5] Deleting segments as the log has been deleted: LogSegment(baseOffset=0, size=39828, lastModifiedTime=1652635825053, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog)
[2022-05-15 18:34:04,487] INFO [LocalLog partition=Sensor-4, dir=/tmp/kafka-logs-5] Deleting segment files LogSegment(baseOffset=0, size=39828, lastModifiedTime=1652635825053, largestRecordTimestamp=Some(0)) (kafka.log.LocalLog$)
[2022-05-15 18:34:04,488] INFO Deleted log /tmp/kafka-logs-5/Sensor-4.a862048540fb42729791ec7261669c7e-delete/00000000000000000000.log.deleted. (kafka.log.LogSegment)
[2022-05-15 18:34:04,488] INFO Deleted offset index /tmp/kafka-logs-5/Sensor-4.a862048540fb42729791ec7261669c7e-delete/00000000000000000000.index.deleted. (kafka.log.LogSegment)
[2022-05-15 18:34:04,489] INFO Deleted time index /tmp/kafka-logs-5/Sensor-4.a862048540fb42729791ec7261669c7e-delete/00000000000000000000.timeindex.deleted. (kafka.log.LogSegment)
[2022-05-15 18:34:04,489] INFO Deleted log for partition Sensor-4 in /tmp/kafka-logs-5/Sensor-4.a862048540fb42729791ec7261669c7e-delete. (kafka.log.LogManager)
[2022-05-15 18:37:51,468] INFO [GroupCoordinator 0]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:37:51,470] INFO [GroupCoordinator 5]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:37:51,470] INFO [GroupCoordinator 1]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:37:51,471] INFO [GroupCoordinator 2]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:37:51,471] INFO [GroupCoordinator 4]: Removed 0 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:37:51,472] INFO [GroupMetadataManager brokerId=3] Group consumer-group transitioned to Dead in generation 0 (kafka.coordinator.group.GroupMetadataManager)
[2022-05-15 18:37:51,478] INFO [GroupCoordinator 3]: Removed 6 offsets associated with deleted partitions: Sensor-3, Sensor-2, Sensor-5, Sensor-1, Sensor-4, Sensor-0. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:37:51,499] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:51,499] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:51,500] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:51,500] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:51,501] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:51,501] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:51,502] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:51,503] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:51,502] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:51,504] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:51,505] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:51,505] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:51,506] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,507] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:51,509] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,510] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,510] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:51,510] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1203 due to node 3 being disconnected (elapsed time since creation: 75ms, elapsed time since send: 75ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:51,511] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:51,512] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,512] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,513] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 937 due to node 2 being disconnected (elapsed time since creation: 49ms, elapsed time since send: 49ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:51,513] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,513] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:51,513] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1100 due to node 0 being disconnected (elapsed time since creation: 498ms, elapsed time since send: 498ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:51,513] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=45778529, epoch=935) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:37:51,514] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:51,511] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=1371449276, epoch=1203) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:37:51,514] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,515] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,515] INFO [ReplicaFetcher replicaId=5, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,515] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:51,515] INFO [ReplicaFetcher replicaId=0, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,516] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 921 due to node 1 being disconnected (elapsed time since creation: 418ms, elapsed time since send: 418ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:51,517] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Cancelled in-flight FETCH request with correlation id 938 due to node 2 being disconnected (elapsed time since creation: 53ms, elapsed time since send: 53ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:51,517] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1233 due to node 4 being disconnected (elapsed time since creation: 70ms, elapsed time since send: 70ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:51,514] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Error sending fetch request (sessionId=1264744095, epoch=1100) to node 0: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:37:51,518] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,518] INFO [ReplicaFetcher replicaId=4, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,519] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,520] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,517] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=1544955620, epoch=921) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:37:51,520] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,520] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,520] INFO [ReplicaFetcher replicaId=2, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,517] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Error sending fetch request (sessionId=2037817385, epoch=938) to node 2: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:37:51,518] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=1037024309, epoch=1233) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:37:51,522] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,521] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:51,522] INFO [ReplicaFetcher replicaId=3, leaderId=2, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,522] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1206 due to node 3 being disconnected (elapsed time since creation: 88ms, elapsed time since send: 88ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:51,522] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,522] INFO [ReplicaFetcher replicaId=1, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,522] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Error sending fetch request (sessionId=433726879, epoch=1204) to node 3: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:37:51,523] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,523] INFO [ReplicaFetcher replicaId=5, leaderId=0, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,523] INFO [ReplicaFetcher replicaId=0, leaderId=3, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,526] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,526] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:51,526] INFO [ReplicaFetcherManager on broker 5] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:51,526] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Client requested connection close from node 4 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:51,527] INFO [ReplicaAlterLogDirsManager on broker 5] Removed fetcher for partitions Set(Sensor-2, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:51,527] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,527] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1233 due to node 4 being disconnected (elapsed time since creation: 82ms, elapsed time since send: 82ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:51,527] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:51,527] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Error sending fetch request (sessionId=352806481, epoch=1231) to node 4: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:37:51,528] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1090 due to node 5 being disconnected (elapsed time since creation: 332ms, elapsed time since send: 332ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:51,528] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,528] INFO [ReplicaFetcher replicaId=2, leaderId=4, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,528] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=1876710802, epoch=1090) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:37:51,528] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,528] INFO [ReplicaFetcher replicaId=4, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,529] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,529] INFO [ReplicaAlterLogDirsManager on broker 0] Removed fetcher for partitions Set(Sensor-5, Sensor-0, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:51,529] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:51,530] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Cancelled in-flight FETCH request with correlation id 921 due to node 1 being disconnected (elapsed time since creation: 436ms, elapsed time since send: 436ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:51,530] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Shutting down (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,531] INFO [ReplicaFetcherManager on broker 2] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:51,530] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Error sending fetch request (sessionId=152536488, epoch=921) to node 1: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:37:51,530] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:51,531] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,531] INFO [ReplicaFetcher replicaId=3, leaderId=1, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,531] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Cancelled in-flight FETCH request with correlation id 1090 due to node 5 being disconnected (elapsed time since creation: 334ms, elapsed time since send: 334ms, request timeout: 30000ms) (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:51,531] INFO [ReplicaAlterLogDirsManager on broker 2] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:51,532] INFO [ReplicaFetcherManager on broker 4] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:51,533] INFO [ReplicaAlterLogDirsManager on broker 4] Removed fetcher for partitions Set(Sensor-2, Sensor-3, Sensor-1) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:51,533] INFO [ReplicaFetcherManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-0) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:51,532] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Error sending fetch request (sessionId=1056502189, epoch=1090) to node 5: (org.apache.kafka.clients.FetchSessionHandler)
java.io.IOException: Client was shutdown before response was read
	at org.apache.kafka.clients.NetworkClientUtils.sendAndReceive(NetworkClientUtils.java:108)
	at kafka.server.ReplicaFetcherBlockingSend.sendRequest(ReplicaFetcherBlockingSend.scala:109)
	at kafka.server.ReplicaFetcherThread.fetchFromLeader(ReplicaFetcherThread.scala:219)
	at kafka.server.AbstractFetcherThread.processFetchRequest(AbstractFetcherThread.scala:322)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3(AbstractFetcherThread.scala:137)
	at kafka.server.AbstractFetcherThread.$anonfun$maybeFetch$3$adapted(AbstractFetcherThread.scala:136)
	at scala.Option.foreach(Option.scala:437)
	at kafka.server.AbstractFetcherThread.maybeFetch(AbstractFetcherThread.scala:136)
	at kafka.server.AbstractFetcherThread.doWork(AbstractFetcherThread.scala:119)
	at kafka.utils.ShutdownableThread.run(ShutdownableThread.scala:96)
[2022-05-15 18:37:51,533] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Stopped (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,533] INFO [ReplicaAlterLogDirsManager on broker 3] Removed fetcher for partitions Set(Sensor-4, Sensor-5, Sensor-0) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:51,535] INFO [ReplicaFetcher replicaId=1, leaderId=5, fetcherId=0] Shutdown completed (kafka.server.ReplicaFetcherThread)
[2022-05-15 18:37:51,538] INFO [ReplicaFetcherManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-3) (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:51,539] INFO [ReplicaAlterLogDirsManager on broker 1] Removed fetcher for partitions Set(Sensor-4, Sensor-2, Sensor-3) (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:51,543] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs/Sensor-5.d1edfb500a1b42fdb60e2e6692a1918f-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:37:51,547] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs/Sensor-0.51c716e7ebca41a8b70ce6c57f1f9ff0-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:37:51,549] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-5/Sensor-2.43a3f786272f4450b3a9b2ba0f1799e5-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:37:51,550] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs/Sensor-1.96060b3895b042228087fd9313f21fd9-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:37:51,552] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-2/Sensor-4.7c44cabdc44345c8b8417212b17bcdf8-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:37:51,552] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-5/Sensor-0.b6251a6988ab411287e067964bb467e7-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:37:51,553] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-3/Sensor-4.ec0db172caa541009d50d3117d95e6d8-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:37:51,556] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-5/Sensor-1.7b7caf9e39954aa4a5f6d64f52f20e70-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:37:51,560] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-3/Sensor-5.c5f910bb92e54a59b18f5098ffcc765b-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:37:51,561] INFO Log for partition Sensor-5 is renamed to /tmp/kafka-logs-2/Sensor-5.02b7746fddf243ad8a09a48a715e78bf-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:37:51,562] INFO Log for partition Sensor-4 is renamed to /tmp/kafka-logs-1/Sensor-4.e6f1e410e8264e60a94825092bf339d7-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:37:51,562] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-4/Sensor-2.97e878c22f014ad089d0ec8d50cb1efd-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:37:51,564] INFO Log for partition Sensor-0 is renamed to /tmp/kafka-logs-3/Sensor-0.965d8fb48d974d25abeeedeb24b4124b-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:37:51,564] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-2/Sensor-3.9e7d284a42744ba6acf7f4aebeddc996-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:37:51,567] INFO Log for partition Sensor-2 is renamed to /tmp/kafka-logs-1/Sensor-2.33c265316b0c400e91582f63fb886bdf-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:37:51,567] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-4/Sensor-3.5c8e34c8c960476797e53d3ee23bb68b-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:37:51,570] INFO Log for partition Sensor-1 is renamed to /tmp/kafka-logs-4/Sensor-1.a8242f2c43324bdbba255004502bf781-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:37:51,571] INFO Log for partition Sensor-3 is renamed to /tmp/kafka-logs-1/Sensor-3.50c5be8c8aa044a8bcfbee65adc31105-delete and is scheduled for deletion (kafka.log.LogManager)
[2022-05-15 18:37:54,834] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:37:54,834] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:37:54,835] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:37:54,835] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:37:54,835] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:37:54,835] INFO Terminating process due to signal SIGTERM (org.apache.kafka.common.utils.LoggingSignalHandler)
[2022-05-15 18:37:54,836] INFO [KafkaServer id=3] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:37:54,836] INFO [KafkaServer id=4] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:37:54,837] INFO [KafkaServer id=1] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:37:54,838] INFO [KafkaServer id=4] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:37:54,838] INFO [KafkaServer id=3] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:37:54,838] INFO [KafkaServer id=2] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:37:54,838] INFO [KafkaServer id=0] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:37:54,838] INFO [KafkaServer id=1] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:37:54,838] INFO [KafkaServer id=0] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:37:54,838] INFO [KafkaServer id=2] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:37:54,841] INFO [KafkaServer id=5] shutting down (kafka.server.KafkaServer)
[2022-05-15 18:37:54,843] INFO [KafkaServer id=5] Starting controlled shutdown (kafka.server.KafkaServer)
[2022-05-15 18:37:54,858] INFO [KafkaServer id=1] Controlled shutdown request returned successfully after 12ms (kafka.server.KafkaServer)
[2022-05-15 18:37:54,859] INFO [KafkaServer id=4] Controlled shutdown request returned successfully after 14ms (kafka.server.KafkaServer)
[2022-05-15 18:37:54,860] INFO [KafkaServer id=2] Controlled shutdown request returned successfully after 12ms (kafka.server.KafkaServer)
[2022-05-15 18:37:54,861] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:37:54,861] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:37:54,862] INFO [KafkaServer id=0] Controlled shutdown request returned successfully after 15ms (kafka.server.KafkaServer)
[2022-05-15 18:37:54,862] INFO [KafkaServer id=5] Controlled shutdown request returned successfully after 12ms (kafka.server.KafkaServer)
[2022-05-15 18:37:54,862] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:37:54,861] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:37:54,862] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:37:54,863] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:37:54,863] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:37:54,863] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:37:54,863] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:37:54,863] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:37:54,864] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:37:54,865] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:37:54,865] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:37:54,865] INFO [KafkaServer id=3] Controlled shutdown request returned successfully after 13ms (kafka.server.KafkaServer)
[2022-05-15 18:37:54,865] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:37:54,865] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:37:54,865] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:37:54,865] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:37:54,866] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:37:54,867] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:37:54,867] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:37:54,869] INFO [/config/changes-event-process-thread]: Shutting down (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:37:54,870] INFO [/config/changes-event-process-thread]: Shutdown completed (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:37:54,870] INFO [/config/changes-event-process-thread]: Stopped (kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread)
[2022-05-15 18:37:54,872] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopping socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:37:54,880] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:37:54,882] INFO [data-plane Kafka Request Handler on Broker 2], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:37:54,884] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:37:54,884] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:37:54,884] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:37:54,884] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:37:54,885] INFO [data-plane Kafka Request Handler on Broker 0], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:37:54,885] INFO [data-plane Kafka Request Handler on Broker 1], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:37:54,886] INFO [data-plane Kafka Request Handler on Broker 4], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:37:54,886] INFO [data-plane Kafka Request Handler on Broker 5], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:37:54,887] INFO [data-plane Kafka Request Handler on Broker 2], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:37:54,889] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Stopped socket server request processors (kafka.network.SocketServer)
[2022-05-15 18:37:54,890] INFO [data-plane Kafka Request Handler on Broker 4], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:37:54,891] INFO [data-plane Kafka Request Handler on Broker 0], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:37:54,891] INFO [data-plane Kafka Request Handler on Broker 3], shutting down (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:37:54,892] INFO [data-plane Kafka Request Handler on Broker 5], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:37:54,894] INFO [ExpirationReaper-2-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:54,894] INFO [data-plane Kafka Request Handler on Broker 1], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:37:54,895] INFO [ExpirationReaper-4-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:54,896] INFO [data-plane Kafka Request Handler on Broker 3], shut down completely (kafka.server.KafkaRequestHandlerPool)
[2022-05-15 18:37:54,896] INFO [ExpirationReaper-0-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:54,899] INFO [ExpirationReaper-1-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:54,899] INFO [ExpirationReaper-3-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:54,900] INFO [ExpirationReaper-5-AlterAcls]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:54,919] INFO [ExpirationReaper-0-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:54,920] INFO [ExpirationReaper-0-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:54,921] INFO [KafkaApi-0] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:37:54,921] INFO [ExpirationReaper-0-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:54,980] INFO [ExpirationReaper-1-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:54,980] INFO [ExpirationReaper-1-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:54,981] INFO [KafkaApi-1] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:37:54,982] INFO [ExpirationReaper-1-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:54,985] INFO [ExpirationReaper-5-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:54,985] INFO [ExpirationReaper-5-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:54,986] INFO [KafkaApi-5] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:37:54,987] INFO [ExpirationReaper-5-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:54,999] INFO [ExpirationReaper-2-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:54,999] INFO [ExpirationReaper-2-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,000] INFO [KafkaApi-2] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:37:55,002] INFO [ExpirationReaper-2-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,042] INFO [ExpirationReaper-3-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,042] INFO [ExpirationReaper-3-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,042] INFO [ExpirationReaper-4-AlterAcls]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,043] INFO [ExpirationReaper-4-AlterAcls]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,044] INFO [KafkaApi-3] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:37:55,044] INFO [KafkaApi-4] Shutdown complete. (kafka.server.KafkaApis)
[2022-05-15 18:37:55,046] INFO [ExpirationReaper-3-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,046] INFO [ExpirationReaper-4-topic]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,064] INFO [ExpirationReaper-0-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,064] INFO [ExpirationReaper-0-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,066] INFO [TransactionCoordinator id=0] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:37:55,067] INFO [Transaction State Manager 0]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:37:55,067] INFO [Transaction Marker Channel Manager 0]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:37:55,068] INFO [Transaction Marker Channel Manager 0]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:37:55,068] INFO [Transaction Marker Channel Manager 0]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:37:55,069] INFO [TransactionCoordinator id=0] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:37:55,069] INFO [GroupCoordinator 0]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:37:55,070] INFO [ExpirationReaper-0-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,090] INFO [ExpirationReaper-1-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,090] INFO [ExpirationReaper-1-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,095] INFO [TransactionCoordinator id=1] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:37:55,095] INFO [ExpirationReaper-2-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,095] INFO [ExpirationReaper-2-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,096] INFO [Transaction State Manager 1]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:37:55,096] INFO [Transaction Marker Channel Manager 1]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:37:55,096] INFO [Transaction Marker Channel Manager 1]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:37:55,096] INFO [Transaction Marker Channel Manager 1]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:37:55,098] INFO [TransactionCoordinator id=1] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:37:55,100] INFO [GroupCoordinator 1]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:37:55,100] INFO [TransactionCoordinator id=2] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:37:55,100] INFO [ExpirationReaper-5-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,100] INFO [ExpirationReaper-5-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,101] INFO [ExpirationReaper-1-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,102] INFO [Transaction State Manager 2]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:37:55,102] INFO [Transaction Marker Channel Manager 2]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:37:55,102] INFO [Transaction Marker Channel Manager 2]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:37:55,102] INFO [Transaction Marker Channel Manager 2]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:37:55,103] INFO [TransactionCoordinator id=2] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:37:55,104] INFO [TransactionCoordinator id=5] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:37:55,104] INFO [GroupCoordinator 2]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:37:55,105] INFO [ExpirationReaper-2-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,105] INFO [Transaction State Manager 5]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:37:55,105] INFO [Transaction Marker Channel Manager 5]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:37:55,106] INFO [Transaction Marker Channel Manager 5]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:37:55,106] INFO [Transaction Marker Channel Manager 5]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:37:55,107] INFO [TransactionCoordinator id=5] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:37:55,108] INFO [GroupCoordinator 5]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:37:55,108] INFO [ExpirationReaper-5-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,115] INFO [ExpirationReaper-2-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,115] INFO [ExpirationReaper-2-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,116] INFO [ExpirationReaper-2-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,116] INFO [ExpirationReaper-5-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,116] INFO [ExpirationReaper-5-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,116] INFO [ExpirationReaper-5-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,134] INFO [ExpirationReaper-3-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,134] INFO [ExpirationReaper-3-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,136] INFO [TransactionCoordinator id=3] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:37:55,138] INFO [Transaction State Manager 3]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:37:55,138] INFO [Transaction Marker Channel Manager 3]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:37:55,139] INFO [Transaction Marker Channel Manager 3]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:37:55,139] INFO [Transaction Marker Channel Manager 3]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:37:55,140] INFO [TransactionCoordinator id=3] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:37:55,141] INFO [GroupCoordinator 3]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:37:55,142] INFO [ExpirationReaper-3-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,146] INFO [ExpirationReaper-4-topic]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,146] INFO [ExpirationReaper-4-topic]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,148] INFO [TransactionCoordinator id=4] Shutting down. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:37:55,149] INFO [Transaction State Manager 4]: Shutdown complete (kafka.coordinator.transaction.TransactionStateManager)
[2022-05-15 18:37:55,150] INFO [Transaction Marker Channel Manager 4]: Shutting down (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:37:55,150] INFO [Transaction Marker Channel Manager 4]: Shutdown completed (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:37:55,150] INFO [Transaction Marker Channel Manager 4]: Stopped (kafka.coordinator.transaction.TransactionMarkerChannelManager)
[2022-05-15 18:37:55,151] INFO [TransactionCoordinator id=4] Shutdown complete. (kafka.coordinator.transaction.TransactionCoordinator)
[2022-05-15 18:37:55,152] INFO [GroupCoordinator 4]: Shutting down. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:37:55,153] INFO [ExpirationReaper-4-Heartbeat]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,155] INFO [ExpirationReaper-4-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,155] INFO [ExpirationReaper-4-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,155] INFO [ExpirationReaper-4-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,156] INFO [ExpirationReaper-4-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,156] INFO [ExpirationReaper-4-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,157] INFO [GroupCoordinator 4]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:37:55,158] INFO [ReplicaManager broker=4] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:37:55,159] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:37:55,159] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:37:55,159] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:37:55,160] INFO [ReplicaFetcherManager on broker 4] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:55,162] INFO [ReplicaFetcherManager on broker 4] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:55,162] INFO [ReplicaAlterLogDirsManager on broker 4] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:55,163] INFO [ReplicaAlterLogDirsManager on broker 4] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:55,163] INFO [ExpirationReaper-4-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,207] INFO [ExpirationReaper-0-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,207] INFO [ExpirationReaper-0-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,208] INFO [ExpirationReaper-0-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,248] INFO [ExpirationReaper-4-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,248] INFO [ExpirationReaper-4-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,248] INFO [ExpirationReaper-4-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,290] INFO [ExpirationReaper-1-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,290] INFO [ExpirationReaper-1-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,291] INFO [ExpirationReaper-1-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,295] INFO [ExpirationReaper-1-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,295] INFO [ExpirationReaper-1-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,296] INFO [GroupCoordinator 1]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:37:55,297] INFO [ReplicaManager broker=1] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:37:55,298] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:37:55,298] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:37:55,298] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:37:55,299] INFO [ReplicaFetcherManager on broker 1] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:55,300] INFO [ExpirationReaper-2-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,300] INFO [ExpirationReaper-2-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,301] INFO [ReplicaFetcherManager on broker 1] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:55,301] INFO [GroupCoordinator 2]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:37:55,302] INFO [ReplicaManager broker=2] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:37:55,302] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:37:55,302] INFO [ReplicaAlterLogDirsManager on broker 1] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:55,302] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:37:55,302] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:37:55,303] INFO [ReplicaAlterLogDirsManager on broker 1] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:55,303] INFO [ExpirationReaper-1-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,303] INFO [ReplicaFetcherManager on broker 2] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:55,304] INFO [ExpirationReaper-5-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,304] INFO [ExpirationReaper-5-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,305] INFO [GroupCoordinator 5]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:37:55,305] INFO [ReplicaFetcherManager on broker 2] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:55,305] INFO [ReplicaManager broker=5] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:37:55,305] INFO [ReplicaAlterLogDirsManager on broker 2] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:55,306] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:37:55,306] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:37:55,306] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:37:55,306] INFO [ReplicaAlterLogDirsManager on broker 2] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:55,306] INFO [ExpirationReaper-2-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,307] INFO [ReplicaFetcherManager on broker 5] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:55,309] INFO [ReplicaFetcherManager on broker 5] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:55,309] INFO [ReplicaAlterLogDirsManager on broker 5] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:55,310] INFO [ReplicaAlterLogDirsManager on broker 5] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:55,310] INFO [ExpirationReaper-5-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,337] INFO [ExpirationReaper-3-Heartbeat]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,337] INFO [ExpirationReaper-3-Heartbeat]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,337] INFO [ExpirationReaper-3-Rebalance]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,388] INFO [ExpirationReaper-1-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,388] INFO [ExpirationReaper-1-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,389] INFO [ExpirationReaper-1-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,403] INFO [ExpirationReaper-4-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,403] INFO [ExpirationReaper-4-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,404] INFO [ExpirationReaper-4-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,408] INFO [ExpirationReaper-0-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,408] INFO [ExpirationReaper-0-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,409] INFO [GroupCoordinator 0]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:37:55,410] INFO [ReplicaManager broker=0] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:37:55,410] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:37:55,410] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:37:55,410] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:37:55,412] INFO [ReplicaFetcherManager on broker 0] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:55,413] INFO [ReplicaFetcherManager on broker 0] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:55,414] INFO [ReplicaAlterLogDirsManager on broker 0] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:55,414] INFO [ReplicaAlterLogDirsManager on broker 0] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:55,414] INFO [ExpirationReaper-0-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,415] INFO [ExpirationReaper-4-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,416] INFO [ExpirationReaper-4-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,416] INFO [ExpirationReaper-4-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,448] INFO [ExpirationReaper-2-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,448] INFO [ExpirationReaper-5-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,448] INFO [ExpirationReaper-2-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,448] INFO [ExpirationReaper-5-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,448] INFO [ExpirationReaper-2-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,449] INFO [ExpirationReaper-5-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,524] INFO [ExpirationReaper-0-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,524] INFO [ExpirationReaper-0-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,525] INFO [ExpirationReaper-0-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,534] INFO [ExpirationReaper-2-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,534] INFO [ExpirationReaper-2-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,534] INFO [ExpirationReaper-2-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,534] INFO [ExpirationReaper-3-Rebalance]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,534] INFO [ExpirationReaper-3-Rebalance]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,535] INFO [GroupCoordinator 3]: Shutdown complete. (kafka.coordinator.group.GroupCoordinator)
[2022-05-15 18:37:55,537] INFO [ReplicaManager broker=3] Shutting down (kafka.server.ReplicaManager)
[2022-05-15 18:37:55,537] INFO [LogDirFailureHandler]: Shutting down (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:37:55,537] INFO [LogDirFailureHandler]: Shutdown completed (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:37:55,537] INFO [LogDirFailureHandler]: Stopped (kafka.server.ReplicaManager$LogDirFailureHandler)
[2022-05-15 18:37:55,538] INFO [ReplicaFetcherManager on broker 3] shutting down (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:55,539] INFO [ExpirationReaper-5-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,539] INFO [ExpirationReaper-5-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,540] INFO [ExpirationReaper-5-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,540] INFO [ReplicaFetcherManager on broker 3] shutdown completed (kafka.server.ReplicaFetcherManager)
[2022-05-15 18:37:55,541] INFO [ReplicaAlterLogDirsManager on broker 3] shutting down (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:55,541] INFO [ReplicaAlterLogDirsManager on broker 3] shutdown completed (kafka.server.ReplicaAlterLogDirsManager)
[2022-05-15 18:37:55,541] INFO [ExpirationReaper-3-Fetch]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,544] INFO [ExpirationReaper-5-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,544] INFO [ExpirationReaper-5-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,544] INFO [ExpirationReaper-5-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,576] INFO [ExpirationReaper-1-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,576] INFO [ExpirationReaper-1-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,577] INFO [ExpirationReaper-1-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,612] INFO [ExpirationReaper-4-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,612] INFO [ExpirationReaper-4-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,617] INFO [ReplicaManager broker=4] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:37:55,617] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,617] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,618] INFO [BrokerToControllerChannelManager broker=4 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,620] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:37:55,620] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,620] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,620] INFO [BrokerToControllerChannelManager broker=4 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,621] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:37:55,622] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:37:55,640] INFO [ExpirationReaper-0-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,640] INFO [ExpirationReaper-0-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,640] INFO [ExpirationReaper-0-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,643] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:37:55,648] INFO [ExpirationReaper-3-Fetch]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,648] INFO [ExpirationReaper-3-Fetch]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,648] INFO [ExpirationReaper-3-Produce]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,650] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:37:55,651] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:37:55,651] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:37:55,651] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:37:55,682] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,682] INFO [Controller id=0, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,682] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,682] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,682] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,684] INFO [Controller id=0, targetBrokerId=2] Node 2 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,684] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,684] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,684] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,684] INFO [Controller id=0, targetBrokerId=5] Node 5 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,685] WARN [Controller id=0, targetBrokerId=2] Connection to node 2 (joao/127.0.1.1:9094) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,685] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,685] WARN [Controller id=0, targetBrokerId=5] Connection to node 5 (joao/127.0.1.1:9097) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,685] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,685] WARN [Controller id=0, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,686] INFO [Controller id=0, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,686] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,686] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,686] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,686] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,734] INFO [ExpirationReaper-2-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,734] INFO [ExpirationReaper-5-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,734] INFO [ExpirationReaper-5-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,734] INFO [ExpirationReaper-2-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,734] INFO [ExpirationReaper-2-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,737] INFO [ExpirationReaper-2-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,737] INFO [ExpirationReaper-2-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,738] INFO [ReplicaManager broker=5] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:37:55,739] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,739] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,739] INFO [BrokerToControllerChannelManager broker=5 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,741] INFO [ReplicaManager broker=2] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:37:55,741] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,741] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,741] INFO [BrokerToControllerChannelManager broker=2 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,742] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:37:55,742] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,743] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,743] INFO [BrokerToControllerChannelManager broker=5 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,743] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:37:55,744] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:37:55,744] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,744] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:37:55,744] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,744] INFO [BrokerToControllerChannelManager broker=2 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,745] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:37:55,746] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:37:55,756] INFO Session: 0x100000b00ad0052 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:37:55,756] INFO EventThread shut down for session: 0x100000b00ad0052 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:37:55,757] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:37:55,758] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:55,765] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:37:55,767] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:37:55,770] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:37:55,770] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:37:55,770] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:37:55,771] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:37:55,771] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:37:55,771] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:37:55,771] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:37:55,772] INFO [ExpirationReaper-3-Produce]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,772] INFO [ExpirationReaper-3-Produce]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,772] INFO [ExpirationReaper-1-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,772] INFO [ExpirationReaper-1-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,772] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:37:55,772] INFO [ExpirationReaper-3-DeleteRecords]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,773] INFO [ExpirationReaper-1-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,776] INFO [Controller id=0, targetBrokerId=2] Client requested connection close from node 2 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,777] INFO [Controller id=0, targetBrokerId=5] Client requested connection close from node 5 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,786] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,786] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,786] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,786] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,786] WARN [Controller id=0, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,786] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,787] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,787] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,787] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,840] INFO [ExpirationReaper-0-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,840] INFO [ExpirationReaper-0-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,841] INFO [ExpirationReaper-0-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,856] INFO [ExpirationReaper-0-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,856] INFO [ExpirationReaper-0-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,860] INFO [ReplicaManager broker=0] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:37:55,860] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,861] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,861] INFO [BrokerToControllerChannelManager broker=0 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,863] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:37:55,863] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,864] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,864] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,865] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:37:55,865] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:37:55,874] INFO Session: 0x100000b00ad0053 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:37:55,874] INFO EventThread shut down for session: 0x100000b00ad0053 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:37:55,875] INFO Session: 0x100000b00ad0050 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:37:55,875] INFO EventThread shut down for session: 0x100000b00ad0050 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:37:55,876] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:37:55,877] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:55,877] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:37:55,878] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:55,885] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:37:55,887] INFO [Controller id=0, targetBrokerId=0] Node 0 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,887] INFO [Controller id=0, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,888] WARN [Controller id=0, targetBrokerId=0] Connection to node 0 (joao/127.0.1.1:9092) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,887] INFO [Controller id=0, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,888] WARN [Controller id=0, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,888] WARN [Controller id=0, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,888] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,888] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,888] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,889] INFO [Controller id=0, targetBrokerId=0] Client requested connection close from node 0 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,890] INFO [Controller id=0, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,892] INFO [Controller id=0, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,894] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:37:55,894] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:37:55,894] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:37:55,894] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:37:55,931] INFO [ExpirationReaper-1-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,931] INFO [ExpirationReaper-1-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,936] INFO [ReplicaManager broker=1] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:37:55,936] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,937] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,937] INFO [BrokerToControllerChannelManager broker=1 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,938] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:37:55,938] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,939] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,939] INFO [BrokerToControllerChannelManager broker=1 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:55,939] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:37:55,940] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:37:55,959] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:37:55,960] INFO [ExpirationReaper-3-DeleteRecords]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,960] INFO [ExpirationReaper-3-DeleteRecords]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,960] INFO [ExpirationReaper-3-ElectLeader]: Shutting down (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:55,966] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:37:55,966] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:37:55,966] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:37:55,967] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:37:55,974] INFO [Controller id=3, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,974] INFO [Controller id=3, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,976] WARN [Controller id=3, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,976] WARN [Controller id=3, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,977] INFO [Controller id=3, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,977] INFO [Controller id=3, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:55,997] INFO Session: 0x100000b00ad004e closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:37:55,997] INFO EventThread shut down for session: 0x100000b00ad004e (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:37:56,001] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:37:56,002] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,070] INFO Session: 0x100000b00ad004f closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:37:56,070] INFO EventThread shut down for session: 0x100000b00ad004f (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:37:56,071] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:37:56,072] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,078] INFO [Controller id=3, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:56,078] INFO [Controller id=3, targetBrokerId=1] Node 1 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:56,078] WARN [Controller id=3, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:56,078] WARN [Controller id=3, targetBrokerId=1] Connection to node 1 (joao/127.0.1.1:9093) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:56,079] INFO [Controller id=3, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:56,079] INFO [Controller id=3, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:56,099] INFO [Controller id=3, targetBrokerId=1] Client requested connection close from node 1 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:56,160] INFO [ExpirationReaper-3-ElectLeader]: Stopped (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:56,160] INFO [ExpirationReaper-3-ElectLeader]: Shutdown completed (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
[2022-05-15 18:37:56,164] INFO [ReplicaManager broker=3] Shut down completely (kafka.server.ReplicaManager)
[2022-05-15 18:37:56,164] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:56,164] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:56,164] INFO [BrokerToControllerChannelManager broker=3 name=alterIsr]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:56,166] INFO Broker to controller channel manager for alterIsr shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:37:56,166] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutting down (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:56,167] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Stopped (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:56,167] INFO [BrokerToControllerChannelManager broker=3 name=forwarding]: Shutdown completed (kafka.server.BrokerToControllerRequestThread)
[2022-05-15 18:37:56,167] INFO Broker to controller channel manager for forwarding shutdown (kafka.server.BrokerToControllerChannelManagerImpl)
[2022-05-15 18:37:56,168] INFO Shutting down. (kafka.log.LogManager)
[2022-05-15 18:37:56,180] INFO [Controller id=3, targetBrokerId=3] Node 3 disconnected. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:56,180] WARN [Controller id=3, targetBrokerId=3] Connection to node 3 (joao/127.0.1.1:9095) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:56,180] INFO [Controller id=3, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:56,184] INFO [ProducerStateManager partition=__consumer_offsets-38] Wrote producer snapshot at offset 74918 with 0 producer ids in 2 ms. (kafka.log.ProducerStateManager)
[2022-05-15 18:37:56,194] INFO Shutdown complete. (kafka.log.LogManager)
[2022-05-15 18:37:56,199] INFO [Controller id=3, targetBrokerId=3] Client requested connection close from node 3 (org.apache.kafka.clients.NetworkClient)
[2022-05-15 18:37:56,202] INFO [feature-zk-node-event-process-thread]: Shutting down (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:37:56,202] INFO [feature-zk-node-event-process-thread]: Shutdown completed (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:37:56,202] INFO [feature-zk-node-event-process-thread]: Stopped (kafka.server.FinalizedFeatureChangeListener$ChangeNotificationProcessorThread)
[2022-05-15 18:37:56,203] INFO [ZooKeeperClient Kafka server] Closing. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:37:56,206] WARN An exception was thrown while closing send thread for session 0x100000b00ad0051. (org.apache.zookeeper.ClientCnxn)
EndOfStreamException: Unable to read additional data from server sessionid 0x100000b00ad0051, likely server has closed socket
	at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1290)
[2022-05-15 18:37:56,308] INFO Session: 0x100000b00ad0051 closed (org.apache.zookeeper.ZooKeeper)
[2022-05-15 18:37:56,308] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,308] INFO EventThread shut down for session: 0x100000b00ad0051 (org.apache.zookeeper.ClientCnxn)
[2022-05-15 18:37:56,308] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,308] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,310] INFO [ZooKeeperClient Kafka server] Closed. (kafka.zookeeper.ZooKeeperClient)
[2022-05-15 18:37:56,311] INFO [ThrottledChannelReaper-Fetch]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,325] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,325] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,325] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,326] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,326] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,327] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,330] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,330] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,331] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,332] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,332] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,333] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:37:56,334] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,334] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,334] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,336] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,336] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,336] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,338] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,338] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,338] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,355] INFO [SocketServer listenerType=ZK_BROKER, nodeId=0] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:37:56,355] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:37:56,355] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:37:56,356] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:37:56,357] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:37:56,357] INFO App info kafka.server for 0 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:37:56,357] INFO [KafkaServer id=0] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:37:56,361] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,361] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:56,361] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,275] INFO [ThrottledChannelReaper-Fetch]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,275] INFO [ThrottledChannelReaper-Fetch]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,275] INFO [ThrottledChannelReaper-Produce]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,308] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,308] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,309] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,309] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,309] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,310] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,311] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,311] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,313] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:37:57,330] INFO [SocketServer listenerType=ZK_BROKER, nodeId=5] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:37:57,331] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:37:57,331] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:37:57,331] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:37:57,332] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:37:57,333] INFO App info kafka.server for 5 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:37:57,333] INFO [KafkaServer id=5] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:37:57,336] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,336] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,336] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,336] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,336] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,337] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,338] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,338] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,339] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,359] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,359] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,359] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,366] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,366] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:57,366] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:58,275] INFO [ThrottledChannelReaper-Produce]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:58,275] INFO [ThrottledChannelReaper-Produce]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:58,275] INFO [ThrottledChannelReaper-Request]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:58,283] INFO [ThrottledChannelReaper-Request]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:58,283] INFO [ThrottledChannelReaper-Request]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:58,284] INFO [ThrottledChannelReaper-ControllerMutation]: Shutting down (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:58,336] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:58,336] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:58,337] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:58,337] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:58,338] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:37:58,339] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:37:58,366] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:58,366] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:58,367] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:37:58,377] INFO [SocketServer listenerType=ZK_BROKER, nodeId=2] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:37:58,377] INFO [SocketServer listenerType=ZK_BROKER, nodeId=1] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:37:58,378] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:37:58,378] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:37:58,378] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:37:58,378] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:37:58,378] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:37:58,378] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:37:58,381] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:37:58,381] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:37:58,382] INFO App info kafka.server for 1 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:37:58,382] INFO App info kafka.server for 2 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:37:58,383] INFO [KafkaServer id=1] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:37:58,383] INFO [KafkaServer id=2] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:37:58,392] INFO [SocketServer listenerType=ZK_BROKER, nodeId=4] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:37:58,393] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:37:58,393] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:37:58,393] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:37:58,394] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:37:58,394] INFO App info kafka.server for 4 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:37:58,395] INFO [KafkaServer id=4] shut down completed (kafka.server.KafkaServer)
[2022-05-15 18:37:59,280] INFO [ThrottledChannelReaper-ControllerMutation]: Stopped (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:59,280] INFO [ThrottledChannelReaper-ControllerMutation]: Shutdown completed (kafka.server.ClientQuotaManager$ThrottledChannelReaper)
[2022-05-15 18:37:59,281] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutting down socket server (kafka.network.SocketServer)
[2022-05-15 18:37:59,301] INFO [SocketServer listenerType=ZK_BROKER, nodeId=3] Shutdown completed (kafka.network.SocketServer)
[2022-05-15 18:37:59,302] INFO Metrics scheduler closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:37:59,302] INFO Closing reporter org.apache.kafka.common.metrics.JmxReporter (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:37:59,302] INFO Metrics reporters closed (org.apache.kafka.common.metrics.Metrics)
[2022-05-15 18:37:59,304] INFO Broker and topic stats closed (kafka.server.BrokerTopicStats)
[2022-05-15 18:37:59,304] INFO App info kafka.server for 3 unregistered (org.apache.kafka.common.utils.AppInfoParser)
[2022-05-15 18:37:59,305] INFO [KafkaServer id=3] shut down completed (kafka.server.KafkaServer)
